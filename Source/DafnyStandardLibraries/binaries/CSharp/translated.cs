// Dafny program the_program compiled into C#
// To recompile, you will need the libraries
//     System.Runtime.Numerics.dll System.Collections.Immutable.dll
// but the 'dotnet' tool in net6.0 should pick those up automatically.
// Optionally, you may want to include compiler switches like
//     /debug /nowarn:162,164,168,183,219,436,1717,1718

using System;
using System.Numerics;
using System.Collections;
[assembly: DafnyAssembly.DafnySourceAttribute(@"// dafny 4.3.0.0
// Command-line arguments: translate cs src/CSharp/dfyconfig.toml --output binaries/CSharp/translated
// the_program


module Std {

  module Base64 {
    opaque predicate IsBase64Char(c: char)
      decreases c
    {
      c == '+' || c == '/' || '0' <= c <= '9' || 'A' <= c <= 'Z' || 'a' <= c <= 'z'
    }

    lemma Base64CharIs7Bit(c: char)
      requires IsBase64Char(c)
      ensures c < 128 as char
      decreases c
    {
      reveal IsBase64Char();
    }

    opaque predicate IsUnpaddedBase64String(s: string)
      decreases s
    {
      |s| % 4 == 0 &&
      forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: 
        k in s ==>
          IsBase64Char(k)
    }

    opaque function IndexToChar(i: index): (c: char)
      ensures IsBase64Char(c)
      decreases i
    {
      reveal IsBase64Char();
      if i == 63 then
        '/'
      else if i == 62 then
        '+'
      else if 52 <= i <= 61 then
        (i - 4) as char
      else if 26 <= i <= 51 then
        i as char + 71 as char
      else
        i as char + 65 as char
    }

    lemma IndexToCharIsBase64(i: index)
      ensures IsBase64Char(IndexToChar(i))
      decreases i
    {
      reveal IndexToChar();
      reveal IsBase64Char();
    }

    opaque function CharToIndex(c: char): (i: index)
      requires IsBase64Char(c)
      decreases c
    {
      reveal IsBase64Char();
      reveal IndexToChar();
      if c == '/' then
        63
      else if c == '+' then
        62
      else if '0' <= c <= '9' then
        (c + 4 as char) as index
      else if 'a' <= c <= 'z' then
        (c - 71 as char) as index
      else
        (c - 65 as char) as index
    }

    lemma {:rlimit 2000} {:vcs_split_on_every_assert} CharToIndexToChar(c: char)
      requires IsBase64Char(c)
      ensures IndexToChar(CharToIndex(c)) == c
      decreases c
    {
      Base64CharIs7Bit(c);
      reveal IsBase64Char();
      reveal IndexToChar();
      reveal CharToIndex();
      if c == '/' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if c == '+' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if '0' <= c <= '9' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if 'a' <= c < 'm' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else if 'm' <= c <= 'z' {
        assert IndexToChar(CharToIndex(c)) == c;
      } else {
        assert IndexToChar(CharToIndex(c)) == c;
      }
    }

    lemma {:vcs_split_on_every_assert} IndexToCharToIndex(i: index)
      ensures (IndexToCharIsBase64(i); CharToIndex(IndexToChar(i)) == i)
      decreases i
    {
      reveal IsBase64Char();
      reveal IndexToChar();
      reveal CharToIndex();
      IndexToCharIsBase64(i);
      if i == 63 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else if i == 62 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else if 52 <= i <= 61 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else if 26 <= i <= 51 {
        assert CharToIndex(IndexToChar(i)) == i;
      } else {
        assert CharToIndex(IndexToChar(i)) == i;
      }
    }

    lemma IndexToCharToIndexAuto()
      ensures forall x: bv6 {:trigger IndexToChar(x)} :: (IndexToCharIsBase64(x); CharToIndex(IndexToChar(x)) == x)
    {
      forall x: index | true
        ensures (IndexToCharIsBase64(x); CharToIndex(IndexToChar(x)) == x)
      {
        IndexToCharToIndex(x);
      }
    }

    lemma CharToIndexToCharAuto()
      ensures forall c: char {:trigger CharToIndex(c)} {:trigger IsBase64Char(c)} | IsBase64Char(c) :: IndexToChar(CharToIndex(c)) == c
    {
      forall c: char | IsBase64Char(c)
        ensures IndexToChar(CharToIndex(c)) == c
      {
        CharToIndexToChar(c);
      }
    }

    opaque function BV24ToSeq(x: bv24): (ret: seq<bv8>)
      ensures |ret| == 3
      decreases x
    {
      var b0: bv8 := ((x >> 16 as bv5) & 255) as bv8;
      var b1: bv8 := ((x >> 8 as bv5) & 255) as bv8;
      var b2: bv8 := (x & 255) as bv8;
      [b0, b1, b2]
    }

    opaque function SeqToBV24(x: seq<bv8>): (ret: bv24)
      requires |x| == 3
      decreases x
    {
      (x[0] as bv24 << 16 as bv5) | (x[1] as bv24 << 8 as bv5) | x[2] as bv24
    }

    lemma BV24ToSeqToBV24(x: bv24)
      ensures SeqToBV24(BV24ToSeq(x)) == x
      decreases x
    {
      reveal BV24ToSeq();
      reveal SeqToBV24();
    }

    lemma SeqToBV24ToSeq(s: seq<bv8>)
      requires |s| == 3
      ensures BV24ToSeq(SeqToBV24(s)) == s
      decreases s
    {
      reveal SeqToBV24();
      reveal BV24ToSeq();
    }

    opaque function BV24ToIndexSeq(x: bv24): (ret: seq<index>)
      ensures |ret| == 4
      decreases x
    {
      var b0: index := ((x >> 18 as bv5) & 63) as index;
      var b1: index := ((x >> 12 as bv5) & 63) as index;
      var b2: index := ((x >> 6 as bv5) & 63) as index;
      var b3: index := (x & 63) as index;
      [b0, b1, b2, b3]
    }

    opaque function IndexSeqToBV24(x: seq<index>): (ret: bv24)
      requires |x| == 4
      decreases x
    {
      (x[0] as bv24 << 18 as bv5) | (x[1] as bv24 << 12 as bv5) | (x[2] as bv24 << 6 as bv5) | x[3] as bv24
    }

    lemma BV24ToIndexSeqToBV24(x: bv24)
      ensures IndexSeqToBV24(BV24ToIndexSeq(x)) == x
      decreases x
    {
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    lemma IndexSeqToBV24ToIndexSeq(s: seq<index>)
      requires |s| == 4
      ensures BV24ToIndexSeq(IndexSeqToBV24(s)) == s
      decreases s
    {
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    opaque function DecodeBlock(s: seq<index>): (ret: seq<bv8>)
      requires |s| == 4
      ensures |ret| == 3
      decreases s
    {
      BV24ToSeq(IndexSeqToBV24(s))
    }

    opaque function EncodeBlock(s: seq<bv8>): (ret: seq<index>)
      requires |s| == 3
      ensures |ret| == 4
      decreases s
    {
      BV24ToIndexSeq(SeqToBV24(s))
    }

    lemma EncodeDecodeBlock(s: seq<bv8>)
      requires |s| == 3
      ensures DecodeBlock(EncodeBlock(s)) == s
      decreases s
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      ghost var b := SeqToBV24(s);
      BV24ToIndexSeqToBV24(b);
      SeqToBV24ToSeq(s);
    }

    lemma DecodeEncodeBlock(s: seq<index>)
      requires |s| == 4
      ensures EncodeBlock(DecodeBlock(s)) == s
      decreases s
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      ghost var b := IndexSeqToBV24(s);
      BV24ToSeqToBV24(b);
      IndexSeqToBV24ToIndexSeq(s);
    }

    opaque function {:vcs_split_on_every_assert} DecodeRecursively(s: seq<index>): (b: seq<bv8>)
      requires |s| % 4 == 0
      decreases |s|
    {
      if |s| == 0 then
        []
      else
        DecodeBlock(s[..4]) + DecodeRecursively(s[4..])
    } by method {
      var resultLength := |s| / 4 * 3;
      var result := new bv8[resultLength] ((i: nat) => 0);
      var i := |s|;
      var j := resultLength;
      reveal DecodeRecursively();
      while i > 0
        invariant i % 4 == 0
        invariant 0 <= i <= |s|
        invariant i * 3 == j * 4
        invariant 0 <= j <= resultLength
        invariant result[j..] == DecodeRecursively(s[i..])
        decreases i - 0
      {
        i := i - 4;
        j := j - 3;
        var block := DecodeBlock(s[i .. i + 4]);
        result[j] := block[0];
        result[j + 1] := block[1];
        result[j + 2] := block[2];
        assert s[i..][..4] == s[i .. i + 4];
        assert s[i..][4..] == s[i + 4..];
        assert result[j .. j + 3] == block;
        calc {
          DecodeBlock(s[i .. i + 4]) + DecodeRecursively(s[i + 4..]);
          DecodeBlock(s[i..][..4]) + DecodeRecursively(s[i..][4..]);
          DecodeRecursively(s[i..]);
        }
      }
      b := result[..];
    }

    lemma /*{:_induction s}*/ DecodeRecursivelyBounds(s: seq<index>)
      requires |s| % 4 == 0
      ensures |DecodeRecursively(s)| == |s| / 4 * 3
      ensures |DecodeRecursively(s)| % 3 == 0
      ensures |DecodeRecursively(s)| == 0 ==> |s| == 0
      decreases s
    {
      reveal DecodeRecursively();
    }

    lemma /*{:_induction s}*/ DecodeRecursivelyBlock(s: seq<index>)
      requires |s| % 4 == 0
      ensures (DecodeRecursivelyBounds(s); ghost var b: seq<bv8> := DecodeRecursively(s); |b| != 0 ==> EncodeBlock(b[..3]) == s[..4])
      decreases s
    {
      DecodeRecursivelyBounds(s);
      if |s| == 0 {
      } else {
        DecodeEncodeBlock(s[..4]);
        reveal DecodeRecursively();
      }
    }

    opaque function {:vcs_split_on_every_assert} EncodeRecursively(b: seq<bv8>): (s: seq<index>)
      requires |b| % 3 == 0
      decreases b
    {
      if |b| == 0 then
        []
      else
        EncodeBlock(b[..3]) + EncodeRecursively(b[3..])
    } by method {
      var resultLength := |b| / 3 * 4;
      var result := new index[resultLength] ((i: nat) => 0);
      var i := |b|;
      var j := resultLength;
      reveal EncodeRecursively();
      while i > 0
        invariant i % 3 == 0
        invariant 0 <= i <= |b|
        invariant i * 4 == j * 3
        invariant 0 <= j <= resultLength
        invariant result[j..] == EncodeRecursively(b[i..])
        decreases i - 0
      {
        i := i - 3;
        j := j - 4;
        var block := EncodeBlock(b[i .. i + 3]);
        result[j] := block[0];
        result[j + 1] := block[1];
        result[j + 2] := block[2];
        result[j + 3] := block[3];
        assert b[i..][..3] == b[i .. i + 3];
        assert b[i..][3..] == b[i + 3..];
        assert result[j .. j + 4] == block;
        calc {
          EncodeBlock(b[i .. i + 3]) + EncodeRecursively(b[i + 3..]);
          EncodeBlock(b[i..][..3]) + EncodeRecursively(b[i..][3..]);
          EncodeRecursively(b[i..]);
        }
      }
      s := result[..];
    }

    lemma /*{:_induction b}*/ EncodeRecursivelyBounds(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures |EncodeRecursively(b)| == |b| / 3 * 4
      ensures |EncodeRecursively(b)| % 4 == 0
      ensures |EncodeRecursively(b)| == 0 ==> |b| == 0
      decreases b
    {
      reveal EncodeRecursively();
    }

    lemma /*{:_induction b}*/ EncodeRecursivelyBlock(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures (EncodeRecursivelyBounds(b); ghost var s: seq<index> := EncodeRecursively(b); |s| != 0 ==> DecodeBlock(s[..4]) == b[..3])
      decreases b
    {
      EncodeRecursivelyBounds(b);
      if |b| == 0 {
      } else {
        EncodeDecodeBlock(b[..3]);
        reveal EncodeRecursively();
      }
    }

    lemma /*{:_induction b}*/ EncodeDecodeRecursively(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures (EncodeRecursivelyBounds(b); DecodeRecursively(EncodeRecursively(b)) == b)
      decreases b
    {
      ghost var s := EncodeRecursively(b);
      EncodeRecursivelyBounds(b);
      DecodeRecursivelyBounds(s);
      if |b| == 0 {
      } else {
        calc {
          DecodeRecursively(EncodeRecursively(b));
        ==
          DecodeRecursively(s);
        ==
          {
            reveal DecodeRecursively();
          }
          DecodeBlock(s[..4]) + DecodeRecursively(s[4..]);
        ==
          {
            EncodeRecursivelyBlock(b);
          }
          b[..3] + DecodeRecursively(s[4..]);
        ==
          {
            reveal EncodeRecursively();
          }
          b[..3] + DecodeRecursively(EncodeRecursively(b[3..]));
        ==
          {
            EncodeDecodeRecursively(b[3..]);
          }
          b[..3] + b[3..];
        ==
          b;
        }
      }
    }

    lemma /*{:_induction s}*/ DecodeEncodeRecursively(s: seq<index>)
      requires |s| % 4 == 0
      ensures (DecodeRecursivelyBounds(s); EncodeRecursively(DecodeRecursively(s)) == s)
      decreases s
    {
      ghost var b := DecodeRecursively(s);
      DecodeRecursivelyBounds(s);
      EncodeRecursivelyBounds(b);
      if |s| == 0 {
      } else {
        calc {
          EncodeRecursively(DecodeRecursively(s));
        ==
          EncodeRecursively(b);
        ==
          {
            reveal EncodeRecursively();
          }
          EncodeBlock(b[..3]) + EncodeRecursively(b[3..]);
        ==
          {
            DecodeRecursivelyBlock(s);
          }
          s[..4] + EncodeRecursively(b[3..]);
        ==
          {
            reveal DecodeRecursively();
          }
          s[..4] + EncodeRecursively(DecodeRecursively(s[4..]));
        ==
          {
            DecodeEncodeRecursively(s[4..]);
          }
          s[..4] + s[4..];
        ==
          s;
        }
      }
    }

    opaque function FromCharsToIndices(s: seq<char>): (b: seq<index>)
      requires forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: k in s ==> IsBase64Char(k)
      ensures |b| == |s|
      decreases s
    {
      seq(|s|, (i: int) requires 0 <= i < |s| => CharToIndex(s[i]))
    }

    opaque function FromIndicesToChars(b: seq<index>): (s: seq<char>)
      ensures forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: k in s ==> IsBase64Char(k)
      ensures |s| == |b|
      decreases b
    {
      seq(|b|, (i: int) requires 0 <= i < |b| => IndexToChar(b[i]))
    }

    lemma FromCharsToIndicesToChars(s: seq<char>)
      requires forall k: char {:trigger IsBase64Char(k)} {:trigger k in s} :: k in s ==> IsBase64Char(k)
      ensures FromIndicesToChars(FromCharsToIndices(s)) == s
      decreases s
    {
      reveal FromIndicesToChars();
      reveal FromCharsToIndices();
      CharToIndexToCharAuto();
    }

    lemma FromIndicesToCharsToIndices(b: seq<index>)
      ensures FromCharsToIndices(FromIndicesToChars(b)) == b
      decreases b
    {
      reveal FromIndicesToChars();
      reveal FromCharsToIndices();
      IndexToCharToIndexAuto();
    }

    opaque function DecodeUnpadded(s: seq<char>): (b: seq<bv8>)
      requires IsUnpaddedBase64String(s)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      DecodeRecursively(FromCharsToIndices(s))
    }

    lemma DecodeUnpaddedBounds(s: seq<char>)
      requires IsUnpaddedBase64String(s)
      ensures |DecodeUnpadded(s)| == |s| / 4 * 3
      ensures |DecodeUnpadded(s)| % 3 == 0
      decreases s
    {
      reveal DecodeUnpadded();
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      ghost var indices := FromCharsToIndices(s);
      assert |indices| == |s|;
      DecodeRecursivelyBounds(indices);
    }

    opaque function EncodeUnpadded(b: seq<bv8>): (s: seq<char>)
      requires |b| % 3 == 0
      decreases b
    {
      EncodeDecodeRecursively(b);
      FromIndicesToChars(EncodeRecursively(b))
    }

    lemma EncodeUnpaddedNotPadded(b: seq<bv8>)
      requires |b| % 3 == 0
      requires b != []
      ensures (EncodeUnpaddedBounds(b); ghost var s: seq<char> := EncodeUnpadded(b); !Is1Padding(s[|s| - 4..]) && !Is2Padding(s[|s| - 4..]))
      decreases b
    {
      ghost var s := EncodeUnpadded(b);
      EncodeUnpaddedBounds(b);
      ghost var suffix := s[|s| - 4..];
      reveal EncodeUnpadded();
      assert forall c: char {:trigger IsBase64Char(c)} {:trigger c in s} :: c in s ==> IsBase64Char(c);
      assert IsBase64Char(s[|s| - 1]);
      assert s[|s| - 1] != '=' by {
        reveal IsBase64Char();
      }
      reveal Is1Padding();
      reveal Is2Padding();
    }

    lemma EncodeUnpaddedBounds(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures |EncodeUnpadded(b)| == |b| / 3 * 4
      ensures |EncodeUnpadded(b)| % 4 == 0
      decreases b
    {
      reveal EncodeUnpadded();
      EncodeRecursivelyBounds(b);
    }

    lemma EncodeUnpaddedBase64(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures IsUnpaddedBase64String(EncodeUnpadded(b))
      decreases b
    {
      reveal EncodeUnpadded();
      EncodeRecursivelyBounds(b);
      reveal IsUnpaddedBase64String();
    }

    lemma EncodeDecodeUnpadded(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures (EncodeUnpaddedBounds(b); EncodeUnpaddedBase64(b); DecodeUnpadded(EncodeUnpadded(b)) == b)
      decreases b
    {
      EncodeUnpaddedBase64(b);
      calc {
        DecodeUnpadded(EncodeUnpadded(b));
      ==
        {
          reveal EncodeUnpadded();
        }
        DecodeUnpadded(FromIndicesToChars(EncodeRecursively(b)));
      ==
        {
          reveal DecodeUnpadded();
          EncodeRecursivelyBounds(b);
        }
        DecodeRecursively(FromCharsToIndices(FromIndicesToChars(EncodeRecursively(b))));
      ==
        {
          FromIndicesToCharsToIndices(EncodeRecursively(b));
        }
        DecodeRecursively(EncodeRecursively(b));
      ==
        {
          EncodeDecodeRecursively(b);
        }
        b;
      }
    }

    lemma DecodeEncodeUnpadded(s: seq<char>)
      requires |s| % 4 == 0
      requires IsUnpaddedBase64String(s)
      ensures (DecodeUnpaddedBounds(s); EncodeUnpadded(DecodeUnpadded(s)) == s)
      decreases s
    {
      DecodeUnpaddedBounds(s);
      reveal IsUnpaddedBase64String();
      ghost var fromCharsToIndicesS := FromCharsToIndices(s);
      calc {
        EncodeUnpadded(DecodeUnpadded(s));
      ==
        {
          reveal DecodeUnpadded();
        }
        EncodeUnpadded(DecodeRecursively(FromCharsToIndices(s)));
      ==
        EncodeUnpadded(DecodeRecursively(fromCharsToIndicesS));
      ==
        {
          reveal EncodeUnpadded();
        }
        assert |fromCharsToIndicesS| % 4 == 0; FromIndicesToChars(EncodeRecursively(DecodeRecursively(fromCharsToIndicesS)));
      ==
        {
          DecodeEncodeRecursively(fromCharsToIndicesS);
        }
        FromIndicesToChars(fromCharsToIndicesS);
      ==
        FromIndicesToChars(FromCharsToIndices(s));
      ==
        {
          FromCharsToIndicesToChars(s);
        }
        s;
      }
    }

    opaque predicate Is1Padding(s: seq<char>)
      decreases s
    {
      |s| == 4 &&
      IsBase64Char(s[0]) &&
      IsBase64Char(s[1]) &&
      IsBase64Char(s[2]) &&
      CharToIndex(s[2]) & 3 == 0 &&
      s[3] == '='
    }

    opaque function Decode1Padding(s: seq<char>): (b: seq<bv8>)
      requires Is1Padding(s)
      ensures |b| == 2
      decreases s
    {
      reveal Is1Padding();
      var d: seq<bv8> := DecodeBlock([CharToIndex(s[0]), CharToIndex(s[1]), CharToIndex(s[2]), 0]);
      [d[0], d[1]]
    }

    opaque function Encode1Padding(b: seq<bv8>): (s: seq<char>)
      requires |b| == 2
      ensures |s| % 4 == 0
      ensures |s| == 4
      decreases b
    {
      var e: seq<index> := EncodeBlock([b[0], b[1], 0]);
      IndexToCharIsBase64(e[0]);
      IndexToCharIsBase64(e[1]);
      IndexToCharIsBase64(e[2]);
      [IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '=']
    }

    lemma EncodeDecodeBlock1Padding(b: seq<bv8>)
      requires |b| == 2
      ensures ghost var e: seq<index> := EncodeBlock([b[0], b[1], 0]); ghost var d: seq<bv8> := DecodeBlock([e[0], e[1], e[2], 0]); [d[0], d[1]] == b
      decreases b
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      reveal BV24ToSeq();
      reveal SeqToBV24();
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    lemma Encode1PaddingIs1Padding(b: seq<bv8>)
      requires |b| == 2
      ensures Is1Padding(Encode1Padding(b))
      decreases b
    {
      ghost var s := Encode1Padding(b);
      ghost var e := EncodeBlock([b[0], b[1], 0]);
      assert s == [IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '='] by {
        reveal Encode1Padding();
      }
      IndexToCharIsBase64(e[0]);
      IndexToCharIsBase64(e[1]);
      IndexToCharIsBase64(e[2]);
      assert CharToIndex(s[2]) & 3 == 0 by {
        reveal Encode1Padding();
        reveal EncodeBlock();
        reveal IndexToChar();
        reveal CharToIndex();
        reveal BV24ToIndexSeq();
        reveal SeqToBV24();
      }
      assert Is1Padding(s) by {
        reveal Is1Padding();
      }
    }

    lemma EncodeDecode1Padding(b: seq<bv8>)
      requires |b| == 2
      ensures (Encode1PaddingIs1Padding(b); Decode1Padding(Encode1Padding(b)) == b)
      decreases b
    {
      Encode1PaddingIs1Padding(b);
      ghost var e := EncodeBlock([b[0], b[1], 0]);
      ghost var s := [CharToIndex(IndexToChar(e[0])), CharToIndex(IndexToChar(e[1])), CharToIndex(IndexToChar(e[2])), 0];
      ghost var s' := [e[0], e[1], e[2], 0];
      ghost var d := DecodeBlock(s);
      ghost var d' := DecodeBlock(s');
      calc {
        Decode1Padding(Encode1Padding(b));
      ==
        {
          reveal Encode1Padding();
        }
        Decode1Padding([IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '=']);
      ==
        {
          reveal Decode1Padding();
        }
        [d[0], d[1]];
      ==
        {
          IndexToCharToIndex(e[0]);
          IndexToCharToIndex(e[1]);
          IndexToCharToIndex(e[2]);
        }
        [d'[0], d'[1]];
      ==
        {
          EncodeDecodeBlock1Padding(b);
        }
        b;
      }
    }

    lemma {:vcs_split_on_every_assert} DecodeEncode1Padding(s: seq<char>)
      requires Is1Padding(s)
      ensures Encode1Padding(Decode1Padding(s)) == s
      decreases s
    {
      reveal Is1Padding();
      ghost var i := [CharToIndex(s[0]), CharToIndex(s[1]), CharToIndex(s[2]), 0];
      ghost var d := DecodeBlock(i);
      ghost var e := EncodeBlock([d[0], d[1], 0]);
      ghost var d' := [IndexToChar(e[0]), IndexToChar(e[1]), IndexToChar(e[2]), '='];
      calc {
        Encode1Padding(Decode1Padding(s));
      ==
        {
          reveal Decode1Padding();
        }
        Encode1Padding([d[0], d[1]]);
      ==
        {
          reveal Encode1Padding();
        }
        d';
      ==
        {
          reveal EncodeBlock();
          reveal DecodeBlock();
          reveal BV24ToSeq();
          reveal SeqToBV24();
          reveal IndexSeqToBV24();
          reveal BV24ToIndexSeq();
          assert d'[0] == IndexToChar(CharToIndex(s[0]));
          assert d'[1] == IndexToChar(CharToIndex(s[1]));
          assert d'[2] == IndexToChar(CharToIndex(s[2]));
        }
        [IndexToChar(CharToIndex(s[0])), IndexToChar(CharToIndex(s[1])), IndexToChar(CharToIndex(s[2])), '='];
      ==
        {
          CharToIndexToChar(s[0]);
          CharToIndexToChar(s[1]);
          CharToIndexToChar(s[2]);
        }
        s;
      }
    }

    opaque predicate Is2Padding(s: seq<char>)
      decreases s
    {
      |s| == 4 &&
      IsBase64Char(s[0]) &&
      IsBase64Char(s[1]) &&
      CharToIndex(s[1]) % 16 == 0 &&
      s[2] == '=' &&
      s[3] == '='
    }

    opaque function Decode2Padding(s: seq<char>): (b: seq<bv8>)
      requires Is2Padding(s)
      ensures |b| == 1
      decreases s
    {
      reveal Is2Padding();
      var d: seq<bv8> := DecodeBlock([CharToIndex(s[0]), CharToIndex(s[1]), 0, 0]);
      [d[0]]
    }

    opaque function Encode2Padding(b: seq<bv8>): (s: seq<char>)
      requires |b| == 1
      ensures |s| % 4 == 0
      ensures |s| == 4
      decreases b
    {
      var e: seq<index> := EncodeBlock([b[0], 0, 0]);
      IndexToCharIsBase64(e[0]);
      IndexToCharIsBase64(e[1]);
      [IndexToChar(e[0]), IndexToChar(e[1]), '=', '=']
    }

    lemma Encode2PaddingIs2Padding(b: seq<bv8>)
      requires |b| == 1
      ensures Is2Padding(Encode2Padding(b))
      decreases b
    {
      reveal IndexToChar();
      reveal Is2Padding();
      reveal CharToIndex();
      reveal Encode2Padding();
      reveal EncodeBlock();
      reveal BV24ToSeq();
      reveal SeqToBV24();
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
      reveal IsBase64Char();
    }

    lemma DecodeEncodeBlock2Padding(b: seq<bv8>)
      requires |b| == 1
      ensures ghost var e: seq<index> := EncodeBlock([b[0], 0, 0]); ghost var d: seq<bv8> := DecodeBlock([e[0], e[1], 0, 0]); [d[0]] == b
      decreases b
    {
      reveal EncodeBlock();
      reveal DecodeBlock();
      reveal BV24ToSeq();
      reveal SeqToBV24();
      reveal IndexSeqToBV24();
      reveal BV24ToIndexSeq();
    }

    lemma EncodeDecode2Padding(b: seq<bv8>)
      requires |b| == 1
      ensures (Encode2PaddingIs2Padding(b); Decode2Padding(Encode2Padding(b)) == b)
      decreases b
    {
      Encode2PaddingIs2Padding(b);
      ghost var e := EncodeBlock([b[0], 0, 0]);
      calc {
        Decode2Padding(Encode2Padding(b));
      ==
        {
          reveal Encode2Padding();
        }
        Decode2Padding([IndexToChar(e[0]), IndexToChar(e[1]), '=', '=']);
      ==
        {
          reveal Decode2Padding();
        }
        [DecodeBlock([CharToIndex(IndexToChar(e[0])), CharToIndex(IndexToChar(e[1])), 0, 0])[0]];
      ==
        {
          IndexToCharToIndex(e[0]);
          IndexToCharToIndex(e[1]);
        }
        [DecodeBlock([e[0], e[1], 0, 0])[0]];
      ==
        {
          DecodeEncodeBlock2Padding(b);
        }
        b;
      }
    }

    lemma DecodeEncode2Padding(s: seq<char>)
      requires Is2Padding(s)
      ensures Encode2Padding(Decode2Padding(s)) == s
      decreases s
    {
      reveal Is2Padding();
      ghost var i := [CharToIndex(s[0]), CharToIndex(s[1]), 0, 0];
      ghost var d := DecodeBlock(i);
      ghost var e := EncodeBlock([d[0], 0, 0]);
      ghost var d' := [IndexToChar(e[0]), IndexToChar(e[1]), '=', '='];
      calc {
        Encode2Padding(Decode2Padding(s));
      ==
        {
          reveal Decode2Padding();
        }
        Encode2Padding([d[0]]);
      ==
        {
          reveal Encode2Padding();
        }
        d';
      ==
        {
          reveal EncodeBlock();
          reveal DecodeBlock();
          reveal BV24ToSeq();
          reveal SeqToBV24();
          reveal IndexSeqToBV24();
          reveal BV24ToIndexSeq();
        }
        [IndexToChar(CharToIndex(s[0])), IndexToChar(CharToIndex(s[1])), '=', '='];
      ==
        {
          CharToIndexToChar(s[0]);
          CharToIndexToChar(s[1]);
        }
        s;
      }
    }

    opaque predicate IsBase64String(s: string)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal Is2Padding();
      var finalBlockStart: int := |s| - 4;
      |s| % 4 == 0 &&
      (IsUnpaddedBase64String(s) || (IsUnpaddedBase64String(s[..finalBlockStart]) && (Is1Padding(s[finalBlockStart..]) || Is2Padding(s[finalBlockStart..]))))
    }

    opaque function DecodeValid(s: seq<char>): (b: seq<bv8>)
      requires IsBase64String(s)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      if s == [] then
        []
      else
        var finalBlockStart: int := |s| - 4; var prefix: seq<char>, suffix: seq<char> := s[..finalBlockStart], s[finalBlockStart..]; if Is1Padding(suffix) then DecodeUnpadded(prefix) + Decode1Padding(suffix) else if Is2Padding(suffix) then DecodeUnpadded(prefix) + Decode2Padding(suffix) else DecodeUnpadded(s)
    }

    lemma AboutDecodeValid(s: seq<char>, b: seq<bv8>)
      requires IsBase64String(s) && b == DecodeValid(s)
      ensures 4 <= |s| ==> ghost var finalBlockStart: int := |s| - 4; ghost var prefix: seq<char>, suffix: seq<char> := s[..finalBlockStart], s[finalBlockStart..]; (Is1Padding(suffix) && IsUnpaddedBase64String(prefix) <==> |b| % 3 == 2 && |b| > 1) && (Is2Padding(suffix) && IsUnpaddedBase64String(prefix) <==> |b| % 3 == 1 && |b| > 0) && (!Is1Padding(suffix) && !Is2Padding(suffix) && IsUnpaddedBase64String(s) <==> |b| % 3 == 0 && |b| > 1)
      decreases s, b
    {
      reveal DecodeValid();
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      if 4 <= |s| {
        ghost var finalBlockStart := |s| - 4;
        ghost var prefix, suffix := s[..finalBlockStart], s[finalBlockStart..];
        if s == [] {
        } else if Is1Padding(suffix) {
          assert !Is2Padding(suffix) by {
            reveal IsBase64Char();
            reveal Is1Padding();
            reveal Is2Padding();
          }
          ghost var x, y := DecodeUnpadded(prefix), Decode1Padding(suffix);
          assert b == x + y;
          assert |x| == |x| / 3 * 3 && |y| == 2 && |b| > 1 by {
            DecodeUnpaddedBounds(prefix);
          }
          Mod3(|x| / 3, |y|, |b|);
        } else if Is2Padding(suffix) {
          ghost var x, y := DecodeUnpadded(prefix), Decode2Padding(suffix);
          assert b == x + y;
          assert |x| == |x| / 3 * 3 && |y| == 1 && |b| > 0 by {
            DecodeUnpaddedBounds(prefix);
          }
          Mod3(|x| / 3, |y|, |b|);
        } else {
          assert b == DecodeUnpadded(s);
          assert |b| % 3 == 0 && |b| > 1 by {
            DecodeUnpaddedBounds(s);
          }
        }
      }
    }

    lemma Mod3(x: nat, k: nat, n: nat)
      requires k < 3 && n == 3 * x + k
      ensures n % 3 == k
      decreases x, k, n
    {
    }

    opaque function DecodeBV(s: seq<char>): (b: Result<seq<bv8>, string>)
      ensures IsBase64String(s) ==> b.Success?
      decreases s
    {
      if IsBase64String(s) then
        Success(DecodeValid(s))
      else
        Failure(""The encoding is malformed"")
    }

    lemma DecodeBVFailure(s: seq<char>)
      ensures !IsBase64String(s) ==> DecodeBV(s).Failure?
      decreases s
    {
      reveal DecodeBV();
    }

    opaque ghost predicate StringIs7Bit(s: string)
      decreases s
    {
      forall c: char {:trigger c in s} :: 
        c in s ==>
          c < 128 as char
    }

    lemma UnpaddedBase64StringIs7Bit(s: string)
      requires IsUnpaddedBase64String(s)
      ensures StringIs7Bit(s)
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal IsBase64Char();
      reveal StringIs7Bit();
    }

    lemma Is7Bit1Padding(s: string)
      requires Is1Padding(s)
      ensures StringIs7Bit(s)
      decreases s
    {
      reveal IsBase64Char();
      reveal Is1Padding();
      reveal StringIs7Bit();
    }

    lemma Is7Bit2Padding(s: string)
      requires Is2Padding(s)
      ensures StringIs7Bit(s)
      decreases s
    {
      reveal IsBase64Char();
      reveal Is2Padding();
      reveal StringIs7Bit();
    }

    opaque function EncodeBV(b: seq<bv8>): (s: seq<char>)
      decreases b
    {
      if |b| % 3 == 0 then
        EncodeUnpaddedBounds(b);
        EncodeUnpadded(b)
      else if |b| % 3 == 1 then
        assert |b| >= 1;
        EncodeUnpaddedBounds(b[..|b| - 1]);
        var s1: seq<char>, s2: seq<char> := EncodeUnpadded(b[..|b| - 1]), Encode2Padding(b[|b| - 1..]);
        s1 + s2
      else
        assert |b| % 3 == 2; assert |b| >= 2; EncodeUnpaddedBounds(b[..|b| - 2]); var s1: seq<char>, s2: seq<char> := EncodeUnpadded(b[..|b| - 2]), Encode1Padding(b[|b| - 2..]); s1 + s2
    }

    lemma EncodeBVIsUnpadded(b: seq<bv8>)
      requires |b| % 3 == 0
      ensures EncodeBV(b) == EncodeUnpadded(b)
      decreases b
    {
      reveal EncodeBV();
    }

    lemma EncodeBVIs2Padded(b: seq<bv8>)
      requires |b| % 3 == 1
      ensures EncodeBV(b) == EncodeUnpadded(b[..|b| - 1]) + Encode2Padding(b[|b| - 1..])
      decreases b
    {
      reveal EncodeBV();
    }

    lemma EncodeBVIs1Padded(b: seq<bv8>)
      requires |b| % 3 == 2
      ensures EncodeBV(b) == EncodeUnpadded(b[..|b| - 2]) + Encode1Padding(b[|b| - 2..])
      decreases b
    {
      reveal EncodeBV();
    }

    lemma EncodeBVLengthCongruentToZeroMod4(b: seq<bv8>)
      ensures |EncodeBV(b)| % 4 == 0
      decreases b
    {
      reveal EncodeBV();
      if |b| % 3 == 0 {
        EncodeUnpaddedBounds(b);
      } else if |b| % 3 == 1 {
        EncodeUnpaddedBounds(b[..|b| - 1]);
      } else {
        EncodeUnpaddedBounds(b[..|b| - 2]);
      }
    }

    lemma EncodeBVIsBase64(b: seq<bv8>)
      ensures IsBase64String(EncodeBV(b))
      decreases b
    {
      reveal EncodeBV();
      reveal IsBase64String();
      EncodeBVLengthExact(b);
      if |EncodeBV(b)| < 4 {
        reveal IsUnpaddedBase64String();
      } else if |b| % 3 == 0 {
        EncodeUnpaddedBase64(b);
      } else if |b| % 3 == 1 {
        ghost var bStart := b[..|b| - 1];
        ghost var bEnd := b[|b| - 1..];
        EncodeUnpaddedBase64(bStart);
        Encode2PaddingIs2Padding(bEnd);
      } else {
        ghost var bStart := b[..|b| - 2];
        ghost var bEnd := b[|b| - 2..];
        EncodeUnpaddedBase64(bStart);
        Encode1PaddingIs1Padding(bEnd);
      }
    }

    lemma EncodeBVLengthExact(b: seq<bv8>)
      ensures ghost var s: seq<char> := EncodeBV(b); (|b| % 3 == 0 ==> |s| == |b| / 3 * 4) && (|b| % 3 != 0 ==> |s| == |b| / 3 * 4 + 4)
      decreases b
    {
      reveal EncodeBV();
      reveal Is1Padding();
      reveal Is2Padding();
      ghost var s := EncodeBV(b);
      if |b| % 3 == 0 {
        assert s == EncodeUnpadded(b);
        EncodeUnpaddedBounds(b);
        assert |s| == |b| / 3 * 4;
      } else if |b| % 3 == 1 {
        EncodeUnpaddedBounds(b[..|b| - 1]);
        assert s == EncodeUnpadded(b[..|b| - 1]) + Encode2Padding(b[|b| - 1..]);
        calc {
          |s|;
        ==
          |EncodeUnpadded(b[..|b| - 1])| + |Encode2Padding(b[|b| - 1..])|;
        ==
          {
            assert |Encode2Padding(b[|b| - 1..])| == 4;
          }
          |EncodeUnpadded(b[..|b| - 1])| + 4;
        ==
          {
            assert |EncodeUnpadded(b[..|b| - 1])| == |b[..|b| - 1]| / 3 * 4;
          }
          |b[..|b| - 1]| / 3 * 4 + 4;
        ==
          {
            assert |b[..|b| - 1]| == |b| - 1;
          }
          (|b| - 1) / 3 * 4 + 4;
        ==
          {
            assert (|b| - 1) / 3 == |b| / 3;
          }
          |b| / 3 * 4 + 4;
        }
      } else {
        EncodeUnpaddedBounds(b[..|b| - 2]);
        assert s == EncodeUnpadded(b[..|b| - 2]) + Encode1Padding(b[|b| - 2..]);
        Encode1PaddingIs1Padding(b[|b| - 2..]);
        calc {
          |s|;
        ==
          |EncodeUnpadded(b[..|b| - 2])| + |Encode1Padding(b[|b| - 2..])|;
        ==
          {
            assert |Encode1Padding(b[|b| - 2..])| == 4;
          }
          |EncodeUnpadded(b[..|b| - 2])| + 4;
        ==
          {
            assert |EncodeUnpadded(b[..|b| - 2])| == |b[..|b| - 2]| / 3 * 4;
          }
          |b[..|b| - 2]| / 3 * 4 + 4;
        ==
          {
            assert |b[..|b| - 2]| == |b| - 2;
          }
          (|b| - 2) / 3 * 4 + 4;
        ==
          {
            assert (|b| - 2) / 3 == |b| / 3;
          }
          |b| / 3 * 4 + 4;
        }
      }
    }

    lemma EncodeBVLengthBound(b: seq<bv8>)
      ensures ghost var s: seq<char> := EncodeBV(b); |s| <= |b| / 3 * 4 + 4
      decreases b
    {
      EncodeBVLengthExact(b);
    }

    lemma SeqPartsMakeWhole<T>(s: seq<T>, i: nat)
      requires i <= |s|
      ensures s[..i] + s[i..] == s
      decreases s, i
    {
    }

    lemma DecodeValidEncodeEmpty(s: seq<char>)
      requires s == []
      ensures (reveal IsUnpaddedBase64String(); reveal IsBase64String(); EncodeBV(DecodeValid(s)) == s)
      decreases s
    {
      assert IsBase64String(s) by {
        reveal IsBase64String();
        reveal IsUnpaddedBase64String();
      }
      ghost var b := DecodeValid(s);
      assert b == [] by {
        reveal DecodeValid();
      }
      assert EncodeBV(b) == [] by {
        reveal EncodeBV();
        reveal EncodeUnpadded();
        reveal EncodeRecursively();
        reveal FromIndicesToChars();
      }
    }

    lemma EncodeDecodeValidEmpty(b: seq<bv8>)
      requires b == []
      ensures (EncodeBVIsBase64(b); DecodeValid(EncodeBV(b)) == b)
      decreases b
    {
      assert EncodeBV(b) == [] by {
        reveal EncodeBV();
        reveal EncodeUnpadded();
        reveal EncodeRecursively();
        reveal FromIndicesToChars();
      }
      EncodeBVIsBase64(b);
      assert DecodeValid([]) == [] by {
        reveal DecodeValid();
      }
    }

    lemma DecodeValidEncodeUnpadded(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires !Is1Padding(s[|s| - 4..])
      requires !Is2Padding(s[|s| - 4..])
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      reveal EncodeBV();
      reveal DecodeValid();
      reveal IsBase64String();
      DecodeUnpaddedBounds(s);
      calc {
        EncodeBV(DecodeValid(s));
      ==
        EncodeBV(DecodeUnpadded(s));
      ==
        EncodeUnpadded(DecodeUnpadded(s));
      ==
        {
          DecodeEncodeUnpadded(s);
        }
        s;
      }
    }

    lemma EncodeDecodeValidUnpadded(b: seq<bv8>)
      requires |b| % 3 == 0
      requires b != []
      ensures ghost var s: seq<char> := EncodeBV(b); IsUnpaddedBase64String(s) && |s| >= 4 && !Is1Padding(s[|s| - 4..]) && !Is2Padding(s[|s| - 4..]) && s == EncodeUnpadded(b)
      decreases b
    {
      EncodeUnpaddedBase64(b);
      EncodeUnpaddedBounds(b);
      ghost var s := EncodeBV(b);
      assert s == EncodeUnpadded(b) by {
        EncodeBVIsUnpadded(b);
      }
      assert !Is1Padding(s[|s| - 4..]) by {
        EncodeUnpaddedNotPadded(b);
      }
      assert !Is2Padding(s[|s| - 4..]) by {
        EncodeUnpaddedNotPadded(b);
      }
    }

    lemma EncodeDecodeValid2Padded(b: seq<bv8>)
      requires |b| % 3 == 1
      ensures ghost var s: seq<char> := EncodeBV(b); s == EncodeUnpadded(b[..|b| - 1]) + Encode2Padding(b[|b| - 1..]) && Is2Padding(s[|s| - 4..])
      decreases b
    {
      EncodeUnpaddedBase64(b[..|b| - 1]);
      EncodeUnpaddedBounds(b[..|b| - 1]);
      reveal EncodeBV();
      ghost var s := EncodeBV(b);
      Encode2PaddingIs2Padding(b[|b| - 1..]);
      assert Is2Padding(s[|s| - 4..]);
    }

    lemma EncodeDecodeValid1Padded(b: seq<bv8>)
      requires |b| % 3 == 2
      ensures ghost var s: seq<char> := EncodeBV(b); s == EncodeUnpadded(b[..|b| - 2]) + Encode1Padding(b[|b| - 2..]) && |s| >= 4 && IsUnpaddedBase64String(s[..|s| - 4]) && Is1Padding(s[|s| - 4..])
      decreases b
    {
      EncodeUnpaddedBase64(b[..|b| - 2]);
      EncodeUnpaddedBounds(b[..|b| - 2]);
      reveal EncodeBV();
      ghost var s := EncodeBV(b);
      Encode1PaddingIs1Padding(b[|b| - 2..]);
      assert Is1Padding(s[|s| - 4..]);
    }

    lemma DecodeValidUnpaddedPartialFrom1PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures (reveal IsUnpaddedBase64String(); reveal IsBase64String(); reveal DecodeValid(); DecodeValid(s)[..|DecodeValid(s)| - 2] == DecodeUnpadded(s[..|s| - 4]))
      decreases s
    {
      reveal IsBase64String();
      reveal DecodeValid();
    }

    lemma DecodeValid1PaddedPartialFrom1PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures (reveal DecodeValid(); DecodeValid(s)[|DecodeValid(s)| - 2..] == Decode1Padding(s[|s| - 4..]))
      decreases s
    {
      reveal DecodeValid();
    }

    lemma DecodeValid1PaddingLengthMod3(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures |DecodeValid(s)| % 3 == 2
      decreases s
    {
      assert IsUnpaddedBase64String(s[..|s| - 4]) by {
        UnpaddedBase64Prefix(s);
      }
      AboutDecodeValid(s, DecodeValid(s));
    }

    lemma {:rlimit 12000} DecodeValidEncode1Padding(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      assert |DecodeValid(s)| % 3 == 2 by {
        DecodeValid1PaddingLengthMod3(s);
      }
      calc {
        EncodeBV(DecodeValid(s));
      ==
        {
          reveal EncodeBV();
        }
        EncodeUnpadded(DecodeValid(s)[..|DecodeValid(s)| - 2]) + Encode1Padding(DecodeValid(s)[|DecodeValid(s)| - 2..]);
      ==
        {
          DecodeValidUnpaddedPartialFrom1PaddedSeq(s);
          reveal IsBase64String();
          reveal IsUnpaddedBase64String();
        }
        EncodeUnpadded(DecodeUnpadded(s[..|s| - 4])) + Encode1Padding(DecodeValid(s)[|DecodeValid(s)| - 2..]);
      ==
        {
          reveal IsUnpaddedBase64String();
          DecodeEncodeUnpadded(s[..|s| - 4]);
        }
        s[..|s| - 4] + Encode1Padding(DecodeValid(s)[|DecodeValid(s)| - 2..]);
      ==
        {
          DecodeValid1PaddedPartialFrom1PaddedSeq(s);
        }
        s[..|s| - 4] + Encode1Padding(Decode1Padding(s[|s| - 4..]));
      ==
        {
          DecodeEncode1Padding(s[|s| - 4..]);
        }
        s[..|s| - 4] + s[|s| - 4..];
      ==
        {
          SeqPartsMakeWhole(s, |s| - 4);
        }
        s;
      }
    }

    lemma DecodeValidPartialsFrom2PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is2Padding(s[|s| - 4..])
      ensures (reveal IsUnpaddedBase64String(); reveal DecodeValid(); reveal IsBase64String(); ghost var b: seq<bv8> := DecodeValid(s); b[..|b| - 1] == DecodeUnpadded(s[..|s| - 4]) && b[|b| - 1..] == Decode2Padding(s[|s| - 4..]))
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal IsBase64String();
      reveal DecodeValid();
      AboutDecodeValid(s, DecodeValid(s));
      assert Is2Padding(s[|s| - 4..]);
    }

    lemma DecodeValidPartialsFrom1PaddedSeq(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is1Padding(s[|s| - 4..])
      ensures (reveal IsUnpaddedBase64String(); reveal DecodeValid(); reveal IsBase64String(); ghost var b: seq<bv8> := DecodeValid(s); b[..|b| - 2] == DecodeUnpadded(s[..|s| - 4]) && b[|b| - 2..] == Decode1Padding(s[|s| - 4..]))
      decreases s
    {
      reveal IsUnpaddedBase64String();
      reveal DecodeValid();
      reveal IsBase64String();
      AboutDecodeValid(s, DecodeValid(s));
    }

    lemma UnpaddedBase64Prefix(s: string)
      requires IsBase64String(s)
      requires |s| >= 4
      ensures IsUnpaddedBase64String(s[..|s| - 4])
      decreases s
    {
      reveal IsBase64String();
      reveal IsUnpaddedBase64String();
    }

    lemma DecodeValid2PaddingLengthMod3(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is2Padding(s[|s| - 4..])
      ensures |DecodeValid(s)| % 3 == 1
      decreases s
    {
      assert IsUnpaddedBase64String(s[..|s| - 4]) by {
        UnpaddedBase64Prefix(s);
      }
      AboutDecodeValid(s, DecodeValid(s));
    }

    lemma DecodeValidEncode2Padding(s: seq<char>)
      requires IsBase64String(s)
      requires |s| >= 4
      requires Is2Padding(s[|s| - 4..])
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      assert |DecodeValid(s)| % 3 == 1 by {
        DecodeValid2PaddingLengthMod3(s);
      }
      calc {
        EncodeBV(DecodeValid(s));
      ==
        {
          reveal EncodeBV();
        }
        EncodeUnpadded(DecodeValid(s)[..|DecodeValid(s)| - 1]) + Encode2Padding(DecodeValid(s)[|DecodeValid(s)| - 1..]);
      ==
        {
          DecodeValidPartialsFrom2PaddedSeq(s);
          reveal IsUnpaddedBase64String();
          reveal IsBase64String();
        }
        EncodeUnpadded(DecodeUnpadded(s[..|s| - 4])) + Encode2Padding(DecodeValid(s)[|DecodeValid(s)| - 1..]);
      ==
        {
          reveal IsBase64String();
          DecodeEncodeUnpadded(s[..|s| - 4]);
        }
        s[..|s| - 4] + Encode2Padding(DecodeValid(s)[|DecodeValid(s)| - 1..]);
      ==
        {
          DecodeValidPartialsFrom2PaddedSeq(s);
        }
        s[..|s| - 4] + Encode2Padding(Decode2Padding(s[|s| - 4..]));
      ==
        {
          DecodeEncode2Padding(s[|s| - 4..]);
        }
        s[..|s| - 4] + s[|s| - 4..];
      ==
        {
          SeqPartsMakeWhole(s, |s| - 4);
        }
        s;
      }
    }

    lemma DecodeValidEncode(s: seq<char>)
      requires IsBase64String(s)
      ensures EncodeBV(DecodeValid(s)) == s
      decreases s
    {
      reveal IsBase64String();
      if s == [] {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncodeEmpty(s);
          }
          s;
        }
      } else if |s| >= 4 && Is1Padding(s[|s| - 4..]) {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncode1Padding(s);
          }
          s;
        }
      } else if |s| >= 4 && Is2Padding(s[|s| - 4..]) {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncode2Padding(s);
          }
          s;
        }
      } else {
        calc {
          EncodeBV(DecodeValid(s));
        ==
          {
            DecodeValidEncodeUnpadded(s);
          }
          s;
        }
      }
    }

    lemma EncodeDecodeValid(b: seq<bv8>)
      ensures (EncodeBVIsBase64(b); DecodeValid(EncodeBV(b)) == b)
      decreases b
    {
      EncodeBVIsBase64(b);
      ghost var s := EncodeBV(b);
      if b == [] {
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            EncodeDecodeValidEmpty(b);
          }
          b;
        }
      } else if |b| % 3 == 0 {
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            EncodeBVIsUnpadded(b);
          }
          DecodeValid(EncodeUnpadded(b));
        ==
          {
            EncodeDecodeValidUnpadded(b);
            reveal DecodeValid();
          }
          DecodeUnpadded(EncodeUnpadded(b));
        ==
          {
            EncodeDecodeUnpadded(b);
          }
          b;
        }
      } else if |b| % 3 == 1 {
        EncodeDecodeValid2Padded(b);
        ghost var prefix := b[..|b| - 1];
        ghost var suffix := b[|b| - 1..];
        EncodeUnpaddedBase64(prefix);
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            reveal EncodeBV();
          }
          DecodeValid(EncodeUnpadded(prefix) + Encode2Padding(suffix));
        ==
          {
            reveal DecodeValid();
            DecodeValidPartialsFrom2PaddedSeq(s);
          }
          DecodeUnpadded(EncodeUnpadded(prefix)) + Decode2Padding(Encode2Padding(suffix));
        ==
          {
            EncodeDecodeUnpadded(prefix);
            EncodeDecode2Padding(suffix);
          }
          prefix + suffix;
        ==
          b;
        }
      } else if |b| % 3 == 2 {
        EncodeDecodeValid1Padded(b);
        ghost var prefix := b[..|b| - 2];
        ghost var suffix := b[|b| - 2..];
        EncodeUnpaddedBase64(prefix);
        calc {
          DecodeValid(EncodeBV(b));
        ==
          {
            reveal EncodeBV();
          }
          DecodeValid(EncodeUnpadded(prefix) + Encode1Padding(suffix));
        ==
          {
            reveal DecodeValid();
            DecodeValidPartialsFrom1PaddedSeq(s);
          }
          DecodeUnpadded(EncodeUnpadded(prefix)) + Decode1Padding(Encode1Padding(suffix));
        ==
          {
            EncodeDecodeUnpadded(prefix);
            EncodeDecode1Padding(suffix);
          }
          prefix + suffix;
        ==
          b;
        }
      }
    }

    lemma DecodeEncodeBV(s: seq<char>)
      requires IsBase64String(s)
      ensures EncodeBV(DecodeBV(s).value) == s
      decreases s
    {
      reveal DecodeBV();
      calc {
        EncodeBV(DecodeBV(s).value);
      ==
        {
          DecodeValidEncode(s);
        }
        s;
      }
    }

    lemma EncodeDecodeBV(b: seq<bv8>)
      ensures DecodeBV(EncodeBV(b)) == Success(b)
      decreases b
    {
      reveal DecodeBV();
      EncodeBVIsBase64(b);
      calc {
        DecodeBV(EncodeBV(b));
      ==
        {
          assert IsBase64String(EncodeBV(b));
        }
        Success(DecodeValid(EncodeBV(b)));
      ==
        {
          EncodeDecodeValid(b);
        }
        Success(b);
      }
    }

    opaque function UInt8sToBVs(u: seq<uint8>): (r: seq<bv8>)
      ensures |r| == |u|
      ensures forall i: int {:trigger u[i]} {:trigger r[i]} :: 0 <= i < |u| ==> r[i] == u[i] as bv8
      decreases u
    {
      seq(|u|, (i: int) requires 0 <= i < |u| => u[i] as bv8)
    }

    opaque function BVsToUInt8s(b: seq<bv8>): (r: seq<uint8>)
      ensures |r| == |b|
      ensures forall i: int {:trigger b[i]} {:trigger r[i]} :: 0 <= i < |b| ==> r[i] == b[i] as uint8
      decreases b
    {
      seq(|b|, (i: int) requires 0 <= i < |b| => b[i] as uint8)
    }

    lemma {:vcs_split_on_every_assert} {:rlimit 1000000} UInt8sToBVsToUInt8s(u: seq<uint8>)
      ensures BVsToUInt8s(UInt8sToBVs(u)) == u
      decreases u
    {
      ghost var b := UInt8sToBVs(u);
      assert |b| == |u|;
      ghost var u' := BVsToUInt8s(b);
      assert |u'| == |b|;
    }

    lemma BVsToUInt8sToBVs(b: seq<bv8>)
      ensures UInt8sToBVs(BVsToUInt8s(b)) == b
      decreases b
    {
      ghost var u := BVsToUInt8s(b);
      assert |b| == |u|;
      ghost var b' := UInt8sToBVs(u);
      assert |b'| == |u|;
    }

    opaque function Encode(u: seq<uint8>): seq<char>
      decreases u
    {
      EncodeBV(UInt8sToBVs(u))
    }

    opaque function Decode(s: seq<char>): (b: Result<seq<uint8>, string>)
      ensures IsBase64String(s) ==> b.Success?
      decreases s
    {
      if IsBase64String(s) then
        var b: seq<bv8> := DecodeValid(s);
        Success(BVsToUInt8s(b))
      else
        Failure(""The encoding is malformed"")
    }

    lemma EncodeDecode(b: seq<uint8>)
      ensures Decode(Encode(b)) == Success(b)
      decreases b
    {
      ghost var bvs := UInt8sToBVs(b);
      ghost var s := EncodeBV(bvs);
      assert Encode(b) == s by {
        reveal Encode();
      }
      assert IsBase64String(s) by {
        EncodeBVIsBase64(bvs);
      }
      ghost var b' := DecodeValid(s);
      assert b' == bvs by {
        EncodeDecodeValid(bvs);
      }
      ghost var us := BVsToUInt8s(b');
      assert Decode(s) == Success(us) by {
        reveal Decode();
      }
      assert b' == bvs;
      assert b == us by {
        UInt8sToBVsToUInt8s(b);
      }
    }

    lemma DecodeEncode(s: seq<char>)
      requires IsBase64String(s)
      ensures Encode(Decode(s).value) == s
      decreases s
    {
      ghost var b := DecodeValid(s);
      ghost var u := BVsToUInt8s(b);
      assert Decode(s) == Success(u) by {
        reveal Decode();
      }
      ghost var s' := EncodeBV(UInt8sToBVs(u));
      assert s' == Encode(u) by {
        reveal Encode();
      }
      assert UInt8sToBVs(BVsToUInt8s(b)) == b by {
        BVsToUInt8sToBVs(b);
      }
      assert s == s' by {
        DecodeValidEncode(s);
      }
    }

    import opened Wrappers

    import opened BoundedInts

    export
      reveals IsBase64Char, index, CharToIndex, IndexToChar, IsBase64String, IsUnpaddedBase64String, Is1Padding, Is2Padding
      provides Encode, Decode, EncodeBV, DecodeBV, EncodeDecode, DecodeEncode, EncodeDecodeBV, DecodeEncodeBV, BoundedInts, Wrappers


    export Internals
      reveals *
      reveals IsBase64Char
      provides Base64CharIs7Bit
      reveals IsUnpaddedBase64String, IndexToChar
      provides IndexToCharIsBase64
      reveals CharToIndex
      provides CharToIndexToChar, IndexToCharToIndex, IndexToCharToIndexAuto, CharToIndexToCharAuto
      reveals BV24ToSeq, SeqToBV24
      provides BV24ToSeqToBV24, SeqToBV24ToSeq
      reveals BV24ToIndexSeq, IndexSeqToBV24
      provides BV24ToIndexSeqToBV24, IndexSeqToBV24ToIndexSeq
      reveals DecodeBlock, EncodeBlock
      provides EncodeDecodeBlock, DecodeEncodeBlock
      reveals DecodeRecursively
      provides DecodeRecursivelyBounds, DecodeRecursivelyBlock
      reveals EncodeRecursively
      provides EncodeRecursivelyBounds, EncodeRecursivelyBlock, EncodeDecodeRecursively, DecodeEncodeRecursively
      reveals FromCharsToIndices, FromIndicesToChars
      provides FromCharsToIndicesToChars, FromIndicesToCharsToIndices
      reveals DecodeUnpadded
      provides DecodeUnpaddedBounds
      reveals EncodeUnpadded
      provides EncodeUnpaddedNotPadded, EncodeUnpaddedBounds, EncodeUnpaddedBase64, EncodeDecodeUnpadded, DecodeEncodeUnpadded
      reveals Is1Padding, Decode1Padding, Encode1Padding
      provides EncodeDecodeBlock1Padding, Encode1PaddingIs1Padding, EncodeDecode1Padding, DecodeEncode1Padding
      reveals Is2Padding, Decode2Padding, Encode2Padding
      provides Encode2PaddingIs2Padding, DecodeEncodeBlock2Padding, EncodeDecode2Padding, DecodeEncode2Padding
      reveals IsBase64String, DecodeValid
      provides AboutDecodeValid, Mod3
      reveals DecodeBV
      provides DecodeBVFailure
      reveals StringIs7Bit
      provides UnpaddedBase64StringIs7Bit, Is7Bit1Padding, Is7Bit2Padding
      reveals EncodeBV
      provides EncodeBVIsUnpadded, EncodeBVIs2Padded, EncodeBVIs1Padded, EncodeBVLengthCongruentToZeroMod4, EncodeBVIsBase64, EncodeBVLengthExact, EncodeBVLengthBound, SeqPartsMakeWhole, DecodeValidEncodeEmpty, EncodeDecodeValidEmpty, DecodeValidEncodeUnpadded, EncodeDecodeValidUnpadded, EncodeDecodeValid2Padded, EncodeDecodeValid1Padded, DecodeValidUnpaddedPartialFrom1PaddedSeq, DecodeValid1PaddedPartialFrom1PaddedSeq, DecodeValid1PaddingLengthMod3, DecodeValidEncode1Padding, DecodeValidPartialsFrom2PaddedSeq, DecodeValidPartialsFrom1PaddedSeq, UnpaddedBase64Prefix, DecodeValid2PaddingLengthMod3, DecodeValidEncode2Padding, DecodeValidEncode, EncodeDecodeValid, DecodeEncodeBV, EncodeDecodeBV
      reveals UInt8sToBVs, BVsToUInt8s
      provides UInt8sToBVsToUInt8s, BVsToUInt8sToBVs
      reveals Encode, Decode
      provides EncodeDecode, DecodeEncode, reveal_IsBase64Char, reveal_IsUnpaddedBase64String, reveal_IndexToChar, reveal_CharToIndex, reveal_BV24ToSeq, reveal_SeqToBV24, reveal_BV24ToIndexSeq, reveal_IndexSeqToBV24, reveal_DecodeBlock, reveal_EncodeBlock, reveal_DecodeRecursively, reveal_EncodeRecursively, reveal_FromCharsToIndices, reveal_FromIndicesToChars, reveal_DecodeUnpadded, reveal_EncodeUnpadded, reveal_Is1Padding, reveal_Decode1Padding, reveal_Encode1Padding, reveal_Is2Padding, reveal_Decode2Padding, reveal_Encode2Padding, reveal_IsBase64String, reveal_DecodeValid, reveal_DecodeBV, reveal_StringIs7Bit, reveal_EncodeBV, reveal_UInt8sToBVs, reveal_BVsToUInt8s, reveal_Encode, reveal_Decode, Wrappers, BoundedInts
      reveals index


    type index = bv6
  }

  module BoundedInts {
    const TWO_TO_THE_0: int := 1
    const TWO_TO_THE_1: int := 2
    const TWO_TO_THE_2: int := 4
    const TWO_TO_THE_4: int := 16
    const TWO_TO_THE_5: int := 32
    const TWO_TO_THE_7: int := 128
    const TWO_TO_THE_8: int := 256
    const TWO_TO_THE_15: int := 32768
    const TWO_TO_THE_16: int := 65536
    const TWO_TO_THE_24: int := 16777216
    const TWO_TO_THE_31: int := 2147483648
    const TWO_TO_THE_32: int := 4294967296
    const TWO_TO_THE_40: int := 1099511627776
    const TWO_TO_THE_48: int := 281474976710656
    const TWO_TO_THE_56: int := 72057594037927936
    const TWO_TO_THE_63: int := 9223372036854775808
    const TWO_TO_THE_64: int := 18446744073709551616
    const TWO_TO_THE_127: int := 170141183460469231731687303715884105728
    const TWO_TO_THE_128: int := 340282366920938463463374607431768211456
    const TWO_TO_THE_256: int := 115792089237316195423570985008687907853269984665640564039457584007913129639936
    const TWO_TO_THE_512: int := 13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096
    const UINT8_MAX: uint8 := 255
    const UINT16_MAX: uint16 := 65535
    const UINT32_MAX: uint32 := 4294967295
    const UINT64_MAX: uint64 := 18446744073709551615
    const INT8_MIN: int8 := -128
    const INT8_MAX: int8 := 127
    const INT16_MIN: int16 := -32768
    const INT16_MAX: int16 := 32767
    const INT32_MIN: int32 := -2147483648
    const INT32_MAX: int32 := 2147483647
    const INT64_MIN: int64 := -9223372036854775808
    const INT64_MAX: int64 := 9223372036854775807
    const NAT8_MAX: nat8 := 127
    const NAT16_MAX: nat16 := 32767
    const NAT32_MAX: nat32 := 2147483647
    const NAT64_MAX: nat64 := 9223372036854775807

    newtype uint8 = x: int
      | 0 <= x < TWO_TO_THE_8

    newtype uint16 = x: int
      | 0 <= x < TWO_TO_THE_16

    newtype uint32 = x: int
      | 0 <= x < TWO_TO_THE_32

    newtype uint64 = x: int
      | 0 <= x < TWO_TO_THE_64

    newtype uint128 = x: int
      | 0 <= x < TWO_TO_THE_128

    newtype int8 = x: int
      | -TWO_TO_THE_7 <= x < TWO_TO_THE_7

    newtype int16 = x: int
      | -TWO_TO_THE_15 <= x < TWO_TO_THE_15

    newtype int32 = x: int
      | -TWO_TO_THE_31 <= x < TWO_TO_THE_31

    newtype int64 = x: int
      | -TWO_TO_THE_63 <= x < TWO_TO_THE_63

    newtype int128 = x: int
      | -TWO_TO_THE_127 <= x < TWO_TO_THE_127

    newtype nat8 = x: int
      | 0 <= x < TWO_TO_THE_7

    newtype nat16 = x: int
      | 0 <= x < TWO_TO_THE_15

    newtype nat32 = x: int
      | 0 <= x < TWO_TO_THE_31

    newtype nat64 = x: int
      | 0 <= x < TWO_TO_THE_63

    newtype nat128 = x: int
      | 0 <= x < TWO_TO_THE_127

    type byte = uint8

    type bytes = seq<byte>

    newtype opt_byte = c: int
      | -1 <= c < TWO_TO_THE_8
  }

  module Collections {

    module Array {
      method BinarySearch<T>(a: array<T>, key: T, less: (T, T) -> bool)
          returns (r: Option<nat>)
        requires SortedBy((x: T, y: T) => less(x, y) || x == y, a[..])
        requires StrictTotalOrdering(less)
        ensures r.Some? ==> r.value < a.Length && a[r.value] == key
        ensures r.None? ==> key !in a[..]
        decreases a
      {
        var lo, hi: nat := 0, a.Length;
        while lo < hi
          invariant 0 <= lo <= hi <= a.Length
          invariant key !in a[..lo] && key !in a[hi..]
          invariant a[..] == old(a[..])
          decreases hi - lo
        {
          var mid := (lo + hi) / 2;
          if less(key, a[mid]) {
            hi := mid;
          } else if less(a[mid], key) {
            lo := mid + 1;
          } else {
            return Some(mid);
          }
        }
        return None;
      }

      import opened Wrappers

      import opened Relations

      import opened Seq
    }

    module Imap {
      function Get<X, Y>(m: imap<X, Y>, x: X): Option<Y>
      {
        if x in m then
          Some(m[x])
        else
          None
      }

      ghost function {:opaque} RemoveKeys<X, Y>(m: imap<X, Y>, xs: iset<X>): (m': imap<X, Y>)
        ensures forall x: X {:trigger m'[x]} :: (x in m && x !in xs ==> x in m') && (x in m && x !in xs ==> m'[x] == m[x])
        ensures forall x: X {:trigger x in m'} :: (x in m' ==> x in m) && (x in m' ==> x !in xs)
        ensures m'.Keys == m.Keys - xs
      {
        imap x: X {:trigger m[x]} {:trigger x in xs} {:trigger x in m} | x in m && x !in xs :: m[x]
      }

      ghost function {:opaque} RemoveKey<X, Y>(m: imap<X, Y>, x: X): (m': imap<X, Y>)
        ensures m' == RemoveKeys(m, iset{x})
        ensures forall x': X {:trigger m'[x']} :: x' in m' ==> m'[x'] == m[x']
      {
        imap i: X {:trigger m[i]} {:trigger i in m} | i in m && i != x :: m[i]
      }

      ghost function {:opaque} Restrict<X, Y>(m: imap<X, Y>, xs: iset<X>): (m': imap<X, Y>)
        ensures m' == RemoveKeys(m, m.Keys - xs)
      {
        imap x: X {:trigger m[x]} {:trigger x in m} {:trigger x in xs} | x in xs && x in m :: m[x]
      }

      ghost predicate EqualOnKey<X, Y>(m: imap<X, Y>, m': imap<X, Y>, x: X)
      {
        (x !in m && x !in m') || (x in m && x in m' && m[x] == m'[x])
      }

      ghost predicate IsSubset<X, Y>(m: imap<X, Y>, m': imap<X, Y>)
      {
        m.Keys <= m'.Keys &&
        forall x: X {:trigger EqualOnKey(m, m', x)} {:trigger x in m} :: 
          x in m ==>
            EqualOnKey(m, m', x)
      }

      ghost function {:opaque} Union<X, Y>(m: imap<X, Y>, m': imap<X, Y>): (r: imap<X, Y>)
        ensures r.Keys == m.Keys + m'.Keys
        ensures forall x: X {:trigger r[x]} :: x in m' ==> r[x] == m'[x]
        ensures forall x: X {:trigger r[x]} :: x in m && x !in m' ==> r[x] == m[x]
      {
        m + m'
      }

      ghost predicate {:opaque} Injective<X, Y>(m: imap<X, Y>)
      {
        forall x: X, x': X {:trigger m[x], m[x']} :: 
          x != x' &&
          x in m &&
          x' in m ==>
            m[x] != m[x']
      }

      ghost function {:opaque} Invert<X, Y>(m: imap<X, Y>): imap<Y, X>
      {
        imap y: Y {:trigger y in m.Values} | y in m.Values :: ghost var x: X :| x in m.Keys && m[x] == y; x
      }

      lemma LemmaInvertIsInjective<X, Y>(m: imap<X, Y>)
        ensures Injective(Invert(m))
      {
        reveal Injective();
        reveal Invert();
      }

      ghost predicate {:opaque} Total<X(!new), Y>(m: imap<X, Y>)
      {
        forall i: X {:trigger m[i]} {:trigger i in m} :: 
          i in m
      }

      ghost predicate {:opaque} Monotonic(m: imap<int, int>)
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          x <= x' ==>
            m[x] <= m[x']
      }

      ghost predicate {:opaque} MonotonicFrom(m: imap<int, int>, start: int)
        decreases start
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          start <= x <= x' ==>
            m[x] <= m[x']
      }

      import opened Wrappers
    }

    module Iset {
      lemma LemmaSubset<T>(x: iset<T>, y: iset<T>)
        requires forall e: T {:trigger e in y} :: e in x ==> e in y
        ensures x <= y
      {
      }

      ghost function {:opaque} Map<X(!new), Y>(xs: iset<X>, f: X --> Y): (ys: iset<Y>)
        requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
        requires Injective(f)
        reads set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
        ensures forall x: X {:trigger f(x)} :: x in xs <==> f(x) in ys
        decreases set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
      {
        ghost var ys: iset<Y> := iset x: X {:trigger f(x)} {:trigger x in xs} | x in xs :: f(x);
        ys
      }

      ghost function {:opaque} Filter<X(!new)>(xs: iset<X>, f: X ~> bool): (ys: iset<X>)
        requires forall x: X {:trigger f.requires(x)} {:trigger x in xs} :: x in xs ==> f.requires(x)
        reads set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o
        ensures forall y: X {:trigger f(y)} {:trigger y in xs} :: y in ys <==> y in xs && f(y)
        decreases set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o
      {
        ghost var ys: iset<X> := iset x: X {:trigger f(x)} {:trigger x in xs} | x in xs && f(x);
        ys
      }

      import opened Functions

      import opened Relations
    }

    module Map {
      function Get<X, Y>(m: map<X, Y>, x: X): Option<Y>
        decreases m
      {
        if x in m then
          Some(m[x])
        else
          None
      }

      function {:opaque} ToImap<X, Y>(m: map<X, Y>): (m': imap<X, Y>)
        ensures forall x: X {:trigger m'[x]} :: (x in m ==> x in m') && (x in m ==> m'[x] == m[x])
        ensures forall x: X {:trigger x in m'} :: x in m' ==> x in m
        decreases m
      {
        imap x: X {:trigger m[x]} {:trigger x in m} | x in m :: m[x]
      }

      function {:opaque} RemoveKeys<X, Y>(m: map<X, Y>, xs: set<X>): (m': map<X, Y>)
        ensures forall x: X {:trigger m'[x]} :: (x in m && x !in xs ==> x in m') && (x in m && x !in xs ==> m'[x] == m[x])
        ensures forall x: X {:trigger x in m'} :: (x in m' ==> x in m) && (x in m' ==> x !in xs)
        ensures m'.Keys == m.Keys - xs
        decreases m, xs
      {
        m - xs
      }

      function {:opaque} Remove<X, Y>(m: map<X, Y>, x: X): (m': map<X, Y>)
        ensures m' == RemoveKeys(m, {x})
        ensures |m'.Keys| <= |m.Keys|
        ensures x in m ==> |m'| == |m| - 1
        ensures x !in m ==> |m'| == |m|
        decreases m
      {
        var m': map<X, Y> := map x': X {:trigger m[x']} {:trigger x' in m} | x' in m && x' != x :: m[x'];
        assert m'.Keys == m.Keys - {x};
        m'
      }

      function {:opaque} Restrict<X, Y>(m: map<X, Y>, xs: set<X>): (m': map<X, Y>)
        ensures m' == RemoveKeys(m, m.Keys - xs)
        decreases m, xs
      {
        map x: X {:trigger m[x]} {:trigger x in m} {:trigger x in xs} | x in xs && x in m :: m[x]
      }

      ghost predicate EqualOnKey<X, Y>(m: map<X, Y>, m': map<X, Y>, x: X)
        decreases m, m'
      {
        (x !in m && x !in m') || (x in m && x in m' && m[x] == m'[x])
      }

      ghost predicate IsSubset<X, Y>(m: map<X, Y>, m': map<X, Y>)
        decreases m, m'
      {
        m.Keys <= m'.Keys &&
        forall x: X {:trigger EqualOnKey(m, m', x)} {:trigger x in m} :: 
          x in m ==>
            EqualOnKey(m, m', x)
      }

      function {:opaque} Union<X, Y>(m: map<X, Y>, m': map<X, Y>): (r: map<X, Y>)
        ensures r.Keys == m.Keys + m'.Keys
        ensures forall x: X {:trigger r[x]} :: x in m' ==> r[x] == m'[x]
        ensures forall x: X {:trigger r[x]} :: x in m && x !in m' ==> r[x] == m[x]
        decreases m, m'
      {
        m + m'
      }

      lemma LemmaDisjointUnionSize<X, Y>(m: map<X, Y>, m': map<X, Y>)
        requires m.Keys !! m'.Keys
        ensures |Union(m, m')| == |m| + |m'|
        decreases m, m'
      {
        ghost var u := Union(m, m');
        assert |u.Keys| == |m.Keys| + |m'.Keys|;
      }

      ghost predicate {:opaque} Injective<X, Y>(m: map<X, Y>)
        decreases m
      {
        forall x: X, x': X {:trigger m[x], m[x']} :: 
          x != x' &&
          x in m &&
          x' in m ==>
            m[x] != m[x']
      }

      ghost function {:opaque} Invert<X, Y>(m: map<X, Y>): map<Y, X>
        decreases m
      {
        map y: Y {:trigger y in m.Values} | y in m.Values :: ghost var x: X :| x in m.Keys && m[x] == y; x
      }

      lemma LemmaInvertIsInjective<X, Y>(m: map<X, Y>)
        ensures Injective(Invert(m))
        decreases m
      {
        reveal Injective();
        reveal Invert();
      }

      ghost predicate {:opaque} Total<X(!new), Y>(m: map<X, Y>)
        decreases m
      {
        forall i: X {:trigger m[i]} {:trigger i in m} :: 
          i in m
      }

      ghost predicate {:opaque} Monotonic(m: map<int, int>)
        decreases m
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          x <= x' ==>
            m[x] <= m[x']
      }

      ghost predicate {:opaque} MonotonicFrom(m: map<int, int>, start: int)
        decreases m, start
      {
        forall x: int, x': int {:trigger m[x], m[x']} :: 
          x in m &&
          x' in m &&
          start <= x <= x' ==>
            m[x] <= m[x']
      }

      import opened Wrappers
    }

    module Seq {
      function First<T>(xs: seq<T>): T
        requires |xs| > 0
        decreases xs
      {
        xs[0]
      }

      function DropFirst<T>(xs: seq<T>): seq<T>
        requires |xs| > 0
        decreases xs
      {
        xs[1..]
      }

      function Last<T>(xs: seq<T>): T
        requires |xs| > 0
        decreases xs
      {
        xs[|xs| - 1]
      }

      function DropLast<T>(xs: seq<T>): seq<T>
        requires |xs| > 0
        decreases xs
      {
        xs[..|xs| - 1]
      }

      lemma LemmaLast<T>(xs: seq<T>)
        requires |xs| > 0
        ensures DropLast(xs) + [Last(xs)] == xs
        decreases xs
      {
      }

      lemma LemmaAppendLast<T>(xs: seq<T>, ys: seq<T>)
        requires 0 < |ys|
        ensures Last(xs + ys) == Last(ys)
        decreases xs, ys
      {
      }

      lemma LemmaConcatIsAssociative<T>(xs: seq<T>, ys: seq<T>, zs: seq<T>)
        ensures xs + (ys + zs) == xs + ys + zs == xs + ys + zs
        decreases xs, ys, zs
      {
      }

      lemma LemmaConcatIsAssociative2<T>(a: seq<T>, b: seq<T>, c: seq<T>, d: seq<T>)
        ensures a + b + c + d == a + (b + c + d)
        decreases a, b, c, d
      {
      }

      lemma EmptySequenceIsRightIdentity(l: seq)
        ensures l == l + []
        decreases l
      {
      }

      ghost predicate IsPrefix<T>(xs: seq<T>, ys: seq<T>)
        ensures IsPrefix(xs, ys) ==> |xs| <= |ys| && xs == ys[..|xs|]
        decreases xs, ys
      {
        xs <= ys
      }

      ghost predicate IsSuffix<T>(xs: seq<T>, ys: seq<T>)
        decreases xs, ys
      {
        |xs| <= |ys| &&
        xs == ys[|ys| - |xs|..]
      }

      lemma LemmaSplitAt<T>(xs: seq<T>, pos: nat)
        requires pos < |xs|
        ensures xs[..pos] + xs[pos..] == xs
        decreases xs, pos
      {
      }

      lemma LemmaElementFromSlice<T>(xs: seq<T>, xs': seq<T>, a: int, b: int, pos: nat)
        requires 0 <= a <= pos < b <= |xs|
        requires xs' == xs[a .. b]
        ensures pos - a < |xs'|
        ensures xs'[pos - a] == xs[pos]
        decreases xs, xs', a, b, pos
      {
      }

      lemma LemmaSliceOfSlice<T>(xs: seq<T>, s1: int, e1: int, s2: int, e2: int)
        requires 0 <= s1 <= e1 <= |xs|
        requires 0 <= s2 <= e2 <= e1 - s1
        ensures xs[s1 .. e1][s2 .. e2] == xs[s1 + s2 .. s1 + e2]
        decreases xs, s1, e1, s2, e2
      {
        ghost var r1 := xs[s1 .. e1];
        ghost var r2 := r1[s2 .. e2];
        ghost var r3 := xs[s1 + s2 .. s1 + e2];
        assert |r2| == |r3|;
        forall i: int {:trigger r2[i], r3[i]} | 0 <= i < |r2|
          ensures r2[i] == r3[i]
        {
        }
      }

      method ToArray<T>(xs: seq<T>) returns (a: array<T>)
        ensures fresh(a)
        ensures a.Length == |xs|
        ensures forall i: int {:trigger xs[i]} {:trigger a[i]} :: 0 <= i < |xs| ==> a[i] == xs[i]
        decreases xs
      {
        a := new T[|xs|] ((i: int) requires 0 <= i < |xs| => xs[i]);
      }

      function {:opaque} ToSet<T>(xs: seq<T>): set<T>
        decreases xs
      {
        set x: T {:trigger x in xs} | x in xs
      }

      lemma LemmaCardinalityOfSet<T>(xs: seq<T>)
        ensures |ToSet(xs)| <= |xs|
        decreases xs
      {
        reveal ToSet();
        if |xs| == 0 {
        } else {
          assert ToSet(xs) == ToSet(DropLast(xs)) + {Last(xs)};
          LemmaCardinalityOfSet(DropLast(xs));
        }
      }

      lemma LemmaCardinalityOfEmptySetIs0<T>(xs: seq<T>)
        ensures |ToSet(xs)| == 0 <==> |xs| == 0
        decreases xs
      {
        reveal ToSet();
        if |xs| != 0 {
          assert xs[0] in ToSet(xs);
        }
      }

      ghost predicate {:opaque} HasNoDuplicates<T>(xs: seq<T>)
        decreases xs
      {
        forall i: int, j: int {:trigger xs[i], xs[j]} :: 
          0 <= i < |xs| &&
          0 <= j < |xs| &&
          i != j ==>
            xs[i] != xs[j]
      }

      lemma {:timeLimitMultiplier 3} /*{:_rlimit 3000000}*/ LemmaNoDuplicatesInConcat<T>(xs: seq<T>, ys: seq<T>)
        requires HasNoDuplicates(xs)
        requires HasNoDuplicates(ys)
        requires multiset(xs) !! multiset(ys)
        ensures HasNoDuplicates(xs + ys)
        decreases xs, ys
      {
        reveal HasNoDuplicates();
        ghost var zs := xs + ys;
        if |zs| > 1 {
          assert forall i: int {:trigger zs[i]} :: 0 <= i < |xs| ==> zs[i] in multiset(xs);
          assert forall j: int {:trigger zs[j]} :: |xs| <= j < |zs| ==> zs[j] in multiset(ys);
          assert forall i: int, j: int {:trigger zs[i], zs[j]} :: i != j && 0 <= i < |xs| && |xs| <= j < |zs| ==> zs[i] != zs[j];
        }
      }

      lemma LemmaCardinalityOfSetNoDuplicates<T>(xs: seq<T>)
        requires HasNoDuplicates(xs)
        ensures |ToSet(xs)| == |xs|
        decreases xs
      {
        reveal HasNoDuplicates();
        reveal ToSet();
        if |xs| == 0 {
        } else {
          LemmaCardinalityOfSetNoDuplicates(DropLast(xs));
          assert ToSet(xs) == ToSet(DropLast(xs)) + {Last(xs)};
        }
      }

      lemma LemmaNoDuplicatesCardinalityOfSet<T>(xs: seq<T>)
        requires |ToSet(xs)| == |xs|
        ensures HasNoDuplicates(xs)
        decreases xs
      {
        reveal HasNoDuplicates();
        reveal ToSet();
        if |xs| == 0 {
        } else {
          assert xs == [First(xs)] + DropFirst(xs);
          assert ToSet(xs) == {First(xs)} + ToSet(DropFirst(xs));
          if First(xs) in DropFirst(xs) {
            assert ToSet(xs) == ToSet(DropFirst(xs));
            LemmaCardinalityOfSet(DropFirst(xs));
          } else {
            assert |ToSet(xs)| == 1 + |ToSet(DropFirst(xs))|;
            LemmaNoDuplicatesCardinalityOfSet(DropFirst(xs));
          }
        }
      }

      lemma LemmaMultisetHasNoDuplicates<T>(xs: seq<T>)
        requires HasNoDuplicates(xs)
        ensures forall x: T {:trigger multiset(xs)[x]} | x in multiset(xs) :: multiset(xs)[x] == 1
        decreases xs
      {
        if |xs| == 0 {
        } else {
          assert xs == DropLast(xs) + [Last(xs)];
          assert Last(xs) !in DropLast(xs) by {
            reveal HasNoDuplicates();
          }
          assert HasNoDuplicates(DropLast(xs)) by {
            reveal HasNoDuplicates();
          }
          LemmaMultisetHasNoDuplicates(DropLast(xs));
        }
      }

      function {:opaque} IndexOf<T(==)>(xs: seq<T>, v: T): (i: nat)
        requires v in xs
        ensures i < |xs| && xs[i] == v
        ensures forall j: int {:trigger xs[j]} :: 0 <= j < i ==> xs[j] != v
        decreases xs
      {
        if xs[0] == v then
          0
        else
          1 + IndexOf(xs[1..], v)
      }

      function {:opaque} IndexOfOption<T(==)>(xs: seq<T>, v: T): (o: Option<nat>)
        ensures if o.Some? then o.value < |xs| && xs[o.value] == v && forall j: int {:trigger xs[j]} :: 0 <= j < o.value ==> xs[j] != v else v !in xs
        decreases xs
      {
        if |xs| == 0 then
          None()
        else if xs[0] == v then
          Some(0)
        else
          var o': Option<nat> := IndexOfOption(xs[1..], v); if o'.Some? then Some(o'.value + 1) else None()
      }

      function {:opaque} LastIndexOf<T(==)>(xs: seq<T>, v: T): (i: nat)
        requires v in xs
        ensures i < |xs| && xs[i] == v
        ensures forall j: int {:trigger xs[j]} :: i < j < |xs| ==> xs[j] != v
        decreases xs
      {
        if xs[|xs| - 1] == v then
          |xs| - 1
        else
          LastIndexOf(xs[..|xs| - 1], v)
      }

      function {:opaque} LastIndexOfOption<T(==)>(xs: seq<T>, v: T): (o: Option<nat>)
        ensures if o.Some? then o.value < |xs| && xs[o.value] == v && forall j: int {:trigger xs[j]} :: o.value < j < |xs| ==> xs[j] != v else v !in xs
        decreases xs
      {
        if |xs| == 0 then
          None()
        else if xs[|xs| - 1] == v then
          Some(|xs| - 1)
        else
          LastIndexOfOption(xs[..|xs| - 1], v)
      }

      function {:opaque} Remove<T>(xs: seq<T>, pos: nat): (ys: seq<T>)
        requires pos < |xs|
        ensures |ys| == |xs| - 1
        ensures forall i: int {:trigger ys[i], xs[i]} | 0 <= i < pos :: ys[i] == xs[i]
        ensures forall i: int {:trigger ys[i]} | pos <= i < |xs| - 1 :: ys[i] == xs[i + 1]
        decreases xs, pos
      {
        xs[..pos] + xs[pos + 1..]
      }

      function {:opaque} RemoveValue<T(==)>(xs: seq<T>, v: T): (ys: seq<T>)
        ensures v !in xs ==> xs == ys
        ensures v in xs ==> |multiset(ys)| == |multiset(xs)| - 1
        ensures v in xs ==> multiset(ys)[v] == multiset(xs)[v] - 1
        ensures HasNoDuplicates(xs) ==> HasNoDuplicates(ys) && ToSet(ys) == ToSet(xs) - {v}
        decreases xs
      {
        reveal HasNoDuplicates();
        reveal ToSet();
        if v !in xs then
          xs
        else
          var i: nat := IndexOf(xs, v); assert xs == xs[..i] + [v] + xs[i + 1..]; xs[..i] + xs[i + 1..]
      }

      function {:opaque} Insert<T>(xs: seq<T>, a: T, pos: nat): seq<T>
        requires pos <= |xs|
        ensures |Insert(xs, a, pos)| == |xs| + 1
        ensures forall i: int {:trigger Insert(xs, a, pos)[i], xs[i]} :: 0 <= i < pos ==> Insert(xs, a, pos)[i] == xs[i]
        ensures forall i: int {:trigger xs[i]} :: pos <= i < |xs| ==> Insert(xs, a, pos)[i + 1] == xs[i]
        ensures Insert(xs, a, pos)[pos] == a
        ensures multiset(Insert(xs, a, pos)) == multiset(xs) + multiset{a}
        decreases xs, pos
      {
        assert xs == xs[..pos] + xs[pos..];
        xs[..pos] + [a] + xs[pos..]
      }

      function {:opaque} Reverse<T>(xs: seq<T>): (ys: seq<T>)
        ensures |ys| == |xs|
        ensures forall i: int {:trigger ys[i]} {:trigger xs[|xs| - i - 1]} :: 0 <= i < |xs| ==> ys[i] == xs[|xs| - i - 1]
        decreases xs
      {
        if xs == [] then
          []
        else
          [xs[|xs| - 1]] + Reverse(xs[0 .. |xs| - 1])
      }

      function {:opaque} Repeat<T>(v: T, length: nat): (xs: seq<T>)
        ensures |xs| == length
        ensures forall i: nat {:trigger xs[i]} | i < |xs| :: xs[i] == v
        decreases length
      {
        if length == 0 then
          []
        else
          [v] + Repeat(v, length - 1)
      }

      function {:opaque} Unzip<A, B>(xs: seq<(A, B)>): (seq<A>, seq<B>)
        ensures |Unzip(xs).0| == |Unzip(xs).1| == |xs|
        ensures forall i: int {:trigger Unzip(xs).0[i]} {:trigger Unzip(xs).1[i]} :: 0 <= i < |xs| ==> (Unzip(xs).0[i], Unzip(xs).1[i]) == xs[i]
        decreases xs
      {
        if |xs| == 0 then
          ([], [])
        else
          var (a: seq<A>, b: seq<B>) := Unzip(DropLast(xs)); (a + [Last(xs).0], b + [Last(xs).1])
      }

      function {:opaque} Zip<A, B>(xs: seq<A>, ys: seq<B>): seq<(A, B)>
        requires |xs| == |ys|
        ensures |Zip(xs, ys)| == |xs|
        ensures forall i: int {:trigger Zip(xs, ys)[i]} :: 0 <= i < |Zip(xs, ys)| ==> Zip(xs, ys)[i] == (xs[i], ys[i])
        ensures Unzip(Zip(xs, ys)).0 == xs
        ensures Unzip(Zip(xs, ys)).1 == ys
        decreases xs, ys
      {
        if |xs| == 0 then
          []
        else
          Zip(DropLast(xs), DropLast(ys)) + [(Last(xs), Last(ys))]
      }

      lemma /*{:_induction xs}*/ LemmaZipOfUnzip<A, B>(xs: seq<(A, B)>)
        ensures Zip(Unzip(xs).0, Unzip(xs).1) == xs
        decreases xs
      {
      }

      lemma MembershipImpliesIndexing<T>(p: T -> bool, xs: seq<T>)
        requires forall t: T {:trigger p(t)} {:trigger t in xs} | t in xs :: p(t)
        ensures forall i: int {:trigger xs[i]} | 0 <= i < |xs| :: p(xs[i])
        decreases xs
      {
      }

      function {:opaque} Max(xs: seq<int>): int
        requires 0 < |xs|
        ensures forall k: int {:trigger k in xs} :: k in xs ==> Max(xs) >= k
        ensures Max(xs) in xs
        decreases xs
      {
        assert xs == [xs[0]] + xs[1..];
        if |xs| == 1 then
          xs[0]
        else
          Math.Max(xs[0], Max(xs[1..]))
      }

      lemma /*{:_induction xs, ys}*/ LemmaMaxOfConcat(xs: seq<int>, ys: seq<int>)
        requires 0 < |xs| && 0 < |ys|
        ensures Max(xs + ys) >= Max(xs)
        ensures Max(xs + ys) >= Max(ys)
        ensures forall i: int {:trigger i in [Max(xs + ys)]} :: i in xs + ys ==> Max(xs + ys) >= i
        decreases xs, ys
      {
        reveal Max();
        if |xs| == 1 {
        } else {
          assert xs[1..] + ys == (xs + ys)[1..];
          LemmaMaxOfConcat(xs[1..], ys);
        }
      }

      function {:opaque} Min(xs: seq<int>): int
        requires 0 < |xs|
        ensures forall k: int {:trigger k in xs} :: k in xs ==> Min(xs) <= k
        ensures Min(xs) in xs
        decreases xs
      {
        assert xs == [xs[0]] + xs[1..];
        if |xs| == 1 then
          xs[0]
        else
          Math.Min(xs[0], Min(xs[1..]))
      }

      lemma /*{:_induction xs, ys}*/ LemmaMinOfConcat(xs: seq<int>, ys: seq<int>)
        requires 0 < |xs| && 0 < |ys|
        ensures Min(xs + ys) <= Min(xs)
        ensures Min(xs + ys) <= Min(ys)
        ensures forall i: int {:trigger i in xs + ys} :: i in xs + ys ==> Min(xs + ys) <= i
        decreases xs, ys
      {
        reveal Min();
        if |xs| == 1 {
        } else {
          assert xs[1..] + ys == (xs + ys)[1..];
          LemmaMinOfConcat(xs[1..], ys);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSubseqMax(xs: seq<int>, from: nat, to: nat)
        requires from < to <= |xs|
        ensures Max(xs[from .. to]) <= Max(xs)
        decreases xs, from, to
      {
        ghost var subseq := xs[from .. to];
        ghost var subseqMax := Max(subseq);
        assert forall x: int {:trigger x in xs[from..]} {:trigger x in subseq} | x in subseq :: x in xs[from..];
        assert subseqMax in subseq;
        assert subseqMax in xs;
      }

      lemma /*{:_induction xs}*/ LemmaSubseqMin(xs: seq<int>, from: nat, to: nat)
        requires from < to <= |xs|
        ensures Min(xs[from .. to]) >= Min(xs)
        decreases xs, from, to
      {
        ghost var subseq := xs[from .. to];
        ghost var subseqMin := Min(subseq);
        assert forall x: int {:trigger x in xs[from..]} {:trigger x in subseq} | x in subseq :: x in xs[from..];
        assert subseqMin in subseq;
        assert subseqMin in xs;
      }

      function Flatten<T>(xs: seq<seq<T>>): seq<T>
        decreases |xs|
      {
        if |xs| == 0 then
          []
        else
          xs[0] + Flatten(xs[1..])
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys}*/ LemmaFlattenConcat<T>(xs: seq<seq<T>>, ys: seq<seq<T>>)
        ensures Flatten(xs + ys) == Flatten(xs) + Flatten(ys)
        decreases xs, ys
      {
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc == {
            Flatten(xs + ys);
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            xs[0] + Flatten(xs[1..] + ys);
            xs[0] + Flatten(xs[1..]) + Flatten(ys);
            Flatten(xs) + Flatten(ys);
          }
        }
      }

      function FlattenReverse<T>(xs: seq<seq<T>>): seq<T>
        decreases |xs|
      {
        if |xs| == 0 then
          []
        else
          FlattenReverse(DropLast(xs)) + Last(xs)
      }

      lemma /*{:_induction xs, ys}*/ LemmaFlattenReverseConcat<T>(xs: seq<seq<T>>, ys: seq<seq<T>>)
        ensures FlattenReverse(xs + ys) == FlattenReverse(xs) + FlattenReverse(ys)
        decreases xs, ys
      {
        if |ys| == 0 {
          assert FlattenReverse(ys) == [];
          assert xs + ys == xs;
        } else {
          calc == {
            FlattenReverse(xs + ys);
            {
              assert Last(xs + ys) == Last(ys);
              assert DropLast(xs + ys) == xs + DropLast(ys);
            }
            FlattenReverse(xs + DropLast(ys)) + Last(ys);
            FlattenReverse(xs) + FlattenReverse(DropLast(ys)) + Last(ys);
            FlattenReverse(xs) + FlattenReverse(ys);
          }
        }
      }

      lemma /*{:_induction xs}*/ LemmaFlattenAndFlattenReverseAreEquivalent<T>(xs: seq<seq<T>>)
        ensures Flatten(xs) == FlattenReverse(xs)
        decreases xs
      {
        if |xs| == 0 {
        } else {
          calc == {
            FlattenReverse(xs);
            FlattenReverse(DropLast(xs)) + Last(xs);
            {
              LemmaFlattenAndFlattenReverseAreEquivalent(DropLast(xs));
            }
            Flatten(DropLast(xs)) + Last(xs);
            Flatten(DropLast(xs)) + Flatten([Last(xs)]);
            {
              LemmaFlattenConcat(DropLast(xs), [Last(xs)]);
              assert xs == DropLast(xs) + [Last(xs)];
            }
            Flatten(xs);
          }
        }
      }

      lemma /*{:_induction xs}*/ LemmaFlattenLengthGeSingleElementLength<T>(xs: seq<seq<T>>, i: int)
        requires 0 <= i < |xs|
        ensures |FlattenReverse(xs)| >= |xs[i]|
        decreases xs, i
      {
        if i < |xs| - 1 {
          LemmaFlattenLengthGeSingleElementLength(xs[..|xs| - 1], i);
        }
      }

      lemma /*{:_induction xs}*/ LemmaFlattenLengthLeMul<T>(xs: seq<seq<T>>, j: int)
        requires forall i: int {:trigger xs[i]} | 0 <= i < |xs| :: |xs[i]| <= j
        ensures |FlattenReverse(xs)| <= |xs| * j
        decreases xs, j
      {
        if |xs| == 0 {
        } else {
          LemmaFlattenLengthLeMul(xs[..|xs| - 1], j);
          assert |FlattenReverse(xs[..|xs| - 1])| <= (|xs| - 1) * j;
        }
      }

      function {:opaque} Map<T, R>(f: T ~> R, xs: seq<T>): (result: seq<R>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        reads set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o
        ensures |result| == |xs|
        ensures forall i: int {:trigger result[i]} :: 0 <= i < |xs| ==> result[i] == f(xs[i])
        decreases set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o, xs
      {
        if |xs| == 0 then
          []
        else
          [f(xs[0])] + Map(f, xs[1..])
      }

      function {:opaque} MapWithResult<T, R, E>(f: T ~> Result<R, E>, xs: seq<T>): (result: Result<seq<R>, E>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        reads set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o
        ensures result.Success? ==> |result.value| == |xs| && forall i: int {:trigger result.value[i]} {:trigger xs[i]} :: (0 <= i < |xs| ==> f(xs[i]).Success?) && (0 <= i < |xs| ==> result.value[i] == f(xs[i]).value)
        decreases set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o, xs
      {
        if |xs| == 0 then
          Success([])
        else
          var head: R :- f(xs[0]); var tail: seq<R> :- MapWithResult(f, xs[1..]); Success([head] + tail)
      }

      lemma {:opaque} {:rlimit 1000000} /*{:_induction f, xs, ys}*/ LemmaMapDistributesOverConcat<T, R>(f: T ~> R, xs: seq<T>, ys: seq<T>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        requires forall j: int {:trigger ys[j]} :: 0 <= j < |ys| ==> f.requires(ys[j])
        ensures Map(f, xs + ys) == Map(f, xs) + Map(f, ys)
        decreases xs, ys
      {
        reveal Map();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc {
            Map(f, xs + ys);
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            Map(f, [xs[0]]) + Map(f, xs[1..] + ys);
            Map(f, [xs[0]]) + Map(f, xs[1..]) + Map(f, ys);
            {
              assert [(xs + ys)[0]] + xs[1..] + ys == xs + ys;
            }
            Map(f, xs) + Map(f, ys);
          }
        }
      }

      function {:opaque} Filter<T>(f: T ~> bool, xs: seq<T>): (result: seq<T>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        reads set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o
        ensures |result| <= |xs|
        ensures forall i: nat {:trigger result[i]} :: i < |result| && f.requires(result[i]) ==> f(result[i])
        decreases set i: int, o: object? {:trigger o in f.reads(xs[i])} | 0 <= i < |xs| && o in f.reads(xs[i]) :: o, xs
      {
        if |xs| == 0 then
          []
        else
          (if f(xs[0]) then [xs[0]] else []) + Filter(f, xs[1..])
      }

      lemma {:opaque} {:vcs_split_on_every_assert} /*{:_induction f, xs, ys}*/ LemmaFilterDistributesOverConcat<T(!new)>(f: T ~> bool, xs: seq<T>, ys: seq<T>)
        requires forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> f.requires(xs[i])
        requires forall j: int {:trigger ys[j]} :: 0 <= j < |ys| ==> f.requires(ys[j])
        ensures Filter(f, xs + ys) == Filter(f, xs) + Filter(f, ys)
        decreases xs, ys
      {
        reveal Filter();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc {
            Filter(f, xs + ys);
            {
              assert {:split_here} (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            Filter(f, [xs[0]]) + Filter(f, xs[1..] + ys);
            Filter(f, [xs[0]]) + (Filter(f, xs[1..]) + Filter(f, ys));
            {
              assert {:split_here} [(xs + ys)[0]] + (xs[1..] + ys) == xs + ys;
            }
            Filter(f, xs) + Filter(f, ys);
          }
        }
      }

      function {:opaque} FoldLeft<A, T>(f: (A, T) -> A, init: A, xs: seq<T>): A
        decreases xs
      {
        if |xs| == 0 then
          init
        else
          FoldLeft(f, f(init, xs[0]), xs[1..])
      }

      lemma {:opaque} /*{:_induction f, xs, ys}*/ LemmaFoldLeftDistributesOverConcat<A, T>(f: (A, T) -> A, init: A, xs: seq<T>, ys: seq<T>)
        ensures FoldLeft(f, init, xs + ys) == FoldLeft(f, FoldLeft(f, init, xs), ys)
        decreases xs, ys
      {
        reveal FoldLeft();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          assert |xs| >= 1;
          assert ([xs[0]] + xs[1..] + ys)[0] == xs[0];
          calc {
            FoldLeft(f, FoldLeft(f, init, xs), ys);
            FoldLeft(f, FoldLeft(f, f(init, xs[0]), xs[1..]), ys);
            {
              LemmaFoldLeftDistributesOverConcat(f, f(init, xs[0]), xs[1..], ys);
            }
            FoldLeft(f, f(init, xs[0]), xs[1..] + ys);
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            FoldLeft(f, init, xs + ys);
          }
        }
      }

      ghost predicate InvFoldLeft<A(!new), B(!new)>(inv: (B, seq<A>) -> bool, stp: (B, A, B) -> bool)
      {
        forall x: A, xs: seq<A>, b: B, b': B {:trigger stp(b, x, b'), [x] + xs} :: 
          inv(b, [x] + xs) &&
          stp(b, x, b') ==>
            inv(b', xs)
      }

      lemma /*{:_induction f, xs}*/ LemmaInvFoldLeft<A, B>(inv: (B, seq<A>) -> bool, stp: (B, A, B) -> bool, f: (B, A) -> B, b: B, xs: seq<A>)
        requires InvFoldLeft(inv, stp)
        requires forall b: B, a: A {:trigger f(b, a)} :: stp(b, a, f(b, a))
        requires inv(b, xs)
        ensures inv(FoldLeft(f, b, xs), [])
        decreases xs
      {
        reveal FoldLeft();
        if xs == [] {
        } else {
          assert [xs[0]] + xs[1..] == xs;
          LemmaInvFoldLeft(inv, stp, f, f(b, xs[0]), xs[1..]);
        }
      }

      function {:opaque} FoldRight<A, T>(f: (T, A) -> A, xs: seq<T>, init: A): A
        decreases xs
      {
        if |xs| == 0 then
          init
        else
          f(xs[0], FoldRight(f, xs[1..], init))
      }

      lemma {:opaque} /*{:_induction f, xs, ys}*/ LemmaFoldRightDistributesOverConcat<A, T>(f: (T, A) -> A, init: A, xs: seq<T>, ys: seq<T>)
        ensures FoldRight(f, xs + ys, init) == FoldRight(f, xs, FoldRight(f, ys, init))
        decreases xs, ys
      {
        reveal FoldRight();
        if |xs| == 0 {
          assert xs + ys == ys;
        } else {
          calc {
            FoldRight(f, xs, FoldRight(f, ys, init));
            f(xs[0], FoldRight(f, xs[1..], FoldRight(f, ys, init)));
            f(xs[0], FoldRight(f, xs[1..] + ys, init));
            {
              assert (xs + ys)[0] == xs[0];
              assert (xs + ys)[1..] == xs[1..] + ys;
            }
            FoldRight(f, xs + ys, init);
          }
        }
      }

      ghost predicate InvFoldRight<A(!new), B(!new)>(inv: (seq<A>, B) -> bool, stp: (A, B, B) -> bool)
      {
        forall x: A, xs: seq<A>, b: B, b': B {:trigger [x] + xs, stp(x, b, b')} :: 
          inv(xs, b) &&
          stp(x, b, b') ==>
            inv([x] + xs, b')
      }

      lemma /*{:_induction f, xs}*/ LemmaInvFoldRight<A, B>(inv: (seq<A>, B) -> bool, stp: (A, B, B) -> bool, f: (A, B) -> B, b: B, xs: seq<A>)
        requires InvFoldRight(inv, stp)
        requires forall a: A, b: B {:trigger f(a, b)} :: stp(a, b, f(a, b))
        requires inv([], b)
        ensures inv(xs, FoldRight(f, xs, b))
        decreases xs
      {
        reveal FoldRight();
        if xs == [] {
        } else {
          assert [xs[0]] + xs[1..] == xs;
        }
      }

      ghost function SetToSeqSpec<T>(s: set<T>): (xs: seq<T>)
        ensures multiset(s) == multiset(xs)
        decreases s
      {
        if s == {} then
          []
        else
          ghost var x: T :| x in s; [x] + SetToSeqSpec(s - {x})
      }

      method SetToSeq<T>(s: set<T>) returns (xs: seq<T>)
        ensures multiset(s) == multiset(xs)
        decreases s
      {
        xs := [];
        var left: set<T> := s;
        while left != {}
          invariant multiset(left) + multiset(xs) == multiset(s)
          decreases left
        {
          var x :| x in left;
          left := left - {x};
          xs := xs + [x];
        }
      }

      lemma SortedUnique<T>(xs: seq<T>, ys: seq<T>, R: (T, T) -> bool)
        requires SortedBy(R, xs)
        requires SortedBy(R, ys)
        requires TotalOrdering(R)
        requires multiset(xs) == multiset(ys)
        ensures xs == ys
        decreases xs, ys
      {
        if xs == [] {
          assert multiset(xs) == multiset{};
          assert multiset(ys) == multiset{};
          assert ys == [];
        } else {
          assert xs == [xs[0]] + xs[1..];
          assert ys == [ys[0]] + ys[1..];
          assert multiset(xs[1..]) == multiset(xs) - multiset{xs[0]};
          assert multiset(ys[1..]) == multiset(ys) - multiset{ys[0]};
          assert multiset(xs[1..]) == multiset(ys[1..]);
          SortedUnique(xs[1..], ys[1..], R);
        }
      }

      ghost function SetToSortedSeqSpec<T>(s: set<T>, R: (T, T) -> bool): (xs: seq<T>)
        requires TotalOrdering(R)
        ensures multiset(s) == multiset(xs)
        ensures SortedBy(R, xs)
        decreases s
      {
        MergeSortBy(R, SetToSeqSpec(s))
      }

      method SetToSortedSeq<T>(s: set<T>, R: (T, T) -> bool) returns (xs: seq<T>)
        requires TotalOrdering(R)
        ensures multiset(s) == multiset(xs)
        ensures SortedBy(R, xs)
        decreases s
      {
        xs := SetToSeq(s);
        xs := MergeSortBy(R, xs);
        SortedUnique(xs, SetToSortedSeqSpec(s, R), R);
      }

      function MergeSortBy<T>(lessThanOrEq: (T, T) -> bool, a: seq<T>): (result: seq<T>)
        requires TotalOrdering(lessThanOrEq)
        ensures multiset(a) == multiset(result)
        ensures SortedBy(lessThanOrEq, result)
        decreases a
      {
        if |a| <= 1 then
          a
        else
          var splitIndex: int := |a| / 2; var left: seq<T>, right: seq<T> := a[..splitIndex], a[splitIndex..]; assert a == left + right; var leftSorted: seq<T> := MergeSortBy(lessThanOrEq, left); var rightSorted: seq<T> := MergeSortBy(lessThanOrEq, right); MergeSortedWith(leftSorted, rightSorted, lessThanOrEq)
      }

      function {:tailrecursion} MergeSortedWith<T>(left: seq<T>, right: seq<T>, lessThanOrEq: (T, T) -> bool): (result: seq<T>)
        requires SortedBy(lessThanOrEq, left)
        requires SortedBy(lessThanOrEq, right)
        requires TotalOrdering(lessThanOrEq)
        ensures multiset(left + right) == multiset(result)
        ensures SortedBy(lessThanOrEq, result)
        decreases left, right
      {
        if |left| == 0 then
          right
        else if |right| == 0 then
          left
        else if lessThanOrEq(left[0], right[0]) then
          LemmaNewFirstElementStillSortedBy(left[0], MergeSortedWith(left[1..], right, lessThanOrEq), lessThanOrEq);
          assert left == [left[0]] + left[1..];
          [left[0]] + MergeSortedWith(left[1..], right, lessThanOrEq)
        else
          LemmaNewFirstElementStillSortedBy(right[0], MergeSortedWith(left, right[1..], lessThanOrEq), lessThanOrEq); assert right == [right[0]] + right[1..]; [right[0]] + MergeSortedWith(left, right[1..], lessThanOrEq)
      }

      lemma LemmaNewFirstElementStillSortedBy<T>(newFirst: T, s: seq<T>, lessOrEqual: (T, T) -> bool)
        requires SortedBy(lessOrEqual, s)
        requires |s| == 0 || lessOrEqual(newFirst, s[0])
        requires TotalOrdering(lessOrEqual)
        ensures SortedBy(lessOrEqual, [newFirst] + s)
        decreases s
      {
      }

      import opened Wrappers

      import opened Relations

      import Math
    }

    module Set {
      lemma LemmaSubset<T>(x: set<T>, y: set<T>)
        requires forall e: T {:trigger e in y} :: e in x ==> e in y
        ensures x <= y
        decreases x, y
      {
      }

      lemma LemmaSubsetSize<T>(x: set<T>, y: set<T>)
        ensures x < y ==> |x| < |y|
        ensures x <= y ==> |x| <= |y|
        decreases x, y
      {
        if x != {} {
          ghost var e :| e in x;
          LemmaSubsetSize(x - {e}, y - {e});
        }
      }

      lemma LemmaSubsetEquality<T>(x: set<T>, y: set<T>)
        requires x <= y
        requires |x| == |y|
        ensures x == y
        decreases x, y
      {
        if x == {} {
        } else {
          ghost var e :| e in x;
          LemmaSubsetEquality(x - {e}, y - {e});
        }
      }

      lemma LemmaSingletonSize<T>(x: set<T>, e: T)
        requires x == {e}
        ensures |x| == 1
        decreases x
      {
      }

      lemma LemmaSingletonEquality<T>(x: set<T>, a: T, b: T)
        requires |x| == 1
        requires a in x
        requires b in x
        ensures a == b
        decreases x
      {
        if a != b {
          assert {a} < x;
          LemmaSubsetSize({a}, x);
          assert false;
        }
      }

      ghost predicate IsSingleton<T>(s: set<T>)
        decreases s
      {
        (exists x: T {:trigger x in s} :: 
          x in s) &&
        forall x: T, y: T {:trigger y in s, x in s} | x in s && y in s :: 
          x == y
      }

      lemma LemmaIsSingleton<T>(s: set<T>)
        ensures |s| == 1 <==> IsSingleton(s)
        decreases s
      {
        if |s| == 1 {
          forall x: T, y: T | x in s && y in s
            ensures x == y
          {
            LemmaSingletonEquality(s, x, y);
          }
        }
        if IsSingleton(s) {
          ghost var x :| x in s;
          assert s == {x};
          assert |s| == 1;
        }
      }

      ghost function ExtractFromNonEmptySet<T>(s: set<T>): (x: T)
        requires |s| != 0
        ensures x in s
        decreases s
      {
        ghost var x: T :| x in s;
        x
      }

      function ExtractFromSingleton<T>(s: set<T>): (x: T)
        requires |s| == 1
        ensures s == {x}
        decreases s
      {
        LemmaIsSingleton(s);
        var x: T :| x in s;
        x
      }

      lemma LemmaMapSize<X(!new), Y>(xs: set<X>, ys: set<Y>, f: X --> Y)
        requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
        requires Injective(f)
        requires forall x: X {:trigger f(x)} :: x in xs <==> f(x) in ys
        requires forall y: Y {:trigger y in ys} :: y in ys ==> exists x: X {:trigger f(x)} {:trigger x in xs} :: x in xs && y == f(x)
        ensures |xs| == |ys|
        decreases xs, ys
      {
        if xs != {} {
          ghost var x :| x in xs;
          ghost var xs' := xs - {x};
          ghost var ys' := ys - {f(x)};
          LemmaMapSize(xs', ys', f);
        }
      }

      function {:opaque} Map<X(!new), Y>(f: X --> Y, xs: set<X>): (ys: set<Y>)
        requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
        requires Injective(f)
        reads set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
        ensures forall x: X {:trigger f(x)} :: x in xs <==> f(x) in ys
        ensures |xs| == |ys|
        decreases set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj, xs
      {
        var ys: set<Y> := set x: X {:trigger f(x)} {:trigger x in xs} | x in xs :: f(x);
        LemmaMapSize(xs, ys, f);
        ys
      }

      lemma LemmaFilterSize<X>(xs: set<X>, ys: set<X>, f: X ~> bool)
        requires forall x: X {:trigger f.requires(x)} {:trigger x in xs} :: x in xs ==> f.requires(x)
        requires forall y: X {:trigger f(y)} {:trigger y in xs} :: (y in ys ==> y in xs) && (y in ys ==> f(y))
        ensures |ys| <= |xs|
        decreases xs, ys
      {
        if ys != {} {
          ghost var y :| y in ys;
          ghost var xs' := xs - {y};
          ghost var ys' := ys - {y};
          LemmaFilterSize(xs', ys', f);
        }
      }

      function {:opaque} Filter<X(!new)>(f: X ~> bool, xs: set<X>): (ys: set<X>)
        requires forall x: X {:trigger f.requires(x)} {:trigger x in xs} :: x in xs ==> f.requires(x)
        reads set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o
        ensures forall y: X {:trigger f(y)} {:trigger y in xs} :: y in ys <==> y in xs && f(y)
        ensures |ys| <= |xs|
        decreases set x: X, o: object? {:trigger o in f.reads(x)} | x in xs && o in f.reads(x) :: o, xs
      {
        var ys: set<X> := set x: X {:trigger f(x)} {:trigger x in xs} | x in xs && f(x);
        LemmaFilterSize(xs, ys, f);
        ys
      }

      lemma LemmaUnionSize<X>(xs: set<X>, ys: set<X>)
        ensures |xs + ys| >= |xs|
        ensures |xs + ys| >= |ys|
        decreases xs, ys
      {
        if ys == {} {
        } else {
          ghost var y :| y in ys;
          if y in xs {
            ghost var xr := xs - {y};
            ghost var yr := ys - {y};
            assert xr + yr == xs + ys - {y};
            LemmaUnionSize(xr, yr);
          } else {
            ghost var yr := ys - {y};
            assert xs + yr == xs + ys - {y};
            LemmaUnionSize(xs, yr);
          }
        }
      }

      function {:opaque} SetRange(a: int, b: int): (s: set<int>)
        requires a <= b
        ensures forall i: int {:trigger i in s} :: a <= i < b <==> i in s
        ensures |s| == b - a
        decreases b - a
      {
        if a == b then
          {}
        else
          {a} + SetRange(a + 1, b)
      }

      function {:opaque} SetRangeZeroBound(n: int): (s: set<int>)
        requires n >= 0
        ensures forall i: int {:trigger i in s} :: 0 <= i < n <==> i in s
        ensures |s| == n
        decreases n
      {
        SetRange(0, n)
      }

      lemma LemmaBoundedSetSize(x: set<int>, a: int, b: int)
        requires forall i: int {:trigger i in x} :: (i in x ==> a <= i) && (i in x ==> i < b)
        requires a <= b
        ensures |x| <= b - a
        decreases x, a, b
      {
        ghost var range := SetRange(a, b);
        forall e: int {:trigger e in range} {:trigger e in x} | e in x
          ensures e in range
        {
        }
        assert x <= range;
        LemmaSubsetSize(x, range);
      }

      lemma LemmaGreatestImpliesMaximal<T(!new)>(R: (T, T) -> bool, max: T, s: set<T>)
        requires IsGreatest(R, max, s)
        ensures IsMaximal(R, max, s)
        decreases s
      {
      }

      lemma LemmaLeastImpliesMinimal<T(!new)>(R: (T, T) -> bool, min: T, s: set<T>)
        requires IsLeast(R, min, s)
        ensures IsMinimal(R, min, s)
        decreases s
      {
      }

      lemma LemmaMaximalEquivalentGreatest<T(!new)>(R: (T, T) -> bool, max: T, s: set<T>)
        requires TotalOrdering(R)
        ensures IsGreatest(R, max, s) <==> IsMaximal(R, max, s)
        decreases s
      {
      }

      lemma LemmaMinimalEquivalentLeast<T(!new)>(R: (T, T) -> bool, min: T, s: set<T>)
        requires TotalOrdering(R)
        ensures IsLeast(R, min, s) <==> IsMinimal(R, min, s)
        decreases s
      {
      }

      lemma LemmaLeastIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires PartialOrdering(R)
        ensures forall min: T, min': T {:trigger IsLeast(R, min', s), IsLeast(R, min, s)} | IsLeast(R, min, s) && IsLeast(R, min', s) :: min == min'
        decreases s
      {
      }

      lemma LemmaGreatestIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires PartialOrdering(R)
        ensures forall max: T, max': T {:trigger IsGreatest(R, max', s), IsGreatest(R, max, s)} | IsGreatest(R, max, s) && IsGreatest(R, max', s) :: max == max'
        decreases s
      {
      }

      lemma LemmaMinimalIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires TotalOrdering(R)
        ensures forall min: T, min': T {:trigger IsMinimal(R, min', s), IsMinimal(R, min, s)} | IsMinimal(R, min, s) && IsMinimal(R, min', s) :: min == min'
        decreases s
      {
      }

      lemma LemmaMaximalIsUnique<T(!new)>(R: (T, T) -> bool, s: set<T>)
        requires TotalOrdering(R)
        ensures forall max: T, max': T {:trigger IsMaximal(R, max', s), IsMaximal(R, max, s)} | IsMaximal(R, max, s) && IsMaximal(R, max', s) :: max == max'
        decreases s
      {
      }

      lemma LemmaFindUniqueMinimal<T(!new)>(R: (T, T) -> bool, s: set<T>) returns (min: T)
        requires |s| > 0 && TotalOrdering(R)
        ensures IsMinimal(R, min, s) && forall min': T {:trigger IsMinimal(R, min', s)} | IsMinimal(R, min', s) :: min == min'
        decreases s
      {
        ghost var x :| x in s;
        if s == {x} {
          min := x;
        } else {
          ghost var min' := LemmaFindUniqueMinimal(R, s - {x});
          if
          case R(min', x) =>
            min := min';
          case R(x, min') =>
            min := x;
        }
      }

      lemma LemmaFindUniqueMaximal<T(!new)>(R: (T, T) -> bool, s: set<T>) returns (max: T)
        requires |s| > 0 && TotalOrdering(R)
        ensures IsMaximal(R, max, s) && forall max': T {:trigger IsMaximal(R, max', s)} | IsMaximal(R, max', s) :: max == max'
        decreases s
      {
        ghost var x :| x in s;
        if s == {x} {
          max := x;
        } else {
          ghost var max' := LemmaFindUniqueMaximal(R, s - {x});
          if
          case R(max', x) =>
            max := x;
          case R(x, max') =>
            max := max';
        }
      }

      import opened Functions

      import opened Relations
    }
  }

  replaceable module Concurrent {

    import opened Wrappers
    class Lock {
      ghost var isLocked: bool

      constructor ()
        ensures !isLocked

      method Lock()
        requires !isLocked
        reads this
        modifies this
        ensures isLocked

      method Unlock()
        requires isLocked
        reads this
        modifies this
        ensures !isLocked
    }

    class AtomicBox<T> {
      ghost const inv: T -> bool

      method Get() returns (t: T)
        reads {}
        ensures inv(t)

      method Put(t: T)
        requires inv(t)
        reads {}
    }

    class MutableMap<K(==), V(==)> {
      ghost const inv: (K, V) -> bool

      method Keys() returns (keys: set<K>)
        reads {}
        ensures forall k: K {:trigger k in keys} | k in keys :: exists v: V {:trigger inv(k, v)} :: inv(k, v)

      method HasKey(k: K) returns (used: bool)
        reads {}
        ensures used ==> exists v: V {:trigger inv(k, v)} :: inv(k, v)

      method Values() returns (values: set<V>)
        reads {}
        ensures forall v: V {:trigger v in values} | v in values :: exists k: K {:trigger inv(k, v)} :: inv(k, v)

      method Items() returns (items: set<(K, V)>)
        reads {}
        ensures forall t: (K, V) {:trigger t.1} {:trigger t.0} {:trigger t in items} | t in items :: inv(t.0, t.1)

      method Put(k: K, v: V)
        requires inv(k, v)
        reads {}

      method Get(k: K) returns (r: Option<V>)
        reads {}
        ensures r.Some? ==> inv(k, r.value)

      method Remove(k: K)
        requires exists v: V {:trigger inv(k, v)} :: inv(k, v)
        reads {}

      method Size() returns (c: nat)
        reads {}
    }
  }

  module DynamicArray {

    import opened BoundedInts

    import opened Wrappers

    export
      reveals DynamicArray
      provides BoundedInts, DynamicArray.items, DynamicArray.capacity, DynamicArray.Repr, DynamicArray.Valid?, DynamicArray.size, DynamicArray.At, DynamicArray.Put, DynamicArray.Push, DynamicArray.PushFast, DynamicArray.PopFast, DynamicArray.Ensure

    class DynamicArray<A> {
      ghost var items: seq<A>
      ghost var Repr: set<object>
      var size: nat
      var capacity: nat
      var data: array<A>

      ghost predicate Valid?()
        reads this, Repr
        decreases Repr + {this}
      {
        Repr == {this, data} &&
        data.Length == capacity as int &&
        size <= capacity &&
        size as int == |items| &&
        items == data[..size]
      }

      constructor ()
        ensures size == 0
        ensures items == []
        ensures fresh(Repr)
        ensures capacity == 0
        ensures Valid?()
      {
        items := [];
        size := 0;
        capacity := 0;
        data := new A[0];
        Repr := {this, data};
      }

      function At(index: nat): (element: A)
        requires index < size
        requires Valid?()
        reads this, Repr
        ensures element == items[index]
        decreases Repr + {this}, index
      {
        data[index]
      }

      method Put(index: nat, element: A)
        requires index < size
        requires Valid?()
        modifies Repr, `items
        ensures Valid?()
        ensures fresh(Repr - old(Repr))
        ensures size == old(size)
        ensures items == old(items)[index := element]
        decreases index
      {
        data[index] := element;
        items := items[index := element];
      }

      method Ensure(reserved: nat, defaultValue: A)
        requires Valid?()
        modifies Repr
        ensures Valid?()
        ensures size == old(size)
        ensures items == old(items)
        ensures fresh(Repr - old(Repr))
        ensures reserved <= capacity - size
        decreases reserved
      {
        var newCapacity := capacity;
        while reserved > newCapacity - size
          invariant newCapacity >= capacity
          decreases reserved - (newCapacity - size)
        {
          newCapacity := DefaultNewCapacity(newCapacity);
        }
        if newCapacity > capacity {
          Realloc(defaultValue, newCapacity);
        }
      }

      method PopFast()
        requires Valid?()
        requires size > 0
        modifies `size, `items
        ensures Valid?()
        ensures size < capacity
        ensures size == old(size) - 1
        ensures capacity == old(capacity)
        ensures items == old(items[..|items| - 1])
      {
        size := size - 1;
        items := items[..|items| - 1];
      }

      method PushFast(element: A)
        requires Valid?()
        requires size < capacity
        modifies Repr
        ensures Valid?()
        ensures fresh(Repr - old(Repr))
        ensures size == old(size) + 1
        ensures capacity == old(capacity)
        ensures items == old(items) + [element]
      {
        data[size] := element;
        size := size + 1;
        items := items + [element];
      }

      method Push(element: A)
        requires Valid?()
        modifies Repr
        ensures Valid?()
        ensures fresh(Repr - old(Repr))
        ensures size == old(size) + 1
        ensures items == old(items) + [element]
        ensures capacity >= old(capacity)
      {
        if size == capacity {
          ReallocDefault(element);
        }
        PushFast(element);
      }

      method Realloc(defaultValue: A, newCapacity: nat)
        requires Valid?()
        requires newCapacity > capacity
        modifies `capacity, `data, `Repr, data
        ensures Valid?()
        ensures capacity == newCapacity
        ensures fresh(data)
        decreases newCapacity
      {
        var oldData, oldCapacity := data, capacity;
        data, capacity := new A[newCapacity] ((_ /* _v0 */: nat) => defaultValue), newCapacity;
        CopyFrom(oldData, oldCapacity);
        Repr := {this, data};
      }

      function DefaultNewCapacity(capacity: nat): nat
        decreases capacity
      {
        if capacity == 0 then
          8
        else
          2 * capacity
      }

      method ReallocDefault(defaultValue: A)
        requires Valid?()
        modifies `capacity, `data, `Repr, data
        ensures Valid?()
        ensures fresh(data)
        ensures capacity == old(DefaultNewCapacity(capacity))
      {
        Realloc(defaultValue, DefaultNewCapacity(capacity));
      }

      method CopyFrom(newData: array<A>, count: nat)
        requires count as int <= newData.Length
        requires count <= capacity
        requires data.Length == capacity as int
        modifies data
        ensures data[..count] == newData[..count]
        ensures data[count..] == old(data[count..])
        decreases newData, count
      {
        forall index: int | 0 <= index < count {
          data[index] := newData[index];
        }
      }
    }
  }

  module FileIO {
    method ReadBytesFromFile(path: string) returns (res: Result<seq<bv8>, string>)
      decreases path
    {
      var isError, bytesRead, errorMsg := FileIOInternalExterns.INTERNAL_ReadBytesFromFile(path);
      return if isError then Failure(errorMsg) else Success(bytesRead);
    }

    method WriteBytesToFile(path: string, bytes: seq<bv8>) returns (res: Result<(), string>)
      decreases path, bytes
    {
      var isError, errorMsg := FileIOInternalExterns.INTERNAL_WriteBytesToFile(path, bytes);
      return if isError then Failure(errorMsg) else Success(());
    }

    import opened Wrappers

    import FileIOInternalExterns

    export
      provides ReadBytesFromFile, WriteBytesToFile, Wrappers

  }

  replaceable module FileIOInternalExterns {
    method INTERNAL_ReadBytesFromFile(path: string)
        returns (isError: bool, bytesRead: seq<bv8>, errorMsg: string)
      decreases path

    method INTERNAL_WriteBytesToFile(path: string, bytes: seq<bv8>)
        returns (isError: bool, errorMsg: string)
      decreases path, bytes
  }

  module Functions {
    ghost predicate Injective<X(!new), Y>(f: X --> Y)
      requires forall x: X {:trigger f.requires(x)} :: f.requires(x)
      reads set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
      decreases set _x0: X, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0)} | _obj in f.reads(_x0) :: _obj
    {
      forall x1: X, x2: X {:trigger f(x2), f(x1)} :: 
        f(x1) == f(x2) ==>
          x1 == x2
    }

    ghost predicate Commutative<T(!new), U(!new)>(f: (T, T) -> U)
      requires forall x: T, y: T {:trigger f.requires(y, x)} {:trigger f.requires(x, y)} :: f.requires(x, y) && f.requires(y, x)
      reads set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
      decreases set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
    {
      forall x: T, y: T {:trigger f(y, x)} {:trigger f(x, y)} :: 
        f(x, y) == f(y, x)
    }

    ghost predicate Associative<T(!new)>(f: (T, T) -> T)
      requires forall x: T, y: T, z: T {:trigger f.requires(x, z), f.requires(y, z)} {:trigger f.requires(y, z), f.requires(x, y)} :: f.requires(x, y) && f.requires(y, z) && f.requires(x, z)
      reads set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
      decreases set _x0: T, _x1: T, _obj: object? /*{:_reads}*/ {:trigger _obj in f.reads(_x0, _x1)} | _obj in f.reads(_x0, _x1) :: _obj
    {
      forall x: T, y: T, z: T {:trigger f(f(x, y), z)} {:trigger f(x, f(y, z))} :: 
        f(x, f(y, z)) == f(f(x, y), z)
    }
  }

  module Math {
    function Min(a: int, b: int): int
      decreases a, b
    {
      if a < b then
        a
      else
        b
    }

    function Min3(a: int, b: int, c: int): int
      decreases a, b, c
    {
      Min(a, Min(b, c))
    }

    function Max(a: int, b: int): int
      decreases a, b
    {
      if a < b then
        b
      else
        a
    }

    function Max3(a: int, b: int, c: int): int
      decreases a, b, c
    {
      Max(a, Max(b, c))
    }

    function Abs(a: int): int
      decreases a
    {
      if a < 0 then
        -a
      else
        a
    }
  }

  module Relations {
    ghost predicate Reflexive<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T {:trigger relation(x, x)} :: 
        relation(x, x)
    }

    ghost predicate Irreflexive<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T {:trigger relation(x, x)} :: 
        !relation(x, x)
    }

    ghost predicate Symmetric<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) <==> relation(y, x)
    }

    ghost predicate AntiSymmetric<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) &&
        relation(y, x) ==>
          x == y
    }

    ghost predicate Asymmetric<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) ==>
          !relation(y, x)
    }

    lemma AsymmetricIsAntiSymmetric<T>(relation: (T, T) -> bool)
      ensures Asymmetric(relation) ==> AntiSymmetric(relation)
    {
    }

    lemma AsymmetricIsIrreflexive<T>(relation: (T, T) -> bool)
      ensures Asymmetric(relation) ==> Irreflexive(relation)
    {
    }

    ghost predicate Connected<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        x != y ==>
          relation(x, y) || relation(y, x)
    }

    ghost predicate StronglyConnected<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T {:trigger relation(y, x)} {:trigger relation(x, y)} :: 
        relation(x, y) || relation(y, x)
    }

    ghost predicate Transitive<T(!new)>(relation: (T, T) -> bool)
    {
      forall x: T, y: T, z: T {:trigger relation(x, z), relation(y, z)} {:trigger relation(y, z), relation(x, y)} :: 
        relation(x, y) &&
        relation(y, z) ==>
          relation(x, z)
    }

    ghost predicate TotalOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      AntiSymmetric(relation) &&
      Transitive(relation) &&
      StronglyConnected(relation)
    }

    ghost predicate StrictTotalOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Irreflexive(relation) &&
      AntiSymmetric(relation) &&
      Transitive(relation) &&
      Connected(relation)
    }

    ghost predicate PreOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      Transitive(relation)
    }

    ghost predicate PartialOrdering<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      Transitive(relation) &&
      AntiSymmetric(relation)
    }

    ghost predicate EquivalenceRelation<T(!new)>(relation: (T, T) -> bool)
    {
      Reflexive(relation) &&
      Symmetric(relation) &&
      Transitive(relation)
    }

    ghost predicate IsLeast<T>(lessOrEqual: (T, T) -> bool, least: T, s: set<T>)
      decreases s
    {
      least in s &&
      forall x: T {:trigger lessOrEqual(least, x)} {:trigger x in s} | x in s :: 
        lessOrEqual(least, x)
    }

    ghost predicate IsMinimal<T>(lessOrEqual: (T, T) -> bool, minimal: T, s: set<T>)
      decreases s
    {
      minimal in s &&
      forall x: T {:trigger lessOrEqual(minimal, x)} {:trigger lessOrEqual(x, minimal)} {:trigger x in s} | x in s && lessOrEqual(x, minimal) :: 
        lessOrEqual(minimal, x)
    }

    ghost predicate IsGreatest<T>(lessOrEqual: (T, T) -> bool, greatest: T, s: set<T>)
      decreases s
    {
      greatest in s &&
      forall x: T {:trigger lessOrEqual(x, greatest)} {:trigger x in s} | x in s :: 
        lessOrEqual(x, greatest)
    }

    ghost predicate IsMaximal<T>(lessOrEqual: (T, T) -> bool, maximal: T, s: set<T>)
      decreases s
    {
      maximal in s &&
      forall x: T {:trigger lessOrEqual(x, maximal)} {:trigger lessOrEqual(maximal, x)} {:trigger x in s} | x in s && lessOrEqual(maximal, x) :: 
        lessOrEqual(x, maximal)
    }

    ghost predicate SortedBy<T>(lessOrEqual: (T, T) -> bool, xs: seq<T>)
      decreases xs
    {
      forall i: int, j: int {:trigger xs[j], xs[i]} | 0 <= i < j < |xs| :: 
        lessOrEqual(xs[i], xs[j])
    }
  }

  module {:disableNonlinearArithmetic} Strings {
    function OfNat(n: nat): (str: string)
      ensures |str| == Log(DecimalConversion.base, n) + 1
      ensures forall c: char {:trigger c in DecimalConversion.chars} {:trigger c in str} | c in str :: c in DecimalConversion.chars
      decreases n
    {
      DecimalConversion.OfNat(n)
    }

    function OfInt(n: int): (str: string)
      ensures DecimalConversion.OfNumberStr(str, '-')
      decreases n
    {
      DecimalConversion.OfInt(n, '-')
    }

    function ToNat(str: string): (n: nat)
      requires forall c: char {:trigger DecimalConversion.charToDigit[c]} {:trigger c in DecimalConversion.charToDigit} {:trigger c in str} | c in str :: c in DecimalConversion.charToDigit && DecimalConversion.charToDigit[c] as int < DecimalConversion.base
      ensures n < Pow(DecimalConversion.base, |str|)
      decreases str
    {
      DecimalConversion.ToNatBound(str);
      DecimalConversion.ToNat(str)
    }

    function ToInt(str: string): (n: int)
      requires str != ""-""
      requires DecimalConversion.ToNumberStr(str, '-')
      decreases str
    {
      DecimalConversion.ToInt(str, '-')
    }

    function EscapeQuotes(str: string): string
      decreases str
    {
      CharStrEscaping.Escape(str, {'\""', '\''}, '\\')
    }

    function UnescapeQuotes(str: string): Option<string>
      decreases str
    {
      CharStrEscaping.Unescape(str, '\\')
    }

    function OfBool(b: bool): string
      decreases b
    {
      if b then
        ""true""
      else
        ""false""
    }

    function OfChar(c: char): string
      decreases c
    {
      [c]
    }

    function Join(sep: string, strs: seq<string>): string
      decreases sep, strs
    {
      if |strs| == 0 then
        """"
      else if |strs| == 1 then
        strs[0]
      else
        strs[0] + sep + Join(sep, strs[1..])
    }

    function Concat(strs: seq<string>): string
      decreases strs
    {
      if |strs| == 0 then
        """"
      else
        strs[0] + Concat(strs[1..])
    }

    lemma /*{:_induction strs}*/ Concat_Join(strs: seq<string>)
      ensures Concat(strs) == Join("""", strs)
      decreases strs
    {
    }

    import opened Wrappers

    import opened Power = Arithmetic.Power

    import opened Logarithm = Arithmetic.Logarithm

    import Arithmetic

    abstract module {:disableNonlinearArithmetic} ParametricConversion refines Arithmetic.LittleEndianNat {
      const chars: CharSeq
      const base := |chars|
      const charToDigit: map<Char, digit>

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      function OfDigits(digits: seq<digit>): (str: String)
        requires forall d: int {:trigger d in digits} | d in digits :: 0 <= d && d < base
        ensures forall c: Char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: Char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate OfNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in chars) &&
          forall c: Char {:trigger c in chars} {:trigger c in str[1..]} | c in str[1..] :: 
            c in chars
      }

      predicate ToNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: Char {:trigger c in charToDigit} {:trigger c in str[1..]} | c in str[1..] :: 
            c in charToDigit
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures OfNumberStr(str, minus)
        decreases n
      {
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:vcs_split_on_every_assert} ToNat(str: String): (n: nat)
        requires forall c: Char {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: Char {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        requires forall c: Char {:trigger charToDigit[c]} {:trigger c in str} | c in str :: charToDigit[c] < base
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires ToNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      import opened Wrappers

      type Char(==)

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    abstract module ParametricEscaping {
      function Escape(str: String, mustEscape: set<Char>, escape: Char): String
        decreases str, mustEscape
      {
        if str == [] then
          str
        else if str[0] in mustEscape then
          [escape, str[0]] + Escape(str[1..], mustEscape, escape)
        else
          [str[0]] + Escape(str[1..], mustEscape, escape)
      }

      function Unescape(str: String, escape: Char): Option<String>
        decreases str
      {
        if str == [] then
          Some(str)
        else if str[0] == escape then
          if |str| > 1 then
            var tl: String :- Unescape(str[2..], escape); Some([str[1]] + tl)
          else
            None
        else
          var tl: String :- Unescape(str[1..], escape); Some([str[0]] + tl)
      }

      lemma {:induction false} Unescape_Escape(str: String, special: set<Char>, escape: Char)
        requires escape in special
        ensures Unescape(Escape(str, special, escape), escape) == Some(str)
        decreases str, special
      {
        if str == [] {
        } else {
          assert str == [str[0]] + str[1..];
          Unescape_Escape(str[1..], special, escape);
        }
      }

      import opened Wrappers

      type Char(==)

      type String = seq<Char>
    }

    module {:disableNonlinearArithmetic} HexConversion refines ParametricConversion {
      const HEX_DIGITS: seq<char> := ""0123456789ABCDEF""
      const chars: CharSeq := HEX_DIGITS
      const charToDigit: map<Char, digit> := map['0' := 0, '1' := 1, '2' := 2, '3' := 3, '4' := 4, '5' := 5, '6' := 6, '7' := 7, '8' := 8, '9' := 9, 'a' := 10, 'b' := 11, 'c' := 12, 'd' := 13, 'e' := 14, 'f' := 15, 'A' := 10, 'B' := 11, 'C' := 12, 'D' := 13, 'E' := 14, 'F' := 15]
      const base := |chars|

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      function OfDigits(digits: seq<digit>): (str: String)
        requires forall d: int {:trigger d in digits} | d in digits :: 0 <= d && d < base
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate OfNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in chars) &&
          forall c: char {:trigger c in chars} {:trigger c in str[1..]} | c in str[1..] :: 
            c in chars
      }

      predicate ToNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: char {:trigger c in charToDigit} {:trigger c in str[1..]} | c in str[1..] :: 
            c in charToDigit
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures OfNumberStr(str, minus)
        decreases n
      {
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:vcs_split_on_every_assert} ToNat(str: String): (n: nat)
        requires forall c: char {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: char {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        requires forall c: char {:trigger charToDigit[c]} {:trigger c in str} | c in str :: charToDigit[c] < base
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires ToNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      type Char = char

      import opened Wrappers

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module {:disableNonlinearArithmetic} DecimalConversion refines ParametricConversion {
      const DIGITS: seq<char> := ""0123456789""
      const chars: CharSeq := DIGITS
      const charToDigit: map<Char, digit> := map['0' := 0, '1' := 1, '2' := 2, '3' := 3, '4' := 4, '5' := 5, '6' := 6, '7' := 7, '8' := 8, '9' := 9]
      const base := |chars|

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      function OfDigits(digits: seq<digit>): (str: String)
        requires forall d: int {:trigger d in digits} | d in digits :: 0 <= d && d < base
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: char {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate OfNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in chars) &&
          forall c: char {:trigger c in chars} {:trigger c in str[1..]} | c in str[1..] :: 
            c in chars
      }

      predicate ToNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: char {:trigger c in charToDigit} {:trigger c in str[1..]} | c in str[1..] :: 
            c in charToDigit
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures OfNumberStr(str, minus)
        decreases n
      {
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:vcs_split_on_every_assert} ToNat(str: String): (n: nat)
        requires forall c: char {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: char {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        requires forall c: char {:trigger charToDigit[c]} {:trigger c in str} | c in str :: charToDigit[c] < base
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires ToNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      type Char = char

      import opened Wrappers

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module CharStrEscaping refines ParametricEscaping {
      function Escape(str: String, mustEscape: set<Char>, escape: Char): String
        decreases str, mustEscape
      {
        if str == [] then
          str
        else if str[0] in mustEscape then
          [escape, str[0]] + Escape(str[1..], mustEscape, escape)
        else
          [str[0]] + Escape(str[1..], mustEscape, escape)
      }

      function Unescape(str: String, escape: Char): Option<String>
        decreases str
      {
        if str == [] then
          Some(str)
        else if str[0] == escape then
          if |str| > 1 then
            var tl: String :- Unescape(str[2..], escape); Some([str[1]] + tl)
          else
            None
        else
          var tl: String :- Unescape(str[1..], escape); Some([str[0]] + tl)
      }

      lemma {:induction false} Unescape_Escape(str: String, special: set<Char>, escape: Char)
        requires escape in special
        ensures Unescape(Escape(str, special, escape), escape) == Some(str)
        decreases str, special
      {
        if str == [] {
        } else {
          assert str == [str[0]] + str[1..];
          Unescape_Escape(str[1..], special, escape);
        }
      }

      type Char = char

      import opened Wrappers

      type String = seq<Char>
    }
  }

  module Unicode {

    module Base {
      const HIGH_SURROGATE_MIN: CodePoint := 55296
      const HIGH_SURROGATE_MAX: CodePoint := 56319
      const LOW_SURROGATE_MIN: CodePoint := 56320
      const LOW_SURROGATE_MAX: CodePoint := 57343
      const ASSIGNED_PLANES: set<bv8> := {0, 1, 2, 3, 14, 15, 16}

      opaque predicate IsInAssignedPlane(i: CodePoint)
        decreases i
      {
        var plane: bv8 := (i >> 16 as bv5) as bv8;
        plane in ASSIGNED_PLANES
      }

      type CodePoint = i: bv24
        | 0 <= i <= 1114111

      type HighSurrogateCodePoint = p: CodePoint
        | HIGH_SURROGATE_MIN <= p <= HIGH_SURROGATE_MAX
        witness HIGH_SURROGATE_MIN

      type LowSurrogateCodePoint = p: CodePoint
        | LOW_SURROGATE_MIN <= p <= LOW_SURROGATE_MAX
        witness LOW_SURROGATE_MIN

      type ScalarValue = p: CodePoint
        | (p < HIGH_SURROGATE_MIN || p > HIGH_SURROGATE_MAX) && (p < LOW_SURROGATE_MIN || p > LOW_SURROGATE_MAX)

      type AssignedCodePoint = p: CodePoint
        | IsInAssignedPlane(p)
        witness *
    }

    abstract module UnicodeEncodingForm {
      function IsMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (b: bool)
        ensures b ==> |s| > 0 && forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases |s|

      function SplitPrefixMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (maybePrefix: Option<MinimalWellFormedCodeUnitSeq>)
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && forall i: int {:trigger s[..i]} | 0 < i < |prefix| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases s

      function EncodeScalarValue(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        decreases v

      function DecodeMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        ensures EncodeScalarValue(v) == m
        decreases m

      lemma LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s: CodeUnitSeq, m1: MinimalWellFormedCodeUnitSeq, m2: MinimalWellFormedCodeUnitSeq)
        requires m1 <= s
        requires m2 <= s
        ensures m1 == m2
        decreases |s|, |m1|, |m2|
      {
        if |m1| > |m2| {
          LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s, m2, m1);
        } else {
          assert m1 <= m2;
          assert m1 == m2 by {
            if m1 < m2 {
              assert false by {
                assert m1 == m2[..|m1|];
              }
            }
          }
        }
      }

      lemma LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m: MinimalWellFormedCodeUnitSeq, s: CodeUnitSeq)
        ensures SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + s) == Some(m)
        decreases m, s
      {
        ghost var ms := m + s;
        ghost var maybePrefix := SplitPrefixMinimalWellFormedCodeUnitSubsequence(ms);
        assert maybePrefix.Some? by {
          assert IsMinimalWellFormedCodeUnitSubsequence(ms[..|m|]);
        }
        ghost var prefix := maybePrefix.Extract();
        assert m <= ms;
        assert prefix <= ms;
        LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(ms, m, prefix);
      }

      function PartitionCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeParts: Option<seq<MinimalWellFormedCodeUnitSeq>>)
        ensures maybeParts.Some? ==> Seq.Flatten(maybeParts.Extract()) == s
        decreases |s|
      {
        if s == [] then
          Some([])
        else
          var prefix: MinimalWellFormedCodeUnitSeq :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(s); var restParts: seq<MinimalWellFormedCodeUnitSeq> :- PartitionCodeUnitSequenceChecked(s[|prefix|..]); Some([prefix] + restParts)
      } by method {
        if s == [] {
          return Some([]);
        }
        var result: seq<MinimalWellFormedCodeUnitSeq> := [];
        var rest := s;
        while |rest| > 0
          invariant PartitionCodeUnitSequenceChecked(s).Some? <==> PartitionCodeUnitSequenceChecked(rest).Some?
          invariant PartitionCodeUnitSequenceChecked(s).Some? ==> true && PartitionCodeUnitSequenceChecked(s).value == result + PartitionCodeUnitSequenceChecked(rest).value
          decreases |rest| - 0
        {
          var prefix :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(rest);
          result := result + [prefix];
          rest := rest[|prefix|..];
        }
        assert result + [] == result;
        return Some(result);
      }

      function PartitionCodeUnitSequence(s: WellFormedCodeUnitSeq): (parts: seq<MinimalWellFormedCodeUnitSeq>)
        ensures Seq.Flatten(parts) == s
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Extract()
      }

      lemma /*{:_induction m}*/ LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq)
        ensures PartitionCodeUnitSequenceChecked(m) == Some([m])
        decreases m
      {
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, []);
        calc == {
          Some(m);
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + []);
          {
            assert m + [] == m;
          }
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m);
        }
        calc == {
          PartitionCodeUnitSequenceChecked(m);
          Some([m] + []);
          {
            assert [m] + [] == [m];
          }
          Some([m]);
        }
      }

      function IsWellFormedCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Some?
      }

      lemma LemmaMinimalWellFormedCodeUnitSubsequenceIsWellFormedSequence(m: MinimalWellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m)
        decreases m
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
      }

      lemma LemmaPrependMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq, s: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m + s)
        decreases m, s
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, s);
      }

      lemma /*{:_induction ms}*/ LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms: seq<MinimalWellFormedCodeUnitSeq>)
        ensures IsWellFormedCodeUnitSequence(Seq.Flatten(ms))
        decreases ms
      {
        if |ms| == 0 {
        } else {
          ghost var head := ms[0];
          ghost var tail := ms[1..];
          LemmaFlattenMinimalWellFormedCodeUnitSubsequences(tail);
          ghost var flatTail := Seq.Flatten(tail);
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(head, flatTail);
        }
      }

      lemma LemmaConcatWellFormedCodeUnitSubsequences(s: WellFormedCodeUnitSeq, t: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(s + t)
        decreases s, t
      {
        ghost var partsS := PartitionCodeUnitSequence(s);
        ghost var partsT := PartitionCodeUnitSequence(t);
        ghost var partsST := partsS + partsT;
        Seq.LemmaFlattenConcat(partsS, partsT);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(partsST);
      }

      function EncodeScalarSequence(vs: seq<ScalarValue>): (s: WellFormedCodeUnitSeq)
        decreases vs
      {
        var ms: seq<MinimalWellFormedCodeUnitSeq> := Seq.Map(EncodeScalarValue, vs);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms);
        Seq.Flatten(ms)
      } by method {
        s := [];
        ghost var unflattened: seq<MinimalWellFormedCodeUnitSeq> := [];
        for i: int := |vs| downto 0
          invariant unflattened == Seq.Map(EncodeScalarValue, vs[i..])
          invariant s == Seq.Flatten(unflattened)
        {
          var next: MinimalWellFormedCodeUnitSeq := EncodeScalarValue(vs[i]);
          unflattened := [next] + unflattened;
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(next, s);
          s := next + s;
        }
      }

      function DecodeCodeUnitSequence(s: WellFormedCodeUnitSeq): (vs: seq<ScalarValue>)
        ensures EncodeScalarSequence(vs) == s
        decreases s
      {
        var parts: seq<MinimalWellFormedCodeUnitSeq> := PartitionCodeUnitSequence(s);
        var vs: seq<ScalarValue> := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        vs
      }

      function DecodeCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeVs: Option<seq<ScalarValue>>)
        ensures IsWellFormedCodeUnitSequence(s) ==> maybeVs.Some? && maybeVs.Extract() == DecodeCodeUnitSequence(s)
        ensures !IsWellFormedCodeUnitSequence(s) ==> true && maybeVs.None?
        decreases s
      {
        if IsWellFormedCodeUnitSequence(s) then
          Some(DecodeCodeUnitSequence(s))
        else
          None
      } by method {
        var maybeParts := PartitionCodeUnitSequenceChecked(s);
        if maybeParts.None? {
          return None;
        }
        var parts := maybeParts.value;
        var vs := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        return Some(vs);
      }

      import opened Wrappers

      import Functions

      import Seq = Collections.Seq

      import opened Base

      type CodeUnitSeq = seq<CodeUnit>

      type WellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsWellFormedCodeUnitSequence(s)
        witness []

      type MinimalWellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsMinimalWellFormedCodeUnitSubsequence(s)
        witness *

      type CodeUnit
    }

    abstract module AbstractUnicodeStrings {
      function ToUTF8Checked(s: string): Option<seq<uint8>>
        decreases s

      function ASCIIToUTF8(s: string): seq<uint8>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint8, s)
      }

      function FromUTF8Checked(bs: seq<uint8>): Option<string>
        decreases bs

      function ToUTF16Checked(s: string): Option<seq<uint16>>
        decreases s

      function ASCIIToUTF16(s: string): seq<uint16>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint16, s)
      }

      function FromUTF16Checked(bs: seq<uint16>): Option<string>
        decreases bs

      import Seq = Collections.Seq

      import opened Wrappers

      import opened BoundedInts
    }

    module UnicodeStringsWithUnicodeChar refines AbstractUnicodeStrings {
      lemma {:vcs_split_on_every_assert} CharIsUnicodeScalarValue(c: char)
        ensures true && ghost var asBits: bv24 := c as bv24; asBits <= 1114111 && (0 <= asBits < Base.HIGH_SURROGATE_MIN || Base.LOW_SURROGATE_MAX < asBits)
        decreases c
      {
        assert c as int < 1114112;
        assume {:axiom} c as bv24 < 1114112 as bv24;
        ghost var asBits := c as int as bv24;
        assert asBits < Base.HIGH_SURROGATE_MIN || asBits > Base.LOW_SURROGATE_MAX;
        assert asBits <= 1114111;
      }

      lemma UnicodeScalarValueIsChar(sv: Base.ScalarValue)
        ensures true && ghost var asInt: int := sv as int; true && (0 <= asInt < 55296 || 57344 <= asInt < 1114112)
        decreases sv
      {
        ghost var asInt := sv as int;
        assert asInt < 55296 || asInt > 57343;
        assert asInt < 56319 || asInt > 56320;
      }

      function CharAsUnicodeScalarValue(c: char): Base.ScalarValue
        decreases c
      {
        CharIsUnicodeScalarValue(c);
        c as Base.ScalarValue
      }

      function CharFromUnicodeScalarValue(sv: Base.ScalarValue): char
        decreases sv
      {
        UnicodeScalarValueIsChar(sv);
        sv as int as char
      }

      function ToUTF8Checked(s: string): Option<seq<uint8>>
        ensures ToUTF8Checked(s).Some?
        decreases s
      {
        var asCodeUnits: seq<Base.ScalarValue> := Seq.Map(CharAsUnicodeScalarValue, s);
        var asUtf8CodeUnits: WellFormedCodeUnitSeq := Utf8EncodingForm.EncodeScalarSequence(asCodeUnits);
        var asBytes: seq<uint8> := Seq.Map((cu: bv8) => cu as uint8, asUtf8CodeUnits);
        Some(asBytes)
      }

      function FromUTF8Checked(bs: seq<uint8>): Option<string>
        decreases bs
      {
        var asCodeUnits: seq<Utf8EncodingForm.CodeUnit> := Seq.Map((c: uint8) => c as Utf8EncodingForm.CodeUnit, bs);
        var utf32: seq<ScalarValue> :- Utf8EncodingForm.DecodeCodeUnitSequenceChecked(asCodeUnits); var asChars: seq<char> := Seq.Map(CharFromUnicodeScalarValue, utf32); Some(asChars)
      }

      function ToUTF16Checked(s: string): Option<seq<uint16>>
        ensures ToUTF16Checked(s).Some?
        decreases s
      {
        var asCodeUnits: seq<Base.ScalarValue> := Seq.Map(CharAsUnicodeScalarValue, s);
        var asUtf16CodeUnits: WellFormedCodeUnitSeq := Utf16EncodingForm.EncodeScalarSequence(asCodeUnits);
        var asBytes: seq<uint16> := Seq.Map((cu: bv16) => cu as uint16, asUtf16CodeUnits);
        Some(asBytes)
      }

      function FromUTF16Checked(bs: seq<uint16>): Option<string>
        decreases bs
      {
        var asCodeUnits: seq<Utf16EncodingForm.CodeUnit> := Seq.Map((c: uint16) => c as Utf16EncodingForm.CodeUnit, bs);
        var utf32: seq<ScalarValue> :- Utf16EncodingForm.DecodeCodeUnitSequenceChecked(asCodeUnits); var asChars: seq<char> := Seq.Map(CharFromUnicodeScalarValue, utf32); Some(asChars)
      }

      function ASCIIToUTF8(s: string): seq<uint8>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint8, s)
      }

      function ASCIIToUTF16(s: string): seq<uint16>
        requires forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases s
      {
        Seq.Map((c: char) requires 0 <= c as int < 128 => c as uint16, s)
      }

      import Base

      import Utf8EncodingForm

      import Utf16EncodingForm

      import Seq = Collections.Seq

      import opened Wrappers

      import opened BoundedInts
    }

    module Utf16EncodingForm refines UnicodeEncodingForm {
      function IsMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (b: bool)
        ensures b ==> |s| > 0 && forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases |s|
      {
        if |s| == 1 then
          IsWellFormedSingleCodeUnitSequence(s)
        else if |s| == 2 then
          var b: bool := IsWellFormedDoubleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else
          false
      }

      function IsWellFormedSingleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 1
        decreases s
      {
        var firstWord: bv16 := s[0];
        0 <= firstWord <= 55295 || 57344 <= firstWord <= 65535
      }

      function IsWellFormedDoubleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 2
        ensures b ==> !IsWellFormedSingleCodeUnitSequence(s[..1])
        decreases s
      {
        var firstWord: bv16 := s[0];
        var secondWord: bv16 := s[1];
        55296 <= firstWord <= 56319 &&
        56320 <= secondWord <= 57343
      }

      function SplitPrefixMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (maybePrefix: Option<MinimalWellFormedCodeUnitSeq>)
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && forall i: int {:trigger s[..i]} | 0 < i < |prefix| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && IsMinimalWellFormedCodeUnitSubsequence(prefix)
        decreases s
      {
        if |s| >= 1 && IsWellFormedSingleCodeUnitSequence(s[..1]) then
          Some(s[..1])
        else if |s| >= 2 && IsWellFormedDoubleCodeUnitSequence(s[..2]) then
          Some(s[..2])
        else
          None
      }

      function EncodeScalarValue(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        decreases v
      {
        if 0 <= v <= 55295 || 57344 <= v <= 65535 then
          EncodeScalarValueSingleWord(v)
        else
          EncodeScalarValueDoubleWord(v)
      }

      function EncodeScalarValueSingleWord(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        requires 0 <= v <= 55295 || 57344 <= v <= 65535
        ensures |m| == 1
        ensures IsWellFormedSingleCodeUnitSequence(m)
        decreases v
      {
        var firstWord: CodeUnit := v as CodeUnit;
        [firstWord]
      }

      function EncodeScalarValueDoubleWord(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        requires 65536 <= v <= 1114111
        ensures |m| == 2
        ensures IsWellFormedDoubleCodeUnitSequence(m)
        decreases v
      {
        var x2: bv10 := (v & 1023) as bv10;
        var x1: bv6 := (v & 64512 >> 10 as bv5) as bv6;
        var u: bv5 := (v & 2031616 >> 16 as bv5) as bv5;
        var w: bv4 := (u - 1) as bv4;
        var firstWord: bv16 := 55296 | (w as CodeUnit << 6 as bv5) | x1 as CodeUnit;
        var secondWord: bv16 := 56320 | x2 as CodeUnit;
        [firstWord, secondWord]
      }

      function DecodeMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        ensures EncodeScalarValue(v) == m
        decreases m
      {
        if |m| == 1 then
          DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(m)
        else
          assert |m| == 2; DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(m)
      }

      function DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 1
        ensures 0 <= v <= 55295 || 57344 <= v <= 65535
        ensures EncodeScalarValueSingleWord(v) == m
        decreases m
      {
        var firstWord: bv16 := m[0];
        var x: bv16 := firstWord as bv16;
        assert EncodeScalarValueSingleWord(x as ScalarValue) == m;
        x as ScalarValue
      }

      function {:rlimit 1200} DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 2
        ensures 65536 <= v <= 1114111
        ensures EncodeScalarValueDoubleWord(v) == m
        decreases m
      {
        var firstWord: bv16 := m[0];
        var secondWord: bv16 := m[1];
        var x2: bv24 := (secondWord & 1023) as bv24;
        var x1: bv24 := (firstWord & 63) as bv24;
        var w: bv24 := (firstWord & 960 >> 6 as bv5) as bv24;
        var u: bv24 := (w + 1) as bv24;
        var v: bv24 := (u << 16 as bv5) | (x1 << 10 as bv5) | x2 as ScalarValue;
        assert {:split_here} true;
        assert EncodeScalarValueDoubleWord(v) == m;
        v
      }

      lemma LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s: CodeUnitSeq, m1: MinimalWellFormedCodeUnitSeq, m2: MinimalWellFormedCodeUnitSeq)
        requires m1 <= s
        requires m2 <= s
        ensures m1 == m2
        decreases |s|, |m1|, |m2|
      {
        if |m1| > |m2| {
          LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s, m2, m1);
        } else {
          assert m1 <= m2;
          assert m1 == m2 by {
            if m1 < m2 {
              assert false by {
                assert m1 == m2[..|m1|];
              }
            }
          }
        }
      }

      lemma LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m: MinimalWellFormedCodeUnitSeq, s: CodeUnitSeq)
        ensures SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + s) == Some(m)
        decreases m, s
      {
        ghost var ms := m + s;
        ghost var maybePrefix := SplitPrefixMinimalWellFormedCodeUnitSubsequence(ms);
        assert maybePrefix.Some? by {
          assert IsMinimalWellFormedCodeUnitSubsequence(ms[..|m|]);
        }
        ghost var prefix := maybePrefix.Extract();
        assert m <= ms;
        assert prefix <= ms;
        LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(ms, m, prefix);
      }

      function PartitionCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeParts: Option<seq<MinimalWellFormedCodeUnitSeq>>)
        ensures maybeParts.Some? ==> Seq.Flatten(maybeParts.Extract()) == s
        decreases |s|
      {
        if s == [] then
          Some([])
        else
          var prefix: MinimalWellFormedCodeUnitSeq :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(s); var restParts: seq<MinimalWellFormedCodeUnitSeq> :- PartitionCodeUnitSequenceChecked(s[|prefix|..]); Some([prefix] + restParts)
      } by method {
        if s == [] {
          return Some([]);
        }
        var result: seq<MinimalWellFormedCodeUnitSeq> := [];
        var rest := s;
        while |rest| > 0
          invariant PartitionCodeUnitSequenceChecked(s).Some? <==> PartitionCodeUnitSequenceChecked(rest).Some?
          invariant PartitionCodeUnitSequenceChecked(s).Some? ==> true && PartitionCodeUnitSequenceChecked(s).value == result + PartitionCodeUnitSequenceChecked(rest).value
          decreases |rest| - 0
        {
          var prefix :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(rest);
          result := result + [prefix];
          rest := rest[|prefix|..];
        }
        assert result + [] == result;
        return Some(result);
      }

      function PartitionCodeUnitSequence(s: WellFormedCodeUnitSeq): (parts: seq<MinimalWellFormedCodeUnitSeq>)
        ensures Seq.Flatten(parts) == s
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Extract()
      }

      lemma /*{:_induction m}*/ LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq)
        ensures PartitionCodeUnitSequenceChecked(m) == Some([m])
        decreases m
      {
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, []);
        calc == {
          Some(m);
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + []);
          {
            assert m + [] == m;
          }
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m);
        }
        calc == {
          PartitionCodeUnitSequenceChecked(m);
          Some([m] + []);
          {
            assert [m] + [] == [m];
          }
          Some([m]);
        }
      }

      function IsWellFormedCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Some?
      }

      lemma LemmaMinimalWellFormedCodeUnitSubsequenceIsWellFormedSequence(m: MinimalWellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m)
        decreases m
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
      }

      lemma LemmaPrependMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq, s: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m + s)
        decreases m, s
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, s);
      }

      lemma /*{:_induction ms}*/ LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms: seq<MinimalWellFormedCodeUnitSeq>)
        ensures IsWellFormedCodeUnitSequence(Seq.Flatten(ms))
        decreases ms
      {
        if |ms| == 0 {
        } else {
          ghost var head := ms[0];
          ghost var tail := ms[1..];
          LemmaFlattenMinimalWellFormedCodeUnitSubsequences(tail);
          ghost var flatTail := Seq.Flatten(tail);
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(head, flatTail);
        }
      }

      lemma LemmaConcatWellFormedCodeUnitSubsequences(s: WellFormedCodeUnitSeq, t: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(s + t)
        decreases s, t
      {
        ghost var partsS := PartitionCodeUnitSequence(s);
        ghost var partsT := PartitionCodeUnitSequence(t);
        ghost var partsST := partsS + partsT;
        Seq.LemmaFlattenConcat(partsS, partsT);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(partsST);
      }

      function EncodeScalarSequence(vs: seq<ScalarValue>): (s: WellFormedCodeUnitSeq)
        decreases vs
      {
        var ms: seq<MinimalWellFormedCodeUnitSeq> := Seq.Map(EncodeScalarValue, vs);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms);
        Seq.Flatten(ms)
      } by method {
        s := [];
        ghost var unflattened: seq<MinimalWellFormedCodeUnitSeq> := [];
        for i: int := |vs| downto 0
          invariant unflattened == Seq.Map(EncodeScalarValue, vs[i..])
          invariant s == Seq.Flatten(unflattened)
        {
          var next: MinimalWellFormedCodeUnitSeq := EncodeScalarValue(vs[i]);
          unflattened := [next] + unflattened;
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(next, s);
          s := next + s;
        }
      }

      function DecodeCodeUnitSequence(s: WellFormedCodeUnitSeq): (vs: seq<ScalarValue>)
        ensures EncodeScalarSequence(vs) == s
        decreases s
      {
        var parts: seq<MinimalWellFormedCodeUnitSeq> := PartitionCodeUnitSequence(s);
        var vs: seq<ScalarValue> := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        vs
      }

      function DecodeCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeVs: Option<seq<ScalarValue>>)
        ensures IsWellFormedCodeUnitSequence(s) ==> maybeVs.Some? && maybeVs.Extract() == DecodeCodeUnitSequence(s)
        ensures !IsWellFormedCodeUnitSequence(s) ==> true && maybeVs.None?
        decreases s
      {
        if IsWellFormedCodeUnitSequence(s) then
          Some(DecodeCodeUnitSequence(s))
        else
          None
      } by method {
        var maybeParts := PartitionCodeUnitSequenceChecked(s);
        if maybeParts.None? {
          return None;
        }
        var parts := maybeParts.value;
        var vs := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        return Some(vs);
      }

      type CodeUnit = bv16

      import opened Wrappers

      import Functions

      import Seq = Collections.Seq

      import opened Base

      type CodeUnitSeq = seq<CodeUnit>

      type WellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsWellFormedCodeUnitSequence(s)
        witness []

      type MinimalWellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsMinimalWellFormedCodeUnitSubsequence(s)
        witness *
    }

    module Utf8EncodingForm refines UnicodeEncodingForm {
      function IsMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (b: bool)
        ensures b ==> |s| > 0 && forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases |s|
      {
        if |s| == 1 then
          var b: bool := IsWellFormedSingleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else if |s| == 2 then
          var b: bool := IsWellFormedDoubleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else if |s| == 3 then
          var b: bool := IsWellFormedTripleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else if |s| == 4 then
          var b: bool := IsWellFormedQuadrupleCodeUnitSequence(s);
          assert b ==> forall i: int {:trigger s[..i]} | 0 < i < |s| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i]);
          b
        else
          false
      }

      function IsWellFormedSingleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 1
        decreases s
      {
        var firstByte: bv8 := s[0];
        true &&
        0 <= firstByte <= 127
      }

      function IsWellFormedDoubleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 2
        ensures b ==> true && !IsWellFormedSingleCodeUnitSequence(s[..1])
        decreases s
      {
        var firstByte: bv8 := s[0];
        var secondByte: bv8 := s[1];
        194 <= firstByte <= 223 &&
        128 <= secondByte <= 191
      }

      function IsWellFormedTripleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 3
        ensures b ==> !IsWellFormedSingleCodeUnitSequence(s[..1]) && !IsWellFormedDoubleCodeUnitSequence(s[..2])
        decreases s
      {
        var firstByte: bv8 := s[0];
        var secondByte: bv8 := s[1];
        var thirdByte: bv8 := s[2];
        ((firstByte == 224 && 160 <= secondByte <= 191) || (225 <= firstByte <= 236 && 128 <= secondByte <= 191) || (firstByte == 237 && 128 <= secondByte <= 159) || (238 <= firstByte <= 239 && 128 <= secondByte <= 191)) &&
        128 <= thirdByte <= 191
      }

      function IsWellFormedQuadrupleCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        requires |s| == 4
        ensures b ==> !IsWellFormedSingleCodeUnitSequence(s[..1]) && !IsWellFormedDoubleCodeUnitSequence(s[..2]) && !IsWellFormedTripleCodeUnitSequence(s[..3])
        decreases s
      {
        var firstByte: bv8 := s[0];
        var secondByte: bv8 := s[1];
        var thirdByte: bv8 := s[2];
        var fourthByte: bv8 := s[3];
        ((firstByte == 240 && 144 <= secondByte <= 191) || (241 <= firstByte <= 243 && 128 <= secondByte <= 191) || (firstByte == 244 && 128 <= secondByte <= 143)) &&
        128 <= thirdByte <= 191 &&
        128 <= fourthByte <= 191
      }

      function SplitPrefixMinimalWellFormedCodeUnitSubsequence(s: CodeUnitSeq): (maybePrefix: Option<MinimalWellFormedCodeUnitSeq>)
        ensures |s| == 0 ==> maybePrefix.None?
        ensures (exists i: int {:trigger s[..i]} | 0 < i <= |s| :: IsMinimalWellFormedCodeUnitSubsequence(s[..i])) <==> true && maybePrefix.Some?
        ensures maybePrefix.Some? ==> true && var prefix: MinimalWellFormedCodeUnitSeq := maybePrefix.Extract(); 0 < |prefix| <= |s| && prefix == s[..|prefix|] && forall i: int {:trigger s[..i]} | 0 < i < |prefix| :: !IsMinimalWellFormedCodeUnitSubsequence(s[..i])
        decreases s
      {
        if |s| >= 1 && IsWellFormedSingleCodeUnitSequence(s[..1]) then
          Some(s[..1])
        else if |s| >= 2 && IsWellFormedDoubleCodeUnitSequence(s[..2]) then
          Some(s[..2])
        else if |s| >= 3 && IsWellFormedTripleCodeUnitSequence(s[..3]) then
          Some(s[..3])
        else if |s| >= 4 && IsWellFormedQuadrupleCodeUnitSequence(s[..4]) then
          Some(s[..4])
        else
          None
      }

      function EncodeScalarValue(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        decreases v
      {
        if v <= 127 then
          EncodeScalarValueSingleByte(v)
        else if v <= 2047 then
          EncodeScalarValueDoubleByte(v)
        else if v <= 65535 then
          EncodeScalarValueTripleByte(v)
        else
          EncodeScalarValueQuadrupleByte(v)
      }

      function EncodeScalarValueSingleByte(v: ScalarValue): (m: MinimalWellFormedCodeUnitSeq)
        requires 0 <= v <= 127
        ensures |m| == 1
        ensures IsWellFormedSingleCodeUnitSequence(m)
        decreases v
      {
        var x: bv7 := (v & 127) as bv7;
        var firstByte: CodeUnit := x as CodeUnit;
        [firstByte]
      }

      function EncodeScalarValueDoubleByte(v: ScalarValue): (s: CodeUnitSeq)
        requires 128 <= v <= 2047
        ensures |s| == 2
        ensures IsWellFormedDoubleCodeUnitSequence(s)
        decreases v
      {
        var x: bv6 := (v & 63) as bv6;
        var y: bv5 := (v & 1984 >> 6 as bv5) as bv5;
        var firstByte: bv8 := 192 | y as CodeUnit;
        var secondByte: bv8 := 128 | x as CodeUnit;
        [firstByte, secondByte]
      }

      function EncodeScalarValueTripleByte(v: ScalarValue): (s: CodeUnitSeq)
        requires 2048 <= v <= 65535
        ensures |s| == 3
        ensures IsWellFormedTripleCodeUnitSequence(s)
        decreases v
      {
        var x: bv6 := (v & 63) as bv6;
        var y: bv6 := (v & 4032 >> 6 as bv5) as bv6;
        var z: bv4 := (v & 61440 >> 12 as bv5) as bv4;
        var firstByte: bv8 := 224 | z as CodeUnit;
        var secondByte: bv8 := 128 | y as CodeUnit;
        var thirdByte: bv8 := 128 | x as CodeUnit;
        [firstByte, secondByte, thirdByte]
      }

      function EncodeScalarValueQuadrupleByte(v: ScalarValue): (s: CodeUnitSeq)
        requires 65536 <= v <= 1114111
        ensures |s| == 4
        ensures IsWellFormedQuadrupleCodeUnitSequence(s)
        decreases v
      {
        assert v <= 2097151;
        var x: bv6 := (v & 63) as bv6;
        var y: bv6 := (v & 4032 >> 6 as bv5) as bv6;
        var z: bv4 := (v & 61440 >> 12 as bv5) as bv4;
        var u2: bv2 := (v & 196608 >> 16 as bv5) as bv2;
        var u1: bv3 := (v & 1835008 >> 18 as bv5) as bv3;
        var firstByte: bv8 := 240 | u1 as CodeUnit;
        var secondByte: bv8 := 128 | (u2 as CodeUnit << 4 as bv4) | z as CodeUnit;
        var thirdByte: bv8 := 128 | y as CodeUnit;
        var fourthByte: bv8 := 128 | x as CodeUnit;
        [firstByte, secondByte, thirdByte, fourthByte]
      }

      function DecodeMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        ensures EncodeScalarValue(v) == m
        decreases m
      {
        if |m| == 1 then
          DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(m)
        else if |m| == 2 then
          DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(m)
        else if |m| == 3 then
          DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(m)
        else
          assert |m| == 4; DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(m)
      }

      function DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 1
        ensures 0 <= v <= 127
        ensures EncodeScalarValueSingleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var x: bv7 := firstByte as bv7;
        x as ScalarValue
      }

      function DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 2
        ensures 128 <= v <= 2047
        ensures EncodeScalarValueDoubleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var secondByte: bv8 := m[1];
        var y: bv24 := (firstByte & 31) as bv24;
        var x: bv24 := (secondByte & 63) as bv24;
        (y << 6 as bv5) | x as ScalarValue
      }

      function {:rlimit 115000} DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 3
        ensures 2048 <= v <= 65535
        ensures EncodeScalarValueTripleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var secondByte: bv8 := m[1];
        var thirdByte: bv8 := m[2];
        var z: bv24 := (firstByte & 15) as bv24;
        var y: bv24 := (secondByte & 63) as bv24;
        var x: bv24 := (thirdByte & 63) as bv24;
        assert {:split_here} true;
        (z << 12 as bv5) | (y << 6 as bv5) | x as ScalarValue
      }

      function {:rlimit 4000} DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(m: MinimalWellFormedCodeUnitSeq): (v: ScalarValue)
        requires |m| == 4
        ensures 65536 <= v <= 1114111
        ensures EncodeScalarValueQuadrupleByte(v) == m
        decreases m
      {
        var firstByte: bv8 := m[0];
        var secondByte: bv8 := m[1];
        var thirdByte: bv8 := m[2];
        var fourthByte: bv8 := m[3];
        var u1: bv24 := (firstByte & 7) as bv24;
        var u2: bv24 := (secondByte & 48 >> 4 as bv4) as bv24;
        var z: bv24 := (secondByte & 15) as bv24;
        var y: bv24 := (thirdByte & 63) as bv24;
        var x: bv24 := (fourthByte & 63) as bv24;
        assert {:split_here} true;
        (u1 << 18 as bv5) | (u2 << 16 as bv5) | (z << 12 as bv5) | (y << 6 as bv5) | x as ScalarValue
      }

      lemma LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s: CodeUnitSeq, m1: MinimalWellFormedCodeUnitSeq, m2: MinimalWellFormedCodeUnitSeq)
        requires m1 <= s
        requires m2 <= s
        ensures m1 == m2
        decreases |s|, |m1|, |m2|
      {
        if |m1| > |m2| {
          LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(s, m2, m1);
        } else {
          assert m1 <= m2;
          assert m1 == m2 by {
            if m1 < m2 {
              assert false by {
                assert m1 == m2[..|m1|];
              }
            }
          }
        }
      }

      lemma LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m: MinimalWellFormedCodeUnitSeq, s: CodeUnitSeq)
        ensures SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + s) == Some(m)
        decreases m, s
      {
        ghost var ms := m + s;
        ghost var maybePrefix := SplitPrefixMinimalWellFormedCodeUnitSubsequence(ms);
        assert maybePrefix.Some? by {
          assert IsMinimalWellFormedCodeUnitSubsequence(ms[..|m|]);
        }
        ghost var prefix := maybePrefix.Extract();
        assert m <= ms;
        assert prefix <= ms;
        LemmaUniquePrefixMinimalWellFormedCodeUnitSeq(ms, m, prefix);
      }

      function PartitionCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeParts: Option<seq<MinimalWellFormedCodeUnitSeq>>)
        ensures maybeParts.Some? ==> Seq.Flatten(maybeParts.Extract()) == s
        decreases |s|
      {
        if s == [] then
          Some([])
        else
          var prefix: MinimalWellFormedCodeUnitSeq :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(s); var restParts: seq<MinimalWellFormedCodeUnitSeq> :- PartitionCodeUnitSequenceChecked(s[|prefix|..]); Some([prefix] + restParts)
      } by method {
        if s == [] {
          return Some([]);
        }
        var result: seq<MinimalWellFormedCodeUnitSeq> := [];
        var rest := s;
        while |rest| > 0
          invariant PartitionCodeUnitSequenceChecked(s).Some? <==> PartitionCodeUnitSequenceChecked(rest).Some?
          invariant PartitionCodeUnitSequenceChecked(s).Some? ==> true && PartitionCodeUnitSequenceChecked(s).value == result + PartitionCodeUnitSequenceChecked(rest).value
          decreases |rest| - 0
        {
          var prefix :- SplitPrefixMinimalWellFormedCodeUnitSubsequence(rest);
          result := result + [prefix];
          rest := rest[|prefix|..];
        }
        assert result + [] == result;
        return Some(result);
      }

      function PartitionCodeUnitSequence(s: WellFormedCodeUnitSeq): (parts: seq<MinimalWellFormedCodeUnitSeq>)
        ensures Seq.Flatten(parts) == s
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Extract()
      }

      lemma /*{:_induction m}*/ LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq)
        ensures PartitionCodeUnitSequenceChecked(m) == Some([m])
        decreases m
      {
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, []);
        calc == {
          Some(m);
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m + []);
          {
            assert m + [] == m;
          }
          SplitPrefixMinimalWellFormedCodeUnitSubsequence(m);
        }
        calc == {
          PartitionCodeUnitSequenceChecked(m);
          Some([m] + []);
          {
            assert [m] + [] == [m];
          }
          Some([m]);
        }
      }

      function IsWellFormedCodeUnitSequence(s: CodeUnitSeq): (b: bool)
        decreases s
      {
        PartitionCodeUnitSequenceChecked(s).Some?
      }

      lemma LemmaMinimalWellFormedCodeUnitSubsequenceIsWellFormedSequence(m: MinimalWellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m)
        decreases m
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
      }

      lemma LemmaPrependMinimalWellFormedCodeUnitSubsequence(m: MinimalWellFormedCodeUnitSeq, s: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(m + s)
        decreases m, s
      {
        LemmaPartitionMinimalWellFormedCodeUnitSubsequence(m);
        LemmaSplitPrefixMinimalWellFormedCodeUnitSubsequenceInvertsPrepend(m, s);
      }

      lemma /*{:_induction ms}*/ LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms: seq<MinimalWellFormedCodeUnitSeq>)
        ensures IsWellFormedCodeUnitSequence(Seq.Flatten(ms))
        decreases ms
      {
        if |ms| == 0 {
        } else {
          ghost var head := ms[0];
          ghost var tail := ms[1..];
          LemmaFlattenMinimalWellFormedCodeUnitSubsequences(tail);
          ghost var flatTail := Seq.Flatten(tail);
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(head, flatTail);
        }
      }

      lemma LemmaConcatWellFormedCodeUnitSubsequences(s: WellFormedCodeUnitSeq, t: WellFormedCodeUnitSeq)
        ensures IsWellFormedCodeUnitSequence(s + t)
        decreases s, t
      {
        ghost var partsS := PartitionCodeUnitSequence(s);
        ghost var partsT := PartitionCodeUnitSequence(t);
        ghost var partsST := partsS + partsT;
        Seq.LemmaFlattenConcat(partsS, partsT);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(partsST);
      }

      function EncodeScalarSequence(vs: seq<ScalarValue>): (s: WellFormedCodeUnitSeq)
        decreases vs
      {
        var ms: seq<MinimalWellFormedCodeUnitSeq> := Seq.Map(EncodeScalarValue, vs);
        LemmaFlattenMinimalWellFormedCodeUnitSubsequences(ms);
        Seq.Flatten(ms)
      } by method {
        s := [];
        ghost var unflattened: seq<MinimalWellFormedCodeUnitSeq> := [];
        for i: int := |vs| downto 0
          invariant unflattened == Seq.Map(EncodeScalarValue, vs[i..])
          invariant s == Seq.Flatten(unflattened)
        {
          var next: MinimalWellFormedCodeUnitSeq := EncodeScalarValue(vs[i]);
          unflattened := [next] + unflattened;
          LemmaPrependMinimalWellFormedCodeUnitSubsequence(next, s);
          s := next + s;
        }
      }

      function DecodeCodeUnitSequence(s: WellFormedCodeUnitSeq): (vs: seq<ScalarValue>)
        ensures EncodeScalarSequence(vs) == s
        decreases s
      {
        var parts: seq<MinimalWellFormedCodeUnitSeq> := PartitionCodeUnitSequence(s);
        var vs: seq<ScalarValue> := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        vs
      }

      function DecodeCodeUnitSequenceChecked(s: CodeUnitSeq): (maybeVs: Option<seq<ScalarValue>>)
        ensures IsWellFormedCodeUnitSequence(s) ==> maybeVs.Some? && maybeVs.Extract() == DecodeCodeUnitSequence(s)
        ensures !IsWellFormedCodeUnitSequence(s) ==> true && maybeVs.None?
        decreases s
      {
        if IsWellFormedCodeUnitSequence(s) then
          Some(DecodeCodeUnitSequence(s))
        else
          None
      } by method {
        var maybeParts := PartitionCodeUnitSequenceChecked(s);
        if maybeParts.None? {
          return None;
        }
        var parts := maybeParts.value;
        var vs := Seq.Map(DecodeMinimalWellFormedCodeUnitSubsequence, parts);
        calc == {
          s;
          Seq.Flatten(parts);
          {
            assert parts == Seq.Map(EncodeScalarValue, vs);
          }
          Seq.Flatten(Seq.Map(EncodeScalarValue, vs));
          EncodeScalarSequence(vs);
        }
        return Some(vs);
      }

      type CodeUnit = bv8

      import opened Wrappers

      import Functions

      import Seq = Collections.Seq

      import opened Base

      type CodeUnitSeq = seq<CodeUnit>

      type WellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsWellFormedCodeUnitSequence(s)
        witness []

      type MinimalWellFormedCodeUnitSeq = s: CodeUnitSeq
        | IsMinimalWellFormedCodeUnitSubsequence(s)
        witness *
    }

    module Utf8EncodingScheme {
      function Serialize(s: Utf8EncodingForm.CodeUnitSeq): (b: seq<byte>)
        decreases s
      {
        Seq.Map((c: bv8) => c as byte, s)
      }

      function Deserialize(b: seq<byte>): (s: Utf8EncodingForm.CodeUnitSeq)
        decreases b
      {
        Seq.Map((b: BoundedInts.uint8) => b as Utf8EncodingForm.CodeUnit, b)
      }

      lemma LemmaSerializeDeserialize(s: Utf8EncodingForm.CodeUnitSeq)
        ensures Deserialize(Serialize(s)) == s
        decreases s
      {
      }

      lemma {:rlimit 3000} LemmaDeserializeSerialize(b: seq<byte>)
        ensures Serialize(Deserialize(b)) == b
        decreases b
      {
        calc {
          Serialize(Deserialize(b));
        ==
          Seq.Map((c: bv8) => c as byte, Seq.Map((b: BoundedInts.uint8) => b as Utf8EncodingForm.CodeUnit, b));
        ==
          Seq.Map((b: BoundedInts.uint8) => b as Utf8EncodingForm.CodeUnit as byte, b);
        ==
          Seq.Map((b: BoundedInts.uint8) => b, b);
        ==
          b;
        }
      }

      import opened Wrappers

      import BoundedInts

      import Seq = Collections.Seq

      import Utf8EncodingForm

      type byte = BoundedInts.uint8
    }
  }

  module Wrappers {
    function Need<E>(condition: bool, error: E): (result: OutcomeResult<E>)
      decreases condition
    {
      if condition then
        Pass'
      else
        Fail'(error)
    }

    datatype Option<+T> = None | Some(value: T) {
      predicate IsFailure()
        decreases this
      {
        None?
      }

      function PropagateFailure<U>(): Option<U>
        requires None?
        decreases this
      {
        None
      }

      function Extract(): T
        requires Some?
        decreases this
      {
        value
      }

      function GetOr(default: T): T
        decreases this
      {
        match this
        case Some(v) =>
          v
        case None() =>
          default
      }

      function ToResult<E>(error: E): Result<T, E>
        decreases this
      {
        match this
        case Some(v) =>
          Success(v)
        case None() =>
          Failure(error)
      }

      function ToOutcome<E>(error: E): Outcome<E>
        decreases this
      {
        match this
        case Some(v) =>
          Pass
        case None() =>
          Fail(error)
      }

      function Map<FC>(rewrap: Option<T> -> FC): FC
        decreases this
      {
        rewrap(this)
      }
    }

    datatype Result<+R, +E> = Success(value: R) | Failure(error: E) {
      predicate IsFailure()
        decreases this
      {
        Failure?
      }

      function PropagateFailure<U>(): (r: Result<U, E>)
        requires Failure?
        decreases this
      {
        Failure(this.error)
      }

      function Extract(): R
        requires Success?
        decreases this
      {
        value
      }

      function GetOr(default: R): R
        decreases this
      {
        match this
        case Success(s) =>
          s
        case Failure(e) =>
          default
      }

      function ToOption(): Option<R>
        decreases this
      {
        match this
        case Success(s) =>
          Some(s)
        case Failure(e) =>
          None()
      }

      function ToOutcome(): Outcome<E>
        decreases this
      {
        match this
        case Success(s) =>
          Pass
        case Failure(e) =>
          Fail(e)
      }

      function Map<FC>(rewrap: Result<R, E> -> FC): FC
        decreases this
      {
        rewrap(this)
      }

      function MapFailure<NewE>(reWrap: E -> NewE): Result<R, NewE>
        decreases this
      {
        match this
        case Success(s) =>
          Success(s)
        case Failure(e) =>
          Failure(reWrap(e))
      }
    }

    datatype Outcome<+E> = Pass | Fail(error: E) {
      predicate IsFailure()
        decreases this
      {
        Fail?
      }

      function PropagateFailure(): Outcome<E>
        requires Fail?
        decreases this
      {
        this
      }

      function ToOption<R>(r: R): Option<R>
        decreases this
      {
        match this
        case Pass() =>
          Some(r)
        case Fail(e) =>
          None()
      }

      function ToResult<R>(r: R): Result<R, E>
        decreases this
      {
        match this
        case Pass() =>
          Success(r)
        case Fail(e) =>
          Failure(e)
      }

      function Map<FC>(rewrap: Outcome<E> -> FC): FC
        decreases this
      {
        rewrap(this)
      }

      function MapFailure<T, NewE>(rewrap: E -> NewE, default: T): Result<T, NewE>
        decreases this
      {
        match this
        case Pass() =>
          Success(default)
        case Fail(e) =>
          Failure(rewrap(e))
      }

      static function Need(condition: bool, error: E): (result: Outcome<E>)
        decreases condition
      {
        if condition then
          Pass
        else
          Fail(error)
      }
    }

    datatype OutcomeResult<+E> = Pass' | Fail'(error: E) {
      predicate IsFailure()
        decreases this
      {
        Fail'?
      }

      function PropagateFailure<U>(): Result<U, E>
        requires IsFailure()
        decreases this
      {
        Failure(this.error)
      }
    }
  }

  
  module CSharpFileIOInternalExterns refines FileIOInternalExterns {
    method {:extern ""DafnyStdLibsExterns.FileIO"", ""INTERNAL_ReadBytesFromFile""} INTERNAL_ReadBytesFromFile(path: string)
        returns (isError: bool, bytesRead: seq<bv8>, errorMsg: string)
      decreases path

    method {:extern ""DafnyStdLibsExterns.FileIO"", ""INTERNAL_WriteBytesToFile""} INTERNAL_WriteBytesToFile(path: string, bytes: seq<bv8>)
        returns (isError: bool, errorMsg: string)
      decreases path, bytes
  }

  module Arithmetic {

    module {:disableNonlinearArithmetic} DivMod {
      lemma LemmaDivIsDivRecursive(x: int, d: int)
        requires 0 < d
        ensures DivRecursive(x, d) == x / d
        decreases x, d
      {
        reveal DivPos();
        reveal DivRecursive();
        LemmaDivInductionAuto(d, x, (u: int) => DivRecursive(u, d) == u / d);
      }

      lemma LemmaDivIsDivRecursiveAuto()
        ensures forall x: int, d: int {:trigger x / d} :: d > 0 ==> DivRecursive(x, d) == x / d
      {
        reveal DivPos();
        reveal DivRecursive();
        forall x: int, d: int | d > 0
          ensures DivRecursive(x, d) == x / d
        {
          LemmaDivIsDivRecursive(x, d);
        }
      }

      lemma LemmaDivBySelf(d: int)
        requires d != 0
        ensures d / d == 1
        decreases d
      {
        DivINL.LemmaDivBySelf(d);
      }

      lemma LemmaDivOf0(d: int)
        requires d != 0
        ensures 0 / d == 0
        decreases d
      {
        DivINL.LemmaDivOf0(d);
      }

      lemma LemmaDivBasics(x: int)
        ensures x != 0 ==> 0 / x == 0
        ensures x / 1 == x
        ensures x != 0 ==> x / x == 1
        decreases x
      {
        if x != 0 {
          LemmaDivBySelf(x);
          LemmaDivOf0(x);
        }
      }

      lemma LemmaDivBasicsAuto()
        ensures forall x: int {:trigger 0 / x} :: x != 0 ==> 0 / x == 0
        ensures forall x: int {:trigger x / 1} :: x / 1 == x
        ensures forall x: int, y: int {:trigger x / y} :: x >= 0 && y > 0 ==> x / y >= 0
        ensures forall x: int, y: int {:trigger x / y} :: x >= 0 && y > 0 ==> x / y <= x
      {
        forall x: int | true
          ensures x != 0 ==> 0 / x == 0
          ensures x / 1 == x
        {
          LemmaDivBasics(x);
        }
        forall x: int, y: int | x >= 0 && y > 0
          ensures 0 <= x / y <= x
        {
          LemmaDivPosIsPos(x, y);
          LemmaDivIsOrderedByDenominator(x, 1, y);
        }
      }

      lemma LemmaSmallDivConverseAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 <= x && 0 < d && x / d == 0 ==> x < d
      {
        forall x: int, d: int | 0 <= x && 0 < d && x / d == 0
          ensures x < d
        {
          LemmaDivInductionAuto(d, x, (u: int) => 0 <= u && 0 < d && u / d == 0 ==> u < d);
        }
      }

      lemma LemmaDivNonZero(x: int, d: int)
        requires x >= d > 0
        ensures x / d > 0
        decreases x, d
      {
        LemmaDivPosIsPosAuto();
        if x / d == 0 {
          LemmaSmallDivConverseAuto();
        }
      }

      lemma LemmaDivNonZeroAuto()
        ensures forall x: int, d: int {:trigger x / d} | x >= d > 0 :: x / d > 0
      {
        forall x: int, d: int | x >= d > 0 {
          LemmaDivNonZero(x, d);
        }
      }

      lemma LemmaDivIsOrderedByDenominator(x: int, y: int, z: int)
        requires 0 <= x
        requires 1 <= y <= z
        ensures x / y >= x / z
        decreases x
      {
        reveal DivPos();
        reveal DivRecursive();
        LemmaDivIsDivRecursiveAuto();
        assert forall u: int, d: int {:trigger u / d} {:trigger DivRecursive(u, d)} :: d > 0 ==> DivRecursive(u, d) == u / d;
        if x < z {
          LemmaDivIsOrdered(0, x, y);
        } else {
          LemmaDivIsOrdered(x - z, x - y, y);
          LemmaDivIsOrderedByDenominator(x - z, y, z);
        }
      }

      lemma LemmaDivIsOrderedByDenominatorAuto()
        ensures forall z: int, y: int, x: int {:trigger x / y, x / z} :: 0 <= x && 1 <= y <= z ==> x / y >= x / z
      {
        forall x: int, y: int, z: int | 0 <= x && 1 <= y <= z
          ensures x / y >= x / z
        {
          LemmaDivIsOrderedByDenominator(x, y, z);
        }
      }

      lemma LemmaDivIsStrictlyOrderedByDenominator(x: int, d: int)
        requires 0 < x
        requires 1 < d
        ensures x / d < x
        decreases x
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 < u ==> u / d < u);
      }

      lemma LemmaDivIsStrictlyOrderedByDenominatorAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 < x && 1 < d ==> x / d < x
      {
        forall x: int, d: int | 0 < x && 1 < d
          ensures x / d < x
        {
          LemmaDivIsStrictlyOrderedByDenominator(x, d);
        }
      }

      lemma LemmaDividingSums(a: int, b: int, d: int, R: int)
        requires 0 < d
        requires R == a % d + b % d - (a + b) % d
        ensures d * (a + b) / d - R == d * a / d + d * b / d
        decreases a, b, d, R
      {
        calc ==> {
          a % d + b % d == R + (a + b) % d;
          a + b - (a + b) % d - R == a - a % d + b - b % d;
          {
            LemmaFundamentalDivMod(a + b, d);
            LemmaFundamentalDivMod(a, d);
            LemmaFundamentalDivMod(b, d);
          }
          d * (a + b) / d - R == d * a / d + d * b / d;
        }
      }

      lemma LemmaDividingSumsAuto()
        ensures forall a: int, b: int, d: int, R: int {:trigger d * (a + b) / d - R, d * a / d + d * b / d} :: 0 < d && R == a % d + b % d - (a + b) % d ==> d * (a + b) / d - R == d * a / d + d * b / d
      {
        forall a: int, b: int, d: int, R: int {:trigger d * (a + b) / d - R, d * a / d + d * b / d} | 0 < d && R == a % d + b % d - (a + b) % d
          ensures d * (a + b) / d - R == d * a / d + d * b / d
        {
          LemmaDividingSums(a, b, d, R);
        }
      }

      lemma LemmaDivPosIsPos(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures 0 <= x / d
        decreases x, d
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u / d >= 0);
      }

      lemma LemmaDivPosIsPosAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 <= x && 0 < d ==> 0 <= x / d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures 0 <= x / d
        {
          LemmaDivPosIsPos(x, d);
        }
      }

      lemma LemmaDivPlusOne(x: int, d: int)
        requires 0 < d
        ensures 1 + x / d == (d + x) / d
        decreases x, d
      {
        LemmaDivAuto(d);
      }

      lemma LemmaDivPlusOneAuto()
        ensures forall x: int, d: int {:trigger 1 + x / d, (d + x) / d} :: 0 < d ==> 1 + x / d == (d + x) / d
      {
        forall x: int, d: int | 0 < d
          ensures 1 + x / d == (d + x) / d
        {
          LemmaDivPlusOne(x, d);
        }
      }

      lemma LemmaDivMinusOne(x: int, d: int)
        requires 0 < d
        ensures -1 + x / d == (-d + x) / d
        decreases x, d
      {
        LemmaDivAuto(d);
      }

      lemma LemmaDivMinusOneAuto()
        ensures forall x: int, d: int {:trigger -1 + x / d, (-d + x) / d} :: 0 < d ==> -1 + x / d == (-d + x) / d
      {
        forall x: int, d: int | 0 < d
          ensures -1 + x / d == (-d + x) / d
        {
          LemmaDivMinusOne(x, d);
        }
      }

      lemma LemmaBasicDiv(d: int)
        requires 0 < d
        ensures forall x: int {:trigger x / d} :: 0 <= x < d ==> x / d == 0
        decreases d
      {
        LemmaDivAuto(d);
      }

      lemma LemmaBasicDivAuto()
        ensures forall d: int, x: int {:trigger x / d} :: 0 <= x < d ==> x / d == 0
      {
        forall x: int, d: int | 0 <= x < d
          ensures x / d == 0
        {
          LemmaBasicDiv(d);
        }
      }

      lemma LemmaDivIsOrdered(x: int, y: int, z: int)
        requires x <= y
        requires 0 < z
        ensures x / z <= y / z
        decreases x, y, z
      {
        LemmaDivInductionAuto(z, x - y, (xy: int) => xy <= 0 ==> (xy + y) / z <= y / z);
      }

      lemma LemmaDivIsOrderedAuto()
        ensures forall x: int, y: int, z: int {:trigger x / z, y / z} :: x <= y && 0 < z ==> x / z <= y / z
      {
        forall x: int, y: int, z: int | x <= y && 0 < z
          ensures x / z <= y / z
        {
          LemmaDivIsOrdered(x, y, z);
        }
      }

      lemma LemmaDivDecreases(x: int, d: int)
        requires 0 < x
        requires 1 < d
        ensures x / d < x
        decreases x, d
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 < u ==> u / d < u);
      }

      lemma LemmaDivDecreasesAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 < x && 1 < d ==> x / d < x
      {
        forall x: int, d: int | 0 < x && 1 < d
          ensures x / d < x
        {
          LemmaDivDecreases(x, d);
        }
      }

      lemma LemmaDivNonincreasing(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures x / d <= x
        decreases x, d
      {
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u / d <= u);
      }

      lemma LemmaDivNonincreasingAuto()
        ensures forall x: int, d: int {:trigger x / d} :: 0 <= x && 0 < d ==> x / d <= x
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures x / d <= x
        {
          LemmaDivNonincreasing(x, d);
        }
      }

      lemma LemmaSmallMod(x: nat, m: nat)
        requires x < m
        requires 0 < m
        ensures x % m == x
        decreases x, m
      {
        ModINL.LemmaSmallMod(x, m);
      }

      lemma LemmaBreakdown(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < y
        requires 0 < z
        ensures 0 < y * z
        ensures x % (y * z) == y * x / y % z + x % y
        decreases x, y, z
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaDivPosIsPos(x, y);
        assert 0 <= x / y;
        calc {
          y * x / y % (y * z) + x % y % (y * z);
        <=
          {
            LemmaPartBound1(x, y, z);
          }
          y * (z - 1) + x % y % (y * z);
        <
          {
            LemmaPartBound2(x, y, z);
          }
          y * (z - 1) + y;
          {
            LemmaMulBasicsAuto();
          }
          y * (z - 1) + y * 1;
          {
            LemmaMulIsDistributiveAuto();
          }
          y * (z - 1 + 1);
          y * z;
        }
        calc {
          x % (y * z);
          {
            LemmaFundamentalDivMod(x, y);
          }
          (y * x / y + x % y) % (y * z);
          {
            LemmaModPropertiesAuto();
            assert 0 <= x % y;
            LemmaMulNonnegative(y, x / y);
            assert y * x / y % (y * z) + x % y % (y * z) < y * z;
            LemmaModAdds(y * x / y, x % y, y * z);
          }
          y * x / y % (y * z) + x % y % (y * z);
          {
            LemmaModPropertiesAuto();
            LemmaMulIncreases(z, y);
            LemmaMulIsCommutativeAuto();
            assert x % y < y <= y * z;
            LemmaSmallMod(x % y, y * z);
            assert x % y % (y * z) == x % y;
          }
          y * x / y % (y * z) + x % y;
          {
            LemmaTruncateMiddle(x / y, y, z);
          }
          y * x / y % z + x % y;
        }
      }

      lemma LemmaBreakdownAuto()
        ensures (forall x: int, y: int, z: int {:trigger y * z, x % (y * z), y * x / y % z + x % y} :: 0 <= x && 0 < y && 0 < z ==> 0 < y * z) && forall x: int, y: int, z: int {:trigger y * z, x % (y * z), y * x / y % z + x % y} :: 0 <= x && 0 < y && 0 < z ==> x % (y * z) == y * x / y % z + x % y
      {
        forall x: int, y: int, z: int | 0 <= x && 0 < y && 0 < z
          ensures 0 < y * z && x % (y * z) == y * x / y % z + x % y
        {
          LemmaBreakdown(x, y, z);
        }
      }

      lemma LemmaRemainderUpper(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures x - d < x / d * d
        decreases x, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u - d < u / d * d);
      }

      lemma LemmaRemainderUpperAuto()
        ensures forall x: int, d: int {:trigger x - d, d * d} :: 0 <= x && 0 < d ==> x - d < x / d * d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures x - d < x / d * d
        {
          LemmaRemainderUpper(x, d);
        }
      }

      lemma LemmaRemainderLower(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures x >= x / d * d
        decreases x, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u ==> u >= u / d * d);
      }

      lemma LemmaRemainderLowerAuto()
        ensures forall x: int, d: int {:trigger x / d * d} :: 0 <= x && 0 < d ==> x >= x / d * d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures x >= x / d * d
        {
          LemmaRemainderLower(x, d);
        }
      }

      lemma LemmaRemainder(x: int, d: int)
        requires 0 <= x
        requires 0 < d
        ensures 0 <= x - x / d * d < d
        decreases x, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, x, (u: int) => 0 <= u - u / d * d < d);
      }

      lemma LemmaRemainderAuto()
        ensures (forall x: int, d: int {:trigger x - x / d * d} :: 0 <= x && 0 < d ==> 0 <= x - x / d * d) && forall x: int, d: int {:trigger x - x / d * d} :: 0 <= x && 0 < d ==> x - x / d * d < d
      {
        forall x: int, d: int | 0 <= x && 0 < d
          ensures 0 <= x - x / d * d < d
        {
          LemmaRemainder(x, d);
        }
      }

      lemma LemmaFundamentalDivMod(x: int, d: int)
        requires d != 0
        ensures x == d * x / d + x % d
        decreases x, d
      {
        ModINL.LemmaFundamentalDivMod(x, d);
      }

      lemma LemmaFundamentalDivModAuto()
        ensures forall x: int, d: int {:trigger d * x / d + x % d} :: d != 0 ==> x == d * x / d + x % d
      {
        forall x: int, d: int | d != 0
          ensures x == d * x / d + x % d
        {
          LemmaFundamentalDivMod(x, d);
        }
      }

      lemma LemmaDivDenominator(x: int, c: nat, d: nat)
        requires 0 <= x
        requires 0 < c
        requires 0 < d
        ensures c * d != 0
        ensures x / c / d == x / (c * d)
        decreases x, c, d
      {
        LemmaMulStrictlyPositiveAuto();
        ghost var R := x % (c * d);
        LemmaModPropertiesAuto();
        LemmaDivPosIsPos(R, c);
        if R / c >= d {
          LemmaFundamentalDivMod(R, c);
          LemmaMulInequality(d, R / c, c);
          LemmaMulIsCommutativeAuto();
          assert false;
        }
        assert R / c < d;
        LemmaMulBasicsAuto();
        LemmaFundamentalDivModConverse(R / c, d, 0, R / c);
        assert R / c % d == R / c;
        LemmaFundamentalDivMod(R, c);
        assert c * R / c + R % c == R;
        assert c * R / c % d + R % c == R;
        ghost var k := x / (c * d);
        LemmaFundamentalDivMod(x, c * d);
        assert x == c * d * x / (c * d) + x % (c * d);
        assert R == x - c * d * x / (c * d);
        assert R == x - c * d * k;
        calc {
          c * x / c % d + x % c;
          {
            LemmaModMultiplesVanish(-k, x / c, d);
            LemmaMulIsCommutativeAuto();
          }
          c * (x / c + -k * d) % d + x % c;
          {
            LemmaHoistOverDenominator(x, -k * d, c);
          }
          c * (x + -k * d * c) / c % d + x % c;
          {
            LemmaMulIsAssociative(-k, d, c);
          }
          c * (x + -k * d * c) / c % d + x % c;
          {
            LemmaMulUnaryNegation(k, d * c);
          }
          c * (x + -(k * d * c)) / c % d + x % c;
          {
            LemmaMulIsAssociative(k, d, c);
          }
          c * (x + -(k * d * c)) / c % d + x % c;
          c * (x - k * d * c) / c % d + x % c;
          {
            LemmaMulIsAssociativeAuto();
            LemmaMulIsCommutativeAuto();
          }
          c * R / c % d + x % c;
          c * R / c + x % c;
          {
            LemmaFundamentalDivMod(R, c);
            assert R == c * R / c + R % c;
            LemmaModMod(x, c, d);
            assert R % c == x % c;
          }
          R;
          {
            LemmaModIsModRecursiveAuto();
          }
          R % (c * d);
          (x - c * d * k) % (c * d);
          {
            LemmaMulUnaryNegation(c * d, k);
          }
          (x + c * d * -k) % (c * d);
          {
            LemmaModMultiplesVanish(-k, x, c * d);
          }
          x % (c * d);
        }
        calc ==> {
          c * x / c + x % c - R == c * x / c - c * x / c % d;
          {
            LemmaFundamentalDivMod(x, c);
          }
          x - R == c * x / c - c * x / c % d;
        }
        calc ==> {
          true;
          {
            LemmaFundamentalDivMod(x / c, d);
          }
          d * x / c / d == x / c - x / c % d;
          c * d * x / c / d == c * (x / c - x / c % d);
          {
            LemmaMulIsAssociativeAuto();
          }
          c * d * x / c / d == c * (x / c - x / c % d);
          {
            LemmaMulIsDistributiveAuto();
          }
          c * d * x / c / d == c * x / c - c * x / c % d;
          c * d * x / c / d == x - R;
          {
            LemmaFundamentalDivMod(x, c * d);
          }
          c * d * x / c / d == c * d * x / (c * d) + x % (c * d) - R;
          c * d * x / c / d == c * d * x / (c * d);
          {
            LemmaMulEqualityConverse(c * d, x / c / d, x / (c * d));
          }
          x / c / d == x / (c * d);
        }
      }

      lemma LemmaDivDenominatorAuto()
        ensures forall c: nat, d: nat {:trigger c * d} :: 0 < c && 0 < d ==> c * d != 0
        ensures forall x: int, c: nat, d: nat {:trigger x / c / d} :: 0 <= x && 0 < c && 0 < d ==> x / c / d == x / (c * d)
      {
        LemmaMulNonzeroAuto();
        forall x: int, c: nat, d: nat | 0 <= x && 0 < c && 0 < d
          ensures x / c / d == x / (c * d)
        {
          LemmaDivDenominator(x, c, d);
        }
      }

      lemma LemmaMulHoistInequality(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < z
        ensures x * y / z <= x * y / z
        decreases x, y, z
      {
        calc {
          x * y / z;
          {
            LemmaFundamentalDivMod(y, z);
          }
          x * (z * y / z + y % z) / z;
          {
            LemmaMulIsDistributiveAuto();
          }
          (x * z * y / z + x * y % z) / z;
        >=
          {
            LemmaModPropertiesAuto();
            LemmaMulNonnegative(x, y % z);
            LemmaDivIsOrdered(x * z * y / z, x * z * y / z + x * y % z, z);
          }
          x * z * y / z / z;
          {
            LemmaMulIsAssociativeAuto();
            LemmaMulIsCommutativeAuto();
          }
          z * x * y / z / z;
          {
            LemmaDivMultiplesVanish(x * y / z, z);
          }
          x * y / z;
        }
      }

      lemma LemmaMulHoistInequalityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * y / z, x * y / z} :: 0 <= x && 0 < z ==> x * y / z <= x * y / z
      {
        forall x: int, y: int, z: int | 0 <= x && 0 < z
          ensures x * y / z <= x * y / z
        {
          LemmaMulHoistInequality(x, y, z);
        }
      }

      lemma LemmaIndistinguishableQuotients(a: int, b: int, d: int)
        requires 0 < d
        requires 0 <= a - a % d <= b < a + d - a % d
        ensures a / d == b / d
        decreases a, b, d
      {
        LemmaDivInductionAuto(d, a - b, (ab: int) => ghost var u: int := ab + b; 0 <= u - u % d <= b < u + d - u % d ==> u / d == b / d);
      }

      lemma LemmaIndistinguishableQuotientsAuto()
        ensures forall a: int, b: int, d: int {:trigger a / d, b / d} :: 0 < d && 0 <= a - a % d <= b < a + d - a % d ==> a / d == b / d
      {
        forall a: int, b: int, d: int | 0 < d && 0 <= a - a % d <= b < a + d - a % d
          ensures a / d == b / d
        {
          LemmaIndistinguishableQuotients(a, b, d);
        }
      }

      lemma LemmaTruncateMiddle(x: int, b: int, c: int)
        requires 0 <= x
        requires 0 < b
        requires 0 < c
        ensures 0 < b * c
        ensures b * x % (b * c) == b * x % c
        decreases x, b, c
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaMulNonnegativeAuto();
        calc {
          b * x;
          {
            LemmaFundamentalDivMod(b * x, b * c);
          }
          b * c * b * x / (b * c) + b * x % (b * c);
          {
            LemmaDivDenominator(b * x, b, c);
          }
          b * c * b * x / b / c + b * x % (b * c);
          {
            LemmaMulIsCommutativeAuto();
            LemmaDivByMultiple(x, b);
          }
          b * c * x / c + b * x % (b * c);
        }
        calc ==> {
          true;
          {
            LemmaFundamentalDivMod(x, c);
          }
          x == c * x / c + x % c;
          b * x == b * (c * x / c + x % c);
          {
            LemmaMulIsDistributiveAuto();
          }
          b * x == b * c * x / c + b * x % c;
          {
            LemmaMulIsAssociativeAuto();
          }
          b * x == b * c * x / c + b * x % c;
        }
      }

      lemma LemmaTruncateMiddleAuto()
        ensures forall x: int, b: int, c: int {:trigger b * x % c} :: 0 <= x && 0 < b && 0 < c && 0 < b * c ==> b * x % (b * c) == b * x % c
      {
        forall x: int, b: int, c: int | 0 <= x && 0 < b && 0 < c && 0 < b * c
          ensures b * x % (b * c) == b * x % c
        {
          LemmaTruncateMiddle(x, b, c);
        }
      }

      lemma LemmaDivMultiplesVanishQuotient(x: int, a: int, d: int)
        requires 0 < x
        requires 0 <= a
        requires 0 < d
        ensures 0 < x * d
        ensures a / d == x * a / (x * d)
        decreases x, a, d
      {
        LemmaMulStrictlyPositive(x, d);
        calc {
          x * a / (x * d);
          {
            LemmaMulNonnegative(x, a);
            LemmaDivDenominator(x * a, x, d);
          }
          x * a / x / d;
          {
            LemmaDivMultiplesVanish(a, x);
          }
          a / d;
        }
      }

      lemma LemmaDivMultiplesVanishQuotientAuto()
        ensures (forall x: int, a: int, d: int {:trigger a / d, x * d, x * a} :: 0 < x && 0 <= a && 0 < d ==> 0 < x * d) && forall x: int, a: int, d: int {:trigger a / d, x * d, x * a} :: 0 < x && 0 <= a && 0 < d ==> a / d == x * a / (x * d)
      {
        forall x: int, a: int, d: int {:trigger x * d, 0 <= a} | 0 < x && 0 <= a && 0 < d
          ensures 0 < x * d && a / d == x * a / (x * d)
        {
          LemmaDivMultiplesVanishQuotient(x, a, d);
        }
      }

      lemma LemmaRoundDown(a: int, r: int, d: int)
        requires 0 < d
        requires a % d == 0
        requires 0 <= r < d
        ensures a == d * (a + r) / d
        decreases a, r, d
      {
        LemmaMulAuto();
        LemmaDivInductionAuto(d, a, (u: int) => u % d == 0 ==> u == d * (u + r) / d);
      }

      lemma LemmaRoundDownAuto()
        ensures forall d: int, r: int, a: int {:trigger d * (a + r) / d} :: 0 < d && a % d == 0 && 0 <= r < d ==> a == d * (a + r) / d
      {
        forall a: int, r: int, d: int {:trigger a + r, r < d} {:trigger a + r, 0 < d} {:trigger 0 <= r, a % d} | 0 < d && a % d == 0 && 0 <= r < d
          ensures a == d * (a + r) / d
        {
          LemmaRoundDown(a, r, d);
        }
      }

      lemma LemmaDivMultiplesVanishFancy(x: int, b: int, d: int)
        requires 0 < d
        requires 0 <= b < d
        ensures (d * x + b) / d == x
        decreases x, b, d
      {
        LemmaDivAuto(d);
        ghost var f := (u: int) => (d * u + b) / d == u;
        LemmaMulInductionAuto(x, f);
        assert f(x);
      }

      lemma LemmaDivMultiplesVanishFancyAuto()
        ensures forall d: int, b: int, x: int {:trigger (d * x + b) / d} :: 0 < d && 0 <= b < d ==> (d * x + b) / d == x
      {
        forall x: int, b: int, d: int {:trigger d * x, b < d} {:trigger d * x, 0 <= b} | 0 < d && 0 <= b < d
          ensures (d * x + b) / d == x
        {
          LemmaDivMultiplesVanishFancy(x, b, d);
        }
      }

      lemma LemmaDivMultiplesVanish(x: int, d: int)
        requires 0 < d
        ensures d * x / d == x
        decreases x, d
      {
        LemmaDivMultiplesVanishFancy(x, 0, d);
      }

      lemma LemmaDivMultiplesVanishAuto()
        ensures forall x: int, d: int {:trigger d * x / d} :: 0 < d ==> d * x / d == x
      {
        forall x: int, d: int | 0 < d
          ensures d * x / d == x
        {
          LemmaDivMultiplesVanish(x, d);
        }
      }

      lemma LemmaDivByMultiple(b: int, d: int)
        requires 0 <= b
        requires 0 < d
        ensures b * d / d == b
        decreases b, d
      {
        LemmaDivMultiplesVanish(b, d);
      }

      lemma LemmaDivByMultipleAuto()
        ensures forall b: int, d: int {:trigger b * d / d} :: 0 <= b && 0 < d ==> b * d / d == b
      {
        forall b: int, d: int | 0 <= b && 0 < d
          ensures b * d / d == b
        {
          LemmaDivByMultiple(b, d);
        }
      }

      lemma LemmaDivByMultipleIsStronglyOrdered(x: int, y: int, m: int, z: int)
        requires x < y
        requires y == m * z
        requires 0 < z
        ensures x / z < y / z
        decreases x, y, m, z
      {
        LemmaModMultiplesBasic(m, z);
        LemmaDivInductionAuto(z, y - x, (yx: int) => ghost var u: int := yx + x; x < u && u % z == 0 ==> x / z < u / z);
      }

      lemma LemmaDivByMultipleIsStronglyOrderedAuto()
        ensures forall z: int, m: int, y: int, x: int {:trigger x / z, m * z, y / z} :: x < y && y == m * z && 0 < z ==> x / z < y / z
      {
        forall x: int, y: int, m: int, z: int | x < y && y == m * z && 0 < z
          ensures x / z < y / z
        {
          LemmaDivByMultipleIsStronglyOrdered(x, y, m, z);
        }
      }

      lemma LemmaMultiplyDivideLe(a: int, b: int, c: int)
        requires 0 < b
        requires a <= b * c
        ensures a / b <= c
        decreases a, b, c
      {
        LemmaModMultiplesBasic(c, b);
        LemmaDivInductionAuto(b, b * c - a, (i: int) => 0 <= i && (i + a) % b == 0 ==> a / b <= (i + a) / b);
        LemmaDivMultiplesVanish(c, b);
      }

      lemma LemmaMultiplyDivideLeAuto()
        ensures forall a: int, b: int, c: int {:trigger a / b, b * c} :: 0 < b && a <= b * c ==> a / b <= c
      {
        forall a: int, b: int, c: int | 0 < b && a <= b * c
          ensures a / b <= c
        {
          LemmaMultiplyDivideLe(a, b, c);
        }
      }

      lemma LemmaMultiplyDivideLt(a: int, b: int, c: int)
        requires 0 < b
        requires a < b * c
        ensures a / b < c
        decreases a, b, c
      {
        LemmaModMultiplesBasic(c, b);
        LemmaDivInductionAuto(b, b * c - a, (i: int) => 0 < i && (i + a) % b == 0 ==> a / b < (i + a) / b);
        LemmaDivMultiplesVanish(c, b);
      }

      lemma LemmaMultiplyDivideLtAuto()
        ensures forall a: int, b: int, c: int {:trigger a / b, b * c} :: 0 < b && a < b * c ==> a / b < c
      {
        forall a: int, b: int, c: int | 0 < b && a < b * c
          ensures a / b < c
        {
          LemmaMultiplyDivideLt(a, b, c);
        }
      }

      lemma LemmaHoistOverDenominator(x: int, j: int, d: nat)
        requires 0 < d
        ensures x / d + j == (x + j * d) / d
        decreases x, j, d
      {
        LemmaDivAuto(d);
        LemmaMulInductionAuto(j, (u: int) => x / d + u == (x + u * d) / d);
      }

      lemma LemmaHoistOverDenominatorAuto()
        ensures forall x: int, j: int, d: nat {:trigger x / d + j} :: 0 < d ==> x / d + j == (x + j * d) / d
      {
        forall x: int, j: int, d: nat | 0 < d
          ensures x / d + j == (x + j * d) / d
        {
          LemmaHoistOverDenominator(x, j, d);
        }
      }

      lemma LemmaPartBound1(a: int, b: int, c: int)
        requires 0 <= a
        requires 0 < b
        requires 0 < c
        ensures 0 < b * c
        ensures b * a / b % (b * c) <= b * (c - 1)
        decreases a, b, c
      {
        LemmaMulStrictlyPositiveAuto();
        calc {
          b * a / b % (b * c);
          {
            LemmaFundamentalDivMod(b * a / b, b * c);
          }
          b * a / b - b * c * b * a / b / (b * c);
          {
            LemmaMulIsAssociativeAuto();
          }
          b * a / b - b * c * b * a / b / (b * c);
          {
            LemmaMulIsDistributiveAuto();
          }
          b * (a / b - c * b * a / b / (b * c));
        }
        calc ==> {
          true;
          {
            LemmaModPropertiesAuto();
          }
          b * a / b % (b * c) < b * c;
          b * (a / b - c * b * a / b / (b * c)) < b * c;
          {
            LemmaMulIsCommutativeAuto();
            LemmaMulStrictInequalityConverseAuto();
          }
          a / b - c * b * a / b / (b * c) < c;
          a / b - c * b * a / b / (b * c) <= c - 1;
          {
            LemmaMulIsCommutativeAuto();
            LemmaMulInequalityAuto();
          }
          b * (a / b - c * b * a / b / (b * c)) <= b * (c - 1);
          b * a / b % (b * c) <= b * (c - 1);
        }
      }

      lemma LemmaPartBound1Auto()
        ensures (forall a: int, b: int, c: int {:trigger b * a / b % (b * c)} :: 0 <= a && 0 < b && 0 < c ==> 0 < b * c) && forall a: int, b: int, c: int {:trigger b * a / b % (b * c)} :: 0 <= a && 0 < b && 0 < c ==> b * a / b % (b * c) <= b * (c - 1)
      {
        forall a: int, b: int, c: int {:trigger b * c, 0 <= a} | 0 <= a && 0 < b && 0 < c
          ensures 0 < b * c && b * a / b % (b * c) <= b * (c - 1)
        {
          LemmaPartBound1(a, b, c);
        }
      }

      lemma /*{:_induction x, m}*/ LemmaModIsModRecursive(x: int, m: int)
        requires m > 0
        ensures ModRecursive(x, m) == x % m
        decreases if x < 0 then -x + m else x
      {
        reveal ModRecursive();
        if x < 0 {
          calc {
            ModRecursive(x, m);
            ModRecursive(x + m, m);
            {
              LemmaModIsModRecursive(x + m, m);
            }
            (x + m) % m;
            {
              LemmaAddModNoop(x, m, m);
            }
            (x % m + m % m) % m;
            {
              LemmaModBasicsAuto();
            }
            x % m % m;
            {
              LemmaModBasicsAuto();
            }
            x % m;
          }
        } else if x < m {
          LemmaSmallMod(x, m);
        } else {
          calc {
            ModRecursive(x, m);
            ModRecursive(x - m, m);
            {
              LemmaModIsModRecursive(x - m, m);
            }
            (x - m) % m;
            {
              LemmaSubModNoop(x, m, m);
            }
            (x % m - m % m) % m;
            {
              LemmaModBasicsAuto();
            }
            x % m % m;
            {
              LemmaModBasicsAuto();
            }
            x % m;
          }
        }
      }

      lemma LemmaModIsModRecursiveAuto()
        ensures forall x: int, d: int {:trigger x % d} :: d > 0 ==> ModRecursive(x, d) == x % d
      {
        reveal ModRecursive();
        forall x: int, d: int | d > 0
          ensures ModRecursive(x, d) == x % d
        {
          LemmaModIsModRecursive(x, d);
        }
      }

      lemma LemmaModBasicsAuto()
        ensures forall m: int {:trigger m % m} :: m > 0 ==> m % m == 0
        ensures forall x: int, m: int {:trigger x % m % m} :: m > 0 ==> x % m % m == x % m
      {
        forall m: int | m > 0
          ensures m % m == 0
        {
          LemmaModAuto(m);
        }
        forall x: int, m: int | m > 0
          ensures x % m % m == x % m
        {
          LemmaModAuto(m);
        }
      }

      lemma LemmaModPropertiesAuto()
        ensures forall m: int {:trigger m % m} :: m > 0 ==> m % m == 0
        ensures forall x: int, m: int {:trigger x % m % m} :: m > 0 ==> x % m % m == x % m
        ensures forall x: int, m: int {:trigger x % m} :: (m > 0 ==> 0 <= x % m) && (m > 0 ==> x % m < m)
      {
        LemmaModBasicsAuto();
        forall x: int, m: int | m > 0
          ensures 0 <= x % m < m
        {
          LemmaModAuto(m);
        }
      }

      lemma LemmaModDecreases(x: nat, m: nat)
        requires 0 < m
        ensures x % m <= x
        decreases x, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModDecreasesAuto()
        ensures forall x: nat, m: nat {:trigger x % m} :: 0 < m ==> x % m <= x
      {
        forall x: nat, m: nat | 0 < m
          ensures x % m <= x
        {
          LemmaModDecreases(x, m);
        }
      }

      lemma LemmaModIsZero(x: nat, m: nat)
        requires x > 0 && m > 0
        requires x % m == 0
        ensures x >= m
        decreases x, m
      {
        if x < m {
          assert x % m == x by {
            LemmaSmallMod(x, m);
          }
          assert false;
        }
      }

      lemma LemmaModIsZeroAuto()
        ensures forall m: nat, x: nat {:trigger x % m} :: x > 0 && m > 0 && x % m == 0 ==> x >= m
      {
        forall x: nat, m: nat | x > 0 && m > 0 && x % m == 0
          ensures x >= m
        {
          LemmaModIsZero(x, m);
        }
      }

      lemma LemmaModMultiplesBasic(x: int, m: int)
        requires m > 0
        ensures x * m % m == 0
        decreases x, m
      {
        LemmaModAuto(m);
        LemmaMulInductionAuto(x, (u: int) => u * m % m == 0);
      }

      lemma LemmaModMultiplesBasicAuto()
        ensures forall x: int, m: int {:trigger x * m % m} :: m > 0 ==> x * m % m == 0
      {
        forall x: int, m: int | m > 0
          ensures x * m % m == 0
        {
          LemmaModMultiplesBasic(x, m);
        }
      }

      lemma LemmaModAddMultiplesVanish(b: int, m: int)
        requires 0 < m
        ensures (m + b) % m == b % m
        decreases b, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModAddMultiplesVanishAuto()
        ensures forall b: int, m: int {:trigger b % m} :: 0 < m ==> (m + b) % m == b % m
      {
        forall b: int, m: int | 0 < m
          ensures (m + b) % m == b % m
        {
          LemmaModAddMultiplesVanish(b, m);
        }
      }

      lemma LemmaModSubMultiplesVanish(b: int, m: int)
        requires 0 < m
        ensures (-m + b) % m == b % m
        decreases b, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModSubMultiplesVanishAuto()
        ensures forall b: int, m: int {:trigger b % m} :: 0 < m ==> (-m + b) % m == b % m
      {
        forall b: int, m: int | 0 < m
          ensures (-m + b) % m == b % m
        {
          LemmaModSubMultiplesVanish(b, m);
        }
      }

      predicate MultiplesVanish(a: int, b: int, m: int)
        requires 0 < m
        decreases a, b, m
      {
        (m * a + b) % m == b % m
      }

      lemma LemmaModMultiplesVanish(a: int, b: int, m: int)
        requires 0 < m
        ensures MultiplesVanish(a, b, m)
        decreases if a > 0 then a else -a
      {
        LemmaModAuto(m);
        LemmaMulAuto();
        assert MultiplesVanish(0, b, m);
        LemmaMulInductionAuto(a, (u: int) => MultiplesVanish(u, b, m));
      }

      lemma LemmaModMultiplesVanishAuto()
        ensures forall a: int, b: int, m: int {:trigger (m * a + b) % m} :: 0 < m ==> MultiplesVanish(a, b, m)
      {
        forall a: int, b: int, m: int | 0 < m
          ensures MultiplesVanish(a, b, m)
        {
          LemmaModMultiplesVanish(a, b, m);
        }
      }

      lemma LemmaModSubtraction(x: nat, s: nat, d: nat)
        requires 0 < d
        requires 0 <= s <= x % d
        ensures x % d - s % d == (x - s) % d
        decreases x, s, d
      {
        LemmaModAuto(d);
      }

      lemma LemmaModSubtractionAuto()
        ensures forall x: nat, s: nat, d: nat {:trigger (x - s) % d} :: 0 < d && 0 <= s <= x % d ==> x % d - s % d == (x - s) % d
      {
        forall x: nat, s: nat, d: nat | 0 < d && 0 <= s <= x % d
          ensures x % d - s % d == (x - s) % d
        {
          LemmaModSubtraction(x, s, d);
        }
      }

      lemma LemmaAddModNoop(x: int, y: int, m: int)
        requires 0 < m
        ensures (x % m + y % m) % m == (x + y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaAddModNoopAuto()
        ensures forall x: int, y: int, m: int {:trigger (x + y) % m} :: 0 < m ==> (x % m + y % m) % m == (x + y) % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures (x % m + y % m) % m == (x + y) % m
        {
          LemmaAddModNoop(x, y, m);
        }
      }

      lemma LemmaAddModNoopRight(x: int, y: int, m: int)
        requires 0 < m
        ensures (x + y % m) % m == (x + y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaAddModNoopRightAuto()
        ensures forall x: int, y: int, m: int {:trigger (x + y) % m} :: 0 < m ==> (x + y % m) % m == (x + y) % m
      {
        forall x: int, y: int, m: int {:trigger x + y % m} | 0 < m
          ensures (x + y % m) % m == (x + y) % m
        {
          LemmaAddModNoopRight(x, y, m);
        }
      }

      lemma LemmaSubModNoop(x: int, y: int, m: int)
        requires 0 < m
        ensures (x % m - y % m) % m == (x - y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaSubModNoopAuto()
        ensures forall x: int, y: int, m: int {:trigger (x - y) % m} :: 0 < m ==> (x % m - y % m) % m == (x - y) % m
      {
        forall x: int, y: int, m: int {:trigger x % m - y % m} | 0 < m
          ensures (x % m - y % m) % m == (x - y) % m
        {
          LemmaSubModNoop(x, y, m);
        }
      }

      lemma LemmaSubModNoopRight(x: int, y: int, m: int)
        requires 0 < m
        ensures (x - y % m) % m == (x - y) % m
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaSubModNoopRightAuto()
        ensures forall x: int, y: int, m: int {:trigger (x - y) % m} :: 0 < m ==> (x - y % m) % m == (x - y) % m
      {
        forall x: int, y: int, m: int {:trigger x - y % m} | 0 < m
          ensures (x - y % m) % m == (x - y) % m
        {
          LemmaSubModNoopRight(x, y, m);
        }
      }

      lemma LemmaModAdds(a: int, b: int, d: int)
        requires 0 < d
        ensures a % d + b % d == (a + b) % d + d * (a % d + b % d) / d
        ensures a % d + b % d < d ==> a % d + b % d == (a + b) % d
        decreases a, b, d
      {
        LemmaMulAuto();
        LemmaDivAuto(d);
      }

      lemma LemmaModAddsAuto()
        ensures forall a: int, b: int, d: int {:trigger (a + b) % d} :: (0 < d ==> a % d + b % d == (a + b) % d + d * (a % d + b % d) / d) && (0 < d ==> a % d + b % d < d ==> a % d + b % d == (a + b) % d)
      {
        forall a: int, b: int, d: int | 0 < d
          ensures a % d + b % d == (a + b) % d + d * (a % d + b % d) / d && (a % d + b % d < d ==> a % d + b % d == (a + b) % d)
        {
          LemmaModAdds(a, b, d);
        }
      }

      lemma {:vcs_split_on_every_assert} LemmaModNegNeg(x: int, d: int)
        requires 0 < d
        ensures x % d == x * (1 - d) % d
        decreases x, d
      {
        assert (x - x * d) % d == x % d by {
          LemmaModAuto(d);
          ghost var f := (i: int) => (x - i * d) % d == x % d;
          assert MulAuto() ==> f(0) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1)) && forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
          LemmaMulInductionAuto(x, f);
        }
        LemmaMulAuto();
      }

      lemma {:timeLimitMultiplier 5} /*{:_rlimit 5000000}*/ LemmaFundamentalDivModConverse(x: int, d: int, q: int, r: int)
        requires d != 0
        requires 0 <= r < d
        requires x == q * d + r
        ensures q == x / d
        ensures r == x % d
        decreases x, d, q, r
      {
        LemmaDivAuto(d);
        LemmaMulInductionAuto(q, (u: int) => u == (u * d + r) / d);
        LemmaMulInductionAuto(q, (u: int) => r == (u * d + r) % d);
      }

      lemma {:timeLimitMultiplier 5} /*{:_rlimit 5000000}*/ LemmaFundamentalDivModConverseAuto()
        ensures forall x: int, d: int, q: int, r: int {:trigger q * d + r, x % d} :: (d != 0 && 0 <= r < d && x == q * d + r ==> q == x / d) && (d != 0 && 0 <= r < d && x == q * d + r ==> r == x % d)
      {
        forall x: int, d: int, q: int, r: int {:trigger x / d, q * d, r < d} {:trigger x / d, q * d, 0 <= r} | d != 0 && 0 <= r < d && x == q * d + r
          ensures q == x / d && r == x % d
        {
          LemmaFundamentalDivModConverse(x, d, q, r);
        }
      }

      lemma LemmaModPosBound(x: int, m: int)
        requires 0 <= x
        requires 0 < m
        ensures 0 <= x % m < m
        decreases x
      {
        LemmaModAuto(m);
      }

      lemma LemmaModPosBoundAuto()
        ensures (forall x: int, m: int {:trigger x % m} :: 0 <= x && 0 < m ==> 0 <= x % m) && forall x: int, m: int {:trigger x % m} :: 0 <= x && 0 < m ==> x % m < m
      {
        forall x: int, m: int | 0 <= x && 0 < m
          ensures 0 <= x % m < m
        {
          LemmaModPosBound(x, m);
        }
      }

      lemma LemmaMulModNoopLeft(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m * y % m == x * y % m
        decreases x, y, m
      {
        LemmaModAuto(m);
        LemmaMulInductionAuto(y, (u: int) => x % m * u % m == x * u % m);
      }

      lemma LemmaMulModNoopLeftAuto()
        ensures forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x % m * y % m == x * y % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m * y % m == x * y % m
        {
          LemmaMulModNoopLeft(x, y, m);
        }
      }

      lemma LemmaMulModNoopRight(x: int, y: int, m: int)
        requires 0 < m
        ensures x * y % m % m == x * y % m
        decreases x, y, m
      {
        LemmaModAuto(m);
        LemmaMulInductionAuto(x, (u: int) => u * y % m % m == u * y % m);
      }

      lemma LemmaMulModNoopRightAuto()
        ensures forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x * y % m % m == x * y % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x * y % m % m == x * y % m
        {
          LemmaMulModNoopRight(x, y, m);
        }
      }

      lemma LemmaMulModNoopGeneral(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m * y % m == x * y % m
        ensures x * y % m % m == x * y % m
        ensures x % m * y % m % m == x * y % m
        decreases x, y, m
      {
        LemmaModPropertiesAuto();
        LemmaMulModNoopLeft(x, y, m);
        LemmaMulModNoopRight(x, y, m);
        LemmaMulModNoopRight(x % m, y, m);
      }

      lemma LemmaMulModNoopGeneralAuto()
        ensures (forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x % m * y % m == x * y % m % m) && forall x: int, y: int, m: int {:trigger x * y % m} :: (0 < m ==> x * y % m % m == x % m * y % m % m) && (0 < m ==> x % m * y % m % m == x * y % m)
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m * y % m == x * y % m % m == x % m * y % m % m == x * y % m
        {
          LemmaMulModNoopGeneral(x, y, m);
        }
      }

      lemma LemmaMulModNoop(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m * y % m % m == x * y % m
        decreases x, y, m
      {
        LemmaMulModNoopGeneral(x, y, m);
      }

      lemma LemmaMulModNoopAuto()
        ensures forall x: int, y: int, m: int {:trigger x * y % m} :: 0 < m ==> x % m * y % m % m == x * y % m
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m * y % m % m == x * y % m
        {
          LemmaMulModNoop(x, y, m);
        }
      }

      lemma LemmaModEquivalence(x: int, y: int, m: int)
        requires 0 < m
        ensures x % m == y % m <==> (x - y) % m == 0
        decreases x, y, m
      {
        LemmaModAuto(m);
      }

      lemma LemmaModEquivalenceAuto()
        ensures forall x: int, y: int, m: int {:trigger x % m, y % m} :: 0 < m && x % m == y % m <==> 0 < m && (x - y) % m == 0
      {
        forall x: int, y: int, m: int | 0 < m
          ensures x % m == y % m <==> 0 < m && (x - y) % m == 0
        {
          LemmaModEquivalence(x, y, m);
        }
      }

      ghost predicate IsModEquivalent(x: int, y: int, m: int)
        requires m > 0
        ensures x % m == y % m <==> (x - y) % m == 0
        decreases x, y, m
      {
        LemmaModEquivalence(x, y, m);
        (x - y) % m == 0
      }

      lemma LemmaModMulEquivalent(x: int, y: int, z: int, m: int)
        requires m > 0
        requires IsModEquivalent(x, y, m)
        ensures IsModEquivalent(x * z, y * z, m)
        decreases x, y, z, m
      {
        LemmaMulModNoopLeft(x, z, m);
        LemmaMulModNoopLeft(y, z, m);
      }

      lemma LemmaModMulEquivalentAuto()
        ensures forall x: int, y: int, z: int, m: int {:trigger IsModEquivalent(x * z, y * z, m)} :: m > 0 && IsModEquivalent(x, y, m) ==> IsModEquivalent(x * z, y * z, m)
      {
        forall x: int, y: int, z: int, m: int | m > 0 && IsModEquivalent(x, y, m)
          ensures IsModEquivalent(x * z, y * z, m)
        {
          LemmaModMulEquivalent(x, y, z, m);
        }
      }

      lemma LemmaModOrdering(x: int, k: int, d: int)
        requires 1 < d
        requires 0 < k
        ensures 0 < d * k
        ensures x % d <= x % (d * k)
        decreases x, k, d
      {
        LemmaMulStrictlyIncreases(d, k);
        calc {
          x % d + d * x / d;
          {
            LemmaFundamentalDivMod(x, d);
          }
          x;
          {
            LemmaFundamentalDivMod(x, d * k);
          }
          x % (d * k) + d * k * x / (d * k);
          {
            LemmaMulIsAssociativeAuto();
          }
          x % (d * k) + d * k * x / (d * k);
        }
        calc {
          x % d;
          {
            LemmaModPropertiesAuto();
          }
          x % d % d;
          {
            LemmaModMultiplesVanish(x / d - k * x / (d * k), x % d, d);
          }
          (x % d + d * (x / d - k * x / (d * k))) % d;
          {
            LemmaMulIsDistributiveSubAuto();
          }
          (x % d + d * x / d - d * k * x / (d * k)) % d;
          x % (d * k) % d;
        <=
          {
            LemmaModPropertiesAuto();
            LemmaModDecreases(x % (d * k), d);
          }
          x % (d * k);
        }
      }

      lemma LemmaModOrderingAuto()
        ensures forall k: int, d: int {:trigger d * k} :: 1 < d && 0 < k ==> 0 < d * k
        ensures forall x: int, k: int, d: int {:trigger x % (d * k)} :: 1 < d && 0 < k ==> x % d <= x % (d * k)
      {
        forall k: int, d: int {:trigger d * k} | 1 < d && 0 < k
          ensures 1 < d && 0 < k ==> 0 < d * k
        {
          LemmaMulStrictlyIncreases(d, k);
        }
        forall x: int, k: int, d: int {:trigger x % (d * k)} | 1 < d && 0 < k
          ensures 1 < d && 0 < k ==> x % d <= x % (d * k)
        {
          LemmaModOrdering(x, k, d);
        }
      }

      lemma LemmaModMod(x: int, a: int, b: int)
        requires 0 < a
        requires 0 < b
        ensures 0 < a * b
        ensures x % (a * b) % a == x % a
        decreases x, a, b
      {
        LemmaMulStrictlyPositiveAuto();
        calc {
          x;
          {
            LemmaFundamentalDivMod(x, a * b);
          }
          a * b * x / (a * b) + x % (a * b);
          {
            LemmaMulIsAssociativeAuto();
          }
          a * b * x / (a * b) + x % (a * b);
          {
            LemmaFundamentalDivMod(x % (a * b), a);
          }
          a * b * x / (a * b) + a * x % (a * b) / a + x % (a * b) % a;
          {
            LemmaMulIsDistributiveAuto();
          }
          a * (b * x / (a * b) + x % (a * b) / a) + x % (a * b) % a;
        }
        LemmaModPropertiesAuto();
        LemmaMulIsCommutativeAuto();
        LemmaFundamentalDivModConverse(x, a, b * x / (a * b) + x % (a * b) / a, x % (a * b) % a);
      }

      lemma LemmaModModAuto()
        ensures forall a: int, b: int {:trigger a * b} :: 0 < a && 0 < b ==> 0 < a * b
        ensures forall x: int, a: int, b: int {:trigger x % (a * b) % a, x % a} :: 0 < a && 0 < b ==> x % (a * b) % a == x % a
      {
        forall a: int, b: int {:trigger a * b} | 0 < a && 0 < b
          ensures 0 < a * b
        {
          LemmaMulStrictlyPositiveAuto();
        }
        forall x: int, a: int, b: int | 0 < a && 0 < b
          ensures x % (a * b) % a == x % a
        {
          LemmaModMod(x, a, b);
        }
      }

      lemma LemmaPartBound2(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < y
        requires 0 < z
        ensures y * z > 0
        ensures x % y % (y * z) < y
        decreases x, y, z
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaModPropertiesAuto();
        assert x % y < y;
        LemmaMulIncreasesAuto();
        LemmaMulIsCommutativeAuto();
        assert y <= y * z;
        assert 0 <= x % y < y * z;
        LemmaModPropertiesAuto();
        LemmaSmallMod(x % y, y * z);
        assert x % y % (y * z) == x % y;
      }

      lemma LemmaPartBound2Auto()
        ensures (forall x: int, y: int, z: int {:trigger y * z, x % y} :: 0 <= x && 0 < y && 0 < z ==> y * z > 0) && forall x: int, y: int, z: int {:trigger y * z, x % y} :: 0 <= x && 0 < y && 0 < z ==> x % y % (y * z) < y
      {
        forall x: int, y: int, z: int {:trigger y * z, 0 <= x} {:trigger 0 < z, 0 < y, 0 <= x} | 0 <= x && 0 < y && 0 < z
          ensures y * z > 0 && x % y % (y * z) < y
        {
          LemmaPartBound2(x, y, z);
        }
      }

      lemma LemmaModBreakdown(x: int, y: int, z: int)
        requires 0 <= x
        requires 0 < y
        requires 0 < z
        ensures y * z > 0
        ensures x % (y * z) == y * x / y % z + x % y
        decreases x, y, z
      {
        LemmaMulStrictlyPositiveAuto();
        LemmaDivPosIsPos(x, y);
        assert 0 <= x / y;
        calc {
          y * x / y % (y * z) + x % y % (y * z);
        <=
          {
            LemmaPartBound1(x, y, z);
          }
          y * (z - 1) + x % y % (y * z);
        <
          {
            LemmaPartBound2(x, y, z);
          }
          y * (z - 1) + y;
          {
            LemmaMulBasicsAuto();
          }
          y * (z - 1) + y * 1;
          {
            LemmaMulIsDistributiveAuto();
          }
          y * (z - 1 + 1);
          y * z;
        }
        calc {
          x % (y * z);
          {
            LemmaFundamentalDivMod(x, y);
          }
          (y * x / y + x % y) % (y * z);
          {
            LemmaModPropertiesAuto();
            assert 0 <= x % y;
            LemmaMulNonnegative(y, x / y);
            assert y * x / y % (y * z) + x % y % (y * z) < y * z;
            LemmaModAdds(y * x / y, x % y, y * z);
          }
          y * x / y % (y * z) + x % y % (y * z);
          {
            LemmaModPropertiesAuto();
            LemmaMulIncreases(z, y);
            LemmaMulIsCommutativeAuto();
            assert x % y < y <= y * z;
            LemmaSmallMod(x % y, y * z);
            assert x % y % (y * z) == x % y;
          }
          y * x / y % (y * z) + x % y;
          {
            LemmaTruncateMiddle(x / y, y, z);
          }
          y * x / y % z + x % y;
        }
      }

      lemma LemmaModBreakdownAuto()
        ensures (forall x: int, y: int, z: int {:trigger x % (y * z)} :: 0 <= x && 0 < y && 0 < z ==> y * z > 0) && forall x: int, y: int, z: int {:trigger x % (y * z)} :: 0 <= x && 0 < y && 0 < z ==> x % (y * z) == y * x / y % z + x % y
      {
        forall x: int, y: int, z: int | 0 <= x && 0 < y && 0 < z
          ensures y * z > 0 && x % (y * z) == y * x / y % z + x % y
        {
          LemmaModBreakdown(x, y, z);
        }
      }

      import opened DivInternals

      import DivINL = DivInternalsNonlinear

      import opened ModInternals

      import ModINL = ModInternalsNonlinear

      import opened MulInternals

      import opened Mul

      import opened GeneralInternals
    }

    module {:disableNonlinearArithmetic} DivInternals {
      function {:opaque} DivPos(x: int, d: int): int
        requires d > 0
        decreases if x < 0 then d - x else x
      {
        if x < 0 then
          -1 + DivPos(x + d, d)
        else if x < d then
          0
        else
          1 + DivPos(x - d, d)
      }

      function {:opaque} DivRecursive(x: int, d: int): int
        requires d != 0
        decreases x, d
      {
        reveal DivPos();
        if d > 0 then
          DivPos(x, d)
        else
          -1 * DivPos(x, -1 * d)
      }

      lemma LemmaDivBasics(n: int)
        requires n > 0
        ensures n / n == -(-n / n) == 1
        ensures forall x: int {:trigger x / n} :: 0 <= x < n <==> x / n == 0
        ensures forall x: int {:trigger (x + n) / n} :: (x + n) / n == x / n + 1
        ensures forall x: int {:trigger (x - n) / n} :: (x - n) / n == x / n - 1
        decreases n
      {
        LemmaModAuto(n);
        LemmaModBasics(n);
        LemmaSmallDiv();
        LemmaDivBySelf(n);
        forall x: int | x / n == 0
          ensures 0 <= x < n
        {
          LemmaFundamentalDivMod(x, n);
        }
      }

      ghost predicate DivAuto(n: int)
        requires n > 0
        decreases n
      {
        ModAuto(n) &&
        n / n == -(-n / n) == 1 &&
        (forall x: int {:trigger x / n} :: 
          0 <= x < n <==> x / n == 0) &&
        DivAutoMinus(n) &&
        DivAutoPlus(n)
      }

      ghost predicate DivAutoPlus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x + y) / n} :: 
          DivPlus(n, x, y)
      }

      ghost predicate DivPlus(n: int, x: int, y: int)
        requires n > 0
        decreases n, x, y
      {
        ghost var z: int := x % n + y % n;
        (0 <= z < n && (x + y) / n == x / n + y / n) || (n <= z < n + n && (x + y) / n == x / n + y / n + 1)
      }

      ghost predicate DivAutoMinus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x - y) / n} :: 
          DivMinus(n, x, y)
      }

      ghost predicate DivMinus(n: int, x: int, y: int)
        requires n > 0
        decreases n, x, y
      {
        ghost var z: int := x % n - y % n;
        (0 <= z < n && (x - y) / n == x / n - y / n) || (-n <= z < 0 && (x - y) / n == x / n - y / n - 1)
      }

      lemma {:vcs_split_on_every_assert} LemmaDivAutoAuxPlus(n: int)
        requires n > 0 && ModAuto(n)
        ensures DivAutoPlus(n)
        decreases n
      {
        LemmaModAuto(n);
        LemmaDivBasics(n);
        ghost var f := (x: int, y: int) => DivPlus(n, x, y);
        forall i: int, j: int | true
          ensures j >= 0 && f(i, j) ==> f(i, j + n)
          ensures i < n && f(i, j) ==> f(i - n, j)
          ensures j < n && f(i, j) ==> f(i, j - n)
          ensures i >= 0 && f(i, j) ==> f(i + n, j)
          ensures 0 <= i < n && 0 <= j < n ==> f(i, j)
        {
          assert (i + n + j) / n == (i + j + n) / n;
          assert (i + j + n) / n == (i + j + n) / n;
          assert i - n + j == i + j - n;
          assert (i - n + j) / n == (i + j - n) / n;
          assert (i + j - n) / n == (i + j - n) / n;
        }
        forall x: int, y: int | true
          ensures DivPlus(n, x, y)
        {
          LemmaModInductionForall2(n, f);
          assert f(x, y);
        }
      }

      lemma {:vcs_split_on_every_assert} LemmaDivAutoAuxMinusHelper(n: int)
        requires n > 0 && ModAuto(n)
        ensures (forall i: int, j: int {:trigger DivMinus(n, i, j + n)} :: j >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i, j + n)) && (forall i: int, j: int {:trigger DivMinus(n, i - n, j)} :: i < n && DivMinus(n, i, j) ==> DivMinus(n, i - n, j)) && (forall i: int, j: int {:trigger DivMinus(n, i, j - n)} :: j < n && DivMinus(n, i, j) ==> DivMinus(n, i, j - n)) && (forall i: int, j: int {:trigger DivMinus(n, i + n, j)} :: i >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i + n, j)) && forall i: int, j: int {:trigger DivMinus(n, i, j)} {:trigger j < n, i < n} {:trigger j < n, 0 <= i} {:trigger 0 <= j, i < n} {:trigger 0 <= j, 0 <= i} :: 0 <= i < n && 0 <= j < n ==> DivMinus(n, i, j)
        decreases n
      {
        LemmaModAuto(n);
        LemmaDivBasics(n);
        forall i: int, j: int | true
          ensures j >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i, j + n)
          ensures i < n && DivMinus(n, i, j) ==> DivMinus(n, i - n, j)
          ensures j < n && DivMinus(n, i, j) ==> DivMinus(n, i, j - n)
          ensures i >= 0 && DivMinus(n, i, j) ==> DivMinus(n, i + n, j)
          ensures 0 <= i < n && 0 <= j < n ==> DivMinus(n, i, j)
        {
          assert (i + n - j) / n == (i - j + n) / n;
          assert (i - (j - n)) / n == (i - j + n) / n;
          assert (i - n - j) / n == (i - j - n) / n;
          assert (i - (j + n)) / n == (i - j - n) / n;
        }
      }

      lemma LemmaDivAutoAuxMinus(n: int)
        requires n > 0 && ModAuto(n)
        ensures DivAutoMinus(n)
        decreases n
      {
        LemmaDivAutoAuxMinusHelper(n);
        ghost var f := (x: int, y: int) => DivMinus(n, x, y);
        LemmaModInductionForall2(n, f);
        forall x: int, y: int | true
          ensures DivMinus(n, x, y)
        {
          assert f(x, y);
        }
      }

      lemma LemmaDivAutoAux(n: int)
        requires n > 0 && ModAuto(n)
        ensures DivAuto(n)
        decreases n
      {
        LemmaDivBasics(n);
        assert (0 + n) / n == 1;
        assert (0 - n) / n == -1;
        LemmaDivAutoAuxPlus(n);
        LemmaDivAutoAuxMinus(n);
      }

      lemma LemmaDivAuto(n: int)
        requires n > 0
        ensures DivAuto(n)
        decreases n
      {
        LemmaModAuto(n);
        LemmaDivAutoAux(n);
      }

      lemma LemmaDivInductionAuto(n: int, x: int, f: int -> bool)
        requires n > 0
        requires DivAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures DivAuto(n)
        ensures f(x)
        decreases n, x
      {
        LemmaDivAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
        assert f(x);
      }

      lemma LemmaDivInductionAutoForall(n: int, f: int -> bool)
        requires n > 0
        requires DivAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures DivAuto(n)
        ensures forall i: int {:trigger f(i)} :: f(i)
        decreases n
      {
        LemmaDivAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
      }

      import opened GeneralInternals

      import opened ModInternals

      import opened ModInternalsNonlinear

      import opened DivInternalsNonlinear

      import opened MulInternals
    }

    module {:z3ArithmeticSolver 6} DivInternalsNonlinear {
      lemma LemmaDivOf0(d: int)
        requires d != 0
        ensures 0 / d == 0
        decreases d
      {
      }

      lemma LemmaDivBySelf(d: int)
        requires d != 0
        ensures d / d == 1
        decreases d
      {
      }

      lemma LemmaSmallDiv()
        ensures forall d: int, x: int {:trigger x / d} :: 0 <= x < d && d > 0 ==> x / d == 0
      {
      }

      lemma LemmaRealDivGt(x: real, y: real)
        requires x > y
        requires y > 0.0
        ensures x / y > 1 as real
        decreases x, y
      {
      }
    }

    module {:disableNonlinearArithmetic} GeneralInternals {
      ghost predicate IsLe(x: int, y: int)
        decreases x, y
      {
        x <= y
      }

      lemma LemmaInductionHelper(n: int, f: int -> bool, x: int)
        requires n > 0
        requires forall i: int {:trigger f(i)} :: 0 <= i < n ==> f(i)
        requires forall i: int {:trigger f(i), f(i + n)} :: i >= 0 && f(i) ==> f(i + n)
        requires forall i: int {:trigger f(i), f(i - n)} :: i < n && f(i) ==> f(i - n)
        ensures f(x)
        decreases if x >= n then x else -x
      {
        if x >= n {
          LemmaInductionHelper(n, f, x - n);
          assert f(x - n + n);
        } else if x < 0 {
          LemmaInductionHelper(n, f, x + n);
          assert f(x + n - n);
        }
      }
    }

    module {:disableNonlinearArithmetic} ModInternals {
      function {:opaque} ModRecursive(x: int, d: int): int
        requires d > 0
        decreases if x < 0 then d - x else x
      {
        if x < 0 then
          ModRecursive(d + x, d)
        else if x < d then
          x
        else
          ModRecursive(x - d, d)
      }

      lemma LemmaModInductionForall(n: int, f: int -> bool)
        requires n > 0
        requires forall i: int {:trigger f(i)} :: 0 <= i < n ==> f(i)
        requires forall i: int {:trigger f(i), f(i + n)} :: i >= 0 && f(i) ==> f(i + n)
        requires forall i: int {:trigger f(i), f(i - n)} :: i < n && f(i) ==> f(i - n)
        ensures forall i: int {:trigger f(i)} :: f(i)
        decreases n
      {
        forall i: int | true
          ensures f(i)
        {
          LemmaInductionHelper(n, f, i);
        }
      }

      lemma LemmaModInductionForall2(n: int, f: (int, int) -> bool)
        requires n > 0
        requires forall i: int, j: int {:trigger f(i, j)} :: 0 <= i < n && 0 <= j < n ==> f(i, j)
        requires forall i: int, j: int {:trigger f(i, j), f(i + n, j)} :: i >= 0 && f(i, j) ==> f(i + n, j)
        requires forall i: int, j: int {:trigger f(i, j), f(i, j + n)} :: j >= 0 && f(i, j) ==> f(i, j + n)
        requires forall i: int, j: int {:trigger f(i, j), f(i - n, j)} :: i < n && f(i, j) ==> f(i - n, j)
        requires forall i: int, j: int {:trigger f(i, j), f(i, j - n)} :: j < n && f(i, j) ==> f(i, j - n)
        ensures forall i: int, j: int {:trigger f(i, j)} :: f(i, j)
        decreases n
      {
        forall x: int, y: int | true
          ensures f(x, y)
        {
          forall i: int | 0 <= i < n
            ensures f(i, y)
          {
            ghost var fj := (j: int) => f(i, j);
            LemmaModInductionForall(n, fj);
            assert fj(y);
          }
          ghost var fi := (i: int) => f(i, y);
          LemmaModInductionForall(n, fi);
          assert fi(x);
        }
      }

      lemma LemmaDivAddDenominator(n: int, x: int)
        requires n > 0
        ensures (x + n) / n == x / n + 1
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x + n, n);
        ghost var zp := (x + n) / n - x / n - 1;
        assert 0 == n * zp + (x + n) % n - x % n by {
          LemmaMulAuto();
        }
        if zp > 0 {
          LemmaMulInequality(1, zp, n);
        }
        if zp < 0 {
          LemmaMulInequality(zp, -1, n);
        }
      }

      lemma LemmaDivSubDenominator(n: int, x: int)
        requires n > 0
        ensures (x - n) / n == x / n - 1
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x - n, n);
        ghost var zm := (x - n) / n - x / n + 1;
        assert 0 == n * zm + (x - n) % n - x % n by {
          LemmaMulAuto();
        }
        if zm > 0 {
          LemmaMulInequality(1, zm, n);
        }
        if zm < 0 {
          LemmaMulInequality(zm, -1, n);
        }
      }

      lemma LemmaModAddDenominator(n: int, x: int)
        requires n > 0
        ensures (x + n) % n == x % n
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x + n, n);
        ghost var zp := (x + n) / n - x / n - 1;
        assert 0 == n * zp + (x + n) % n - x % n by {
          LemmaMulAuto();
        }
        if zp > 0 {
          LemmaMulInequality(1, zp, n);
        }
        if zp < 0 {
          LemmaMulInequality(zp, -1, n);
        }
      }

      lemma LemmaModSubDenominator(n: int, x: int)
        requires n > 0
        ensures (x - n) % n == x % n
        decreases n, x
      {
        LemmaFundamentalDivMod(x, n);
        LemmaFundamentalDivMod(x - n, n);
        ghost var zm := (x - n) / n - x / n + 1;
        assert 0 == n * zm + (x - n) % n - x % n by {
          LemmaMulAuto();
        }
        if zm > 0 {
          LemmaMulInequality(1, zm, n);
        }
        if zm < 0 {
          LemmaMulInequality(zm, -1, n);
        }
      }

      lemma LemmaModBelowDenominator(n: int, x: int)
        requires n > 0
        ensures 0 <= x < n <==> x % n == x
        decreases n, x
      {
        forall x: int | true
          ensures 0 <= x < n <==> x % n == x
        {
          if 0 <= x < n {
            LemmaSmallMod(x, n);
          }
          LemmaModRange(x, n);
        }
      }

      lemma LemmaModBasics(n: int)
        requires n > 0
        ensures forall x: int {:trigger (x + n) % n} :: (x + n) % n == x % n
        ensures forall x: int {:trigger (x - n) % n} :: (x - n) % n == x % n
        ensures forall x: int {:trigger (x + n) / n} :: (x + n) / n == x / n + 1
        ensures forall x: int {:trigger (x - n) / n} :: (x - n) / n == x / n - 1
        ensures forall x: int {:trigger x % n} :: 0 <= x < n <==> x % n == x
        decreases n
      {
        forall x: int | true
          ensures (x + n) % n == x % n
          ensures (x - n) % n == x % n
          ensures (x + n) / n == x / n + 1
          ensures (x - n) / n == x / n - 1
          ensures 0 <= x < n <==> x % n == x
        {
          LemmaModBelowDenominator(n, x);
          LemmaModAddDenominator(n, x);
          LemmaModSubDenominator(n, x);
          LemmaDivAddDenominator(n, x);
          LemmaDivSubDenominator(n, x);
        }
      }

      lemma {:vcs_split_on_every_assert} LemmaQuotientAndRemainder(x: int, q: int, r: int, n: int)
        requires n > 0
        requires 0 <= r < n
        requires x == q * n + r
        ensures q == x / n
        ensures r == x % n
        decreases if q > 0 then q else -q
      {
        LemmaModBasics(n);
        if q > 0 {
          MulInternalsNonlinear.LemmaMulIsDistributiveAdd(n, q - 1, 1);
          LemmaMulIsCommutativeAuto();
          assert q * n + r == (q - 1) * n + n + r;
          LemmaQuotientAndRemainder(x - n, q - 1, r, n);
        } else if q < 0 {
          Mul.LemmaMulIsDistributiveSub(n, q + 1, 1);
          LemmaMulIsCommutativeAuto();
          assert q * n + r == (q + 1) * n - n + r;
          LemmaQuotientAndRemainder(x + n, q + 1, r, n);
        } else {
          LemmaSmallDiv();
          assert r / n == 0;
        }
      }

      ghost predicate ModAuto(n: int)
        requires n > 0
        decreases n
      {
        n % n == -n % n == 0 &&
        (forall x: int {:trigger x % n % n} :: 
          x % n % n == x % n) &&
        (forall x: int {:trigger x % n} :: 
          0 <= x < n <==> x % n == x) &&
        ModAutoPlus(n) &&
        ModAutoMinus(n)
      }

      ghost predicate ModAutoPlus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x + y) % n} :: 
          ghost var z: int := x % n + y % n; (0 <= z < n && (x + y) % n == z) || (n <= z < n + n && (x + y) % n == z - n)
      }

      ghost predicate ModAutoMinus(n: int)
        requires n > 0
        decreases n
      {
        forall x: int, y: int {:trigger (x - y) % n} :: 
          ghost var z: int := x % n - y % n; (0 <= z < n && (x - y) % n == z) || (-n <= z < 0 && (x - y) % n == z + n)
      }

      lemma LemmaModAuto(n: int)
        requires n > 0
        ensures ModAuto(n)
        decreases n
      {
        LemmaModBasics(n);
        LemmaModAutoPlus(n);
        LemmaModAutoMinus(n);
      }

      lemma {:rlimit 2000} LemmaModAutoMinus(n: int)
        requires n > 0
        ensures ModAutoMinus(n)
        decreases n
      {
        LemmaModBasics(n);
        LemmaMulIsCommutativeAuto();
        LemmaMulIsDistributiveSubAuto();
        forall x: int, y: int {:trigger (x - y) % n} | true
          ensures ghost var z: int := x % n - y % n; (0 <= z < n && (x - y) % n == z) || (-n <= z < 0 && (x - y) % n == z + n)
        {
          ghost var xq, xr := x / n, x % n;
          LemmaFundamentalDivMod(x, n);
          assert x == xq * n + xr;
          ghost var yq, yr := y / n, y % n;
          LemmaFundamentalDivMod(y, n);
          assert y == yq * n + yr;
          if xr - yr >= 0 {
            LemmaQuotientAndRemainder(x - y, xq - yq, xr - yr, n);
          } else {
            LemmaQuotientAndRemainder(x - y, xq - yq - 1, xr - yr + n, n);
          }
        }
      }

      lemma LemmaModAutoPlus(n: int)
        requires n > 0
        ensures ModAutoPlus(n)
        decreases n
      {
        LemmaMulIsCommutativeAuto();
        LemmaMulIsDistributiveAddAuto();
        forall x: int, y: int {:trigger (x + y) % n} | true
          ensures ghost var z: int := x % n + y % n; (0 <= z < n && (x + y) % n == z) || (n <= z < 2 * n && (x + y) % n == z - n)
        {
          ghost var xq, xr := x / n, x % n;
          LemmaFundamentalDivMod(x, n);
          assert x == xq * n + xr;
          ghost var yq, yr := y / n, y % n;
          LemmaFundamentalDivMod(y, n);
          assert y == yq * n + yr;
          if xr + yr < n {
            LemmaQuotientAndRemainder(x + y, xq + yq, xr + yr, n);
          } else {
            LemmaQuotientAndRemainder(x + y, xq + yq + 1, xr + yr - n, n);
          }
        }
      }

      lemma LemmaModInductionAuto(n: int, x: int, f: int -> bool)
        requires n > 0
        requires ModAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures ModAuto(n)
        ensures f(x)
        decreases n, x
      {
        LemmaModAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
        assert f(x);
      }

      lemma LemmaModInductionAutoForall(n: int, f: int -> bool)
        requires n > 0
        requires ModAuto(n) ==> (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i)) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + n)) && forall i: int {:trigger IsLe(i + 1, n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n)
        ensures ModAuto(n)
        ensures forall i: int {:trigger f(i)} :: f(i)
        decreases n
      {
        LemmaModAuto(n);
        assert forall i: int {:trigger f(i)} {:trigger IsLe(0, i)} :: IsLe(0, i) && i < n ==> f(i);
        assert forall i: int {:trigger f(i), f(i + n)} :: IsLe(0, i) && f(i) ==> f(i + n);
        assert forall i: int {:trigger f(i), f(i - n)} :: IsLe(i + 1, n) && f(i) ==> f(i - n);
        LemmaModInductionForall(n, f);
      }

      import opened GeneralInternals

      import opened Mul

      import opened MulInternalsNonlinear

      import opened MulInternals

      import opened ModInternalsNonlinear

      import opened DivInternalsNonlinear
    }

    module {:z3ArithmeticSolver 6} ModInternalsNonlinear {
      lemma LemmaModOfZeroIsZero(m: int)
        requires 0 < m
        ensures 0 % m == 0
        decreases m
      {
      }

      lemma LemmaFundamentalDivMod(x: int, d: int)
        requires d != 0
        ensures x == d * x / d + x % d
        decreases x, d
      {
      }

      lemma Lemma0ModAnything()
        ensures forall m: int {:trigger 0 % m} :: m > 0 ==> 0 % m == 0
      {
      }

      lemma LemmaSmallMod(x: nat, m: nat)
        requires x < m
        requires 0 < m
        ensures x % m == x
        decreases x, m
      {
      }

      lemma LemmaModRange(x: int, m: int)
        requires m > 0
        ensures 0 <= x % m < m
        decreases x, m
      {
      }
    }

    module {:disableNonlinearArithmetic} MulInternals {
      function {:opaque} MulPos(x: int, y: int): int
        requires x >= 0
        decreases x, y
      {
        if x == 0 then
          0
        else
          y + MulPos(x - 1, y)
      }

      function MulRecursive(x: int, y: int): int
        decreases x, y
      {
        if x >= 0 then
          MulPos(x, y)
        else
          -1 * MulPos(-1 * x, y)
      }

      lemma LemmaMulInduction(f: int -> bool)
        requires f(0)
        requires forall i: int {:trigger f(i), f(i + 1)} :: i >= 0 && f(i) ==> f(i + 1)
        requires forall i: int {:trigger f(i), f(i - 1)} :: i <= 0 && f(i) ==> f(i - 1)
        ensures forall i: int {:trigger f(i)} :: f(i)
      {
        forall i: int | true
          ensures f(i)
        {
          LemmaInductionHelper(1, f, i);
        }
      }

      lemma LemmaMulCommutes()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == y * x
      {
        forall x: int, y: int | true
          ensures x * y == y * x
        {
          LemmaMulInduction((i: int) => x * i == i * x);
        }
      }

      lemma LemmaMulSuccessor()
        ensures forall x: int, y: int {:trigger (x + 1) * y} :: (x + 1) * y == x * y + y
        ensures forall x: int, y: int {:trigger (x - 1) * y} :: (x - 1) * y == x * y - y
      {
        LemmaMulCommutes();
        forall x: int, y: int | true
          ensures (x + 1) * y == x * y + y
          ensures (x - 1) * y == x * y - y
        {
          LemmaMulIsDistributiveAdd(y, x, 1);
          LemmaMulIsDistributiveAdd(y, x, -1);
        }
      }

      lemma LemmaMulDistributes()
        ensures forall x: int, y: int, z: int {:trigger (x + y) * z} :: (x + y) * z == x * z + y * z
        ensures forall x: int, y: int, z: int {:trigger (x - y) * z} :: (x - y) * z == x * z - y * z
      {
        LemmaMulSuccessor();
        forall x: int, y: int, z: int | true
          ensures (x + y) * z == x * z + y * z
          ensures (x - y) * z == x * z - y * z
        {
          ghost var f1 := (i: int) => (x + i) * z == x * z + i * z;
          ghost var f2 := (i: int) => (x - i) * z == x * z - i * z;
          assert forall i: int {:trigger (x + i + 1) * z} :: (x + i + 1) * z == (x + i + 1) * z && (x + i + 1) * z == (x + i) * z + z;
          assert forall i: int {:trigger (x + i - 1) * z} :: (x + i - 1) * z == (x + i - 1) * z && (x + i - 1) * z == (x + i) * z - z;
          assert forall i: int {:trigger (x - (i + 1)) * z} :: (x - (i + 1)) * z == (x - i - 1) * z && (x - i - 1) * z == (x - i) * z - z;
          assert forall i: int {:trigger (x - (i - 1)) * z} :: (x - (i - 1)) * z == (x - i + 1) * z && (x - i + 1) * z == (x - i) * z + z;
          LemmaMulInduction(f1);
          LemmaMulInduction(f2);
          assert f1(y);
          assert f2(y);
        }
      }

      ghost predicate MulAuto()
      {
        (forall x: int, y: int {:trigger x * y} :: 
          x * y == y * x) &&
        (forall x: int, y: int, z: int {:trigger (x + y) * z} :: 
          (x + y) * z == x * z + y * z) &&
        forall x: int, y: int, z: int {:trigger (x - y) * z} :: 
          (x - y) * z == x * z - y * z
      }

      lemma LemmaMulAuto()
        ensures MulAuto()
      {
        LemmaMulCommutes();
        LemmaMulDistributes();
      }

      lemma LemmaMulInductionAuto(x: int, f: int -> bool)
        requires MulAuto() ==> f(0) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1)) && forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1)
        ensures MulAuto()
        ensures f(x)
        decreases x
      {
        LemmaMulCommutes();
        LemmaMulDistributes();
        assert forall i: int {:trigger f(i)} :: IsLe(0, i) && f(i) ==> f(i + 1);
        assert forall i: int {:trigger f(i)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
        LemmaMulInduction(f);
        assert f(x);
      }

      lemma LemmaMulInductionAutoForall(f: int -> bool)
        requires MulAuto() ==> f(0) && (forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1)) && forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1)
        ensures MulAuto()
        ensures forall i: int {:trigger f(i)} :: f(i)
      {
        LemmaMulCommutes();
        LemmaMulDistributes();
        assert forall i: int {:trigger f(i)} :: IsLe(0, i) && f(i) ==> f(i + 1);
        assert forall i: int {:trigger f(i)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
        LemmaMulInduction(f);
      }

      import opened GeneralInternals

      import opened MulInternalsNonlinear
    }

    module {:z3ArithmeticSolver 6} MulInternalsNonlinear {
      lemma LemmaMulStrictlyPositive(x: int, y: int)
        ensures 0 < x && 0 < y ==> 0 < x * y
        decreases x, y
      {
      }

      lemma LemmaMulNonzero(x: int, y: int)
        ensures x * y != 0 <==> x != 0 && y != 0
        decreases x, y
      {
      }

      lemma LemmaMulIsAssociative(x: int, y: int, z: int)
        ensures x * y * z == x * y * z
        decreases x, y, z
      {
      }

      lemma LemmaMulIsDistributiveAdd(x: int, y: int, z: int)
        ensures x * (y + z) == x * y + x * z
        decreases x, y, z
      {
      }

      lemma LemmaMulOrdering(x: int, y: int)
        requires x != 0
        requires y != 0
        requires 0 <= x * y
        ensures x * y >= x && x * y >= y
        decreases x, y
      {
      }

      lemma LemmaMulStrictInequality(x: int, y: int, z: int)
        requires x < y
        requires z > 0
        ensures x * z < y * z
        decreases x, y, z
      {
      }
    }

    abstract module {:disableNonlinearArithmetic} LittleEndianNat {
      function BASE(): nat
        ensures BASE() > 1

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module {:disableNonlinearArithmetic} Logarithm {
      function {:opaque} Log(base: nat, pow: nat): nat
        requires base > 1
        decreases pow
      {
        if pow < base then
          0
        else
          LemmaDivPosIsPosAuto(); LemmaDivDecreasesAuto(); 1 + Log(base, pow / base)
      }

      lemma {:induction false} LemmaLog0(base: nat, pow: nat)
        requires base > 1
        requires pow < base
        ensures Log(base, pow) == 0
        decreases base, pow
      {
        reveal Log();
      }

      lemma {:induction false} LemmaLogS(base: nat, pow: nat)
        requires base > 1
        requires pow >= base
        ensures pow / base >= 0
        ensures Log(base, pow) == 1 + Log(base, pow / base)
        decreases base, pow
      {
        LemmaDivPosIsPosAuto();
        reveal Log();
      }

      lemma {:induction false} LemmaLogSAuto()
        ensures forall pow: nat, base: nat {:trigger Log(base, pow / base)} | base > 1 && pow >= base :: pow / base >= 0 && Log(base, pow) == 1 + Log(base, pow / base)
      {
        forall base: nat, pow: nat | base > 1 && pow >= base
          ensures pow / base >= 0 && Log(base, pow) == 1 + Log(base, pow / base)
        {
          LemmaLogS(base, pow);
        }
      }

      lemma {:induction false} LemmaLogIsOrdered(base: nat, pow: nat, pow': nat)
        requires base > 1
        requires pow <= pow'
        ensures Log(base, pow) <= Log(base, pow')
        decreases pow
      {
        reveal Log();
        if pow' < base {
          assert Log(base, pow) == 0 == Log(base, pow');
        } else if pow < base {
          assert Log(base, pow) == 0;
        } else {
          LemmaDivPosIsPosAuto();
          LemmaDivDecreasesAuto();
          LemmaDivIsOrderedAuto();
          LemmaLogIsOrdered(base, pow / base, pow' / base);
        }
      }

      lemma {:induction false} LemmaLogPow(base: nat, n: nat)
        requires base > 1
        ensures (LemmaPowPositive(base, n); Log(base, Pow(base, n)) == n)
        decreases base, n
      {
        if n == 0 {
          reveal Pow();
          reveal Log();
        } else {
          LemmaPowPositive(base, n);
          calc {
            Log(base, Pow(base, n));
            {
              reveal Pow();
            }
            Log(base, base * Pow(base, n - 1));
            {
              LemmaPowPositive(base, n - 1);
              LemmaMulIncreases(Pow(base, n - 1), base);
              LemmaMulIsCommutative(Pow(base, n - 1), base);
              LemmaLogS(base, base * Pow(base, n - 1));
            }
            1 + Log(base, base * Pow(base, n - 1) / base);
            {
              LemmaDivMultiplesVanish(Pow(base, n - 1), base);
            }
            1 + Log(base, Pow(base, n - 1));
            {
              LemmaLogPow(base, n - 1);
            }
            1 + n - 1;
          }
        }
      }

      import opened Mul

      import opened DivMod

      import opened Power
    }

    module {:disableNonlinearArithmetic} Mul {
      lemma LemmaMulIsMulRecursive(x: int, y: int)
        ensures x * y == MulRecursive(x, y)
        decreases x, y
      {
        if x >= 0 {
          LemmaMulIsMulPos(x, y);
        }
        if x <= 0 {
          LemmaMulIsMulPos(-x, y);
        }
        LemmaMulAuto();
      }

      lemma LemmaMulIsMulRecursiveAuto()
        ensures forall x: int, y: int {:trigger MulRecursive(x, y)} :: x * y == MulRecursive(x, y)
      {
        forall x: int, y: int | true
          ensures x * y == MulRecursive(x, y)
        {
          LemmaMulIsMulRecursive(x, y);
        }
      }

      lemma /*{:_induction x, y}*/ LemmaMulIsMulPos(x: int, y: int)
        requires x >= 0
        ensures x * y == MulPos(x, y)
        decreases x, y
      {
        reveal MulPos();
        LemmaMulInductionAuto(x, (u: int) => u >= 0 ==> u * y == MulPos(u, y));
      }

      lemma LemmaMulBasics(x: int)
        ensures 0 * x == 0
        ensures x * 0 == 0
        ensures 1 * x == x
        ensures x * 1 == x
        decreases x
      {
      }

      lemma LemmaMulBasicsAuto()
        ensures forall x: int {:trigger 0 * x} :: 0 * x == 0
        ensures forall x: int {:trigger x * 0} :: x * 0 == 0
        ensures forall x: int {:trigger 1 * x} :: 1 * x == x
        ensures forall x: int {:trigger x * 1} :: x * 1 == x
      {
      }

      lemma LemmaMulNonzero(x: int, y: int)
        ensures x * y != 0 <==> x != 0 && y != 0
        decreases x, y
      {
        MulINL.LemmaMulNonzero(x, y);
      }

      lemma LemmaMulNonzeroAuto()
        ensures forall x: int, y: int {:trigger x * y} :: x * y != 0 <==> x != 0 && y != 0
      {
        forall x: int, y: int | true
          ensures x * y != 0 <==> x != 0 && y != 0
        {
          LemmaMulNonzero(x, y);
        }
      }

      lemma LemmaMulByZeroIsZeroAuto()
        ensures forall x: int {:trigger 0 * x} {:trigger x * 0} :: x * 0 == 0 * x && 0 * x == 0
      {
        forall x: int {:trigger 0 * x} {:trigger x * 0} | true
          ensures x * 0 == 0 * x == 0
        {
          LemmaMulBasics(x);
        }
      }

      lemma LemmaMulIsAssociative(x: int, y: int, z: int)
        ensures x * y * z == x * y * z
        decreases x, y, z
      {
        MulINL.LemmaMulIsAssociative(x, y, z);
      }

      lemma LemmaMulIsAssociativeAuto()
        ensures forall x: int, y: int, z: int {:trigger x * y * z} {:trigger x * y * z} :: x * y * z == x * y * z
      {
        forall x: int, y: int, z: int | true
          ensures x * y * z == x * y * z
        {
          LemmaMulIsAssociative(x, y, z);
        }
      }

      lemma LemmaMulIsCommutative(x: int, y: int)
        ensures x * y == y * x
        decreases x, y
      {
      }

      lemma LemmaMulIsCommutativeAuto()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == y * x
      {
      }

      lemma LemmaMulOrdering(x: int, y: int)
        requires x != 0
        requires y != 0
        requires 0 <= x * y
        ensures x * y >= x && x * y >= y
        decreases x, y
      {
        MulINL.LemmaMulOrdering(x, y);
      }

      lemma LemmaMulOrderingAuto()
        ensures forall x: int, y: int {:trigger x * y} :: (0 != x && 0 != y && x * y >= 0 ==> x * y >= x) && (0 != x && 0 != y && x * y >= 0 ==> x * y >= y)
      {
        forall x: int, y: int | 0 != x && 0 != y && x * y >= 0
          ensures x * y >= x && x * y >= y
        {
          LemmaMulOrdering(x, y);
        }
      }

      lemma LemmaMulEquality(x: int, y: int, z: int)
        requires x == y
        ensures x * z == y * z
        decreases x, y, z
      {
      }

      lemma LemmaMulEqualityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x == y ==> x * z == y * z
      {
        forall x: int, y: int, z: int | x == y
          ensures x * z == y * z
        {
          LemmaMulEquality(x, y, z);
        }
      }

      lemma LemmaMulInequality(x: int, y: int, z: int)
        requires x <= y
        requires z >= 0
        ensures x * z <= y * z
        decreases x, y, z
      {
        LemmaMulInductionAuto(z, (u: int) => u >= 0 ==> x * u <= y * u);
      }

      lemma LemmaMulInequalityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x <= y && z >= 0 ==> x * z <= y * z
      {
        forall x: int, y: int, z: int | x <= y && z >= 0
          ensures x * z <= y * z
        {
          LemmaMulInequality(x, y, z);
        }
      }

      lemma LemmaMulStrictInequality(x: int, y: int, z: int)
        requires x < y
        requires z > 0
        ensures x * z < y * z
        decreases x, y, z
      {
        MulINL.LemmaMulStrictInequality(x, y, z);
      }

      lemma LemmaMulStrictInequalityAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x < y && z > 0 ==> x * z < y * z
      {
        forall x: int, y: int, z: int | x < y && z > 0
          ensures x * z < y * z
        {
          LemmaMulStrictInequality(x, y, z);
        }
      }

      lemma LemmaMulUpperBound(x: int, XBound: int, y: int, YBound: int)
        requires x <= XBound
        requires y <= YBound
        requires 0 <= x
        requires 0 <= y
        ensures x * y <= XBound * YBound
        decreases x, XBound, y, YBound
      {
        LemmaMulInequality(x, XBound, y);
        LemmaMulInequality(y, YBound, XBound);
      }

      lemma LemmaMulUpperBoundAuto()
        ensures forall YBound: int, y: int, XBound: int, x: int {:trigger x * y, XBound * YBound} :: x <= XBound && y <= YBound && 0 <= x && 0 <= y ==> x * y <= XBound * YBound
      {
        forall x: int, XBound: int, y: int, YBound: int | x <= XBound && y <= YBound && 0 <= x && 0 <= y
          ensures x * y <= XBound * YBound
        {
          LemmaMulUpperBound(x, XBound, y, YBound);
        }
      }

      lemma LemmaMulStrictUpperBound(x: int, XBound: int, y: int, YBound: int)
        requires x < XBound
        requires y < YBound
        requires 0 < x
        requires 0 < y
        ensures x * y <= (XBound - 1) * (YBound - 1)
        decreases x, XBound, y, YBound
      {
        LemmaMulInequality(x, XBound - 1, y);
        LemmaMulInequality(y, YBound - 1, XBound - 1);
      }

      lemma LemmaMulStrictUpperBoundAuto()
        ensures forall YBound: int, y: int, XBound: int, x: int {:trigger x * y, (XBound - 1) * (YBound - 1)} :: x < XBound && y < YBound && 0 < x && 0 < y ==> x * y <= (XBound - 1) * (YBound - 1)
      {
        forall x: int, XBound: int, y: int, YBound: int {:trigger (XBound - 1) * (YBound - 1), x * y} {:trigger YBound - 1, XBound - 1, 0 < y, 0 < x} {:trigger YBound - 1, 0 < y, x < XBound} {:trigger XBound - 1, 0 < x, y < YBound} {:trigger y < YBound, x < XBound} | x < XBound && y < YBound && 0 < x && 0 < y
          ensures x * y <= (XBound - 1) * (YBound - 1)
        {
          LemmaMulStrictUpperBound(x, XBound, y, YBound);
        }
      }

      lemma LemmaMulLeftInequality(x: int, y: int, z: int)
        requires 0 < x
        ensures y <= z ==> x * y <= x * z
        ensures y < z ==> x * y < x * z
        decreases x, y, z
      {
        LemmaMulInductionAuto(x, (u: int) => u > 0 ==> y <= z ==> u * y <= u * z);
        LemmaMulInductionAuto(x, (u: int) => u > 0 ==> y < z ==> u * y < u * z);
      }

      lemma LemmaMulLeftInequalityAuto()
        ensures (forall x: int, y: int, z: int {:trigger x * y, x * z} :: x > 0 ==> y <= z ==> x * y <= x * z) && forall x: int, y: int, z: int {:trigger x * y, x * z} :: x > 0 ==> y < z ==> x * y < x * z
      {
        forall x: int, y: int, z: int | (y <= z || y < z) && 0 < x
          ensures (y <= z ==> x * y <= x * z) && (y < z ==> x * y < x * z)
        {
          LemmaMulLeftInequality(x, y, z);
        }
      }

      lemma LemmaMulEqualityConverse(m: int, x: int, y: int)
        requires m != 0
        requires m * x == m * y
        ensures x == y
        decreases m, x, y
      {
        LemmaMulInductionAuto(m, (u: int) => x > y && 0 < u ==> x * u > y * u);
        LemmaMulInductionAuto(m, (u: int) => x > y && 0 > u ==> x * u < y * u);
        LemmaMulInductionAuto(m, (u: int) => x < y && 0 < u ==> x * u < y * u);
        LemmaMulInductionAuto(m, (u: int) => x < y && 0 > u ==> x * u > y * u);
      }

      lemma LemmaMulEqualityConverseAuto()
        ensures forall m: int, x: int, y: int {:trigger m * x, m * y} :: m != 0 && m * x == m * y ==> x == y
      {
        forall m: int, x: int, y: int | m != 0 && m * x == m * y
          ensures x == y
        {
          LemmaMulEqualityConverse(m, x, y);
        }
      }

      lemma LemmaMulInequalityConverse(x: int, y: int, z: int)
        requires x * z <= y * z
        requires z > 0
        ensures x <= y
        decreases x, y, z
      {
        LemmaMulInductionAuto(z, (u: int) => x * u <= y * u && u > 0 ==> x <= y);
      }

      lemma LemmaMulInequalityConverseAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x * z <= y * z && z > 0 ==> x <= y
      {
        forall x: int, y: int, z: int | x * z <= y * z && z > 0
          ensures x <= y
        {
          LemmaMulInequalityConverse(x, y, z);
        }
      }

      lemma LemmaMulStrictInequalityConverse(x: int, y: int, z: int)
        requires x * z < y * z
        requires z >= 0
        ensures x < y
        decreases x, y, z
      {
        LemmaMulInductionAuto(z, (u: int) => x * u < y * u && u >= 0 ==> x < y);
      }

      lemma LemmaMulStrictInequalityConverseAuto()
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x * z < y * z && z >= 0 ==> x < y
      {
        forall x: int, y: int, z: int | x * z < y * z && z >= 0
          ensures x < y
        {
          LemmaMulStrictInequalityConverse(x, y, z);
        }
      }

      lemma LemmaMulIsDistributiveAdd(x: int, y: int, z: int)
        ensures x * (y + z) == x * y + x * z
        decreases x, y, z
      {
        MulINL.LemmaMulIsDistributiveAdd(x, y, z);
      }

      lemma LemmaMulIsDistributiveAddAuto()
        ensures forall x: int, y: int, z: int {:trigger x * (y + z)} :: x * (y + z) == x * y + x * z
      {
        forall x: int, y: int, z: int | true
          ensures x * (y + z) == x * y + x * z
        {
          LemmaMulIsDistributiveAdd(x, y, z);
        }
      }

      lemma LemmaMulIsDistributiveAddOtherWay(x: int, y: int, z: int)
        ensures (y + z) * x == y * x + z * x
        decreases x, y, z
      {
        LemmaMulAuto();
      }

      lemma LemmaMulIsDistributiveAddOtherWayAuto()
        ensures forall x: int, y: int, z: int {:trigger (y + z) * x} :: (y + z) * x == y * x + z * x
      {
        forall x: int, y: int, z: int | true
          ensures (y + z) * x == y * x + z * x
        {
          LemmaMulIsDistributiveAddOtherWay(x, y, z);
        }
      }

      lemma LemmaMulIsDistributiveSub(x: int, y: int, z: int)
        ensures x * (y - z) == x * y - x * z
        decreases x, y, z
      {
        LemmaMulAuto();
      }

      lemma LemmaMulIsDistributiveSubAuto()
        ensures forall x: int, y: int, z: int {:trigger x * (y - z)} :: x * (y - z) == x * y - x * z
      {
        forall x: int, y: int, z: int | true
          ensures x * (y - z) == x * y - x * z
        {
          LemmaMulIsDistributiveSub(x, y, z);
        }
      }

      lemma LemmaMulIsDistributive(x: int, y: int, z: int)
        ensures x * (y + z) == x * y + x * z
        ensures x * (y - z) == x * y - x * z
        ensures (y + z) * x == y * x + z * x
        ensures (y - z) * x == y * x - z * x
        ensures x * (y + z) == (y + z) * x
        ensures x * (y - z) == (y - z) * x
        ensures x * y == y * x
        ensures x * z == z * x
        decreases x, y, z
      {
        LemmaMulAuto();
      }

      lemma LemmaMulIsDistributiveAuto()
        ensures forall x: int, y: int, z: int {:trigger x * (y + z)} :: x * (y + z) == x * y + x * z
        ensures forall x: int, y: int, z: int {:trigger x * (y - z)} :: x * (y - z) == x * y - x * z
        ensures forall x: int, y: int, z: int {:trigger (y + z) * x} :: (y + z) * x == y * x + z * x
        ensures forall x: int, y: int, z: int {:trigger (y - z) * x} :: (y - z) * x == y * x - z * x
      {
        LemmaMulIsDistributiveAddAuto();
        LemmaMulIsDistributiveSubAuto();
        LemmaMulIsCommutativeAuto();
      }

      lemma LemmaMulStrictlyPositive(x: int, y: int)
        ensures 0 < x && 0 < y ==> 0 < x * y
        decreases x, y
      {
        MulINL.LemmaMulStrictlyPositive(x, y);
      }

      lemma LemmaMulStrictlyPositiveAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> 0 < x * y
      {
        forall x: int, y: int | 0 < x && 0 < y
          ensures 0 < x * y
        {
          LemmaMulStrictlyPositive(x, y);
        }
      }

      lemma LemmaMulStrictlyIncreases(x: int, y: int)
        requires 1 < x
        requires 0 < y
        ensures y < x * y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => 1 < u ==> y < u * y);
      }

      lemma LemmaMulStrictlyIncreasesAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 1 < x && 0 < y ==> y < x * y
      {
        forall x: int, y: int | 1 < x && 0 < y
          ensures y < x * y
        {
          LemmaMulStrictlyIncreases(x, y);
        }
      }

      lemma LemmaMulIncreases(x: int, y: int)
        requires 0 < x
        requires 0 < y
        ensures y <= x * y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => 0 < u ==> y <= u * y);
      }

      lemma LemmaMulIncreasesAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> y <= x * y
      {
        forall x: int, y: int | 0 < x && 0 < y
          ensures y <= x * y
        {
          LemmaMulIncreases(x, y);
        }
      }

      lemma LemmaMulNonnegative(x: int, y: int)
        requires 0 <= x
        requires 0 <= y
        ensures 0 <= x * y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => 0 <= u ==> 0 <= u * y);
      }

      lemma LemmaMulNonnegativeAuto()
        ensures forall x: int, y: int {:trigger x * y} :: 0 <= x && 0 <= y ==> 0 <= x * y
      {
        forall x: int, y: int | 0 <= x && 0 <= y
          ensures 0 <= x * y
        {
          LemmaMulNonnegative(x, y);
        }
      }

      lemma LemmaMulUnaryNegation(x: int, y: int)
        ensures -x * y == -(x * y) == x * -y
        decreases x, y
      {
        LemmaMulInductionAuto(x, (u: int) => -u * y == -(u * y) == u * -y);
      }

      lemma LemmaMulUnaryNegationAuto()
        ensures forall x: int, y: int {:trigger -x * y} {:trigger x * -y} :: -x * y == -(x * y) && -(x * y) == x * -y
      {
        forall x: int, y: int | true
          ensures -x * y == -(x * y) == x * -y
        {
          LemmaMulUnaryNegation(x, y);
        }
      }

      lemma LemmaMulCancelsNegatives(x: int, y: int)
        ensures x * y == -x * -y
        decreases x, y
      {
        LemmaMulUnaryNegationAuto();
      }

      lemma LemmaMulCancelsNegativesAuto()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == -x * -y
      {
        forall x: int, y: int | true
          ensures x * y == -x * -y
        {
          LemmaMulCancelsNegatives(x, y);
        }
      }

      lemma LemmaMulProperties()
        ensures forall x: int, y: int {:trigger x * y} :: x * y == y * x
        ensures forall x: int {:trigger x * 1} {:trigger 1 * x} :: x * 1 == 1 * x && 1 * x == x
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x < y && z > 0 ==> x * z < y * z
        ensures forall x: int, y: int, z: int {:trigger x * z, y * z} :: x <= y && z >= 0 ==> x * z <= y * z
        ensures forall x: int, y: int, z: int {:trigger x * (y + z)} :: x * (y + z) == x * y + x * z
        ensures forall x: int, y: int, z: int {:trigger x * (y - z)} :: x * (y - z) == x * y - x * z
        ensures forall x: int, y: int, z: int {:trigger (y + z) * x} :: (y + z) * x == y * x + z * x
        ensures forall x: int, y: int, z: int {:trigger (y - z) * x} :: (y - z) * x == y * x - z * x
        ensures forall x: int, y: int, z: int {:trigger x * y * z} {:trigger x * y * z} :: x * y * z == x * y * z
        ensures forall x: int, y: int {:trigger x * y} :: x * y != 0 <==> x != 0 && y != 0
        ensures forall x: int, y: int {:trigger x * y} :: 0 <= x && 0 <= y ==> 0 <= x * y
        ensures forall x: int, y: int {:trigger x * y} :: (0 < x && 0 < y && 0 <= x * y ==> x <= x * y) && (0 < x && 0 < y && 0 <= x * y ==> y <= x * y)
        ensures forall x: int, y: int {:trigger x * y} :: 1 < x && 0 < y ==> y < x * y
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> y <= x * y
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> 0 < x * y
      {
        LemmaMulStrictInequalityAuto();
        LemmaMulInequalityAuto();
        LemmaMulIsDistributiveAuto();
        LemmaMulIsAssociativeAuto();
        LemmaMulOrderingAuto();
        LemmaMulNonzeroAuto();
        LemmaMulNonnegativeAuto();
        LemmaMulStrictlyIncreasesAuto();
        LemmaMulIncreasesAuto();
      }

      import MulINL = MulInternalsNonlinear

      import opened MulInternals
    }

    module {:disableNonlinearArithmetic} Power {
      function {:opaque} Pow(b: int, e: nat): int
        decreases e
      {
        if e == 0 then
          1
        else
          b * Pow(b, e - 1)
      }

      lemma /*{:_induction b}*/ LemmaPow0(b: int)
        ensures Pow(b, 0) == 1
        decreases b
      {
        reveal Pow();
      }

      lemma LemmaPow0Auto()
        ensures forall b: nat {:trigger Pow(b, 0)} :: Pow(b, 0) == 1
      {
        reveal Pow();
        forall b: nat {:trigger Pow(b, 0)} | true
          ensures Pow(b, 0) == 1
        {
          LemmaPow0(b);
        }
      }

      lemma /*{:_induction b}*/ LemmaPow1(b: int)
        ensures Pow(b, 1) == b
        decreases b
      {
        calc {
          Pow(b, 1);
          {
            reveal Pow();
          }
          b * Pow(b, 0);
          {
            LemmaPow0(b);
          }
          b * 1;
          {
            LemmaMulBasicsAuto();
          }
          b;
        }
      }

      lemma LemmaPow1Auto()
        ensures forall b: nat {:trigger Pow(b, 1)} :: Pow(b, 1) == b
      {
        reveal Pow();
        forall b: nat {:trigger Pow(b, 1)} | true
          ensures Pow(b, 1) == b
        {
          LemmaPow1(b);
        }
      }

      lemma /*{:_induction e}*/ Lemma0Pow(e: nat)
        requires e > 0
        ensures Pow(0, e) == 0
        decreases e
      {
        reveal Pow();
        LemmaMulBasicsAuto();
        if e != 1 {
          Lemma0Pow(e - 1);
        }
      }

      lemma Lemma0PowAuto()
        ensures forall e: nat {:trigger Pow(0, e)} :: e > 0 ==> Pow(0, e) == 0
      {
        reveal Pow();
        forall e: nat {:trigger Pow(0, e)} | e > 0
          ensures Pow(0, e) == 0
        {
          Lemma0Pow(e);
        }
      }

      lemma /*{:_induction e}*/ Lemma1Pow(e: nat)
        ensures Pow(1, e) == 1
        decreases e
      {
        reveal Pow();
        LemmaMulBasicsAuto();
        if e != 0 {
          Lemma1Pow(e - 1);
        }
      }

      lemma Lemma1PowAuto()
        ensures forall e: nat {:trigger Pow(1, e)} :: Pow(1, e) == 1
      {
        reveal Pow();
        forall e: nat {:trigger Pow(1, e)} | true
          ensures Pow(1, e) == 1
        {
          Lemma1Pow(e);
        }
      }

      lemma /*{:_induction x}*/ LemmaSquareIsPow2(x: nat)
        ensures Pow(x, 2) == x * x
        decreases x
      {
        reveal Pow();
      }

      lemma LemmaSquareIsPow2Auto()
        ensures forall x: nat {:trigger Pow(x, 2)} :: Pow(x, 2) == x * x
      {
        reveal Pow();
        forall x: nat {:trigger Pow(x, 2)} | true
          ensures Pow(x, 2) == x * x
        {
        }
      }

      lemma /*{:_induction b, e}*/ LemmaPowPositive(b: int, e: nat)
        requires b > 0
        ensures 0 < Pow(b, e)
        decreases b, e
      {
        LemmaMulIncreasesAuto();
        LemmaPow0Auto();
        reveal Pow();
        LemmaMulInductionAuto(e, (u: int) => 0 <= u ==> 0 < Pow(b, u));
      }

      lemma LemmaPowPositiveAuto()
        ensures forall b: int, e: nat {:trigger Pow(b, e)} :: b > 0 ==> 0 < Pow(b, e)
      {
        reveal Pow();
        forall b: int, e: nat {:trigger Pow(b, e)} | b > 0
          ensures 0 < Pow(b, e)
        {
          LemmaPowPositive(b, e);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowAdds(b: int, e1: nat, e2: nat)
        ensures Pow(b, e1 + e2) == Pow(b, e1) * Pow(b, e2)
        decreases e1
      {
        if e1 == 0 {
          calc {
            Pow(b, e1) * Pow(b, e2);
            {
              LemmaPow0(b);
            }
            1 * Pow(b, e2);
            {
              LemmaMulBasicsAuto();
            }
            Pow(b, 0 + e2);
          }
        } else {
          calc {
            Pow(b, e1) * Pow(b, e2);
            {
              reveal Pow();
            }
            b * Pow(b, e1 - 1) * Pow(b, e2);
            {
              LemmaMulIsAssociativeAuto();
            }
            b * Pow(b, e1 - 1) * Pow(b, e2);
            {
              LemmaPowAdds(b, e1 - 1, e2);
            }
            b * Pow(b, e1 - 1 + e2);
            {
              reveal Pow();
            }
            Pow(b, e1 + e2);
          }
        }
      }

      lemma LemmaPowAddsAuto()
        ensures forall b: int, e1: nat, e2: nat {:trigger Pow(b, e1 + e2)} :: Pow(b, e1 + e2) == Pow(b, e1) * Pow(b, e2)
      {
        reveal Pow();
        forall b: int, e1: nat, e2: nat {:trigger Pow(b, e1 + e2)} | true
          ensures Pow(b, e1 + e2) == Pow(b, e1) * Pow(b, e2)
        {
          LemmaPowAdds(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowSubAddCancel(b: int, e1: nat, e2: nat)
        requires e1 >= e2
        ensures Pow(b, e1 - e2) * Pow(b, e2) == Pow(b, e1)
        decreases e1
      {
        LemmaPowAdds(b, e1 - e2, e2);
      }

      lemma LemmaPowSubAddCancelAuto()
        ensures forall b: int, e1: nat, e2: nat {:trigger Pow(b, e1 - e2)} | e1 >= e2 :: Pow(b, e1 - e2) * Pow(b, e2) == Pow(b, e1)
      {
        reveal Pow();
        forall b: int, e1: nat, e2: nat | e1 >= e2 {
          LemmaPowSubAddCancel(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowSubtracts(b: nat, e1: nat, e2: nat)
        requires b > 0
        requires e1 <= e2
        ensures Pow(b, e1) > 0
        ensures Pow(b, e2 - e1) == Pow(b, e2) / Pow(b, e1) > 0
        decreases b, e1, e2
      {
        LemmaPowPositiveAuto();
        calc {
          Pow(b, e2) / Pow(b, e1);
          {
            LemmaPowSubAddCancel(b, e2, e1);
          }
          Pow(b, e2 - e1) * Pow(b, e1) / Pow(b, e1);
          {
            LemmaDivByMultiple(Pow(b, e2 - e1), Pow(b, e1));
          }
          Pow(b, e2 - e1);
        }
      }

      lemma LemmaPowSubtractsAuto()
        ensures forall b: nat, e1: nat {:trigger Pow(b, e1)} :: b > 0 ==> Pow(b, e1) > 0
        ensures forall e2: nat, e1: nat, b: nat {:trigger Pow(b, e2 - e1)} :: (b > 0 && e1 <= e2 ==> Pow(b, e2 - e1) == Pow(b, e2) / Pow(b, e1)) && (b > 0 && e1 <= e2 ==> Pow(b, e2) / Pow(b, e1) > 0)
      {
        reveal Pow();
        LemmaPowPositiveAuto();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e2 - e1)} | b > 0 && e1 <= e2
          ensures Pow(b, e2 - e1) == Pow(b, e2) / Pow(b, e1) > 0
        {
          LemmaPowSubtracts(b, e1, e2);
        }
      }

      lemma /*{:_induction a, b, c}*/ LemmaPowMultiplies(a: int, b: nat, c: nat)
        ensures 0 <= b * c
        ensures Pow(Pow(a, b), c) == Pow(a, b * c)
        decreases c
      {
        LemmaMulNonnegative(b, c);
        if c == 0 {
          LemmaMulBasicsAuto();
          calc {
            Pow(a, b * c);
            {
              LemmaPow0(a);
            }
            1;
            {
              LemmaPow0(Pow(a, b));
            }
            Pow(Pow(a, b), c);
          }
        } else {
          calc {
            b * c - b;
            {
              LemmaMulBasicsAuto();
            }
            b * c - b * 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            b * (c - 1);
          }
          LemmaMulNonnegative(b, c - 1);
          assert 0 <= b * c - b;
          calc {
            Pow(a, b * c);
            Pow(a, b + b * c - b);
            {
              LemmaPowAdds(a, b, b * c - b);
            }
            Pow(a, b) * Pow(a, b * c - b);
            Pow(a, b) * Pow(a, b * (c - 1));
            {
              LemmaPowMultiplies(a, b, c - 1);
            }
            Pow(a, b) * Pow(Pow(a, b), c - 1);
            {
              reveal Pow();
            }
            Pow(Pow(a, b), c);
          }
        }
      }

      lemma LemmaPowMultipliesAuto()
        ensures forall b: nat, c: nat {:trigger b * c} :: 0 <= b * c
        ensures forall a: int, b: nat, c: nat {:trigger Pow(a, b * c)} :: Pow(Pow(a, b), c) == Pow(a, b * c)
      {
        reveal Pow();
        LemmaMulNonnegativeAuto();
        forall a: int, b: nat, c: nat {:trigger Pow(a, b * c)} | true
          ensures Pow(Pow(a, b), c) == Pow(a, b * c)
        {
          LemmaPowMultiplies(a, b, c);
        }
      }

      lemma /*{:_induction a, b, e}*/ LemmaPowDistributes(a: int, b: int, e: nat)
        ensures Pow(a * b, e) == Pow(a, e) * Pow(b, e)
        decreases e
      {
        reveal Pow();
        LemmaMulBasicsAuto();
        if e > 0 {
          calc {
            Pow(a * b, e);
            a * b * Pow(a * b, e - 1);
            {
              LemmaPowDistributes(a, b, e - 1);
            }
            a * b * Pow(a, e - 1) * Pow(b, e - 1);
            {
              LemmaMulIsAssociativeAuto();
              LemmaMulIsCommutativeAuto();
            }
            a * Pow(a, e - 1) * b * Pow(b, e - 1);
            Pow(a, e) * Pow(b, e);
          }
        }
      }

      lemma LemmaPowDistributesAuto()
        ensures forall a: int, b: int, e: nat {:trigger Pow(a * b, e)} :: Pow(a * b, e) == Pow(a, e) * Pow(b, e)
      {
        reveal Pow();
        forall a: int, b: int, e: nat {:trigger Pow(a * b, e)} | true
          ensures Pow(a * b, e) == Pow(a, e) * Pow(b, e)
        {
          LemmaPowDistributes(a, b, e);
        }
      }

      lemma LemmaPowAuto()
        ensures forall x: int {:trigger Pow(x, 0)} :: Pow(x, 0) == 1
        ensures forall x: int {:trigger Pow(x, 1)} :: Pow(x, 1) == x
        ensures forall x: int, y: int {:trigger Pow(x, y)} :: y == 0 ==> Pow(x, y) == 1
        ensures forall x: int, y: int {:trigger Pow(x, y)} :: y == 1 ==> Pow(x, y) == x
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 0 < y ==> x <= x * y
        ensures forall x: int, y: int {:trigger x * y} :: 0 < x && 1 < y ==> x < x * y
        ensures forall x: int, y: nat, z: nat {:trigger Pow(x, y + z)} :: Pow(x, y + z) == Pow(x, y) * Pow(x, z)
        ensures forall x: int, y: nat, z: nat {:trigger Pow(x, y - z)} :: y >= z ==> Pow(x, y - z) * Pow(x, z) == Pow(x, y)
        ensures forall x: int, y: int, z: nat {:trigger Pow(x * y, z)} :: Pow(x * y, z) == Pow(x, z) * Pow(y, z)
      {
        reveal Pow();
        LemmaPow0Auto();
        LemmaPow1Auto();
        LemmaPowDistributesAuto();
        LemmaPowAddsAuto();
        LemmaPowSubAddCancelAuto();
        LemmaMulAuto();
        LemmaMulIncreasesAuto();
        LemmaMulStrictlyIncreasesAuto();
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowStrictlyIncreases(b: nat, e1: nat, e2: nat)
        requires 1 < b
        requires e1 < e2
        ensures Pow(b, e1) < Pow(b, e2)
        decreases b, e1, e2
      {
        reveal Pow();
        LemmaPowAuto();
        ghost var f := (e: int) => 0 < e ==> Pow(b, e1) < Pow(b, e1 + e);
        forall i: int {:trigger IsLe(0, i)} | IsLe(0, i) && f(i)
          ensures f(i + 1)
        {
          assert 0 < i ==> Pow(b, e1) < Pow(b, e1 + i);
          calc {
            Pow(b, e1 + i);
          <=
            {
              LemmaPowPositive(b, e1 + i);
              LemmaMulLeftInequality(Pow(b, e1 + i), 1, b);
            }
            Pow(b, e1 + i) * b;
          ==
            {
              LemmaPow1(b);
            }
            Pow(b, e1 + i) * Pow(b, 1);
          ==
            {
              LemmaPowAdds(b, e1 + i, 1);
            }
            Pow(b, e1 + i + 1);
          ==
            calc {
              e1 + i + 1;
              e1 + i + 1;
            }
            Pow(b, e1 + i + 1);
          }
          assert f(i + 1);
        }
        LemmaMulInductionAuto(e2 - e1, f);
        assert Pow(b, e1) < Pow(b, e1 + e2 - e1) == Pow(b, e2) by {
          assert 0 < e2 - e1;
        }
      }

      lemma LemmaPowStrictlyIncreasesAuto()
        ensures forall e2: nat, e1: nat, b: nat {:trigger Pow(b, e1), Pow(b, e2)} :: 1 < b && e1 < e2 ==> Pow(b, e1) < Pow(b, e2)
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | 1 < b && e1 < e2
          ensures Pow(b, e1) < Pow(b, e2)
        {
          LemmaPowStrictlyIncreases(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowIncreases(b: nat, e1: nat, e2: nat)
        requires b > 0
        requires e1 <= e2
        ensures Pow(b, e1) <= Pow(b, e2)
        decreases b, e1, e2
      {
        reveal Pow();
        LemmaPowAuto();
        ghost var f := (e: int) => 0 <= e ==> Pow(b, e1) <= Pow(b, e1 + e);
        forall i: int {:trigger IsLe(0, i)} | IsLe(0, i) && f(i)
          ensures f(i + 1)
        {
          calc {
            Pow(b, e1 + i);
          <=
            {
              LemmaPowPositive(b, e1 + i);
              LemmaMulLeftInequality(Pow(b, e1 + i), 1, b);
            }
            Pow(b, e1 + i) * b;
          ==
            {
              LemmaPow1(b);
            }
            Pow(b, e1 + i) * Pow(b, 1);
          ==
            {
              LemmaPowAdds(b, e1 + i, 1);
            }
            Pow(b, e1 + i + 1);
          }
        }
        LemmaMulInductionAuto(e2 - e1, f);
        assert Pow(b, e1) <= Pow(b, e1 + e2 - e1) by {
          assert 0 <= e2 - e1;
        }
      }

      lemma LemmaPowIncreasesAuto()
        ensures forall e2: nat, e1: nat, b: nat {:trigger Pow(b, e1), Pow(b, e2)} :: 1 < b && e1 <= e2 ==> Pow(b, e1) <= Pow(b, e2)
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | 1 < b && e1 <= e2
          ensures Pow(b, e1) <= Pow(b, e2)
        {
          LemmaPowIncreases(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowStrictlyIncreasesConverse(b: nat, e1: nat, e2: nat)
        requires b > 0
        requires Pow(b, e1) < Pow(b, e2)
        ensures e1 < e2
        decreases b, e1, e2
      {
        if e1 >= e2 {
          LemmaPowIncreases(b, e2, e1);
          assert false;
        }
      }

      lemma LemmaPowStrictlyIncreasesConverseAuto()
        ensures forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} :: b > 0 && Pow(b, e1) < Pow(b, e2) ==> e1 < e2
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | b > 0 && Pow(b, e1) < Pow(b, e2)
          ensures e1 < e2
        {
          LemmaPowStrictlyIncreasesConverse(b, e1, e2);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowIncreasesConverse(b: nat, e1: nat, e2: nat)
        requires 1 < b
        requires Pow(b, e1) <= Pow(b, e2)
        ensures e1 <= e2
        decreases b, e1, e2
      {
        if e1 > e2 {
          LemmaPowStrictlyIncreases(b, e2, e1);
          assert false;
        }
      }

      lemma LemmaPowIncreasesConverseAuto()
        ensures forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} :: 1 < b && Pow(b, e1) <= Pow(b, e2) ==> e1 <= e2
      {
        reveal Pow();
        forall b: nat, e1: nat, e2: nat {:trigger Pow(b, e1), Pow(b, e2)} | 1 < b && Pow(b, e1) <= Pow(b, e2)
          ensures e1 <= e2
        {
          LemmaPowIncreasesConverse(b, e1, e2);
        }
      }

      lemma /*{:_induction b, x, y, z}*/ LemmaPullOutPows(b: nat, x: nat, y: nat, z: nat)
        requires b > 0
        ensures 0 <= x * y
        ensures 0 <= y * z
        ensures Pow(Pow(b, x * y), z) == Pow(Pow(b, x), y * z)
        decreases b, x, y, z
      {
        LemmaMulNonnegative(x, y);
        LemmaMulNonnegative(y, z);
        LemmaPowPositive(b, x);
        calc {
          Pow(Pow(b, x * y), z);
          {
            LemmaPowMultiplies(b, x, y);
          }
          Pow(Pow(Pow(b, x), y), z);
          {
            LemmaPowMultiplies(Pow(b, x), y, z);
          }
          Pow(Pow(b, x), y * z);
        }
      }

      lemma LemmaPullOutPowsAuto()
        ensures forall y: nat, z: nat {:trigger z * y} :: 0 <= z * y && 0 <= y * z
        ensures forall b: nat, x: nat, y: nat, z: nat {:trigger Pow(Pow(b, x * y), z)} :: b > 0 ==> Pow(Pow(b, x * y), z) == Pow(Pow(b, x), y * z)
      {
        reveal Pow();
        LemmaMulNonnegativeAuto();
        forall b: nat, x: nat, y: nat, z: nat {:trigger Pow(Pow(b, x * y), z)} | b > 0
          ensures Pow(Pow(b, x * y), z) == Pow(Pow(b, x), y * z)
        {
          LemmaPullOutPows(b, x, y, z);
        }
      }

      lemma /*{:_induction b, e1, e2}*/ LemmaPowDivisionInequality(x: nat, b: nat, e1: nat, e2: nat)
        requires b > 0
        requires e2 <= e1
        requires x < Pow(b, e1)
        ensures Pow(b, e2) > 0
        ensures x / Pow(b, e2) < Pow(b, e1 - e2)
        decreases x, b, e1, e2
      {
        LemmaPowPositiveAuto();
        if x / Pow(b, e2) >= Pow(b, e1 - e2) {
          assert x / Pow(b, e2) >= Pow(b, e1 - e2);
          assert x / Pow(b, e2) * Pow(b, e2) >= Pow(b, e1 - e2) * Pow(b, e2) by {
            LemmaMulInequality(Pow(b, e1 - e2), x / Pow(b, e2), Pow(b, e2));
          }
          assert x - x % Pow(b, e2) >= Pow(b, e1 - e2) * Pow(b, e2) by {
            LemmaFundamentalDivMod(x, Pow(b, e2));
            LemmaMulIsCommutativeAuto();
          }
          assert x - x % Pow(b, e2) >= Pow(b, e1) by {
            LemmaPowAdds(b, e1 - e2, e2);
          }
          assert x >= Pow(b, e1) by {
            LemmaModPropertiesAuto();
          }
        }
      }

      lemma LemmaPowDivisionInequalityAuto()
        ensures forall b: nat, e2: nat {:trigger Pow(b, e2)} :: b > 0 ==> Pow(b, e2) > 0
        ensures forall x: nat, b: nat, e1: nat, e2: nat {:trigger x / Pow(b, e2), Pow(b, e1 - e2)} :: b > 0 && e2 <= e1 && x < Pow(b, e1) ==> x / Pow(b, e2) < Pow(b, e1 - e2)
      {
        reveal Pow();
        LemmaPowPositiveAuto();
        forall x: nat, b: nat, e1: nat, e2: nat {:trigger x / Pow(b, e2), Pow(b, e1 - e2)} | b > 0 && e2 <= e1 && x < Pow(b, e1)
          ensures x / Pow(b, e2) < Pow(b, e1 - e2)
        {
          LemmaPowDivisionInequality(x, b, e1, e2);
        }
      }

      lemma /*{:_induction b, e}*/ LemmaPowMod(b: nat, e: nat)
        requires b > 0 && e > 0
        ensures Pow(b, e) % b == 0
        decreases b, e
      {
        reveal Pow();
        calc {
          Pow(b, e) % b;
          b * Pow(b, e - 1) % b;
          {
            LemmaMulIsAssociativeAuto();
          }
          Pow(b, e - 1) * b % b;
          {
            LemmaPowPositiveAuto();
            LemmaModMultiplesBasic(Pow(b, e - 1), b);
          }
          0;
        }
      }

      lemma LemmaPowModAuto()
        ensures forall b: nat, e: nat {:trigger Pow(b, e)} :: b > 0 && e > 0 ==> Pow(b, e) % b == 0
      {
        reveal Pow();
        forall b: nat, e: nat {:trigger Pow(b, e)} | b > 0 && e > 0
          ensures Pow(b, e) % b == 0
        {
          LemmaPowMod(b, e);
        }
      }

      lemma /*{:_induction b, e, m}*/ LemmaPowModNoop(b: int, e: nat, m: int)
        requires m > 0
        ensures Pow(b % m, e) % m == Pow(b, e) % m
        decreases e
      {
        reveal Pow();
        LemmaModPropertiesAuto();
        if e > 0 {
          calc {
            Pow(b % m, e) % m;
            b % m * Pow(b % m, e - 1) % m;
            {
              LemmaMulModNoopGeneral(b, Pow(b % m, e - 1), m);
            }
            b % m * Pow(b % m, e - 1) % m % m % m;
            {
              LemmaPowModNoop(b, e - 1, m);
            }
            b % m * Pow(b, e - 1) % m % m % m;
            {
              LemmaMulModNoopGeneral(b, Pow(b, e - 1), m);
            }
            b * Pow(b, e - 1) % m % m;
            b * Pow(b, e - 1) % m;
            Pow(b, e) % m;
          }
        }
      }

      lemma LemmaPowModNoopAuto()
        ensures forall b: nat, e: nat, m: nat {:trigger Pow(b % m, e)} :: m > 0 ==> Pow(b % m, e) % m == Pow(b, e) % m
      {
        reveal Pow();
        forall b: nat, e: nat, m: nat {:trigger Pow(b % m, e)} | m > 0
          ensures Pow(b % m, e) % m == Pow(b, e) % m
        {
          LemmaPowModNoop(b, e, m);
        }
      }

      import opened DivMod

      import opened GeneralInternals

      import opened Mul

      import opened MulInternals
    }

    module {:disableNonlinearArithmetic} Power2 {
      function {:opaque} Pow2(e: nat): nat
        ensures Pow2(e) > 0
        decreases e
      {
        reveal Pow();
        LemmaPowPositive(2, e);
        Pow(2, e)
      }

      lemma /*{:_induction e}*/ LemmaPow2(e: nat)
        ensures Pow2(e) == Pow(2, e)
        decreases e
      {
        reveal Pow();
        reveal Pow2();
        if e != 0 {
          LemmaPow2(e - 1);
        }
      }

      lemma LemmaPow2Auto()
        ensures forall e: nat {:trigger Pow2(e)} :: Pow2(e) == Pow(2, e)
      {
        reveal Pow();
        reveal Pow2();
        forall e: nat {:trigger Pow2(e)} | true
          ensures Pow2(e) == Pow(2, e)
        {
          LemmaPow2(e);
        }
      }

      lemma LemmaPow2MaskDiv2(e: nat)
        requires 0 < e
        ensures (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1
        decreases e
      {
        LemmaPow2Auto();
        LemmaPowAuto();
        ghost var f := (e: int) => 0 < e ==> (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1;
        assert forall i: int {:trigger IsLe(0, i)} :: IsLe(0, i) && f(i) ==> f(i + 1);
        assert forall i: int {:trigger IsLe(i, 0)} :: IsLe(i, 0) && f(i) ==> f(i - 1);
        LemmaMulInductionAuto(e, f);
      }

      lemma LemmaPow2MaskDiv2Auto()
        ensures forall e: nat {:trigger Pow2(e)} :: 0 < e ==> (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1
      {
        reveal Pow2();
        forall e: nat {:trigger Pow2(e)} | 0 < e
          ensures (Pow2(e) - 1) / 2 == Pow2(e - 1) - 1
        {
          LemmaPow2MaskDiv2(e);
        }
      }

      lemma Lemma2To64()
        ensures Pow2(0) == 1
        ensures Pow2(1) == 2
        ensures Pow2(2) == 4
        ensures Pow2(3) == 8
        ensures Pow2(4) == 16
        ensures Pow2(5) == 32
        ensures Pow2(6) == 64
        ensures Pow2(7) == 128
        ensures Pow2(8) == 256
        ensures Pow2(9) == 512
        ensures Pow2(10) == 1024
        ensures Pow2(11) == 2048
        ensures Pow2(12) == 4096
        ensures Pow2(13) == 8192
        ensures Pow2(14) == 16384
        ensures Pow2(15) == 32768
        ensures Pow2(16) == 65536
        ensures Pow2(17) == 131072
        ensures Pow2(18) == 262144
        ensures Pow2(19) == 524288
        ensures Pow2(20) == 1048576
        ensures Pow2(21) == 2097152
        ensures Pow2(22) == 4194304
        ensures Pow2(23) == 8388608
        ensures Pow2(24) == 16777216
        ensures Pow2(25) == 33554432
        ensures Pow2(26) == 67108864
        ensures Pow2(27) == 134217728
        ensures Pow2(28) == 268435456
        ensures Pow2(29) == 536870912
        ensures Pow2(30) == 1073741824
        ensures Pow2(31) == 2147483648
        ensures Pow2(32) == 4294967296
        ensures Pow2(64) == 18446744073709551616
      {
        reveal Pow2();
        reveal Pow();
      }

      import opened GeneralInternals

      import opened MulInternals

      import opened Power
    }
  }

  module JSON {

    module API {
      opaque function Serialize(js: Values.JSON): (bs: SerializationResult<seq<byte>>)
        decreases js
      {
        var js: Grammar.JSON :- Serializer.JSON(js); ZeroCopy.Serialize(js)
      }

      method SerializeAlloc(js: Values.JSON) returns (bs: SerializationResult<array<byte>>)
        decreases js
      {
        var js :- Serializer.JSON(js);
        bs := ZeroCopy.SerializeAlloc(js);
      }

      method SerializeInto(js: Values.JSON, bs: array<byte>) returns (len: SerializationResult<uint32>)
        modifies bs
        decreases js, bs
      {
        var js :- Serializer.JSON(js);
        len := ZeroCopy.SerializeInto(js, bs);
      }

      opaque function Deserialize(bs: seq<byte>): (js: DeserializationResult<Values.JSON>)
        decreases bs
      {
        var js: Grammar.JSON :- ZeroCopy.Deserialize(bs); Deserializer.JSON(js)
      }

      import Values

      import Serializer

      import Deserializer

      import ZeroCopy = ZeroCopy.API

      import opened BoundedInts

      import opened Errors
    }

    module {:disableNonlinearArithmetic} ByteStrConversion refines Strings.ParametricConversion {
      const chars: CharSeq := ['0' as byte, '1' as byte, '2' as byte, '3' as byte, '4' as byte, '5' as byte, '6' as byte, '7' as byte, '8' as byte, '9' as byte]
      const charToDigit: map<Char, digit> := map['0' as byte := 0, '1' as byte := 1, '2' as byte := 2, '3' as byte := 3, '4' as byte := 4, '5' as byte := 5, '6' as byte := 6, '7' as byte := 7, '8' as byte := 8, '9' as byte := 9]
      const base := |chars|

      function BASE(): nat
        ensures BASE() > 1
      {
        base
      }

      function OfDigits(digits: seq<digit>): (str: String)
        requires forall d: int {:trigger d in digits} | d in digits :: 0 <= d && d < base
        ensures forall c: uint8 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        ensures |str| == |digits|
        decreases digits
      {
        if digits == [] then
          []
        else
          assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
      }

      function OfNat(n: nat): (str: String)
        ensures |str| == Log(base, n) + 1
        ensures forall c: uint8 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
        decreases n
      {
        if n == 0 then
          reveal Log();
          [chars[0]]
        else
          LemmaFromNatLen2(n); OfDigits(FromNat(n))
      }

      predicate OfNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in chars) &&
          forall c: uint8 {:trigger c in chars} {:trigger c in str[1..]} | c in str[1..] :: 
            c in chars
      }

      predicate ToNumberStr(str: String, minus: Char)
        decreases str
      {
        str != [] ==>
          (str[0] == minus || str[0] in charToDigit) &&
          forall c: uint8 {:trigger c in charToDigit} {:trigger c in str[1..]} | c in str[1..] :: 
            c in charToDigit
      }

      function OfInt(n: int, minus: Char): (str: String)
        ensures OfNumberStr(str, minus)
        decreases n
      {
        if n >= 0 then
          OfNat(n)
        else
          [minus] + OfNat(-n)
      }

      function {:vcs_split_on_every_assert} ToNat(str: String): (n: nat)
        requires forall c: uint8 {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        decreases str
      {
        if str == [] then
          0
        else
          LemmaMulNonnegativeAuto(); ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]]
      }

      lemma {:induction false} ToNatBound(str: String)
        requires base > 0
        requires forall c: uint8 {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
        requires forall c: uint8 {:trigger charToDigit[c]} {:trigger c in str} | c in str :: charToDigit[c] < base
        ensures ToNat(str) < Pow(base, |str|)
        decreases str
      {
        if str == [] {
          reveal Pow();
        } else {
          calc <= {
            ToNat(str);
            ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
            ToNat(str[..|str| - 1]) * base + base - 1;
            {
              ToNatBound(str[..|str| - 1]);
              LemmaMulInequalityAuto();
            }
            (Pow(base, |str| - 1) - 1) * base + base - 1;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(base, |str| - 1) * base - 1;
            {
              reveal Pow();
              LemmaMulIsCommutativeAuto();
            }
            Pow(base, |str|) - 1;
          }
        }
      }

      function ToInt(str: String, minus: Char): (s: int)
        requires str != [minus]
        requires ToNumberStr(str, minus)
        decreases str
      {
        if [minus] <= str then
          -(ToNat(str[1..]) as int)
        else
          assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
      }

      function {:opaque} ToNatRight(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
      }

      function {:opaque} ToNatLeft(xs: seq<digit>): nat
        decreases xs
      {
        if |xs| == 0 then
          0
        else
          LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
        ensures ToNatRight(xs) == ToNatLeft(xs)
        decreases xs
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        if xs == [] {
        } else {
          if DropLast(xs) == [] {
            calc {
              ToNatLeft(xs);
              Last(xs) * Pow(BASE(), |xs| - 1);
              {
                reveal Pow();
              }
              Last(xs);
              First(xs);
              {
                assert ToNatRight(DropFirst(xs)) == 0;
              }
              ToNatRight(xs);
            }
          } else {
            calc {
              ToNatLeft(xs);
              ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
              }
              ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
              ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
              }
              ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
              {
                assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                reveal Pow();
                LemmaMulProperties();
              }
              ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
              {
                LemmaToNatLeftEqToNatRight(DropFirst(xs));
              }
              ToNatRight(xs);
            }
          }
        }
      }

      lemma LemmaToNatLeftEqToNatRightAuto()
        ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
      {
        reveal ToNatRight();
        reveal ToNatLeft();
        forall xs: seq<digit> | true
          ensures ToNatRight(xs) == ToNatLeft(xs)
        {
          LemmaToNatLeftEqToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
        requires |xs| == 1
        ensures ToNatRight(xs) == First(xs)
        decreases xs
      {
        reveal ToNatRight();
        assert ToNatRight(DropFirst(xs)) == 0;
      }

      lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
        requires |xs| == 2
        ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
        decreases xs
      {
        reveal ToNatRight();
        LemmaSeqLen1(DropLast(xs));
      }

      lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
        ensures ToNatRight(xs + [0]) == ToNatRight(xs)
        decreases xs
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        calc {
          ToNatRight(xs + [0]);
          ToNatLeft(xs + [0]);
          ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
          {
            LemmaMulBasicsAuto();
          }
          ToNatLeft(xs);
          ToNatRight(xs);
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
        ensures ToNatRight(xs) < Pow(BASE(), |xs|)
        decreases xs
      {
        reveal Pow();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var len' := |xs| - 1;
          ghost var pow := Pow(BASE(), len');
          calc {
            ToNatRight(xs);
            {
              LemmaToNatLeftEqToNatRight(xs);
            }
            ToNatLeft(xs);
            {
              reveal ToNatLeft();
            }
            ToNatLeft(DropLast(xs)) + Last(xs) * pow;
          <
            {
              LemmaToNatLeftEqToNatRight(DropLast(xs));
              LemmaSeqNatBound(DropLast(xs));
            }
            pow + Last(xs) * pow;
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            pow + (BASE() - 1) * pow;
            {
              LemmaMulIsDistributiveAuto();
            }
            Pow(BASE(), len' + 1);
          }
        }
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
        requires 0 <= i <= |xs|
        ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
        decreases xs, i
      {
        reveal ToNatRight();
        reveal Pow();
        if i == 1 {
          assert ToNatRight(xs[..1]) == First(xs);
        } else if i > 1 {
          calc {
            ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
            {
              assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
              LemmaMulProperties();
            }
            ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
            {
              LemmaMulIsDistributiveAddOtherWayAuto();
            }
            (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
            {
              LemmaSeqPrefix(DropFirst(xs), i - 1);
            }
            ToNatRight(xs);
          }
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys| > 0
        requires Last(xs) < Last(ys)
        ensures ToNatRight(xs) < ToNatRight(ys)
        decreases xs, ys
      {
        reveal ToNatLeft();
        LemmaToNatLeftEqToNatRightAuto();
        ghost var len' := |xs| - 1;
        calc {
          ToNatRight(xs);
          ToNatLeft(xs);
        <
          {
            LemmaSeqNatBound(DropLast(xs));
          }
          Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
        ==
          {
            LemmaMulIsDistributiveAuto();
          }
          (1 + Last(xs)) * Pow(BASE(), len');
        <=
          {
            LemmaPowPositiveAuto();
            LemmaMulInequalityAuto();
          }
          ToNatLeft(ys);
          ToNatRight(ys);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
        requires 0 <= i <= |xs| == |ys|
        requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases |xs| - i
      {
        if i == |xs| {
          assert xs[..i] == xs;
          assert ys[..i] == ys;
        } else {
          if xs[i] == ys[i] {
            reveal ToNatLeft();
            assert DropLast(xs[..i + 1]) == xs[..i];
            assert DropLast(ys[..i + 1]) == ys[..i];
            LemmaToNatLeftEqToNatRightAuto();
            assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
          } else if xs[i] < ys[i] {
            LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
          } else {
            LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
          }
          reveal ToNatRight();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires xs != ys
        ensures ToNatRight(xs) != ToNatRight(ys)
        decreases xs, ys
      {
        ghost var i: nat, n: nat := 0, |xs|;
        while i < n
          invariant 0 <= i < n
          invariant xs[..i] == ys[..i]
          decreases n - i
        {
          if xs[i] != ys[i] {
            break;
          }
          i := i + 1;
        }
        assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
        reveal ToNatLeft();
        assert xs[..i + 1][..i] == xs[..i];
        assert ys[..i + 1][..i] == ys[..i];
        LemmaPowPositiveAuto();
        LemmaMulStrictInequalityAuto();
        assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
        LemmaToNatLeftEqToNatRightAuto();
        LemmaSeqPrefixNeq(xs, ys, i + 1);
      }

      lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
        requires |xs| == |ys|
        requires ToNatRight(xs) == ToNatRight(ys)
        ensures xs == ys
        decreases xs, ys
      {
        calc ==> {
          xs != ys;
          {
            LemmaSeqNeq(xs, ys);
          }
          ToNatRight(xs) != ToNatRight(ys);
          false;
        }
      }

      lemma /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
        requires |xs| >= 1
        ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
        decreases xs
      {
        if |xs| == 1 {
          LemmaSeqLen1(xs);
          LemmaModEquivalenceAuto();
        } else {
          assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
            reveal ToNatRight();
            calc ==> {
              true;
              {
                LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              }
              IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
              {
                LemmaModMultiplesBasicAuto();
              }
              IsModEquivalent(ToNatRight(xs), First(xs), BASE());
            }
          }
        }
      }

      function {:opaque} FromNat(n: nat): (xs: seq<digit>)
        decreases n
      {
        if n == 0 then
          []
        else
          LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
      }

      lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
        ensures n == 0 ==> |FromNat(n)| == 0
        ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
        decreases n
      {
        reveal FromNat();
        ghost var digits := FromNat(n);
        if n == 0 {
        } else {
          assert |digits| == Log(BASE(), n) + 1 by {
            LemmaDivBasicsAuto();
            ghost var digits' := FromNat(n / BASE());
            assert |digits| == |digits'| + 1;
            if n < BASE() {
              LemmaLog0(BASE(), n);
              assert n / BASE() == 0 by {
                LemmaBasicDiv(BASE());
              }
            } else {
              LemmaLogS(BASE(), n);
              assert n / BASE() > 0 by {
                LemmaDivNonZeroAuto();
              }
            }
          }
        }
      }

      lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
        requires Pow(BASE(), len) > n
        ensures |FromNat(n)| <= len
        decreases n, len
      {
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            |FromNat(n)|;
          ==
            {
              LemmaDivBasicsAuto();
            }
            1 + |FromNat(n / BASE())|;
          <=
            {
              LemmaMultiplyDivideLtAuto();
              LemmaDivDecreasesAuto();
              reveal Pow();
              LemmaFromNatLen(n / BASE(), len - 1);
            }
            len;
          }
        }
      }

      lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
        ensures ToNatRight(FromNat(n)) == n
        decreases n
      {
        reveal ToNatRight();
        reveal FromNat();
        if n == 0 {
        } else {
          calc {
            ToNatRight(FromNat(n));
            {
              LemmaDivBasicsAuto();
            }
            ToNatRight([n % BASE()] + FromNat(n / BASE()));
            n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
            {
              LemmaDivDecreasesAuto();
              LemmaNatSeqNat(n / BASE());
            }
            n % BASE() + n / BASE() * BASE();
            {
              LemmaFundamentalDivMod(n, BASE());
            }
            n;
          }
        }
      }

      function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires |xs| <= n
        ensures |ys| == n
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases n - |xs|
      {
        if |xs| >= n then
          xs
        else
          LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
      }

      function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
        requires n > 0
        ensures |ys| % n == 0
        ensures ToNatRight(ys) == ToNatRight(xs)
        decreases xs, n
      {
        var newLen: int := |xs| + n - |xs| % n;
        LemmaSubModNoopRight(|xs| + n, |xs|, n);
        LemmaModBasicsAuto();
        assert newLen % n == 0;
        LemmaSeqNatBound(xs);
        LemmaPowIncreasesAuto();
        SeqExtend(xs, newLen)
      }

      function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
        requires Pow(BASE(), len) > n
        ensures |xs| == len
        ensures ToNatRight(xs) == n
        decreases n, len
      {
        LemmaFromNatLen(n, len);
        LemmaNatSeqNat(n);
        SeqExtend(FromNat(n), len)
      }

      lemma /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
        requires ToNatRight(xs) == 0
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        decreases xs
      {
        reveal ToNatRight();
        if |xs| == 0 {
        } else {
          LemmaMulNonnegativeAuto();
          assert First(xs) == 0;
          LemmaMulNonzeroAuto();
          LemmaSeqZero(DropFirst(xs));
        }
      }

      function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
        ensures |xs| == len
        ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
        ensures ToNatRight(xs) == 0
        decreases len
      {
        LemmaPowPositive(BASE(), len);
        var xs: seq<digit> := FromNatWithLen(0, len);
        LemmaSeqZero(xs);
        xs
      }

      lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
        ensures Pow(BASE(), |xs|) > ToNatRight(xs)
        ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
        decreases xs
      {
        reveal FromNat();
        reveal ToNatRight();
        LemmaSeqNatBound(xs);
        if |xs| > 0 {
          calc {
            FromNatWithLen(ToNatRight(xs), |xs|) != xs;
            {
              LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
            }
            ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
            ToNatRight(xs) != ToNatRight(xs);
            false;
          }
        }
      }

      function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqAdd(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
        decreases xs, ys, zs, cout
      {
        reveal SeqAdd();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
          ghost var sum: int := Last(xs) + Last(ys) + cin;
          ghost var z := if sum < BASE() then sum else sum - BASE();
          assert sum == z + cout * BASE();
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
            {
              LemmaMulEquality(sum, z + cout * BASE(), pow);
              assert sum * pow == (z + cout * BASE()) * pow;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
            ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
          }
        }
      }

      function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
        requires |xs| == |ys|
        ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
        decreases xs
      {
        if |xs| == 0 then
          ([], 0)
        else
          var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
      }

      lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
        requires |xs| == |ys|
        requires SeqSub(xs, ys) == (zs, cout)
        ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
        decreases xs, ys, zs, cout
      {
        reveal SeqSub();
        if |xs| == 0 {
          reveal ToNatRight();
        } else {
          ghost var pow := Pow(BASE(), |xs| - 1);
          var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
          ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
          assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(zs);
            ToNatLeft(zs);
            ToNatLeft(zs') + z * pow;
            {
              LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
            }
            ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
            {
              LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
              assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
              LemmaMulIsDistributiveAuto();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
            {
              LemmaMulIsAssociative(cout, BASE(), pow);
              reveal Pow();
            }
            ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
            ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
          }
        }
      }

      import opened BoundedInts

      type Char = byte

      import opened Wrappers

      type String = seq<Char>

      type CharSeq = chars: seq<Char>
        | |chars| > 1
        witness *

      import opened DivMod

      import opened Mul

      import opened Power

      import opened Seq = Collections.Seq

      import opened Logarithm

      type digit = i: nat
        | 0 <= i < BASE()
    }

    module Deserializer {
      function Bool(js: Grammar.jbool): bool
        decreases js
      {
        assert js.Bytes() in {Grammar.TRUE, Grammar.FALSE};
        js.At(0) == 't' as byte
      }

      function UnsupportedEscape16(code: seq<uint16>): DeserializationError
        decreases code
      {
        UnsupportedEscape(FromUTF16Checked(code).GetOr(""Couldn't decode UTF-16""))
      }

      const HEX_TABLE_16 := Uint16StrConversion.charToDigit

      function ToNat16(str: Uint16StrConversion.String): uint16
        requires |str| <= 4
        requires forall c: uint16 {:trigger c in HEX_TABLE_16} {:trigger c in str} | c in str :: c in HEX_TABLE_16
        decreases str
      {
        assume {:axiom} false;
        Uint16StrConversion.ToNatBound(str);
        var hd: nat := Uint16StrConversion.ToNat(str);
        assert hd < 65536 by {
          reveal Pow();
        }
        hd as uint16
      }

      function {:tailrecursion} {:vcs_split_on_every_assert} Unescape(str: seq<uint16>, start: nat := 0, prefix: seq<uint16> := []): DeserializationResult<seq<uint16>>
        decreases |str| - start
      {
        if start >= |str| then
          Success(prefix)
        else if str[start] == '\\' as uint16 then
          if |str| == start + 1 then
            Failure(EscapeAtEOS)
          else
            var c: uint16 := str[start + 1]; if c == 'u' as uint16 then if |str| <= start + 6 then Failure(EscapeAtEOS) else var code: seq<uint16> := str[start + 2 .. start + 6]; if exists c: uint16 {:trigger c in HEX_TABLE_16} {:trigger c in code} | c in code :: c !in HEX_TABLE_16 then Failure(UnsupportedEscape16(code)) else var hd: uint16 := ToNat16(code); Unescape(str, start + 6, prefix + [hd]) else var unescaped: uint16 := match c case 34 => 34 as uint16 case 92 => 92 as uint16 case 98 => 8 as uint16 case 102 => 12 as uint16 case 110 => 10 as uint16 case 114 => 13 as uint16 case 116 => 9 as uint16 case _ /* _v4 */ => 0 as uint16; if unescaped as int == 0 then Failure(UnsupportedEscape16(str[start .. start + 2])) else Unescape(str, start + 2, prefix + [unescaped])
        else
          Unescape(str, start + 1, prefix + [str[start]])
      }

      function String(js: Grammar.jstring): DeserializationResult<string>
        decreases js
      {
        var asUtf32: string :- FromUTF8Checked(js.contents.Bytes()).ToResult(DeserializationError.InvalidUnicode); var asUint16: seq<uint16> :- ToUTF16Checked(asUtf32).ToResult(DeserializationError.InvalidUnicode); var unescaped: seq<uint16> :- Unescape(asUint16); FromUTF16Checked(unescaped).ToResult(DeserializationError.InvalidUnicode)
      }

      const DIGITS := ByteStrConversion.charToDigit
      const MINUS := '-' as uint8

      function ToInt(sign: jsign, n: jnum): DeserializationResult<int>
        decreases sign, n
      {
        var n: int := ByteStrConversion.ToNat(n.Bytes());
        Success(if sign.Char?('-') then -n else n)
      }

      function Number(js: Grammar.jnumber): DeserializationResult<Values.Decimal>
        decreases js
      {
        var JNumber(minus: jminus, num: jnum, frac: Maybe<jfrac>, exp: Maybe<jexp>) := js;
        var n: int :- ToInt(minus, num); var e10: int :- match exp case Empty() => Success(0) case NonEmpty(JExp(_ /* _v5 */, sign, num)) => ToInt(sign, num); match frac case Empty() => Success(Values.Decimal(n, e10)) case NonEmpty(JFrac(_ /* _v6 */, num)) => var pow10: int := num.Length() as int; var frac: int :- ToInt(minus, num); Success(Values.Decimal(n * Pow(10, pow10) + frac, e10 - pow10))
      }

      function KeyValue(js: Grammar.jKeyValue): DeserializationResult<(string, Values.JSON)>
        decreases js
      {
        var k: string :- String(js.k); var v: Values.JSON :- Value(js.v); Success((k, v))
      }

      function Object(js: Grammar.jobject): DeserializationResult<seq<(string, Values.JSON)>>
        decreases js
      {
        Seq.MapWithResult((d: Suffixed<jKeyValue, jcomma>) requires d in js.data => KeyValue(d.t), js.data)
      }

      function Array(js: Grammar.jarray): DeserializationResult<seq<Values.JSON>>
        decreases js
      {
        Seq.MapWithResult((d: Suffixed<Value, jcomma>) requires d in js.data => Value(d.t), js.data)
      }

      function Value(js: Grammar.Value): DeserializationResult<Values.JSON>
        decreases js
      {
        match js
        case Null(_ /* _v7 */) =>
          Success(Values.Null())
        case Bool(b) =>
          Success(Values.Bool(Bool(b)))
        case String(str) =>
          var s: string :- String(str); Success(Values.String(s))
        case Number(dec) =>
          var n: Values.Decimal :- Number(dec); Success(Values.Number(n))
        case Object(obj) =>
          var o: seq<(string, Values.JSON)> :- Object(obj); Success(Values.Object(o))
        case Array(arr) =>
          var a: seq<Values.JSON> :- Array(arr); Success(Values.Array(a))
      }

      function JSON(js: Grammar.JSON): DeserializationResult<Values.JSON>
        decreases js
      {
        Value(js.t)
      }

      import Values

      import Spec

      import ByteStrConversion

      import opened Seq = Collections.Seq

      import opened Wrappers

      import opened BoundedInts

      import opened Logarithm = Arithmetic.Logarithm

      import opened Power = Arithmetic.Power

      import opened Strings

      import opened UnicodeStringsWithUnicodeChar = Unicode.UnicodeStringsWithUnicodeChar

      import opened Errors

      import opened DynamicArray

      import opened Grammar

      import opened Core = Utils.Views.Core

      module {:disableNonlinearArithmetic} Uint16StrConversion refines Strings.ParametricConversion {
        const chars: CharSeq := ['0' as uint16, '1' as uint16, '2' as uint16, '3' as uint16, '4' as uint16, '5' as uint16, '6' as uint16, '7' as uint16, '8' as uint16, '9' as uint16, 'a' as uint16, 'b' as uint16, 'c' as uint16, 'd' as uint16, 'e' as uint16, 'f' as uint16, 'A' as uint16, 'B' as uint16, 'C' as uint16, 'D' as uint16, 'E' as uint16, 'F' as uint16]
        const charToDigit: map<Char, digit> := map['0' as uint16 := 0, '1' as uint16 := 1, '2' as uint16 := 2, '3' as uint16 := 3, '4' as uint16 := 4, '5' as uint16 := 5, '6' as uint16 := 6, '7' as uint16 := 7, '8' as uint16 := 8, '9' as uint16 := 9, 'a' as uint16 := 10, 'b' as uint16 := 11, 'c' as uint16 := 12, 'd' as uint16 := 13, 'e' as uint16 := 14, 'f' as uint16 := 15, 'A' as uint16 := 10, 'B' as uint16 := 11, 'C' as uint16 := 12, 'D' as uint16 := 13, 'E' as uint16 := 14, 'F' as uint16 := 15]
        const base := |chars|

        function BASE(): nat
          ensures BASE() > 1
        {
          base
        }

        function OfDigits(digits: seq<digit>): (str: String)
          requires forall d: int {:trigger d in digits} | d in digits :: 0 <= d && d < base
          ensures forall c: uint16 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
          ensures |str| == |digits|
          decreases digits
        {
          if digits == [] then
            []
          else
            assert digits[0] in digits; assert forall d: int {:trigger d in digits} {:trigger d in digits[1..]} | d in digits[1..] :: d in digits; OfDigits(digits[1..]) + [chars[digits[0]]]
        }

        function OfNat(n: nat): (str: String)
          ensures |str| == Log(base, n) + 1
          ensures forall c: uint16 {:trigger c in chars} {:trigger c in str} | c in str :: c in chars
          decreases n
        {
          if n == 0 then
            reveal Log();
            [chars[0]]
          else
            LemmaFromNatLen2(n); OfDigits(FromNat(n))
        }

        predicate OfNumberStr(str: String, minus: Char)
          decreases str
        {
          str != [] ==>
            (str[0] == minus || str[0] in chars) &&
            forall c: uint16 {:trigger c in chars} {:trigger c in str[1..]} | c in str[1..] :: 
              c in chars
        }

        predicate ToNumberStr(str: String, minus: Char)
          decreases str
        {
          str != [] ==>
            (str[0] == minus || str[0] in charToDigit) &&
            forall c: uint16 {:trigger c in charToDigit} {:trigger c in str[1..]} | c in str[1..] :: 
              c in charToDigit
        }

        function OfInt(n: int, minus: Char): (str: String)
          ensures OfNumberStr(str, minus)
          decreases n
        {
          if n >= 0 then
            OfNat(n)
          else
            [minus] + OfNat(-n)
        }

        function {:vcs_split_on_every_assert} ToNat(str: String): (n: nat)
          requires forall c: uint16 {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
          decreases str
        {
          if str == [] then
            0
          else
            LemmaMulNonnegativeAuto(); ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]]
        }

        lemma {:induction false} ToNatBound(str: String)
          requires base > 0
          requires forall c: uint16 {:trigger c in charToDigit} {:trigger c in str} | c in str :: c in charToDigit
          requires forall c: uint16 {:trigger charToDigit[c]} {:trigger c in str} | c in str :: charToDigit[c] < base
          ensures ToNat(str) < Pow(base, |str|)
          decreases str
        {
          if str == [] {
            reveal Pow();
          } else {
            calc <= {
              ToNat(str);
              ToNat(str[..|str| - 1]) * base + charToDigit[str[|str| - 1]];
              ToNat(str[..|str| - 1]) * base + base - 1;
              {
                ToNatBound(str[..|str| - 1]);
                LemmaMulInequalityAuto();
              }
              (Pow(base, |str| - 1) - 1) * base + base - 1;
              {
                LemmaMulIsDistributiveAuto();
              }
              Pow(base, |str| - 1) * base - 1;
              {
                reveal Pow();
                LemmaMulIsCommutativeAuto();
              }
              Pow(base, |str|) - 1;
            }
          }
        }

        function ToInt(str: String, minus: Char): (s: int)
          requires str != [minus]
          requires ToNumberStr(str, minus)
          decreases str
        {
          if [minus] <= str then
            -(ToNat(str[1..]) as int)
          else
            assert str == [] || str == [str[0]] + str[1..]; ToNat(str)
        }

        function {:opaque} ToNatRight(xs: seq<digit>): nat
          decreases xs
        {
          if |xs| == 0 then
            0
          else
            LemmaMulNonnegativeAuto(); ToNatRight(DropFirst(xs)) * BASE() + First(xs)
        }

        function {:opaque} ToNatLeft(xs: seq<digit>): nat
          decreases xs
        {
          if |xs| == 0 then
            0
          else
            LemmaPowPositiveAuto(); LemmaMulNonnegativeAuto(); ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1)
        }

        lemma {:vcs_split_on_every_assert} /*{:_induction xs}*/ LemmaToNatLeftEqToNatRight(xs: seq<digit>)
          ensures ToNatRight(xs) == ToNatLeft(xs)
          decreases xs
        {
          reveal ToNatRight();
          reveal ToNatLeft();
          if xs == [] {
          } else {
            if DropLast(xs) == [] {
              calc {
                ToNatLeft(xs);
                Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  reveal Pow();
                }
                Last(xs);
                First(xs);
                {
                  assert ToNatRight(DropFirst(xs)) == 0;
                }
                ToNatRight(xs);
              }
            } else {
              calc {
                ToNatLeft(xs);
                ToNatLeft(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  LemmaToNatLeftEqToNatRight(DropLast(xs));
                }
                ToNatRight(DropLast(xs)) + Last(xs) * Pow(BASE(), |xs| - 1);
                ToNatRight(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  LemmaToNatLeftEqToNatRight(DropFirst(DropLast(xs)));
                }
                ToNatLeft(DropFirst(DropLast(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 1);
                {
                  assert DropFirst(DropLast(xs)) == DropLast(DropFirst(xs));
                  reveal Pow();
                  LemmaMulProperties();
                }
                ToNatLeft(DropLast(DropFirst(xs))) * BASE() + First(xs) + Last(xs) * Pow(BASE(), |xs| - 2) * BASE();
                {
                  LemmaMulIsDistributiveAddOtherWayAuto();
                }
                ToNatLeft(DropFirst(xs)) * BASE() + First(xs);
                {
                  LemmaToNatLeftEqToNatRight(DropFirst(xs));
                }
                ToNatRight(xs);
              }
            }
          }
        }

        lemma LemmaToNatLeftEqToNatRightAuto()
          ensures forall xs: seq<digit> {:trigger ToNatLeft(xs)} {:trigger ToNatRight(xs)} :: ToNatRight(xs) == ToNatLeft(xs)
        {
          reveal ToNatRight();
          reveal ToNatLeft();
          forall xs: seq<digit> | true
            ensures ToNatRight(xs) == ToNatLeft(xs)
          {
            LemmaToNatLeftEqToNatRight(xs);
          }
        }

        lemma /*{:_induction xs}*/ LemmaSeqLen1(xs: seq<digit>)
          requires |xs| == 1
          ensures ToNatRight(xs) == First(xs)
          decreases xs
        {
          reveal ToNatRight();
          assert ToNatRight(DropFirst(xs)) == 0;
        }

        lemma /*{:_induction xs}*/ LemmaSeqLen2(xs: seq<digit>)
          requires |xs| == 2
          ensures ToNatRight(xs) == First(xs) + xs[1] * BASE()
          decreases xs
        {
          reveal ToNatRight();
          LemmaSeqLen1(DropLast(xs));
        }

        lemma /*{:_induction xs}*/ LemmaSeqAppendZero(xs: seq<digit>)
          ensures ToNatRight(xs + [0]) == ToNatRight(xs)
          decreases xs
        {
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          calc {
            ToNatRight(xs + [0]);
            ToNatLeft(xs + [0]);
            ToNatLeft(xs) + 0 * Pow(BASE(), |xs|);
            {
              LemmaMulBasicsAuto();
            }
            ToNatLeft(xs);
            ToNatRight(xs);
          }
        }

        lemma /*{:_induction xs}*/ LemmaSeqNatBound(xs: seq<digit>)
          ensures ToNatRight(xs) < Pow(BASE(), |xs|)
          decreases xs
        {
          reveal Pow();
          if |xs| == 0 {
            reveal ToNatRight();
          } else {
            ghost var len' := |xs| - 1;
            ghost var pow := Pow(BASE(), len');
            calc {
              ToNatRight(xs);
              {
                LemmaToNatLeftEqToNatRight(xs);
              }
              ToNatLeft(xs);
              {
                reveal ToNatLeft();
              }
              ToNatLeft(DropLast(xs)) + Last(xs) * pow;
            <
              {
                LemmaToNatLeftEqToNatRight(DropLast(xs));
                LemmaSeqNatBound(DropLast(xs));
              }
              pow + Last(xs) * pow;
            <=
              {
                LemmaPowPositiveAuto();
                LemmaMulInequalityAuto();
              }
              pow + (BASE() - 1) * pow;
              {
                LemmaMulIsDistributiveAuto();
              }
              Pow(BASE(), len' + 1);
            }
          }
        }

        lemma {:vcs_split_on_every_assert} /*{:_induction xs, i}*/ LemmaSeqPrefix(xs: seq<digit>, i: nat)
          requires 0 <= i <= |xs|
          ensures ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i) == ToNatRight(xs)
          decreases xs, i
        {
          reveal ToNatRight();
          reveal Pow();
          if i == 1 {
            assert ToNatRight(xs[..1]) == First(xs);
          } else if i > 1 {
            calc {
              ToNatRight(xs[..i]) + ToNatRight(xs[i..]) * Pow(BASE(), i);
              ToNatRight(DropFirst(xs[..i])) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i);
              {
                assert DropFirst(xs[..i]) == DropFirst(xs)[..i - 1];
                LemmaMulProperties();
              }
              ToNatRight(DropFirst(xs)[..i - 1]) * BASE() + First(xs) + ToNatRight(xs[i..]) * Pow(BASE(), i - 1) * BASE();
              {
                LemmaMulIsDistributiveAddOtherWayAuto();
              }
              (ToNatRight(DropFirst(xs)[..i - 1]) + ToNatRight(DropFirst(xs)[i - 1..]) * Pow(BASE(), i - 1)) * BASE() + First(xs);
              {
                LemmaSeqPrefix(DropFirst(xs), i - 1);
              }
              ToNatRight(xs);
            }
          }
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqMswInequality(xs: seq<digit>, ys: seq<digit>)
          requires |xs| == |ys| > 0
          requires Last(xs) < Last(ys)
          ensures ToNatRight(xs) < ToNatRight(ys)
          decreases xs, ys
        {
          reveal ToNatLeft();
          LemmaToNatLeftEqToNatRightAuto();
          ghost var len' := |xs| - 1;
          calc {
            ToNatRight(xs);
            ToNatLeft(xs);
          <
            {
              LemmaSeqNatBound(DropLast(xs));
            }
            Pow(BASE(), len') + Last(xs) * Pow(BASE(), len');
          ==
            {
              LemmaMulIsDistributiveAuto();
            }
            (1 + Last(xs)) * Pow(BASE(), len');
          <=
            {
              LemmaPowPositiveAuto();
              LemmaMulInequalityAuto();
            }
            ToNatLeft(ys);
            ToNatRight(ys);
          }
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqPrefixNeq(xs: seq<digit>, ys: seq<digit>, i: nat)
          requires 0 <= i <= |xs| == |ys|
          requires ToNatRight(xs[..i]) != ToNatRight(ys[..i])
          ensures ToNatRight(xs) != ToNatRight(ys)
          decreases |xs| - i
        {
          if i == |xs| {
            assert xs[..i] == xs;
            assert ys[..i] == ys;
          } else {
            if xs[i] == ys[i] {
              reveal ToNatLeft();
              assert DropLast(xs[..i + 1]) == xs[..i];
              assert DropLast(ys[..i + 1]) == ys[..i];
              LemmaToNatLeftEqToNatRightAuto();
              assert ToNatRight(xs[..i + 1]) == ToNatLeft(xs[..i + 1]);
            } else if xs[i] < ys[i] {
              LemmaSeqMswInequality(xs[..i + 1], ys[..i + 1]);
            } else {
              LemmaSeqMswInequality(ys[..i + 1], xs[..i + 1]);
            }
            reveal ToNatRight();
            LemmaSeqPrefixNeq(xs, ys, i + 1);
          }
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqNeq(xs: seq<digit>, ys: seq<digit>)
          requires |xs| == |ys|
          requires xs != ys
          ensures ToNatRight(xs) != ToNatRight(ys)
          decreases xs, ys
        {
          ghost var i: nat, n: nat := 0, |xs|;
          while i < n
            invariant 0 <= i < n
            invariant xs[..i] == ys[..i]
            decreases n - i
          {
            if xs[i] != ys[i] {
              break;
            }
            i := i + 1;
          }
          assert ToNatLeft(xs[..i]) == ToNatLeft(ys[..i]);
          reveal ToNatLeft();
          assert xs[..i + 1][..i] == xs[..i];
          assert ys[..i + 1][..i] == ys[..i];
          LemmaPowPositiveAuto();
          LemmaMulStrictInequalityAuto();
          assert ToNatLeft(xs[..i + 1]) != ToNatLeft(ys[..i + 1]);
          LemmaToNatLeftEqToNatRightAuto();
          LemmaSeqPrefixNeq(xs, ys, i + 1);
        }

        lemma /*{:_induction xs, ys}*/ LemmaSeqEq(xs: seq<digit>, ys: seq<digit>)
          requires |xs| == |ys|
          requires ToNatRight(xs) == ToNatRight(ys)
          ensures xs == ys
          decreases xs, ys
        {
          calc ==> {
            xs != ys;
            {
              LemmaSeqNeq(xs, ys);
            }
            ToNatRight(xs) != ToNatRight(ys);
            false;
          }
        }

        lemma /*{:_induction xs}*/ LemmaSeqLswModEquivalence(xs: seq<digit>)
          requires |xs| >= 1
          ensures IsModEquivalent(ToNatRight(xs), First(xs), BASE())
          decreases xs
        {
          if |xs| == 1 {
            LemmaSeqLen1(xs);
            LemmaModEquivalenceAuto();
          } else {
            assert IsModEquivalent(ToNatRight(xs), First(xs), BASE()) by {
              reveal ToNatRight();
              calc ==> {
                true;
                {
                  LemmaModEquivalence(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
                }
                IsModEquivalent(ToNatRight(xs), ToNatRight(DropFirst(xs)) * BASE() + First(xs), BASE());
                {
                  LemmaModMultiplesBasicAuto();
                }
                IsModEquivalent(ToNatRight(xs), First(xs), BASE());
              }
            }
          }
        }

        function {:opaque} FromNat(n: nat): (xs: seq<digit>)
          decreases n
        {
          if n == 0 then
            []
          else
            LemmaDivBasicsAuto(); LemmaDivDecreasesAuto(); [n % BASE()] + FromNat(n / BASE())
        }

        lemma /*{:_induction n}*/ LemmaFromNatLen2(n: nat)
          ensures n == 0 ==> |FromNat(n)| == 0
          ensures n > 0 ==> |FromNat(n)| == Log(BASE(), n) + 1
          decreases n
        {
          reveal FromNat();
          ghost var digits := FromNat(n);
          if n == 0 {
          } else {
            assert |digits| == Log(BASE(), n) + 1 by {
              LemmaDivBasicsAuto();
              ghost var digits' := FromNat(n / BASE());
              assert |digits| == |digits'| + 1;
              if n < BASE() {
                LemmaLog0(BASE(), n);
                assert n / BASE() == 0 by {
                  LemmaBasicDiv(BASE());
                }
              } else {
                LemmaLogS(BASE(), n);
                assert n / BASE() > 0 by {
                  LemmaDivNonZeroAuto();
                }
              }
            }
          }
        }

        lemma /*{:_induction n, len}*/ LemmaFromNatLen(n: nat, len: nat)
          requires Pow(BASE(), len) > n
          ensures |FromNat(n)| <= len
          decreases n, len
        {
          reveal FromNat();
          if n == 0 {
          } else {
            calc {
              |FromNat(n)|;
            ==
              {
                LemmaDivBasicsAuto();
              }
              1 + |FromNat(n / BASE())|;
            <=
              {
                LemmaMultiplyDivideLtAuto();
                LemmaDivDecreasesAuto();
                reveal Pow();
                LemmaFromNatLen(n / BASE(), len - 1);
              }
              len;
            }
          }
        }

        lemma /*{:_induction n}*/ LemmaNatSeqNat(n: nat)
          ensures ToNatRight(FromNat(n)) == n
          decreases n
        {
          reveal ToNatRight();
          reveal FromNat();
          if n == 0 {
          } else {
            calc {
              ToNatRight(FromNat(n));
              {
                LemmaDivBasicsAuto();
              }
              ToNatRight([n % BASE()] + FromNat(n / BASE()));
              n % BASE() + ToNatRight(FromNat(n / BASE())) * BASE();
              {
                LemmaDivDecreasesAuto();
                LemmaNatSeqNat(n / BASE());
              }
              n % BASE() + n / BASE() * BASE();
              {
                LemmaFundamentalDivMod(n, BASE());
              }
              n;
            }
          }
        }

        function {:opaque} SeqExtend(xs: seq<digit>, n: nat): (ys: seq<digit>)
          requires |xs| <= n
          ensures |ys| == n
          ensures ToNatRight(ys) == ToNatRight(xs)
          decreases n - |xs|
        {
          if |xs| >= n then
            xs
          else
            LemmaSeqAppendZero(xs); SeqExtend(xs + [0], n)
        }

        function {:opaque} SeqExtendMultiple(xs: seq<digit>, n: nat): (ys: seq<digit>)
          requires n > 0
          ensures |ys| % n == 0
          ensures ToNatRight(ys) == ToNatRight(xs)
          decreases xs, n
        {
          var newLen: int := |xs| + n - |xs| % n;
          LemmaSubModNoopRight(|xs| + n, |xs|, n);
          LemmaModBasicsAuto();
          assert newLen % n == 0;
          LemmaSeqNatBound(xs);
          LemmaPowIncreasesAuto();
          SeqExtend(xs, newLen)
        }

        function {:opaque} FromNatWithLen(n: nat, len: nat): (xs: seq<digit>)
          requires Pow(BASE(), len) > n
          ensures |xs| == len
          ensures ToNatRight(xs) == n
          decreases n, len
        {
          LemmaFromNatLen(n, len);
          LemmaNatSeqNat(n);
          SeqExtend(FromNat(n), len)
        }

        lemma /*{:_induction xs}*/ LemmaSeqZero(xs: seq<digit>)
          requires ToNatRight(xs) == 0
          ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
          decreases xs
        {
          reveal ToNatRight();
          if |xs| == 0 {
          } else {
            LemmaMulNonnegativeAuto();
            assert First(xs) == 0;
            LemmaMulNonzeroAuto();
            LemmaSeqZero(DropFirst(xs));
          }
        }

        function {:opaque} SeqZero(len: nat): (xs: seq<digit>)
          ensures |xs| == len
          ensures forall i: int {:trigger xs[i]} :: 0 <= i < |xs| ==> xs[i] == 0
          ensures ToNatRight(xs) == 0
          decreases len
        {
          LemmaPowPositive(BASE(), len);
          var xs: seq<digit> := FromNatWithLen(0, len);
          LemmaSeqZero(xs);
          xs
        }

        lemma /*{:_induction xs}*/ LemmaSeqNatSeq(xs: seq<digit>)
          ensures Pow(BASE(), |xs|) > ToNatRight(xs)
          ensures FromNatWithLen(ToNatRight(xs), |xs|) == xs
          decreases xs
        {
          reveal FromNat();
          reveal ToNatRight();
          LemmaSeqNatBound(xs);
          if |xs| > 0 {
            calc {
              FromNatWithLen(ToNatRight(xs), |xs|) != xs;
              {
                LemmaSeqNeq(FromNatWithLen(ToNatRight(xs), |xs|), xs);
              }
              ToNatRight(FromNatWithLen(ToNatRight(xs), |xs|)) != ToNatRight(xs);
              ToNatRight(xs) != ToNatRight(xs);
              false;
            }
          }
        }

        function {:opaque} SeqAdd(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
          requires |xs| == |ys|
          ensures var (zs: seq<digit>, cout: nat) := SeqAdd(xs, ys); |zs| == |xs| && 0 <= cout <= 1
          decreases xs
        {
          if |xs| == 0 then
            ([], 0)
          else
            var (zs': seq<digit>, cin: nat) := SeqAdd(DropLast(xs), DropLast(ys)); var sum: int := Last(xs) + Last(ys) + cin; var (sum_out: int, cout: int) := if sum < BASE() then (sum, 0) else (sum - BASE(), 1); (zs' + [sum_out], cout)
        }

        lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqAdd(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
          requires |xs| == |ys|
          requires SeqAdd(xs, ys) == (zs, cout)
          ensures ToNatRight(xs) + ToNatRight(ys) == ToNatRight(zs) + cout * Pow(BASE(), |xs|)
          decreases xs, ys, zs, cout
        {
          reveal SeqAdd();
          if |xs| == 0 {
            reveal ToNatRight();
          } else {
            ghost var pow := Pow(BASE(), |xs| - 1);
            var (zs', cin) := SeqAdd(DropLast(xs), DropLast(ys));
            ghost var sum: int := Last(xs) + Last(ys) + cin;
            ghost var z := if sum < BASE() then sum else sum - BASE();
            assert sum == z + cout * BASE();
            reveal ToNatLeft();
            LemmaToNatLeftEqToNatRightAuto();
            calc {
              ToNatRight(zs);
              ToNatLeft(zs);
              ToNatLeft(zs') + z * pow;
              {
                LemmaSeqAdd(DropLast(xs), DropLast(ys), zs', cin);
              }
              ToNatLeft(DropLast(xs)) + ToNatLeft(DropLast(ys)) - cin * pow + z * pow;
              {
                LemmaMulEquality(sum, z + cout * BASE(), pow);
                assert sum * pow == (z + cout * BASE()) * pow;
                LemmaMulIsDistributiveAuto();
              }
              ToNatLeft(xs) + ToNatLeft(ys) - cout * BASE() * pow;
              {
                LemmaMulIsAssociative(cout, BASE(), pow);
                reveal Pow();
              }
              ToNatLeft(xs) + ToNatLeft(ys) - cout * Pow(BASE(), |xs|);
              ToNatRight(xs) + ToNatRight(ys) - cout * Pow(BASE(), |xs|);
            }
          }
        }

        function {:opaque} SeqSub(xs: seq<digit>, ys: seq<digit>): (seq<digit>, nat)
          requires |xs| == |ys|
          ensures var (zs: seq<digit>, cout: nat) := SeqSub(xs, ys); |zs| == |xs| && 0 <= cout <= 1
          decreases xs
        {
          if |xs| == 0 then
            ([], 0)
          else
            var (zs: seq<digit>, cin: nat) := SeqSub(DropLast(xs), DropLast(ys)); var (diff_out: int, cout: int) := if Last(xs) >= Last(ys) + cin then (Last(xs) - Last(ys) - cin, 0) else (BASE() + Last(xs) - Last(ys) - cin, 1); (zs + [diff_out], cout)
        }

        lemma {:vcs_split_on_every_assert} /*{:_induction xs, ys, zs}*/ LemmaSeqSub(xs: seq<digit>, ys: seq<digit>, zs: seq<digit>, cout: nat)
          requires |xs| == |ys|
          requires SeqSub(xs, ys) == (zs, cout)
          ensures ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|) == ToNatRight(zs)
          decreases xs, ys, zs, cout
        {
          reveal SeqSub();
          if |xs| == 0 {
            reveal ToNatRight();
          } else {
            ghost var pow := Pow(BASE(), |xs| - 1);
            var (zs', cin) := SeqSub(DropLast(xs), DropLast(ys));
            ghost var z := if Last(xs) >= Last(ys) + cin then Last(xs) - Last(ys) - cin else BASE() + Last(xs) - Last(ys) - cin;
            assert cout * BASE() + Last(xs) - cin - Last(ys) == z;
            reveal ToNatLeft();
            LemmaToNatLeftEqToNatRightAuto();
            calc {
              ToNatRight(zs);
              ToNatLeft(zs);
              ToNatLeft(zs') + z * pow;
              {
                LemmaSeqSub(DropLast(xs), DropLast(ys), zs', cin);
              }
              ToNatLeft(DropLast(xs)) - ToNatLeft(DropLast(ys)) + cin * pow + z * pow;
              {
                LemmaMulEquality(cout * BASE() + Last(xs) - cin - Last(ys), z, pow);
                assert pow * (cout * BASE() + Last(xs) - cin - Last(ys)) == pow * z;
                LemmaMulIsDistributiveAuto();
              }
              ToNatLeft(xs) - ToNatLeft(ys) + cout * BASE() * pow;
              {
                LemmaMulIsAssociative(cout, BASE(), pow);
                reveal Pow();
              }
              ToNatLeft(xs) - ToNatLeft(ys) + cout * Pow(BASE(), |xs|);
              ToNatRight(xs) - ToNatRight(ys) + cout * Pow(BASE(), |xs|);
            }
          }
        }

        import opened BoundedInts

        type Char = uint16

        import opened Wrappers

        type String = seq<Char>

        type CharSeq = chars: seq<Char>
          | |chars| > 1
          witness *

        import opened DivMod

        import opened Mul

        import opened Power

        import opened Seq = Collections.Seq

        import opened Logarithm

        type digit = i: nat
          | 0 <= i < BASE()
      }
    }

    module Errors {

      import Wrappers

      import Strings

      import opened BoundedInts
      datatype DeserializationError = UnterminatedSequence | UnsupportedEscape(str: string) | EscapeAtEOS | EmptyNumber | ExpectingEOF | IntOverflow | ReachedEOF | ExpectingByte(expected: byte, b: opt_byte) | ExpectingAnyByte(expected_sq: seq<byte>, b: opt_byte) | InvalidUnicode {
        function ToString(): string
          decreases this
        {
          match this
          case UnterminatedSequence() =>
            ""Unterminated sequence""
          case UnsupportedEscape(str) =>
            ""Unsupported escape sequence: "" + str
          case EscapeAtEOS() =>
            ""Escape character at end of string""
          case EmptyNumber() =>
            ""Number must contain at least one digit""
          case ExpectingEOF() =>
            ""Expecting EOF""
          case IntOverflow() =>
            ""Input length does not fit in a 32-bit counter""
          case ReachedEOF() =>
            ""Reached EOF""
          case ExpectingByte(b0, b) =>
            var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
            ""Expecting '"" + [b0 as char] + ""', read "" + c
          case ExpectingAnyByte(bs0, b) =>
            var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
            var c0s: seq<char> := seq(|bs0|, (idx: int) requires 0 <= idx < |bs0| => bs0[idx] as char);
            ""Expecting one of '"" + c0s + ""', read "" + c
          case InvalidUnicode() =>
            ""Invalid Unicode sequence""
        }
      }

      datatype SerializationError = OutOfMemory | IntTooLarge(i: int) | StringTooLong(s: string) | InvalidUnicode {
        function ToString(): string
          decreases this
        {
          match this
          case OutOfMemory() =>
            ""Out of memory""
          case IntTooLarge(i: int) =>
            ""Integer too large: "" + Strings.OfInt(i)
          case StringTooLong(s: string) =>
            ""String too long: "" + s
          case InvalidUnicode() =>
            ""Invalid Unicode sequence""
        }
      }

      type SerializationResult<+T> = Wrappers.Result<T, SerializationError>

      type DeserializationResult<+T> = Wrappers.Result<T, DeserializationError>
    }

    module Grammar {
      const EMPTY := View.OfBytes([])
      const DOUBLEQUOTE := View.OfBytes(['\""' as byte])
      const PERIOD := View.OfBytes(['.' as byte])
      const E := View.OfBytes(['e' as byte])
      const COLON := View.OfBytes([':' as byte])
      const COMMA := View.OfBytes([',' as byte])
      const LBRACE := View.OfBytes(['{' as byte])
      const RBRACE := View.OfBytes(['}' as byte])
      const LBRACKET := View.OfBytes(['[' as byte])
      const RBRACKET := View.OfBytes([']' as byte])
      const MINUS := View.OfBytes(['-' as byte])

      predicate Blank?(b: byte)
        decreases b
      {
        b == 32 || b == 9 || b == 10 || b == 13
      }

      ghost predicate Blanks?(v: View)
        decreases v
      {
        forall b: uint8 {:trigger Blank?(b)} {:trigger b in v.Bytes()} | b in v.Bytes() :: 
          Blank?(b)
      }

      ghost predicate NoTrailingSuffix<S, D>(s: seq<Suffixed<D, S>>)
        decreases s
      {
        forall idx: int {:trigger s[idx]} | 0 <= idx < |s| :: 
          s[idx].suffix.Empty? <==> idx == |s| - 1
      }

      const NULL: bytes := ['n' as byte, 'u' as byte, 'l' as byte, 'l' as byte]
      const TRUE: bytes := ['t' as byte, 'r' as byte, 'u' as byte, 'e' as byte]
      const FALSE: bytes := ['f' as byte, 'a' as byte, 'l' as byte, 's' as byte, 'e' as byte]

      ghost predicate Null?(v: View)
        decreases v
      {
        v.Bytes() == NULL
      }

      ghost predicate Bool?(v: View)
        decreases v
      {
        v.Bytes() in {TRUE, FALSE}
      }

      predicate Digit?(b: byte)
        decreases b
      {
        '0' as byte <= b <= '9' as byte
      }

      ghost predicate Digits?(v: View)
        decreases v
      {
        forall b: uint8 {:trigger Digit?(b)} {:trigger b in v.Bytes()} | b in v.Bytes() :: 
          Digit?(b)
      }

      ghost predicate Num?(v: View)
        decreases v
      {
        Digits?(v) &&
        !v.Empty?
      }

      ghost predicate Int?(v: View)
        decreases v
      {
        v.Char?('0') || (Num?(v) && v.At(0) != '0' as byte)
      }

      import opened BoundedInts

      import opened Core = Utils.Views.Core

      type jchar = v: View
        | v.Length() == 1
        witness View.OfBytes(['b' as byte])

      type jquote = v: View
        | v.Char?('\""')
        witness DOUBLEQUOTE

      type jperiod = v: View
        | v.Char?('.')
        witness PERIOD

      type je = v: View
        | v.Char?('e') || v.Char?('E')
        witness E

      type jcolon = v: View
        | v.Char?(':')
        witness COLON

      type jcomma = v: View
        | v.Char?(',')
        witness COMMA

      type jlbrace = v: View
        | v.Char?('{')
        witness LBRACE

      type jrbrace = v: View
        | v.Char?('}')
        witness RBRACE

      type jlbracket = v: View
        | v.Char?('[')
        witness LBRACKET

      type jrbracket = v: View
        | v.Char?(']')
        witness RBRACKET

      type jminus = v: View
        | v.Char?('-') || v.Empty?
        witness MINUS

      type jsign = v: View
        | v.Char?('-') || v.Char?('+') || v.Empty?
        witness EMPTY

      type jblanks = v: View
        | Blanks?(v)
        witness View.OfBytes([])

      datatype Structural<+T> = Structural(before: jblanks, t: T, after: jblanks)

      datatype Maybe<+T> = Empty | NonEmpty(t: T)

      datatype Suffixed<+T, +S> = Suffixed(t: T, suffix: Maybe<Structural<S>>)

      type SuffixedSequence<+D, +S> = s: seq<Suffixed<D, S>>
        | NoTrailingSuffix(s)

      datatype Bracketed<+L, +D, +S, +R> = Bracketed(l: Structural<L>, data: SuffixedSequence<D, S>, r: Structural<R>)

      type jnull = v: View
        | Null?(v)
        witness View.OfBytes(NULL)

      type jbool = v: View
        | Bool?(v)
        witness View.OfBytes(TRUE)

      type jdigits = v: View
        | Digits?(v)
        witness View.OfBytes([])

      type jnum = v: View
        | Num?(v)
        witness View.OfBytes(['0' as byte])

      type jint = v: View
        | Int?(v)
        witness View.OfBytes(['0' as byte])

      type jstr = v: View
        | true
        witness View.OfBytes([])

      datatype jstring = JString(lq: jquote, contents: jstr, rq: jquote)

      datatype jKeyValue = KeyValue(k: jstring, colon: Structural<jcolon>, v: Value)

      type jobject = Bracketed<jlbrace, jKeyValue, jcomma, jrbrace>

      type jarray = Bracketed<jlbracket, Value, jcomma, jrbracket>

      type jmembers = SuffixedSequence<jKeyValue, jcomma>

      type jmember = Suffixed<jKeyValue, jcomma>

      type jitems = SuffixedSequence<Value, jcomma>

      type jitem = Suffixed<Value, jcomma>

      datatype jfrac = JFrac(period: jperiod, num: jnum)

      datatype jexp = JExp(e: je, sign: jsign, num: jnum)

      datatype jnumber = JNumber(minus: jminus, num: jnum, frac: Maybe<jfrac>, exp: Maybe<jexp>)

      datatype Value = Null(n: jnull) | Bool(b: jbool) | String(str: jstring) | Number(num: jnumber) | Object(obj: jobject) | Array(arr: jarray)

      type JSON = Structural<Value>
    }

    module Serializer {
      function Bool(b: bool): jbool
        decreases b
      {
        View.OfBytes(if b then TRUE else FALSE)
      }

      function CheckLength<T>(s: seq<T>, err: SerializationError): Outcome<SerializationError>
        decreases s, err
      {
        Outcome.Need(|s| < TWO_TO_THE_32, err)
      }

      function String(str: string): Result<jstring>
        decreases str
      {
        var bs: bytes :- Spec.EscapeToUTF8(str); var o: Outcome<SerializationError> := CheckLength(bs, StringTooLong(str)); if o.Pass? then Success(Grammar.JString(Grammar.DOUBLEQUOTE, View.OfBytes(bs), Grammar.DOUBLEQUOTE)) else Failure(o.error)
      }

      function Sign(n: int): jminus
        decreases n
      {
        View.OfBytes(if n < 0 then ['-' as byte] else [])
      }

      const DIGITS := ByteStrConversion.chars
      const MINUS := '-' as byte

      function Int'(n: int): (str: bytes)
        ensures forall c: uint8 {:trigger c in DIGITS} {:trigger c in str} | c in str :: c in DIGITS || c == MINUS
        decreases n
      {
        ByteStrConversion.OfInt(n, MINUS)
      }

      function Int(n: int): Result<View>
        decreases n
      {
        var bs: bytes := Int'(n);
        var o: Outcome<SerializationError> := CheckLength(bs, IntTooLarge(n));
        if o.Pass? then
          Success(View.OfBytes(bs))
        else
          Failure(o.error)
      }

      function {:vcs_split_on_every_assert} {:rlimit 1000} Number(dec: Values.Decimal): Result<jnumber>
        decreases dec
      {
        var minus: jminus := Sign(dec.n);
        var num: jnum :- Int(Math.Abs(dec.n)); var frac: Maybe<jfrac> := Empty(); var exp: Maybe<jexp> :- if dec.e10 == 0 then Success(Empty()) else var e: je := View.OfBytes(['e' as byte]); var sign: jsign := Sign(dec.e10); var num: jnum :- Int(Math.Abs(dec.e10)); Success(NonEmpty(JExp(e, sign, num))); Success(JNumber(minus, num, Empty, exp))
      }

      function MkStructural<T>(v: T): Structural<T>
      {
        Structural(EMPTY, v, EMPTY)
      }

      const COLON: Structural<jcolon> := MkStructural(Grammar.COLON)

      function KeyValue(kv: (string, Values.JSON)): Result<jKeyValue>
        decreases kv
      {
        var k: jstring :- String(kv.0); var v: Grammar.Value :- Value(kv.1); Success(Grammar.KeyValue(k, COLON, v))
      }

      function MkSuffixedSequence<D, S>(ds: seq<D>, suffix: Structural<S>, start: nat := 0): SuffixedSequence<D, S>
        decreases |ds| - start
      {
        if start >= |ds| then
          []
        else if start == |ds| - 1 then
          [Suffixed(ds[start], Empty)]
        else
          [Suffixed(ds[start], NonEmpty(suffix))] + MkSuffixedSequence(ds, suffix, start + 1)
      }

      const COMMA: Structural<jcomma> := MkStructural(Grammar.COMMA)

      function Object(obj: seq<(string, Values.JSON)>): Result<jobject>
        decreases obj
      {
        var items: seq<jKeyValue> :- Seq.MapWithResult((v: (string, Values.JSON)) requires v in obj => KeyValue(v), obj); Success(Bracketed(MkStructural(LBRACE), MkSuffixedSequence(items, COMMA), MkStructural(RBRACE)))
      }

      function Array(arr: seq<Values.JSON>): Result<jarray>
        decreases arr
      {
        var items: seq<Grammar.Value> :- Seq.MapWithResult((v: Values.JSON) requires v in arr => Value(v), arr); Success(Bracketed(MkStructural(LBRACKET), MkSuffixedSequence(items, COMMA), MkStructural(RBRACKET)))
      }

      function Value(js: Values.JSON): Result<Grammar.Value>
        decreases js
      {
        match js
        case Null() =>
          Success(Grammar.Null(View.OfBytes(NULL)))
        case Bool(b) =>
          Success(Grammar.Bool(Bool(b)))
        case String(str) =>
          var s: jstring :- String(str); Success(Grammar.String(s))
        case Number(dec) =>
          var n: jnumber :- Number(dec); Success(Grammar.Number(n))
        case Object(obj) =>
          var o: jobject :- Object(obj); Success(Grammar.Object(o))
        case Array(arr) =>
          var a: jarray :- Array(arr); Success(Grammar.Array(a))
      }

      function JSON(js: Values.JSON): Result<Grammar.JSON>
        decreases js
      {
        var val: Grammar.Value :- Value(js); Success(MkStructural(val))
      }

      import Seq = Collections.Seq

      import Math

      import Values

      import Spec

      import opened Wrappers

      import opened BoundedInts

      import opened Strings

      import opened Errors

      import opened DynamicArray

      import opened Grammar

      import opened Core = Utils.Views.Core

      import ByteStrConversion

      type Result<+T> = SerializationResult<T>

      type bytes = seq<uint8>

      type bytes32 = bs: bytes
        | |bs| < TWO_TO_THE_32

      type string32 = s: string
        | |s| < TWO_TO_THE_32
    }

    module Spec {
      function EscapeUnicode(c: uint16): seq<uint16>
        decreases c
      {
        var sStr: String := Strings.HexConversion.OfNat(c as nat);
        Seq.MembershipImpliesIndexing((c: char) => 0 <= c as int < 128, sStr);
        var s: seq<uint16> := ASCIIToUTF16(sStr);
        assert |s| <= 4 by {
          assert c as nat <= 65535;
          assert Log(16, c as nat) <= Log(16, 65535) by {
            LemmaLogIsOrdered(16, c as nat, 65535);
          }
          assert Log(16, 65535) == 3 by {
            reveal Log();
          }
        }
        s + seq(4 - |s|, (_ /* _v8 */: int) => ' ' as uint16)
      }

      function Escape(str: seq<uint16>, start: nat := 0): seq<uint16>
        decreases |str| - start
      {
        if start >= |str| then
          []
        else
          (match str[start] case 34 => ASCIIToUTF16(""\\\"""") case 92 => ASCIIToUTF16(""\\\\"") case 8 => ASCIIToUTF16(""\\b"") case 12 => ASCIIToUTF16(""\\f"") case 10 => ASCIIToUTF16(""\\n"") case 13 => ASCIIToUTF16(""\\r"") case 9 => ASCIIToUTF16(""\\t"") case c => (if c < 31 then ASCIIToUTF16(""\\u"") + EscapeUnicode(c) else [str[start]])) + Escape(str, start + 1)
      }

      function EscapeToUTF8(str: string, start: nat := 0): Result<bytes>
        decreases str, start
      {
        var utf16: seq<uint16> :- ToUTF16Checked(str).ToResult(SerializationError.InvalidUnicode); var escaped: seq<uint16> := Escape(utf16); var utf32: string :- FromUTF16Checked(escaped).ToResult(SerializationError.InvalidUnicode); ToUTF8Checked(utf32).ToResult(SerializationError.InvalidUnicode)
      }

      function String(str: string): Result<bytes>
        decreases str
      {
        var inBytes: bytes :- EscapeToUTF8(str); Success(ASCIIToUTF8(""\"""") + inBytes + ASCIIToUTF8(""\""""))
      }

      lemma OfIntOnlyASCII(n: int)
        ensures true && ghost var s: string := Strings.OfInt(n); true && forall i: int {:trigger s[i]} | 0 <= i < |s| :: 0 <= s[i] as int && s[i] as int < 128
        decreases n
      {
        ghost var s := Strings.OfInt(n);
        forall i: int | 0 <= i < |s|
          ensures 0 <= s[i] as int < 128
        {
          if i == 0 {
          } else {
            ghost var isHexDigit := (c: char) => c in Strings.HexConversion.HEX_DIGITS;
            assert Strings.HexConversion.OfNumberStr(s, '-');
            assert isHexDigit(s[i]);
          }
        }
      }

      function IntToBytes(n: int): bytes
        decreases n
      {
        var s: string := Strings.OfInt(n);
        OfIntOnlyASCII(n);
        ASCIIToUTF8(s)
      }

      function Number(dec: Decimal): Result<bytes>
        decreases dec
      {
        Success(IntToBytes(dec.n) + if dec.e10 == 0 then [] else ASCIIToUTF8(""e"") + IntToBytes(dec.e10))
      }

      function KeyValue(kv: (string, JSON)): Result<bytes>
        decreases kv
      {
        var key: bytes :- String(kv.0); var value: bytes :- JSON(kv.1); Success(key + ASCIIToUTF8("":"") + value)
      }

      function Join(sep: bytes, items: seq<Result<bytes>>): Result<bytes>
        decreases sep, items
      {
        if |items| == 0 then
          Success([])
        else
          var first: bytes :- items[0]; if |items| == 1 then Success(first) else var rest: bytes :- Join(sep, items[1..]); Success(first + sep + rest)
      }

      function Object(obj: seq<(string, JSON)>): Result<bytes>
        decreases obj
      {
        var middle: bytes :- Join(ASCIIToUTF8("",""), seq(|obj|, (i: int) requires 0 <= i < |obj| => KeyValue(obj[i]))); Success(ASCIIToUTF8(""{"") + middle + ASCIIToUTF8(""}""))
      }

      function Array(arr: seq<JSON>): Result<bytes>
        decreases arr
      {
        var middle: bytes :- Join(ASCIIToUTF8("",""), seq(|arr|, (i: int) requires 0 <= i < |arr| => JSON(arr[i]))); Success(ASCIIToUTF8(""["") + middle + ASCIIToUTF8(""]""))
      }

      function JSON(js: JSON): Result<bytes>
        decreases js
      {
        match js
        case Null() =>
          Success(ASCIIToUTF8(""null""))
        case Bool(b) =>
          Success(if b then ASCIIToUTF8(""true"") else ASCIIToUTF8(""false""))
        case String(str) =>
          String(str)
        case Number(dec) =>
          Number(dec)
        case Object(obj) =>
          Object(obj)
        case Array(arr) =>
          Array(arr)
      }

      import Seq = Collections.Seq

      import opened BoundedInts

      import opened Strings

      import opened Values

      import opened Wrappers

      import opened Errors

      import opened UnicodeStringsWithUnicodeChar = Unicode.UnicodeStringsWithUnicodeChar

      import opened Logarithm = Arithmetic.Logarithm

      type Result<+T> = SerializationResult<T>
    }

    module Values {
      function Int(n: int): Decimal
        decreases n
      {
        Decimal(n, 0)
      }

      datatype Decimal = Decimal(n: int, e10: int)

      datatype JSON = Null | Bool(b: bool) | String(str: string) | Number(num: Decimal) | Object(obj: seq<(string, JSON)>) | Array(arr: seq<JSON>)
    }

    module ConcreteSyntax {

      module Spec {
        function View(v: Vs.View): bytes
          decreases v
        {
          v.Bytes()
        }

        function Structural<T>(self: Structural<T>, fT: T -> bytes): bytes
          decreases self
        {
          View(self.before) + fT(self.t) + View(self.after)
        }

        function StructuralView(self: Structural<Vs.View>): bytes
          decreases self
        {
          Structural<Vs.View>(self, View)
        }

        function Maybe<T>(self: Maybe<T>, fT: T -> bytes): (bs: bytes)
          ensures self.Empty? ==> bs == []
          ensures self.NonEmpty? ==> bs == fT(self.t)
          decreases self
        {
          if self.Empty? then
            []
          else
            fT(self.t)
        }

        function ConcatBytes<T>(ts: seq<T>, fT: T --> bytes): (b: bytes)
          requires forall d: T {:trigger fT.requires(d)} {:trigger d in ts} | d in ts :: fT.requires(d)
          ensures |ts| == 1 ==> b == fT(ts[0])
          decreases ts
        {
          if |ts| == 0 then
            []
          else
            fT(ts[0]) + ConcatBytes(ts[1..], fT)
        }

        function Bracketed<D, S>(self: Bracketed<Vs.View, D, S, Vs.View>, fDatum: Suffixed<D, S> --> bytes): bytes
          requires forall d: Suffixed<D, S> {:trigger fDatum.requires(d)} | d < self :: fDatum.requires(d)
          decreases self
        {
          StructuralView(self.l) + ConcatBytes(self.data, fDatum) + StructuralView(self.r)
        }

        function KeyValue(self: jKeyValue): bytes
          decreases self
        {
          String(self.k) + StructuralView(self.colon) + Value(self.v)
        }

        function Frac(self: jfrac): bytes
          decreases self
        {
          View(self.period) + View(self.num)
        }

        function Exp(self: jexp): bytes
          decreases self
        {
          View(self.e) + View(self.sign) + View(self.num)
        }

        function Number(self: jnumber): bytes
          decreases self
        {
          View(self.minus) + View(self.num) + Maybe(self.frac, Frac) + Maybe(self.exp, Exp)
        }

        function String(self: jstring): bytes
          decreases self
        {
          View(self.lq) + View(self.contents) + View(self.rq)
        }

        function CommaSuffix(c: Maybe<Structural<jcomma>>): bytes
          decreases c
        {
          Maybe<Structural<Vs.View>>(c, StructuralView)
        }

        function Member(self: jmember): bytes
          decreases self
        {
          KeyValue(self.t) + CommaSuffix(self.suffix)
        }

        function Item(self: jitem): bytes
          decreases self
        {
          Value(self.t) + CommaSuffix(self.suffix)
        }

        function Object(obj: jobject): bytes
          decreases obj
        {
          Bracketed(obj, (d: jmember) requires d < obj => Member(d))
        }

        function Array(arr: jarray): bytes
          decreases arr
        {
          Bracketed(arr, (d: jitem) requires d < arr => Item(d))
        }

        function Value(self: Value): (b: bytes)
          ensures self.String? ==> b == String(self.str)
          ensures self.Number? ==> b == Number(self.num)
          ensures self.Object? ==> b == Object(self.obj)
          ensures self.Array? ==> b == Array(self.arr)
          decreases self
        {
          match self {
            case Null(n) =>
              View(n)
            case Bool(b) =>
              View(b)
            case String(str) =>
              String(str)
            case Number(num) =>
              Number(num)
            case Object(obj) =>
              Object(obj)
            case Array(arr) =>
              Array(arr)
          }
        }

        lemma /*{:_induction v}*/ UnfoldValueNumber(v: Value)
          requires v.Number?
          ensures Value(v) == Number(v.num)
          decreases v
        {
          assert Value(v) == match v { case Number(num) => Number(num) case _ /* _v1 */ => [] };
        }

        lemma /*{:_induction v}*/ UnfoldValueObject(v: Value)
          requires v.Object?
          ensures Value(v) == Object(v.obj)
          decreases v
        {
          assert Value(v) == match v { case Object(obj) => Object(obj) case _ /* _v2 */ => [] };
        }

        lemma /*{:_induction v}*/ UnfoldValueArray(v: Value)
          requires v.Array?
          ensures Value(v) == Array(v.arr)
          decreases v
        {
          assert Value(v) == match v { case Array(arr) => Array(arr) case _ /* _v3 */ => [] };
        }

        function JSON(js: JSON): bytes
          decreases js
        {
          Structural(js, Value)
        }

        import Vs = Utils.Views.Core

        import opened BoundedInts

        import opened Grammar
      }

      module SpecProperties {
        ghost predicate Bracketed_Morphism_Requires<D, S>(bracketed: Bracketed<Vs.View, D, S, Vs.View>, pd0: Suffixed<D, S> --> bytes, pd1: Suffixed<D, S> --> bytes)
          decreases bracketed
        {
          (forall d: Suffixed<D, S> {:trigger pd0.requires(d)} | d < bracketed :: 
            pd0.requires(d)) &&
          (forall d: Suffixed<D, S> {:trigger pd1.requires(d)} | d < bracketed :: 
            pd1.requires(d)) &&
          forall d: Suffixed<D, S> {:trigger pd1(d)} {:trigger pd0(d)} | d < bracketed :: 
            pd0(d) == pd1(d)
        }

        lemma Bracketed_Morphism<D, S>(bracketed: Bracketed<Vs.View, D, S, Vs.View>, pd0: Suffixed<D, S> --> bytes, pd1: Suffixed<D, S> --> bytes)
          requires Bracketed_Morphism_Requires(bracketed, pd0, pd1)
          ensures Spec.Bracketed(bracketed, pd0) == Spec.Bracketed(bracketed, pd1)
          decreases bracketed
        {
          calc {
            Spec.Bracketed(bracketed, pd0);
            {
              ConcatBytes_Morphism(bracketed.data, pd0, pd1);
            }
            Spec.Bracketed(bracketed, pd1);
          }
        }

        lemma {:induction ts} /*{:_induction ts}*/ ConcatBytes_Morphism<T>(ts: seq<T>, pt0: T --> bytes, pt1: T --> bytes)
          requires forall d: T {:trigger pt0.requires(d)} {:trigger d in ts} | d in ts :: pt0.requires(d)
          requires forall d: T {:trigger pt1.requires(d)} {:trigger d in ts} | d in ts :: pt1.requires(d)
          requires forall d: T {:trigger pt1(d)} {:trigger pt0(d)} {:trigger d in ts} | d in ts :: pt0(d) == pt1(d)
          ensures Spec.ConcatBytes(ts, pt0) == Spec.ConcatBytes(ts, pt1)
          decreases ts
        {
        }

        lemma {:induction ts0} {:rlimit 10000} /*{:_induction ts0}*/ ConcatBytes_Linear<T>(ts0: seq<T>, ts1: seq<T>, pt: T --> bytes)
          requires forall d: T {:trigger pt.requires(d)} {:trigger d in ts0} | d in ts0 :: pt.requires(d)
          requires forall d: T {:trigger pt.requires(d)} {:trigger d in ts1} | d in ts1 :: pt.requires(d)
          ensures Spec.ConcatBytes(ts0 + ts1, pt) == Spec.ConcatBytes(ts0, pt) + Spec.ConcatBytes(ts1, pt)
          decreases ts0, ts1
        {
          if |ts0| == 0 {
            assert [] + ts1 == ts1;
          } else {
            assert ts0 + ts1 == [ts0[0]] + (ts0[1..] + ts1);
          }
        }

        import Spec

        import Vs = Utils.Views.Core

        import opened BoundedInts

        import opened Grammar
      }
    }

    module Utils {

      module Cursors {

        import opened BoundedInts

        import opened Wrappers

        import opened Vs = Views.Core

        import opened Lx = Lexers.Core
        datatype Split<+T> = SP(t: T, cs: FreshCursor) {
          ghost predicate BytesSplitFrom?(cs0: Cursor, spec: T -> bytes)
            decreases this, cs0
          {
            cs0.Bytes() == spec(t) + cs.Bytes()
          }

          ghost predicate SplitFrom?(cs0: Cursor, spec: T -> bytes)
            decreases this, cs0
          {
            cs.SplitFrom?(cs0) &&
            BytesSplitFrom?(cs0, spec)
          }

          ghost predicate StrictlySplitFrom?(cs0: Cursor, spec: T -> bytes)
            decreases this, cs0
          {
            cs.StrictlySplitFrom?(cs0) &&
            BytesSplitFrom?(cs0, spec)
          }
        }

        type Cursor = ps: Cursor_
          | ps.Valid?
          witness Cursor([], 0, 0, 0)

        type FreshCursor = ps: Cursor
          | ps.BOF?
          witness Cursor([], 0, 0, 0)

        datatype CursorError<+R> = EOF | ExpectingByte(expected: byte, b: opt_byte) | ExpectingAnyByte(expected_sq: seq<byte>, b: opt_byte) | OtherError(err: R) {
          function ToString(pr: R -> string): string
            decreases this
          {
            match this
            case EOF() =>
              ""Reached EOF""
            case ExpectingByte(b0, b) =>
              var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
              ""Expecting '"" + [b0 as char] + ""', read "" + c
            case ExpectingAnyByte(bs0, b) =>
              var c: seq<char> := if b > 0 then ""'"" + [b as char] + ""'"" else ""EOF"";
              var c0s: seq<char> := seq(|bs0|, (idx: int) requires 0 <= idx < |bs0| => bs0[idx] as char);
              ""Expecting one of '"" + c0s + ""', read "" + c
            case OtherError(err) =>
              pr(err)
          }
        }

        type CursorResult<+R> = Result<Cursor, CursorError<R>>

        datatype Cursor_ = Cursor(s: bytes, beg: uint32, point: uint32, end: uint32) {
          ghost const Valid?: bool := 0 <= beg as int <= point as int <= end as int <= |s| < TWO_TO_THE_32
          const BOF? := point == beg
          const EOF? := point == end

          static function OfView(v: View): FreshCursor
            decreases v
          {
            Cursor(v.s, v.beg, v.beg, v.end)
          }

          static function OfBytes(bs: bytes): FreshCursor
            requires |bs| < TWO_TO_THE_32
            decreases bs
          {
            Cursor(bs, 0, 0, |bs| as uint32)
          }

          function Bytes(): bytes
            requires Valid?
            decreases this
          {
            s[beg .. end]
          }

          ghost predicate StrictlyAdvancedFrom?(other: Cursor): (b: bool)
            requires Valid?
            ensures b ==> SuffixLength() < other.SuffixLength()
            ensures b ==> beg == other.beg && end == other.end ==> forall idx: uint32 {:trigger other.s[idx]} {:trigger s[idx]} | beg <= idx < point :: s[idx] == other.s[idx]
            decreases this, other
          {
            s == other.s &&
            beg == other.beg &&
            end == other.end &&
            point > other.point
          }

          ghost predicate AdvancedFrom?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            this == other || StrictlyAdvancedFrom?(other)
          }

          ghost predicate StrictSuffixOf?(other: Cursor)
            requires Valid?
            ensures StrictSuffixOf?(other) ==> Length() < other.Length()
            decreases this, other
          {
            s == other.s &&
            beg > other.beg &&
            end == other.end
          }

          ghost predicate SuffixOf?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            this == other || StrictSuffixOf?(other)
          }

          ghost predicate StrictlySplitFrom?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            BOF? &&
            StrictSuffixOf?(other)
          }

          ghost predicate SplitFrom?(other: Cursor)
            requires Valid?
            decreases this, other
          {
            this == other || StrictlySplitFrom?(other)
          }

          function Prefix(): View
            requires Valid?
            decreases this
          {
            View(s, beg, point)
          }

          function Suffix(): Cursor
            requires Valid?
            decreases this
          {
            this.(beg := point)
          }

          function Split(): (sp: Split<View>)
            requires Valid?
            ensures sp.SplitFrom?(this, (v: View) => v.Bytes())
            ensures beg != point ==> sp.StrictlySplitFrom?(this, (v: View) => v.Bytes())
            ensures !BOF? ==> sp.StrictlySplitFrom?(this, (v: View) => v.Bytes()) && sp.cs.StrictSuffixOf?(this)
            ensures !EOF? <==> !sp.cs.EOF?
            decreases this
          {
            SP(this.Prefix(), this.Suffix())
          }

          function PrefixLength(): uint32
            requires Valid?
            decreases this
          {
            point - beg
          }

          function SuffixLength(): uint32
            requires Valid?
            decreases this
          {
            end - point
          }

          function Length(): uint32
            requires Valid?
            decreases this
          {
            end - beg
          }

          lemma /*{:_induction this}*/ PrefixSuffixLength()
            requires Valid?
            ensures Length() == PrefixLength() + SuffixLength()
            decreases this
          {
          }

          ghost predicate ValidIndex?(idx: uint32)
            decreases this, idx
          {
            beg as int + idx as int < end as int
          }

          function At(idx: uint32): byte
            requires Valid?
            requires ValidIndex?(idx)
            decreases this, idx
          {
            s[beg + idx]
          }

          ghost predicate ValidSuffixIndex?(idx: uint32)
            decreases this, idx
          {
            point as int + idx as int < end as int
          }

          function SuffixAt(idx: uint32): byte
            requires Valid?
            requires ValidSuffixIndex?(idx)
            decreases this, idx
          {
            s[point + idx]
          }

          function Peek(): (r: opt_byte)
            requires Valid?
            ensures r < 0 <==> EOF?
            decreases this
          {
            if EOF? then
              -1
            else
              SuffixAt(0) as opt_byte
          }

          predicate LookingAt(c: char): (b: bool)
            requires Valid?
            requires c as int < 256
            ensures b <==> !EOF? && SuffixAt(0) == c as byte
            decreases this, c
          {
            Peek() == c as opt_byte
          }

          function Skip(n: uint32): (ps: Cursor)
            requires Valid?
            requires point as int + n as int <= end as int
            ensures n == 0 ==> ps == this
            ensures n > 0 ==> ps.StrictlyAdvancedFrom?(this)
            decreases this, n
          {
            this.(point := point + n)
          }

          function Unskip(n: uint32): Cursor
            requires Valid?
            requires beg as int <= point as int - n as int
            decreases this, n
          {
            this.(point := point - n)
          }

          function Get<R>(err: R): (ppr: CursorResult<R>)
            requires Valid?
            ensures ppr.Success? ==> ppr.value.StrictlyAdvancedFrom?(this)
            decreases this
          {
            if EOF? then
              Failure(OtherError(err))
            else
              Success(Skip(1))
          }

          function AssertByte<R>(b: byte): (pr: CursorResult<R>)
            requires Valid?
            ensures pr.Success? ==> !EOF?
            ensures pr.Success? ==> s[point] == b
            ensures pr.Success? ==> pr.value.StrictlyAdvancedFrom?(this)
            decreases this, b
          {
            var nxt: opt_byte := Peek();
            if nxt == b as opt_byte then
              Success(Skip(1))
            else
              Failure(ExpectingByte(b, nxt))
          }

          function {:tailrecursion} AssertBytes<R>(bs: bytes, offset: uint32 := 0): (pr: CursorResult<R>)
            requires Valid?
            requires |bs| < TWO_TO_THE_32
            requires offset <= |bs| as uint32
            requires forall b: uint8 {:trigger b in bs} | b in bs :: b as int < 256
            ensures pr.Success? ==> pr.value.AdvancedFrom?(this)
            ensures pr.Success? && offset < |bs| as uint32 ==> pr.value.StrictlyAdvancedFrom?(this)
            ensures pr.Success? ==> s[point .. pr.value.point] == bs[offset..]
            decreases SuffixLength()
          {
            if offset == |bs| as uint32 then
              Success(this)
            else
              var ps: Cursor :- AssertByte(bs[offset] as byte); ps.AssertBytes(bs, offset + 1)
          }

          function AssertChar<R>(c0: char): (pr: CursorResult<R>)
            requires Valid?
            requires c0 as int < 256
            ensures pr.Success? ==> pr.value.StrictlyAdvancedFrom?(this)
            decreases this, c0
          {
            AssertByte(c0 as byte)
          }

          function SkipByte(): (ps: Cursor)
            requires Valid?
            ensures ps.AdvancedFrom?(this)
            ensures !EOF? ==> ps.StrictlyAdvancedFrom?(this)
            decreases SuffixLength()
          {
            if EOF? then
              this
            else
              Skip(1)
          }

          function SkipIf(p: byte -> bool): (ps: Cursor)
            requires Valid?
            ensures ps.AdvancedFrom?(this)
            ensures !EOF? && p(SuffixAt(0)) ==> ps.StrictlyAdvancedFrom?(this)
            decreases SuffixLength()
          {
            if EOF? || !p(SuffixAt(0)) then
              this
            else
              Skip(1)
          }

          function SkipWhile(p: byte -> bool): (ps: Cursor)
            requires Valid?
            ensures ps.AdvancedFrom?(this)
            ensures forall idx: uint32 {:trigger ps.s[idx]} | point <= idx < ps.point :: p(ps.s[idx])
            decreases SuffixLength()
          {
            if EOF? || !p(SuffixAt(0)) then
              this
            else
              Skip(1).SkipWhile(p)
          } by method {
            var point' := this.point;
            var end := this.end;
            while point' < end && p(this.s[point'])
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.Valid?
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.SkipWhile(p) == this.SkipWhile(p)
              decreases end as int - point' as int
            {
              point' := point' + 1;
            }
            return Cursor(this.s, this.beg, point', this.end);
          }

          function SkipWhileLexer<A, R>(step: Lexer<A, R>, st: A): (pr: CursorResult<R>)
            requires Valid?
            ensures pr.Success? ==> pr.value.AdvancedFrom?(this)
            decreases SuffixLength()
          {
            match step(st, Peek())
            case Accept() =>
              Success(this)
            case Reject(err) =>
              Failure(OtherError(err))
            case Partial(st) =>
              if EOF? then
                Failure(EOF)
              else
                Skip(1).SkipWhileLexer(step, st)
          } by method {
            var point' := point;
            var end := this.end;
            var st' := st;
            while true
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.Valid?
              invariant var thisAfter: Cursor_ := this.(point := point'); thisAfter.SkipWhileLexer(step, st') == this.SkipWhileLexer(step, st)
              decreases var thisAfter: Cursor_ := this.(point := point'); thisAfter.SuffixLength()
            {
              var eof := point' == end;
              var minusone: opt_byte := -1;
              var c := if eof then minusone else this.s[point'] as opt_byte;
              match step(st', c)
              case {:split false} Accept() =>
                return Success(Cursor(this.s, this.beg, point', this.end));
              case {:split false} Reject(err) =>
                return Failure(OtherError(err));
              case {:split false} Partial(st'') =>
                if eof {
                  return Failure(EOF);
                } else {
                  st' := st'';
                  point' := point' + 1;
                }
            }
          }
        }
      }

      module Lexers {

        module Core {

          import opened Wrappers

          import opened BoundedInts
          datatype LexerResult<+T, +R> = Accept | Reject(err: R) | Partial(st: T)

          type Lexer<!T, +R> = (T, opt_byte) -> LexerResult<T, R>
        }

        module Strings {
          const StringBodyLexerStart: StringBodyLexerState := false

          function StringBody<R>(escaped: StringBodyLexerState, byte: opt_byte): LexerResult<StringBodyLexerState, R>
            decreases escaped, byte
          {
            if byte == '\\' as opt_byte then
              Partial(!escaped)
            else if byte == '\""' as opt_byte && !escaped then
              Accept
            else
              Partial(false)
          }

          const StringLexerStart: StringLexerState := Start

          function String(st: StringLexerState, byte: opt_byte): LexerResult<StringLexerState, string>
            decreases st, byte
          {
            match st
            case Start() =>
              if byte == '\""' as opt_byte then
                Partial(Body(false))
              else
                Reject(""String must start with double quote"")
            case End() =>
              Accept
            case Body(escaped) =>
              if byte == '\\' as opt_byte then
                Partial(Body(!escaped))
              else if byte == '\""' as opt_byte && !escaped then
                Partial(End)
              else
                Partial(Body(false))
          }

          import opened Core

          import opened BoundedInts

          type StringBodyLexerState = bool

          datatype StringLexerState = Start | Body(escaped: bool) | End
        }
      }

      module Parsers {
        opaque function ParserWitness<T, R>(): (p: Parser_<T, R>)
          ensures p.Valid?()
        {
          Parser((_ /* _v9 */: FreshCursor) => Failure(EOF), (_ /* _v10 */: T) => [])
        }

        opaque function SubParserWitness<T, R>(): (subp: SubParser_<T, R>)
          ensures subp.Valid?()
        {
          SubParser(Cursor([], 0, 0, 0), (cs: FreshCursor) => false, (cs: FreshCursor) => Failure(EOF), (_ /* _v11 */: T) => [])
        }

        import opened BoundedInts

        import opened Wrappers

        import opened Core = Views.Core

        import opened Cursors

        type SplitResult<+T, +R> = Result<Split<T>, CursorError<R>>

        type Parser<!T, +R> = p: Parser_<T, R>
          | p.Valid?()
          witness ParserWitness<T, R>()

        datatype Parser_<!T, +R> = Parser(fn: FreshCursor -> SplitResult<T, R>, ghost spec: T -> bytes) {
          ghost predicate Valid?()
            decreases this
          {
            forall cs': FreshCursor {:trigger fn(cs')} :: 
              fn(cs').Success? ==>
                fn(cs').value.StrictlySplitFrom?(cs', spec)
          }
        }

        datatype SubParser_<!T, +R> = SubParser(ghost cs: Cursor, ghost pre: FreshCursor -> bool, fn: FreshCursor --> SplitResult<T, R>, ghost spec: T -> bytes) {
          ghost predicate Valid?()
            decreases this
          {
            (forall cs': FreshCursor {:trigger fn.requires(cs')} {:trigger pre(cs')} | pre(cs') :: 
              fn.requires(cs')) &&
            (forall cs': FreshCursor {:trigger pre(cs')} {:trigger cs'.StrictlySplitFrom?(cs)} | cs'.StrictlySplitFrom?(cs) :: 
              pre(cs')) &&
            forall cs': FreshCursor {:trigger fn(cs')} {:trigger pre(cs')} | pre(cs') :: 
              fn(cs').Success? ==>
                fn(cs').value.StrictlySplitFrom?(cs', spec)
          }
        }

        type SubParser<!T, +R> = p: SubParser_<T, R>
          | p.Valid?()
          witness SubParserWitness<T, R>()
      }

      module Views {

        module Core {
          predicate Adjacent(lv: View, rv: View)
            decreases lv, rv
          {
            lv.end == rv.beg &&
            lv.s == rv.s
          }

          function Merge(lv: View, rv: View): (v: View)
            requires Adjacent(lv, rv)
            ensures v.Bytes() == lv.Bytes() + rv.Bytes()
            decreases lv, rv
          {
            lv.(end := rv.end)
          }

          import opened BoundedInts

          type View = v: View_
            | v.Valid?
            witness View([], 0, 0)

          datatype View_ = View(s: bytes, beg: uint32, end: uint32) {
            ghost const Valid?: bool := 0 <= beg as int <= end as int <= |s| < TWO_TO_THE_32
            static const Empty: View := View([], 0, 0)
            const Empty? := beg == end

            function Length(): uint32
              requires Valid?
              decreases this
            {
              end - beg
            }

            function Bytes(): bytes
              requires Valid?
              decreases this
            {
              s[beg .. end]
            }

            static function OfBytes(bs: bytes): (v: View)
              requires |bs| < TWO_TO_THE_32
              ensures v.Bytes() == bs
              decreases bs
            {
              View(bs, 0 as uint32, |bs| as uint32)
            }

            static function OfString(s: string): bytes
              requires forall c: char {:trigger c in s} | c in s :: c as int < 256
              decreases s
            {
              seq(|s|, (i: int) requires 0 <= i < |s| => assert s[i] in s; s[i] as byte)
            }

            ghost predicate SliceOf?(v': View)
              decreases this, v'
            {
              v'.s == s &&
              v'.beg <= beg &&
              end <= v'.end
            }

            ghost predicate StrictPrefixOf?(v': View)
              decreases this, v'
            {
              v'.s == s &&
              v'.beg == beg &&
              end < v'.end
            }

            ghost predicate StrictSuffixOf?(v': View)
              decreases this, v'
            {
              v'.s == s &&
              v'.beg < beg &&
              end == v'.end
            }

            predicate Byte?(c: byte)
              requires Valid?
              decreases this, c
            {
              Bytes() == [c]
            } by method {
              return Length() == 1 && At(0) == c;
            }

            predicate Char?(c: char)
              requires Valid?
              requires c as int < 256
              decreases this, c
            {
              Byte?(c as byte)
            }

            ghost predicate ValidIndex?(idx: uint32)
              decreases this, idx
            {
              beg as int + idx as int < end as int
            }

            function At(idx: uint32): byte
              requires Valid?
              requires ValidIndex?(idx)
              decreases this, idx
            {
              s[beg + idx]
            }

            function Peek(): (r: opt_byte)
              requires Valid?
              ensures r < 0 <==> Empty?
              decreases this
            {
              if Empty? then
                -1
              else
                At(0) as opt_byte
            }

            method CopyTo(dest: array<byte>, start: uint32 := 0)
              requires Valid?
              requires start as int + Length() as int <= dest.Length
              requires start as int + Length() as int < TWO_TO_THE_32
              modifies dest
              ensures dest[start .. start + Length()] == Bytes()
              ensures dest[start + Length()..] == old(dest[start + Length()..])
              decreases this, dest, start
            {
              for idx: uint32 := 0 to Length()
                invariant dest[start .. start + idx] == Bytes()[..idx]
                invariant dest[start + Length()..] == old(dest[start + Length()..])
              {
                dest[start + idx] := s[beg + idx];
              }
            }
          }
        }

        module Writers {

          import opened BoundedInts

          import opened Wrappers

          import opened Core
          datatype Chain = Empty | Chain(previous: Chain, v: View) {
            function Length(): nat
              decreases this
            {
              if Empty? then
                0
              else
                previous.Length() + v.Length() as int
            }

            function Count(): nat
              decreases this
            {
              if Empty? then
                0
              else
                previous.Count() + 1
            }

            function Bytes(): (bs: bytes)
              ensures |bs| == Length()
              decreases this
            {
              if Empty? then
                []
              else
                previous.Bytes() + v.Bytes()
            }

            function Append(v': View): (c: Chain)
              ensures c.Bytes() == Bytes() + v'.Bytes()
              decreases this, v'
            {
              if Chain? && Adjacent(v, v') then
                Chain(previous, Merge(v, v'))
              else
                Chain(this, v')
            }

            method {:tailrecursion} CopyTo(dest: array<byte>, end: uint32)
              requires end as int == Length() <= dest.Length
              modifies dest
              ensures dest[..end] == Bytes()
              ensures dest[end..] == old(dest[end..])
              decreases this, dest, end
            {
              if Chain? {
                var end := end - v.Length();
                v.CopyTo(dest, end);
                previous.CopyTo(dest, end);
              }
            }
          }

          type Writer = w: Writer_
            | w.Valid?
            witness Writer(0, Chain.Empty)

          datatype Writer_ = Writer(length: uint32, chain: Chain) {
            static const Empty: Writer := Writer(0, Chain.Empty)
            const Empty? := chain.Empty?
            const Unsaturated? := length != UINT32_MAX

            ghost function Length(): nat
              decreases this
            {
              chain.Length()
            }

            ghost const Valid? := length == if chain.Length() >= TWO_TO_THE_32 then UINT32_MAX else chain.Length() as uint32

            function Bytes(): (bs: bytes)
              ensures |bs| == Length()
              decreases this
            {
              chain.Bytes()
            }

            static function SaturatedAddU32(a: uint32, b: uint32): uint32
              decreases a, b
            {
              if a <= UINT32_MAX - b then
                a + b
              else
                UINT32_MAX
            }

            opaque function Append(v': View): (rw: Writer)
              requires Valid?
              ensures rw.Unsaturated? <==> v'.Length() < UINT32_MAX - length
              ensures rw.Bytes() == Bytes() + v'.Bytes()
              decreases this, v'
            {
              Writer(SaturatedAddU32(length, v'.Length()), chain.Append(v'))
            }

            function Then(fn: Writer ~> Writer): Writer
              requires Valid?
              requires fn.requires(this)
              reads fn.reads(this)
              decreases fn.reads(this), this
            {
              fn(this)
            }

            method {:tailrecursion} CopyTo(dest: array<byte>)
              requires Valid?
              requires Unsaturated?
              requires Length() <= dest.Length
              modifies dest
              ensures dest[..length] == Bytes()
              ensures dest[length..] == old(dest[length..])
              decreases this, dest
            {
              chain.CopyTo(dest, length);
            }

            method ToArray() returns (bs: array<byte>)
              requires Valid?
              requires Unsaturated?
              ensures fresh(bs)
              ensures bs[..] == Bytes()
              decreases this
            {
              bs := new byte[length] ((i: nat) => 0);
              CopyTo(bs);
            }
          }
        }
      }
    }

    module ZeroCopy {

      module API {
        opaque function Serialize(js: Grammar.JSON): (bs: SerializationResult<seq<byte>>)
          ensures bs == Success(Spec.JSON(js))
          decreases js
        {
          Success(Serializer.Text(js).Bytes())
        }

        method SerializeAlloc(js: Grammar.JSON) returns (bs: SerializationResult<array<byte>>)
          ensures bs.Success? ==> fresh(bs.value)
          ensures bs.Success? ==> bs.value[..] == Spec.JSON(js)
          decreases js
        {
          bs := Serializer.Serialize(js);
        }

        method SerializeInto(js: Grammar.JSON, bs: array<byte>) returns (len: SerializationResult<uint32>)
          modifies bs
          ensures len.Success? ==> len.value as int <= bs.Length
          ensures len.Success? ==> bs[..len.value] == Spec.JSON(js)
          ensures len.Success? ==> bs[len.value..] == old(bs[len.value..])
          ensures len.Failure? ==> unchanged(bs)
          decreases js, bs
        {
          len := Serializer.SerializeTo(js, bs);
        }

        opaque function Deserialize(bs: seq<byte>): (js: DeserializationResult<Grammar.JSON>)
          ensures js.Success? ==> bs == Spec.JSON(js.value)
          decreases bs
        {
          Deserializer.API.OfBytes(bs)
        }

        import Grammar

        import Spec = ConcreteSyntax.Spec

        import Serializer

        import Deserializer

        import opened BoundedInts

        import opened Wrappers

        import opened Errors
      }

      module Deserializer {

        module Core {
          const SpecView := (v: Vs.View) => Spec.View(v)

          opaque function Get(cs: FreshCursor, err: JSONError): (pr: ParseResult<jchar>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs, err
          {
            var cs: Cursor :- cs.Get(err); Success(cs.Split())
          }

          opaque function WS(cs: FreshCursor): (sp: Split<jblanks>)
            ensures sp.SplitFrom?(cs, SpecView)
            ensures sp.cs.SuffixOf?(cs)
            ensures !cs.BOF? ==> sp.cs.StrictSuffixOf?(cs)
            ensures cs.EOF? ==> sp.cs.SuffixOf?(cs.Suffix())
            decreases cs
          {
            cs.SkipWhile(Blank?).Split()
          } by method {
            reveal WS();
            var point' := cs.point;
            var end := cs.end;
            while point' < end && Blank?(cs.s[point'])
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.Valid?
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.SkipWhile(Blank?) == cs.SkipWhile(Blank?)
              decreases end as int - point' as int
            {
              point' := point' + 1;
            }
            return Cursor(cs.s, cs.beg, point', cs.end).Split();
          }

          opaque function {:vcs_split_on_every_assert} {:rlimit 1000000} Structural<T>(cs: FreshCursor, parser: Parser<T>): (pr: ParseResult<Structural<T>>)
            requires forall cs: FreshCursor {:trigger parser.fn.requires(cs)} :: parser.fn.requires(cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, (st: Structural<T>) => Spec.Structural(st, parser.spec))
            decreases cs, parser
          {
            var SP(before: jblanks, cs: FreshCursor) := WS(cs);
            var SP(val: T, cs: FreshCursor) :- parser.fn(cs); var SP(after: jblanks, cs: FreshCursor) := WS(cs); Success(SP(Grammar.Structural(before, val, after), cs))
          }

          function {:rlimit 100000} TryStructural(cs: FreshCursor): (sp: Split<Structural<jopt>>)
            ensures sp.SplitFrom?(cs, (st: Structural<jopt>) => Spec.Structural(st, SpecView))
            decreases cs
          {
            var SP(before: jblanks, cs: FreshCursor) := WS(cs);
            var SP(val: View, cs: FreshCursor) := cs.SkipByte().Split();
            var SP(after: jblanks, cs: FreshCursor) := WS(cs);
            SP(Grammar.Structural(before, val, after), cs)
          }

          ghost predicate ValueParserValid(sp: SubParser<Value>)
            decreases sp
          {
            forall t: Value {:trigger Spec.Value(t)} {:trigger sp.spec(t)} :: 
              sp.spec(t) == Spec.Value(t)
          }

          import opened BoundedInts

          import opened Wrappers

          import Spec = ConcreteSyntax.Spec

          import Vs = Utils.Views.Core

          import opened Cursors = Utils.Cursors

          import opened Parsers = Utils.Parsers

          import opened Grammar

          import Errors

          import opened Seq = Collections.Seq

          type JSONError = Errors.DeserializationError

          type Error = CursorError<JSONError>

          type ParseResult<+T> = SplitResult<T, JSONError>

          type Parser<!T> = Parsers.Parser<T, JSONError>

          type SubParser<!T> = Parsers.SubParser<T, JSONError>

          type jopt = v: Vs.View
            | v.Length() <= 1
            witness Vs.View.OfBytes([])

          type ValueParser = sp: SubParser<Value>
            | ValueParserValid(sp)
            witness *
        }
        type Error = Core.Error

        abstract module SequenceParams {
          const OPEN: byte
          const CLOSE: byte

          ghost function ElementSpec(t: TElement): bytes

          function Element(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TElement>)
            requires cs.StrictlySplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs.Length()

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core

          type TElement
        }

        abstract module Sequences {
          const SEPARATOR: byte := ',' as byte
          const SpecViewClose: jclose -> bytes := SpecView
          const SpecViewOpen: jopen -> bytes := SpecView

          ghost function SuffixedElementSpec(e: TSuffixedElement): bytes
            decreases e
          {
            ElementSpec(e.t) + Spec.CommaSuffix(e.suffix)
          }

          ghost function BracketedSpec(ts: TBracketed): bytes
            decreases ts
          {
            Spec.Bracketed(ts, SuffixedElementSpec)
          }

          ghost function SuffixedElementsSpec(ts: seq<TSuffixedElement>): bytes
            decreases ts
          {
            Spec.ConcatBytes(ts, SuffixedElementSpec)
          }

          opaque function Open(cs: FreshCursor): (pr: ParseResult<jopen>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewOpen)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(OPEN); Success(cs.Split())
          }

          opaque function Close(cs: FreshCursor): (pr: ParseResult<jclose>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewClose)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(CLOSE); Success(cs.Split())
          }

          opaque function BracketedFromParts(ghost cs: Cursor, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>, close: Split<Structural<jclose>>): (sp: Split<TBracketed>)
            requires Grammar.NoTrailingSuffix(elems.t)
            requires open.StrictlySplitFrom?(cs, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires close.StrictlySplitFrom?(elems.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            ensures sp.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, open, elems, close
          {
            var sp: Split<Bracketed<jopen, TElement, jcomma, jclose>> := SP(Grammar.Bracketed(open.t, elems.t, close.t), close.cs);
            calc {
              cs.Bytes();
              Spec.Structural(open.t, SpecView) + open.cs.Bytes();
              {
                assert open.cs.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + (SuffixedElementsSpec(elems.t) + elems.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView), SuffixedElementsSpec(elems.t), elems.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              {
                assert elems.cs.Bytes() == Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + (Spec.Structural(close.t, SpecView) + close.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t), Spec.Structural(close.t, SpecView), close.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              Spec.Bracketed(sp.t, SuffixedElementSpec) + close.cs.Bytes();
            }
            assert sp.StrictlySplitFrom?(cs, BracketedSpec);
            sp
          }

          opaque function AppendWithSuffix(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jcomma>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty?
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures elems'.SplitFrom?(cs0, SuffixedElementsSpec)
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, NonEmpty(sep.t));
            var elems': Split<seq<Suffixed<TElement, jcomma>>> := SP(elems.t + [suffixed], sep.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
              assert {:focus} cs0.Bytes() == SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() by {
                assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes() by {
                  assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
                  assert elems.cs.Bytes() == ElementSpec(suffixed.t) + elem.cs.Bytes();
                  assert elem.cs.Bytes() == Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes();
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), elem.cs.Bytes());
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix), sep.cs.Bytes());
                }
                Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix));
              }
              assert SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty? by {
              assert elems'.t == elems.t + [suffixed];
            }
            assert {:split_here} elems'.cs.Length() < elems.cs.Length();
            assert elems'.SplitFrom?(cs0, SuffixedElementsSpec) by {
              assert elems'.BytesSplitFrom?(cs0, SuffixedElementsSpec) by {
                assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
              }
              assert elems'.cs.SplitFrom?(cs0) by {
                assert elems'.cs.StrictlySplitFrom?(cs0) by {
                  assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
                }
              }
            }
            elems'
          }

          opaque function {:rlimit 10000} {:vcs_split_on_every_assert} AppendLast(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jclose>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures NoTrailingSuffix(elems'.t)
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures sep.StrictlySplitFrom?(elems'.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, Empty());
            var elems': Split<seq<Suffixed<TElement, jcomma>>> := SP(elems.t + [suffixed], elem.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
              assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() by {
                assert elem.t == suffixed.t;
              }
              assert SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            elems'
          }

          lemma {:rlimit 10000} AboutTryStructural(cs: FreshCursor)
            ensures ghost var sp: Split<Structural<jopt>> := Core.TryStructural(cs); ghost var s0: opt_byte := sp.t.t.Peek(); ((!cs.BOF? || !cs.EOF?) && s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.SplitFrom?(cs, (st: Structural<jcomma>) => Spec.Structural(st, SpecView))) && ((!cs.BOF? || !cs.EOF?) && s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.SplitFrom?(cs, (st: Structural<jclose>) => Spec.Structural(st, SpecView)))
            decreases cs
          {
          }

          lemma {:vcs_split_on_every_assert} AboutLists<T>(xs: seq<T>, i: uint32)
            requires 0 <= i as int < |xs|
            ensures xs[i as int .. i as int + 1] == [xs[i as int]]
            decreases xs, i
          {
          }

          opaque function {:vcs_split_on_every_assert} {:tailrecursion} Elements(ghost cs0: FreshCursor, json: ValueParser, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>): (pr: ParseResult<TBracketed>)
            requires open.StrictlySplitFrom?(cs0, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs0, BracketedSpec)
            decreases elems.cs.Length()
          {
            var elem: Split<TElement> :- Element(elems.cs, json); if elem.cs.EOF? then Failure(EOF) else AboutTryStructural(elem.cs); var sep: Split<Structural<jopt>> := Core.TryStructural(elem.cs); var s0: opt_byte := sep.t.t.Peek(); if s0 == SEPARATOR as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Char?(',') by {
    calc {
      sep.t.t.Char?(',');
      sep.t.t.Byte?(',' as byte);
      sep.t.t.Byte?(SEPARATOR);
      sep.t.t.Bytes() == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [SEPARATOR];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [SEPARATOR];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == SEPARATOR as opt_byte;
      sep.t.t.At(0) as opt_byte == SEPARATOR as opt_byte;
      s0 == SEPARATOR as opt_byte;
      true;
    }
  } var sep: Split<Structural<jcomma>> := sep; assert AppendWithSuffix.requires(open.cs, json, elems, elem, sep) by {
    assert {:focus} elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
    assert {:split_here} true;
  } var elems: Split<seq<TSuffixedElement>> := AppendWithSuffix(open.cs, json, elems, elem, sep); Elements(cs0, json, open, elems) else if s0 == CLOSE as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Byte?(CLOSE) by {
    calc {
      sep.t.t.Byte?(CLOSE);
      sep.t.t.Bytes() == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [CLOSE];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [CLOSE];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == CLOSE as opt_byte;
      sep.t.t.At(0) as opt_byte == CLOSE as opt_byte;
      s0 == CLOSE as opt_byte;
      true;
    }
  } var sep: Split<Structural<jclose>> := sep; assert AppendLast.requires(open.cs, json, elems, elem, sep) by {
    assert elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
  } var elems': Split<seq<TSuffixedElement>> := AppendLast(open.cs, json, elems, elem, sep); assert elems'.SplitFrom?(open.cs, SuffixedElementsSpec) by {
    assert elems'.StrictlySplitFrom?(open.cs, SuffixedElementsSpec);
  } var bracketed: Split<TBracketed> := BracketedFromParts(cs0, open, elems', sep); assert bracketed.StrictlySplitFrom?(cs0, BracketedSpec); Success(bracketed) else var separator: byte := SEPARATOR; var pr: Result<Split<Bracketed<jopen, TElement, jcomma, jclose>>, CursorError<Errors.DeserializationError>> := Failure(ExpectingAnyByte([CLOSE, separator], s0)); pr
          }

          lemma AboutCloseParser()
            ensures Parsers.Parser(Close, SpecViewClose).Valid?()
          {
            assert Parsers.Parser(Close, SpecViewClose).Valid?() by {
              forall cs': FreshCursor | true
                ensures Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose)
              {
                if Close(cs').Success? {
                  assert Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose) by {
                    assert Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose);
                  }
                }
              }
            }
          }

          opaque function {:vcs_split_on_every_assert} Bracketed(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TBracketed>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, json
          {
            var open: Split<Structural<jopen>> :- Core.Structural<jopen>(cs, Parsers.Parser(Open, SpecViewOpen)); assert open.cs.StrictlySplitFrom?(json.cs); var elems: Split<seq<Suffixed<TElement, jcomma>>> := SP([], open.cs); if open.cs.Peek() == CLOSE as opt_byte then var p: Parser_<jclose, JSONError> := Parsers.Parser(Close, SpecViewClose); assert p.Valid?() by {
    AboutCloseParser();
  } var close: Split<Structural<jclose>> :- Core.Structural<jclose>(open.cs, p); Success(BracketedFromParts(cs, open, elems, close)) else Elements(cs, json, open, elems)
          }

          lemma Valid(x: TBracketed)
            ensures x.l.t.Byte?(OPEN)
            ensures x.r.t.Byte?(CLOSE)
            ensures NoTrailingSuffix(x.data)
            ensures forall pf: Suffixed<TElement, jcomma> {:trigger pf.suffix} {:trigger pf in x.data} | pf in x.data :: pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            decreases x
          {
            ghost var xlt: jopen := x.l.t;
            ghost var xrt: jclose := x.r.t;
            forall pf: Suffixed<TElement, jcomma> | pf in x.data
              ensures pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            {
              if pf.suffix.NonEmpty? {
                ghost var xtt := pf.suffix.t.t;
              }
            }
          }

          import opened Wrappers

          import opened BoundedInts

          import opened Params : SequenceParams

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import Parsers = Utils.Parsers

          import opened Core

          type jopen = v: Vs.View
            | v.Byte?(OPEN)
            witness Vs.View.OfBytes([OPEN])

          type jclose = v: Vs.View
            | v.Byte?(CLOSE)
            witness Vs.View.OfBytes([CLOSE])

          type TBracketed = Bracketed<jopen, TElement, jcomma, jclose>

          type TSuffixedElement = Suffixed<TElement, jcomma>
        }

        module API {
          function LiftCursorError(err: Cursors.CursorError<DeserializationError>): DeserializationError
            decreases err
          {
            match err
            case EOF() =>
              ReachedEOF
            case ExpectingByte(expected, b) =>
              ExpectingByte(expected, b)
            case ExpectingAnyByte(expected_sq, b) =>
              ExpectingAnyByte(expected_sq, b)
            case OtherError(err) =>
              err
          }

          opaque function {:vcs_split_on_every_assert} {:rlimit 10000} JSON(cs: Cursors.FreshCursor): (pr: DeserializationResult<Cursors.Split<JSON>>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.JSON)
            decreases cs
          {
            Core.Structural(cs, Parsers.Parser(Values.Value, Spec.Value)).MapFailure(LiftCursorError)
          }

          opaque function Text(v: View): (jsr: DeserializationResult<JSON>)
            ensures jsr.Success? ==> v.Bytes() == Spec.JSON(jsr.value)
            decreases v
          {
            var SP(text: JSON, cs: FreshCursor) :- JSON(Cursors.Cursor.OfView(v)); assert Cursors.SP(text, cs).BytesSplitFrom?(Cursors.Cursor.OfView(v), Spec.JSON); assert v.Bytes() == Spec.JSON(text) + cs.Bytes(); :- Need(cs.EOF?, Errors.ExpectingEOF); assert cs.Bytes() == []; Success(text)
          }

          opaque function OfBytes(bs: bytes): (jsr: DeserializationResult<JSON>)
            ensures jsr.Success? ==> bs == Spec.JSON(jsr.value)
            decreases bs
          {
            :- Need(|bs| < TWO_TO_THE_32, Errors.IntOverflow); Text(Vs.View.OfBytes(bs))
          }

          import opened BoundedInts

          import opened Wrappers

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Core

          import opened Errors

          import Cursors = Utils.Cursors

          import Values
        }

        module Values {
          opaque function {:vcs_split_on_every_assert} Value(cs: FreshCursor): (pr: ParseResult<Value>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Value)
            decreases cs.Length(), 1
          {
            var c: opt_byte := cs.Peek();
            if c == '{' as opt_byte then
              var SP(obj: jobject, cs': FreshCursor) :- Objects.Object(cs, ValueParser(cs)); var v: Value := Grammar.Object(obj); var sp: Split<Value> := SP(v, cs'); assert sp.StrictlySplitFrom?(cs, Spec.Value) by {
    Spec.UnfoldValueObject(v);
    assert SP(obj, cs').StrictlySplitFrom?(cs, Spec.Object);
  } Spec.UnfoldValueObject(v); assert sp.StrictlySplitFrom?(cs, Spec.Value); Success(sp)
            else if c == '[' as opt_byte then
              var SP(arr: jarray, cs': FreshCursor) :- Arrays.Array(cs, ValueParser(cs)); var v: Value := Grammar.Array(arr); var sp: Split<Value> := SP(v, cs'); assert sp.StrictlySplitFrom?(cs, Spec.Value) by {
    assert SP(arr, cs').StrictlySplitFrom?(cs, Spec.Array);
    Spec.UnfoldValueArray(v);
  } assert sp.StrictlySplitFrom?(cs, Spec.Value); Success(sp)
            else if c == '\""' as opt_byte then
              var SP(str: jstring, cs': FreshCursor) :- Strings.String(cs); assert SP(Grammar.String(str), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    calc {
      SP(Grammar.String(str), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.String(str), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.String(str)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.String(str) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(str, cs').BytesSplitFrom?(cs, Spec.String);
      SP(str, cs').StrictlySplitFrom?(cs, Spec.String);
      true;
    }
  } Success(SP(Grammar.String(str), cs'))
            else if c == 't' as opt_byte then
              var SP(cst: Vs.View, cs': FreshCursor) :- Constants.Constant(cs, TRUE); assert SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    ghost var f := (_ /* _v12 */: Value) => TRUE;
    calc {
      SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.View(cst) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == cst.Bytes() + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == TRUE + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == f(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      {
        assert cs'.StrictlySplitFrom?(cs) <==> cs'.SplitFrom?(cs) by {
          assert cs' != cs;
        }
      }
      cs'.SplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      SP(Grammar.Bool(cst), cs').SplitFrom?(cs, f);
      true;
    }
  } Success(SP(Grammar.Bool(cst), cs'))
            else if c == 'f' as opt_byte then
              var SP(cst: Vs.View, cs': FreshCursor) :- Constants.Constant(cs, FALSE); assert SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    ghost var f := (_ /* _v13 */: Value) => FALSE;
    calc {
      SP(Grammar.Bool(cst), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.View(cst) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == cst.Bytes() + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == FALSE + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == f(Grammar.Bool(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      {
        assert cs'.StrictlySplitFrom?(cs) <==> cs'.SplitFrom?(cs) by {
          assert cs' != cs;
        }
      }
      cs'.SplitFrom?(cs) &&
      SP(Grammar.Bool(cst), cs').BytesSplitFrom?(cs, f);
      SP(Grammar.Bool(cst), cs').SplitFrom?(cs, f);
      true;
    }
  } Success(SP(Grammar.Bool(cst), cs'))
            else if c == 'n' as opt_byte then
              var SP(cst: Vs.View, cs': FreshCursor) :- Constants.Constant(cs, NULL); assert SP(Grammar.Null(cst), cs').StrictlySplitFrom?(cs, Spec.Value) by {
    ghost var f := (_ /* _v14 */: Value) => NULL;
    calc {
      SP(Grammar.Null(cst), cs').StrictlySplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Null(cst), cs').BytesSplitFrom?(cs, Spec.Value);
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.Value(Grammar.Null(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == Spec.View(cst) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == cst.Bytes() + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == NULL + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      cs.Bytes() == f(Grammar.Null(cst)) + cs'.Bytes();
      cs'.StrictlySplitFrom?(cs) &&
      SP(Grammar.Null(cst), cs').BytesSplitFrom?(cs, f);
      {
        assert cs'.StrictlySplitFrom?(cs) <==> cs'.SplitFrom?(cs) by {
          assert cs' != cs;
        }
      }
      cs'.SplitFrom?(cs) &&
      SP(Grammar.Null(cst), cs').BytesSplitFrom?(cs, f);
      SP(Grammar.Null(cst), cs').SplitFrom?(cs, f);
      true;
    }
  } Success(SP(Grammar.Null(cst), cs'))
            else
              var SP(num: jnumber, cs': FreshCursor) :- Numbers.Number(cs); var v: Value := Grammar.Number(num); var sp: Split<Value> := SP(v, cs'); assert sp.StrictlySplitFrom?(cs, Spec.Value) by {
    assert SP(num, cs').StrictlySplitFrom?(cs, Spec.Number);
    Spec.UnfoldValueNumber(v);
  } assert sp.StrictlySplitFrom?(cs, Spec.Value); Success(sp)
          }

          opaque function ValueParser(cs: FreshCursor): (p: ValueParser)
            ensures cs.SplitFrom?(p.cs)
            decreases cs.Length(), 0
          {
            var pre: FreshCursor -> bool := (ps': FreshCursor) => ps'.Length() < cs.Length();
            var fn: FreshCursor --> ParseResult<Value> := (ps': FreshCursor) requires pre(ps') => Value(ps');
            Parsers.SubParser(cs, pre, fn, Spec.Value)
          }

          import Strings

          import Numbers

          import Objects

          import Arrays

          import Constants

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened BoundedInts

          import opened Wrappers

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module Constants {
          opaque function Constant(cs: FreshCursor, expected: bytes): (pr: ParseResult<Vs.View>)
            requires |expected| < TWO_TO_THE_32
            ensures pr.Success? ==> pr.value.t.Bytes() == expected
            ensures pr.Success? ==> pr.value.SplitFrom?(cs, (_ /* _v15 */: View_) => expected)
            decreases cs, expected
          {
            var cs: Cursor :- cs.AssertBytes(expected); Success(cs.Split())
          }

          import opened BoundedInts

          import opened Wrappers

          import opened Grammar

          import opened Core

          import opened Cursors = Utils.Cursors
        }

        module Strings {
          opaque function StringBody(cs: Cursor): (pr: CursorResult<JSONError>)
            ensures pr.Success? ==> pr.value.AdvancedFrom?(cs)
            decreases cs
          {
            cs.SkipWhileLexer(Strings.StringBody, StringBodyLexerStart)
          } by method {
            reveal StringBody();
            var escaped := false;
            for point': uint32 := cs.point to cs.end
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.Valid?
              invariant var csAfter: Cursor_ := cs.(point := point'); csAfter.SkipWhileLexer(Strings.StringBody, escaped) == StringBody(cs)
            {
              var byte := cs.s[point'];
              if byte == '\""' as byte && !escaped {
                return Success(Cursor(cs.s, cs.beg, point', cs.end));
              } else if byte == '\\' as byte {
                escaped := !escaped;
              } else {
                escaped := false;
              }
            }
            return Failure(EOF);
          }

          function Quote(cs: FreshCursor): (pr: ParseResult<jquote>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var cs: Cursor :- cs.AssertChar('\""'); Success(cs.Split())
          }

          opaque function {:rlimit 10000} String(cs: FreshCursor): (pr: ParseResult<jstring>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.String)
            decreases cs
          {
            var SP(lq: jquote, cs: FreshCursor) :- Quote(cs); var contents: Cursor :- StringBody(cs); var SP(contents: View, cs: FreshCursor) := contents.Split(); var SP(rq: jquote, cs: FreshCursor) :- Quote(cs); Success(SP(Grammar.JString(lq, contents, rq), cs))
          }

          import opened Wrappers

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened LC = Utils.Lexers.Core

          import opened Strings = Utils.Lexers.Strings

          import opened Parsers = Utils.Parsers

          import opened Core
        }

        module Numbers {
          opaque function Digits(cs: FreshCursor): (sp: Split<jdigits>)
            ensures sp.SplitFrom?(cs, SpecView)
            decreases cs
          {
            cs.SkipWhile(Digit?).Split()
          }

          opaque function NonEmptyDigits(cs: FreshCursor): (pr: ParseResult<jnum>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var sp: Split<jdigits> := Digits(cs);
            if sp.t.Empty? then
              Failure(OtherError(Errors.EmptyNumber))
            else
              Success(sp)
          }

          opaque function NonZeroInt(cs: FreshCursor): (pr: ParseResult<jint>)
            requires cs.Peek() != '0' as opt_byte
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            NonEmptyDigits(cs)
          }

          opaque function OptionalMinus(cs: FreshCursor): (sp: Split<jminus>)
            ensures sp.SplitFrom?(cs, SpecView)
            decreases cs
          {
            cs.SkipIf((c: uint8) => c == '-' as byte).Split()
          }

          opaque function OptionalSign(cs: FreshCursor): (sp: Split<jsign>)
            ensures sp.SplitFrom?(cs, SpecView)
            decreases cs
          {
            cs.SkipIf((c: uint8) => c == '-' as byte || c == '+' as byte).Split()
          }

          opaque function TrimmedInt(cs: FreshCursor): (pr: ParseResult<jint>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var sp: Split<View> := cs.SkipIf((c: uint8) => c == '0' as byte).Split();
            if sp.t.Empty? then
              NonZeroInt(sp.cs)
            else
              Success(sp)
          }

          opaque function {:vcs_split_on_every_assert} {:rlimit 100000} Exp(cs: FreshCursor): (pr: ParseResult<Maybe<jexp>>)
            ensures pr.Success? ==> pr.value.SplitFrom?(cs, (exp: Maybe<jexp>) => Spec.Maybe(exp, Spec.Exp))
            decreases cs
          {
            var SP(e: View, cs: FreshCursor) := cs.SkipIf((c: uint8) => c == 'e' as byte || c == 'E' as byte).Split();
            if e.Empty? then
              Success(SP(Empty(), cs))
            else
              assert e.Char?('e') || e.Char?('E'); var SP(sign: jsign, cs: FreshCursor) := OptionalSign(cs); var SP(num: jnum, cs: FreshCursor) :- NonEmptyDigits(cs); Success(SP(NonEmpty(JExp(e, sign, num)), cs))
          }

          opaque function Frac(cs: FreshCursor): (pr: ParseResult<Maybe<jfrac>>)
            ensures pr.Success? ==> pr.value.SplitFrom?(cs, (frac: Maybe<jfrac>) => Spec.Maybe(frac, Spec.Frac))
            decreases cs
          {
            var SP(period: View, cs: FreshCursor) := cs.SkipIf((c: uint8) => c == '.' as byte).Split();
            if period.Empty? then
              Success(SP(Empty(), cs))
            else
              var SP(num: jnum, cs: FreshCursor) :- NonEmptyDigits(cs); Success(SP(NonEmpty(JFrac(period, num)), cs))
          }

          opaque function NumberFromParts(ghost cs: Cursor, minus: Split<jminus>, num: Split<jint>, frac: Split<Maybe<jfrac>>, exp: Split<Maybe<jexp>>): (sp: Split<jnumber>)
            requires minus.SplitFrom?(cs, SpecView)
            requires num.StrictlySplitFrom?(minus.cs, SpecView)
            requires frac.SplitFrom?(num.cs, (frac: Maybe<jfrac>) => Spec.Maybe(frac, Spec.Frac))
            requires exp.SplitFrom?(frac.cs, (exp: Maybe<jexp>) => Spec.Maybe(exp, Spec.Exp))
            ensures sp.StrictlySplitFrom?(cs, Spec.Number)
            decreases cs, minus, num, frac, exp
          {
            var sp: Split<jnumber> := SP(Grammar.JNumber(minus.t, num.t, frac.t, exp.t), exp.cs);
            assert cs.Bytes() == Spec.Number(sp.t) + exp.cs.Bytes() by {
              assert cs.Bytes() == Spec.View(minus.t) + Spec.View(num.t) + Spec.Maybe(frac.t, Spec.Frac) + Spec.Maybe(exp.t, Spec.Exp) + exp.cs.Bytes() by {
                assert cs.Bytes() == Spec.View(minus.t) + minus.cs.Bytes();
                assert minus.cs.Bytes() == Spec.View(num.t) + num.cs.Bytes();
                assert num.cs.Bytes() == Spec.Maybe(frac.t, Spec.Frac) + frac.cs.Bytes();
                assert frac.cs.Bytes() == Spec.Maybe(exp.t, Spec.Exp) + exp.cs.Bytes();
                Seq.LemmaConcatIsAssociative(Spec.View(minus.t), Spec.View(num.t), num.cs.Bytes());
                Seq.LemmaConcatIsAssociative(Spec.View(minus.t) + Spec.View(num.t), Spec.Maybe(frac.t, Spec.Frac), frac.cs.Bytes());
                Seq.LemmaConcatIsAssociative(Spec.View(minus.t) + Spec.View(num.t) + Spec.Maybe(frac.t, Spec.Frac), Spec.Maybe(exp.t, Spec.Exp), exp.cs.Bytes());
              }
            }
            assert sp.StrictlySplitFrom?(cs, Spec.Number);
            sp
          }

          opaque function Number(cs: FreshCursor): (pr: ParseResult<jnumber>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Number)
            decreases cs
          {
            var minus: Split<jminus> := OptionalMinus(cs);
            var num: Split<jint> :- TrimmedInt(minus.cs); var frac: Split<Maybe<jfrac>> :- Frac(num.cs); var exp: Split<Maybe<jexp>> :- Exp(frac.cs); Success(NumberFromParts(cs, minus, num, frac, exp))
          }

          import opened BoundedInts

          import opened Wrappers

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module ArrayParams refines SequenceParams {
          const OPEN: byte := '[' as byte
          const CLOSE: byte := ']' as byte

          function ElementSpec(t: TElement): bytes
            decreases t
          {
            Spec.Value(t)
          }

          function Element(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TElement>)
            requires cs.StrictlySplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs.Length()
          {
            json.fn(cs)
          }

          import opened Strings

          import opened Wrappers

          type TElement = Value

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module Arrays refines Sequences {
          lemma {:vcs_split_on_every_assert} /*{:_induction arr}*/ BracketedToArray(arr: jarray)
            ensures Spec.Bracketed(arr, SuffixedElementSpec) == Spec.Array(arr)
            decreases arr
          {
            ghost var rItem := (d: jitem) requires d < arr => Spec.Item(d);
            assert Spec.Bracketed(arr, SuffixedElementSpec) == Spec.Bracketed(arr, rItem) by {
              assert SpecProperties.Bracketed_Morphism_Requires(arr, SuffixedElementSpec, rItem);
              SpecProperties.Bracketed_Morphism(arr, SuffixedElementSpec, rItem);
            }
            calc {
              Spec.Bracketed(arr, SuffixedElementSpec);
              Spec.Bracketed(arr, rItem);
              Spec.Array(arr);
            }
          }

          opaque function {:vcs_split_on_every_assert} Array(cs: FreshCursor, json: ValueParser): (pr: ParseResult<jarray>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Array)
            decreases cs, json
          {
            var sp: Split<TBracketed> :- Bracketed(cs, json); assert sp.StrictlySplitFrom?(cs, BracketedSpec); BracketedToArray(sp.t); Success(sp)
          }

          const SEPARATOR: byte := ',' as byte
          const SpecViewClose: jclose -> bytes := SpecView
          const SpecViewOpen: jopen -> bytes := SpecView

          ghost function SuffixedElementSpec(e: TSuffixedElement): bytes
            decreases e
          {
            ElementSpec(e.t) + Spec.CommaSuffix(e.suffix)
          }

          ghost function BracketedSpec(ts: TBracketed): bytes
            decreases ts
          {
            Spec.Bracketed(ts, SuffixedElementSpec)
          }

          ghost function SuffixedElementsSpec(ts: seq<TSuffixedElement>): bytes
            decreases ts
          {
            Spec.ConcatBytes(ts, SuffixedElementSpec)
          }

          opaque function Open(cs: FreshCursor): (pr: ParseResult<jopen>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewOpen)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(OPEN); Success(cs.Split())
          }

          opaque function Close(cs: FreshCursor): (pr: ParseResult<jclose>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewClose)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(CLOSE); Success(cs.Split())
          }

          opaque function BracketedFromParts(ghost cs: Cursor, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>, close: Split<Structural<jclose>>): (sp: Split<TBracketed>)
            requires Grammar.NoTrailingSuffix(elems.t)
            requires open.StrictlySplitFrom?(cs, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires close.StrictlySplitFrom?(elems.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            ensures sp.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, open, elems, close
          {
            var sp: Split<Bracketed<jopen, TElement, jcomma, jclose>> := SP(Grammar.Bracketed(open.t, elems.t, close.t), close.cs);
            calc {
              cs.Bytes();
              Spec.Structural(open.t, SpecView) + open.cs.Bytes();
              {
                assert open.cs.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + (SuffixedElementsSpec(elems.t) + elems.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView), SuffixedElementsSpec(elems.t), elems.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              {
                assert elems.cs.Bytes() == Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + (Spec.Structural(close.t, SpecView) + close.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t), Spec.Structural(close.t, SpecView), close.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              Spec.Bracketed(sp.t, SuffixedElementSpec) + close.cs.Bytes();
            }
            assert sp.StrictlySplitFrom?(cs, BracketedSpec);
            sp
          }

          opaque function AppendWithSuffix(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jcomma>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty?
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures elems'.SplitFrom?(cs0, SuffixedElementsSpec)
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, NonEmpty(sep.t));
            var elems': Split<seq<Suffixed<Value, jcomma>>> := SP(elems.t + [suffixed], sep.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
              assert {:focus} cs0.Bytes() == SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() by {
                assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes() by {
                  assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
                  assert elems.cs.Bytes() == ElementSpec(suffixed.t) + elem.cs.Bytes();
                  assert elem.cs.Bytes() == Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes();
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), elem.cs.Bytes());
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix), sep.cs.Bytes());
                }
                Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix));
              }
              assert SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            assert forall e: Suffixed<Value, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty? by {
              assert elems'.t == elems.t + [suffixed];
            }
            assert {:split_here} elems'.cs.Length() < elems.cs.Length();
            assert elems'.SplitFrom?(cs0, SuffixedElementsSpec) by {
              assert elems'.BytesSplitFrom?(cs0, SuffixedElementsSpec) by {
                assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
              }
              assert elems'.cs.SplitFrom?(cs0) by {
                assert elems'.cs.StrictlySplitFrom?(cs0) by {
                  assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
                }
              }
            }
            elems'
          }

          opaque function {:rlimit 10000} {:vcs_split_on_every_assert} AppendLast(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jclose>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures NoTrailingSuffix(elems'.t)
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures sep.StrictlySplitFrom?(elems'.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, Empty());
            var elems': Split<seq<Suffixed<Value, jcomma>>> := SP(elems.t + [suffixed], elem.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
              assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() by {
                assert elem.t == suffixed.t;
              }
              assert SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            elems'
          }

          lemma {:rlimit 10000} AboutTryStructural(cs: FreshCursor)
            ensures ghost var sp: Split<Structural<jopt>> := Core.TryStructural(cs); ghost var s0: opt_byte := sp.t.t.Peek(); ((!cs.BOF? || !cs.EOF?) && s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.SplitFrom?(cs, (st: Structural<jcomma>) => Spec.Structural(st, SpecView))) && ((!cs.BOF? || !cs.EOF?) && s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.SplitFrom?(cs, (st: Structural<jclose>) => Spec.Structural(st, SpecView)))
            decreases cs
          {
          }

          lemma {:vcs_split_on_every_assert} AboutLists<T>(xs: seq<T>, i: uint32)
            requires 0 <= i as int < |xs|
            ensures xs[i as int .. i as int + 1] == [xs[i as int]]
            decreases xs, i
          {
          }

          opaque function {:vcs_split_on_every_assert} {:tailrecursion} Elements(ghost cs0: FreshCursor, json: ValueParser, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>): (pr: ParseResult<TBracketed>)
            requires open.StrictlySplitFrom?(cs0, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs0, BracketedSpec)
            decreases elems.cs.Length()
          {
            var elem: Split<TElement> :- Element(elems.cs, json); if elem.cs.EOF? then Failure(EOF) else AboutTryStructural(elem.cs); var sep: Split<Structural<jopt>> := Core.TryStructural(elem.cs); var s0: opt_byte := sep.t.t.Peek(); if s0 == SEPARATOR as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Char?(',') by {
    calc {
      sep.t.t.Char?(',');
      sep.t.t.Byte?(',' as byte);
      sep.t.t.Byte?(SEPARATOR);
      sep.t.t.Bytes() == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [SEPARATOR];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [SEPARATOR];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == SEPARATOR as opt_byte;
      sep.t.t.At(0) as opt_byte == SEPARATOR as opt_byte;
      s0 == SEPARATOR as opt_byte;
      true;
    }
  } var sep: Split<Structural<jcomma>> := sep; assert AppendWithSuffix.requires(open.cs, json, elems, elem, sep) by {
    assert {:focus} elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
    assert {:split_here} true;
  } var elems: Split<seq<TSuffixedElement>> := AppendWithSuffix(open.cs, json, elems, elem, sep); Elements(cs0, json, open, elems) else if s0 == CLOSE as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Byte?(CLOSE) by {
    calc {
      sep.t.t.Byte?(CLOSE);
      sep.t.t.Bytes() == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [CLOSE];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [CLOSE];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == CLOSE as opt_byte;
      sep.t.t.At(0) as opt_byte == CLOSE as opt_byte;
      s0 == CLOSE as opt_byte;
      true;
    }
  } var sep: Split<Structural<jclose>> := sep; assert AppendLast.requires(open.cs, json, elems, elem, sep) by {
    assert elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
  } var elems': Split<seq<TSuffixedElement>> := AppendLast(open.cs, json, elems, elem, sep); assert elems'.SplitFrom?(open.cs, SuffixedElementsSpec) by {
    assert elems'.StrictlySplitFrom?(open.cs, SuffixedElementsSpec);
  } var bracketed: Split<TBracketed> := BracketedFromParts(cs0, open, elems', sep); assert bracketed.StrictlySplitFrom?(cs0, BracketedSpec); Success(bracketed) else var separator: byte := SEPARATOR; var pr: Result<Split<Bracketed<jopen, Value, jcomma, jclose>>, CursorError<Errors.DeserializationError>> := Failure(ExpectingAnyByte([CLOSE, separator], s0)); pr
          }

          lemma AboutCloseParser()
            ensures Parsers.Parser(Close, SpecViewClose).Valid?()
          {
            assert Parsers.Parser(Close, SpecViewClose).Valid?() by {
              forall cs': FreshCursor | true
                ensures Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose)
              {
                if Close(cs').Success? {
                  assert Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose) by {
                    assert Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose);
                  }
                }
              }
            }
          }

          opaque function {:vcs_split_on_every_assert} Bracketed(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TBracketed>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, json
          {
            var open: Split<Structural<jopen>> :- Core.Structural<jopen>(cs, Parsers.Parser(Open, SpecViewOpen)); assert open.cs.StrictlySplitFrom?(json.cs); var elems: Split<seq<Suffixed<Value, jcomma>>> := SP([], open.cs); if open.cs.Peek() == CLOSE as opt_byte then var p: Parser_<jclose, JSONError> := Parsers.Parser(Close, SpecViewClose); assert p.Valid?() by {
    AboutCloseParser();
  } var close: Split<Structural<jclose>> :- Core.Structural<jclose>(open.cs, p); Success(BracketedFromParts(cs, open, elems, close)) else Elements(cs, json, open, elems)
          }

          lemma Valid(x: TBracketed)
            ensures x.l.t.Byte?(OPEN)
            ensures x.r.t.Byte?(CLOSE)
            ensures NoTrailingSuffix(x.data)
            ensures forall pf: Suffixed<TElement, jcomma> {:trigger pf.suffix} {:trigger pf in x.data} | pf in x.data :: pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            decreases x
          {
            ghost var xlt: jopen := x.l.t;
            ghost var xrt: jclose := x.r.t;
            forall pf: Suffixed<TElement, jcomma> | pf in x.data
              ensures pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            {
              if pf.suffix.NonEmpty? {
                ghost var xtt := pf.suffix.t.t;
              }
            }
          }

          import opened Params = ArrayParams

          import opened Wrappers

          import opened BoundedInts

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import Parsers = Utils.Parsers

          import opened Core

          type jopen = v: Vs.View
            | v.Byte?(OPEN)
            witness Vs.View.OfBytes([OPEN])

          type jclose = v: Vs.View
            | v.Byte?(CLOSE)
            witness Vs.View.OfBytes([CLOSE])

          type TBracketed = Bracketed<jopen, TElement, jcomma, jclose>

          type TSuffixedElement = Suffixed<TElement, jcomma>
        }

        module ObjectParams refines SequenceParams {
          const OPEN: byte := '{' as byte
          const CLOSE: byte := '}' as byte

          function Colon(cs: FreshCursor): (pr: ParseResult<jcolon>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecView)
            decreases cs
          {
            var cs: Cursor :- cs.AssertChar(':'); Success(cs.Split())
          }

          opaque function KeyValueFromParts(ghost cs: Cursor, k: Split<jstring>, colon: Split<Structural<jcolon>>, v: Split<Value>): (sp: Split<jKeyValue>)
            requires k.StrictlySplitFrom?(cs, Spec.String)
            requires colon.StrictlySplitFrom?(k.cs, (c: Structural<jcolon>) => Spec.Structural(c, SpecView))
            requires v.StrictlySplitFrom?(colon.cs, Spec.Value)
            ensures sp.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs, k, colon, v
          {
            var sp: Split<jKeyValue> := SP(Grammar.KeyValue(k.t, colon.t, v.t), v.cs);
            assert cs.Bytes() == Spec.KeyValue(sp.t) + v.cs.Bytes() by {
              assert cs.Bytes() == Spec.String(k.t) + Spec.Structural(colon.t, SpecView) + Spec.Value(v.t) + v.cs.Bytes() by {
                assert cs.Bytes() == Spec.String(k.t) + k.cs.Bytes();
                assert k.cs.Bytes() == Spec.Structural(colon.t, SpecView) + colon.cs.Bytes();
                assert colon.cs.Bytes() == Spec.Value(v.t) + v.cs.Bytes();
                Seq.LemmaConcatIsAssociative(Spec.String(k.t), Spec.Structural(colon.t, SpecView), colon.cs.Bytes());
                Seq.LemmaConcatIsAssociative(Spec.String(k.t) + Spec.Structural(colon.t, SpecView), Spec.Value(v.t), v.cs.Bytes());
              }
            }
            assert sp.StrictlySplitFrom?(cs, ElementSpec);
            sp
          }

          function ElementSpec(t: TElement): bytes
            decreases t
          {
            Spec.KeyValue(t)
          }

          function {:vcs_split_on_every_assert} Element(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TElement>)
            requires cs.StrictlySplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, ElementSpec)
            decreases cs.Length()
          {
            var k: Split<jstring> :- Strings.String(cs); assert k.cs.StrictlySplitFrom?(json.cs); assert k.StrictlySplitFrom?(cs, Spec.String); var p: Parser_<jcolon, JSONError> := Parsers.Parser(Colon, SpecView); assert p.Valid?(); var colon: Split<Structural<jcolon>> :- Core.Structural(k.cs, p); assert colon.StrictlySplitFrom?(k.cs, (st: Structural<jcolon>) => Spec.Structural(st, SpecView)); assert colon.cs.StrictlySplitFrom?(json.cs); assert json.fn.requires(colon.cs) by {
    assert json.pre(colon.cs) by {
      assert colon.cs.StrictlySplitFrom?(json.cs);
      assert json.Valid?();
    }
    assert json.Valid?();
  } var v: Split<Value> :- json.fn(colon.cs); assert v.StrictlySplitFrom?(colon.cs, Spec.Value) by {
    assert v.cs.StrictlySplitFrom?(colon.cs) by {
      assert v.StrictlySplitFrom?(colon.cs, json.spec) by {
        assert json.Valid?();
      }
    }
    assert v.BytesSplitFrom?(colon.cs, Spec.Value) by {
      calc {
        colon.cs.Bytes();
        {
          assert v.BytesSplitFrom?(colon.cs, json.spec) by {
            assert json.Valid?();
          }
        }
        json.spec(v.t) + v.cs.Bytes();
        {
          assert json.spec(v.t) == Spec.Value(v.t) by {
            assert ValueParserValid(json);
          }
        }
        Spec.Value(v.t) + v.cs.Bytes();
      }
    }
  } var kv: Split<jKeyValue> := KeyValueFromParts(cs, k, colon, v); Success(kv)
          }

          import Strings

          import opened Wrappers

          type TElement = jKeyValue

          import opened BoundedInts

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import opened Core
        }

        module Objects refines Sequences {
          lemma {:vcs_split_on_every_assert} /*{:_induction obj}*/ BracketedToObject(obj: jobject)
            ensures Spec.Bracketed(obj, SuffixedElementSpec) == Spec.Object(obj)
            decreases obj
          {
            ghost var rMember := (d: jmember) requires d < obj => Spec.Member(d);
            assert Spec.Bracketed(obj, SuffixedElementSpec) == Spec.Bracketed(obj, rMember) by {
              assert Spec.Bracketed(obj, SuffixedElementSpec) == Spec.Bracketed(obj, rMember) by {
                assert SpecProperties.Bracketed_Morphism_Requires(obj, SuffixedElementSpec, rMember);
                SpecProperties.Bracketed_Morphism(obj, SuffixedElementSpec, rMember);
              }
            }
            calc {
              Spec.Bracketed(obj, SuffixedElementSpec);
              Spec.Bracketed(obj, rMember);
              Spec.Object(obj);
            }
          }

          opaque function {:vcs_split_on_every_assert} {:rlimit 10000} Object(cs: FreshCursor, json: ValueParser): (pr: ParseResult<jobject>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, Spec.Object)
            decreases cs, json
          {
            var sp: Split<TBracketed> :- Bracketed(cs, json); assert sp.StrictlySplitFrom?(cs, BracketedSpec); BracketedToObject(sp.t); Success(sp)
          }

          const SEPARATOR: byte := ',' as byte
          const SpecViewClose: jclose -> bytes := SpecView
          const SpecViewOpen: jopen -> bytes := SpecView

          ghost function SuffixedElementSpec(e: TSuffixedElement): bytes
            decreases e
          {
            ElementSpec(e.t) + Spec.CommaSuffix(e.suffix)
          }

          ghost function BracketedSpec(ts: TBracketed): bytes
            decreases ts
          {
            Spec.Bracketed(ts, SuffixedElementSpec)
          }

          ghost function SuffixedElementsSpec(ts: seq<TSuffixedElement>): bytes
            decreases ts
          {
            Spec.ConcatBytes(ts, SuffixedElementSpec)
          }

          opaque function Open(cs: FreshCursor): (pr: ParseResult<jopen>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewOpen)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(OPEN); Success(cs.Split())
          }

          opaque function Close(cs: FreshCursor): (pr: ParseResult<jclose>)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, SpecViewClose)
            decreases cs
          {
            var cs: Cursor :- cs.AssertByte(CLOSE); Success(cs.Split())
          }

          opaque function BracketedFromParts(ghost cs: Cursor, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>, close: Split<Structural<jclose>>): (sp: Split<TBracketed>)
            requires Grammar.NoTrailingSuffix(elems.t)
            requires open.StrictlySplitFrom?(cs, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires close.StrictlySplitFrom?(elems.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            ensures sp.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, open, elems, close
          {
            var sp: Split<Bracketed<jopen, TElement, jcomma, jclose>> := SP(Grammar.Bracketed(open.t, elems.t, close.t), close.cs);
            calc {
              cs.Bytes();
              Spec.Structural(open.t, SpecView) + open.cs.Bytes();
              {
                assert open.cs.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + (SuffixedElementsSpec(elems.t) + elems.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView), SuffixedElementsSpec(elems.t), elems.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
              {
                assert elems.cs.Bytes() == Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + (Spec.Structural(close.t, SpecView) + close.cs.Bytes());
              {
                Seq.LemmaConcatIsAssociative(Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t), Spec.Structural(close.t, SpecView), close.cs.Bytes());
              }
              Spec.Structural(open.t, SpecView) + SuffixedElementsSpec(elems.t) + Spec.Structural(close.t, SpecView) + close.cs.Bytes();
              Spec.Bracketed(sp.t, SuffixedElementSpec) + close.cs.Bytes();
            }
            assert sp.StrictlySplitFrom?(cs, BracketedSpec);
            sp
          }

          opaque function AppendWithSuffix(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jcomma>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty?
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures elems'.SplitFrom?(cs0, SuffixedElementsSpec)
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, NonEmpty(sep.t));
            var elems': Split<seq<Suffixed<jKeyValue, jcomma>>> := SP(elems.t + [suffixed], sep.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
              assert {:focus} cs0.Bytes() == SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() by {
                assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes() by {
                  assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + elems.cs.Bytes();
                  assert elems.cs.Bytes() == ElementSpec(suffixed.t) + elem.cs.Bytes();
                  assert elem.cs.Bytes() == Spec.CommaSuffix(suffixed.suffix) + sep.cs.Bytes();
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), elem.cs.Bytes());
                  Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix), sep.cs.Bytes());
                }
                Seq.LemmaConcatIsAssociative(SuffixedElementsSpec(elems.t), ElementSpec(suffixed.t), Spec.CommaSuffix(suffixed.suffix));
              }
              assert SuffixedElementsSpec(elems.t) + (ElementSpec(suffixed.t) + Spec.CommaSuffix(suffixed.suffix)) + sep.cs.Bytes() == SuffixedElementsSpec(elems'.t) + sep.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            assert forall e: Suffixed<jKeyValue, jcomma> {:trigger e.suffix} {:trigger e in elems'.t} | e in elems'.t :: e.suffix.NonEmpty? by {
              assert elems'.t == elems.t + [suffixed];
            }
            assert {:split_here} elems'.cs.Length() < elems.cs.Length();
            assert elems'.SplitFrom?(cs0, SuffixedElementsSpec) by {
              assert elems'.BytesSplitFrom?(cs0, SuffixedElementsSpec) by {
                assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
              }
              assert elems'.cs.SplitFrom?(cs0) by {
                assert elems'.cs.StrictlySplitFrom?(cs0) by {
                  assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
                }
              }
            }
            elems'
          }

          opaque function {:rlimit 10000} {:vcs_split_on_every_assert} AppendLast(ghost cs0: FreshCursor, ghost json: ValueParser, elems: Split<seq<TSuffixedElement>>, elem: Split<TElement>, sep: Split<Structural<jclose>>): (elems': Split<seq<TSuffixedElement>>)
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(cs0, SuffixedElementsSpec)
            requires elem.StrictlySplitFrom?(elems.cs, ElementSpec)
            requires sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec)
            ensures NoTrailingSuffix(elems'.t)
            ensures elems'.cs.Length() < elems.cs.Length()
            ensures elems'.cs.StrictlySplitFrom?(json.cs)
            ensures sep.StrictlySplitFrom?(elems'.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView))
            decreases cs0, json, elems, elem, sep
          {
            var suffixed: Suffixed<TElement, jcomma> := Suffixed(elem.t, Empty());
            var elems': Split<seq<Suffixed<jKeyValue, jcomma>>> := SP(elems.t + [suffixed], elem.cs);
            assert cs0.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
              assert cs0.Bytes() == SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() by {
                assert elem.t == suffixed.t;
              }
              assert SuffixedElementsSpec(elems.t) + ElementSpec(suffixed.t) + elem.cs.Bytes() == SuffixedElementsSpec(elems'.t) + elem.cs.Bytes() by {
                assert SuffixedElementsSpec(elems.t) + SuffixedElementSpec(suffixed) == SuffixedElementsSpec(elems.t + [suffixed]) by {
                  SpecProperties.ConcatBytes_Linear(elems.t, [suffixed], SuffixedElementSpec);
                  assert Spec.ConcatBytes(elems.t, SuffixedElementSpec) + Spec.ConcatBytes([suffixed], SuffixedElementSpec) == Spec.ConcatBytes(elems.t + [suffixed], SuffixedElementSpec);
                }
              }
            }
            assert elems'.StrictlySplitFrom?(cs0, SuffixedElementsSpec);
            elems'
          }

          lemma {:rlimit 10000} AboutTryStructural(cs: FreshCursor)
            ensures ghost var sp: Split<Structural<jopt>> := Core.TryStructural(cs); ghost var s0: opt_byte := sp.t.t.Peek(); ((!cs.BOF? || !cs.EOF?) && s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == SEPARATOR as opt_byte ==> ghost var sp: Split<Structural<jcomma>> := sp; sp.SplitFrom?(cs, (st: Structural<jcomma>) => Spec.Structural(st, SpecView))) && ((!cs.BOF? || !cs.EOF?) && s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.cs.StrictSuffixOf?(cs)) && (s0 == CLOSE as opt_byte ==> ghost var sp: Split<Structural<jclose>> := sp; sp.SplitFrom?(cs, (st: Structural<jclose>) => Spec.Structural(st, SpecView)))
            decreases cs
          {
          }

          lemma {:vcs_split_on_every_assert} AboutLists<T>(xs: seq<T>, i: uint32)
            requires 0 <= i as int < |xs|
            ensures xs[i as int .. i as int + 1] == [xs[i as int]]
            decreases xs, i
          {
          }

          opaque function {:vcs_split_on_every_assert} {:tailrecursion} Elements(ghost cs0: FreshCursor, json: ValueParser, open: Split<Structural<jopen>>, elems: Split<seq<TSuffixedElement>>): (pr: ParseResult<TBracketed>)
            requires open.StrictlySplitFrom?(cs0, (c: Structural<jopen>) => Spec.Structural(c, SpecView))
            requires elems.cs.StrictlySplitFrom?(json.cs)
            requires elems.SplitFrom?(open.cs, SuffixedElementsSpec)
            requires forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs0, BracketedSpec)
            decreases elems.cs.Length()
          {
            var elem: Split<TElement> :- Element(elems.cs, json); if elem.cs.EOF? then Failure(EOF) else AboutTryStructural(elem.cs); var sep: Split<Structural<jopt>> := Core.TryStructural(elem.cs); var s0: opt_byte := sep.t.t.Peek(); if s0 == SEPARATOR as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Char?(',') by {
    calc {
      sep.t.t.Char?(',');
      sep.t.t.Byte?(',' as byte);
      sep.t.t.Byte?(SEPARATOR);
      sep.t.t.Bytes() == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [SEPARATOR];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [SEPARATOR];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [SEPARATOR];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == SEPARATOR as opt_byte;
      sep.t.t.At(0) as opt_byte == SEPARATOR as opt_byte;
      s0 == SEPARATOR as opt_byte;
      true;
    }
  } var sep: Split<Structural<jcomma>> := sep; assert AppendWithSuffix.requires(open.cs, json, elems, elem, sep) by {
    assert {:focus} elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jcomma>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
    assert {:split_here} true;
  } var elems: Split<seq<TSuffixedElement>> := AppendWithSuffix(open.cs, json, elems, elem, sep); Elements(cs0, json, open, elems) else if s0 == CLOSE as opt_byte && sep.t.t.Length() == 1 then assert sep.t.t.Byte?(CLOSE) by {
    calc {
      sep.t.t.Byte?(CLOSE);
      sep.t.t.Bytes() == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.end as int] == [CLOSE];
      {
        assert sep.t.t.beg as int + 1 == sep.t.t.end as int by {
          assert sep.t.t.Length() == 1;
        }
      }
      sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [CLOSE];
      {
        assert sep.t.t.s[sep.t.t.beg as int .. sep.t.t.beg as int + 1] == [sep.t.t.s[sep.t.t.beg as int]] by {
          AboutLists(sep.t.t.s, sep.t.t.beg);
        }
      }
      [sep.t.t.s[sep.t.t.beg as int]] == [CLOSE];
      sep.t.t.s[sep.t.t.beg as int] as opt_byte == CLOSE as opt_byte;
      sep.t.t.At(0) as opt_byte == CLOSE as opt_byte;
      s0 == CLOSE as opt_byte;
      true;
    }
  } var sep: Split<Structural<jclose>> := sep; assert AppendLast.requires(open.cs, json, elems, elem, sep) by {
    assert elems.cs.StrictlySplitFrom?(json.cs);
    assert elems.SplitFrom?(open.cs, SuffixedElementsSpec);
    assert elem.StrictlySplitFrom?(elems.cs, ElementSpec);
    assert sep.StrictlySplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
      assert sep.BytesSplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView)) by {
        assert sep.SplitFrom?(elem.cs, (c: Structural<jclose>) => Spec.Structural(c, SpecView));
      }
      assert sep.cs.StrictlySplitFrom?(elem.cs) by {
        assert sep.cs.BOF?;
        assert sep.cs.StrictSuffixOf?(elem.cs) by {
          assert !elem.cs.EOF?;
        }
      }
    }
    assert forall e: Suffixed<TElement, jcomma> {:trigger e.suffix} {:trigger e in elems.t} | e in elems.t :: e.suffix.NonEmpty?;
  } var elems': Split<seq<TSuffixedElement>> := AppendLast(open.cs, json, elems, elem, sep); assert elems'.SplitFrom?(open.cs, SuffixedElementsSpec) by {
    assert elems'.StrictlySplitFrom?(open.cs, SuffixedElementsSpec);
  } var bracketed: Split<TBracketed> := BracketedFromParts(cs0, open, elems', sep); assert bracketed.StrictlySplitFrom?(cs0, BracketedSpec); Success(bracketed) else var separator: byte := SEPARATOR; var pr: Result<Split<Bracketed<jopen, jKeyValue, jcomma, jclose>>, CursorError<Errors.DeserializationError>> := Failure(ExpectingAnyByte([CLOSE, separator], s0)); pr
          }

          lemma AboutCloseParser()
            ensures Parsers.Parser(Close, SpecViewClose).Valid?()
          {
            assert Parsers.Parser(Close, SpecViewClose).Valid?() by {
              forall cs': FreshCursor | true
                ensures Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose)
              {
                if Close(cs').Success? {
                  assert Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose) by {
                    assert Close(cs').Success? ==> Close(cs').value.StrictlySplitFrom?(cs', SpecViewClose);
                  }
                }
              }
            }
          }

          opaque function {:vcs_split_on_every_assert} Bracketed(cs: FreshCursor, json: ValueParser): (pr: ParseResult<TBracketed>)
            requires cs.SplitFrom?(json.cs)
            ensures pr.Success? ==> pr.value.StrictlySplitFrom?(cs, BracketedSpec)
            decreases cs, json
          {
            var open: Split<Structural<jopen>> :- Core.Structural<jopen>(cs, Parsers.Parser(Open, SpecViewOpen)); assert open.cs.StrictlySplitFrom?(json.cs); var elems: Split<seq<Suffixed<jKeyValue, jcomma>>> := SP([], open.cs); if open.cs.Peek() == CLOSE as opt_byte then var p: Parser_<jclose, JSONError> := Parsers.Parser(Close, SpecViewClose); assert p.Valid?() by {
    AboutCloseParser();
  } var close: Split<Structural<jclose>> :- Core.Structural<jclose>(open.cs, p); Success(BracketedFromParts(cs, open, elems, close)) else Elements(cs, json, open, elems)
          }

          lemma Valid(x: TBracketed)
            ensures x.l.t.Byte?(OPEN)
            ensures x.r.t.Byte?(CLOSE)
            ensures NoTrailingSuffix(x.data)
            ensures forall pf: Suffixed<TElement, jcomma> {:trigger pf.suffix} {:trigger pf in x.data} | pf in x.data :: pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            decreases x
          {
            ghost var xlt: jopen := x.l.t;
            ghost var xrt: jclose := x.r.t;
            forall pf: Suffixed<TElement, jcomma> | pf in x.data
              ensures pf.suffix.NonEmpty? ==> pf.suffix.t.t.Byte?(SEPARATOR)
            {
              if pf.suffix.NonEmpty? {
                ghost var xtt := pf.suffix.t.t;
              }
            }
          }

          import opened Params = ObjectParams

          import opened Wrappers

          import opened BoundedInts

          import SpecProperties = ConcreteSyntax.SpecProperties

          import opened Vs = Utils.Views.Core

          import opened Grammar

          import opened Cursors = Utils.Cursors

          import Parsers = Utils.Parsers

          import opened Core

          type jopen = v: Vs.View
            | v.Byte?(OPEN)
            witness Vs.View.OfBytes([OPEN])

          type jclose = v: Vs.View
            | v.Byte?(CLOSE)
            witness Vs.View.OfBytes([CLOSE])

          type TBracketed = Bracketed<jopen, TElement, jcomma, jclose>

          type TSuffixedElement = Suffixed<TElement, jcomma>
        }
      }

      module Serializer {
        method Serialize(js: JSON) returns (rbs: SerializationResult<array<byte>>)
          ensures rbs.Success? ==> fresh(rbs.value)
          ensures rbs.Success? ==> rbs.value[..] == Spec.JSON(js)
          decreases js
        {
          var writer := Text(js);
          :- Need(writer.Unsaturated?, OutOfMemory);
          var bs := writer.ToArray();
          return Success(bs);
        }

        method SerializeTo(js: JSON, dest: array<byte>) returns (len: SerializationResult<uint32>)
          modifies dest
          ensures len.Success? ==> len.value as int <= dest.Length
          ensures len.Success? ==> dest[..len.value] == Spec.JSON(js)
          ensures len.Success? ==> dest[len.value..] == old(dest[len.value..])
          ensures len.Failure? ==> unchanged(dest)
          decreases js, dest
        {
          var writer := Text(js);
          :- Need(writer.Unsaturated?, OutOfMemory);
          :- Need(writer.length as int <= dest.Length, OutOfMemory);
          writer.CopyTo(dest);
          return Success(writer.length);
        }

        opaque function Text(js: JSON): (wr: Writer)
          ensures wr.Bytes() == Spec.JSON(js)
          decreases js
        {
          JSON(js)
        }

        opaque function JSON(js: JSON, writer: Writer := Writer.Empty): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.JSON(js)
          decreases js, writer
        {
          Seq.LemmaConcatIsAssociative2(writer.Bytes(), js.before.Bytes(), Spec.Value(js.t), js.after.Bytes());
          writer.Append(js.before).Then((wr: Writer) => Value(js.t, wr)).Append(js.after)
        }

        opaque function {:vcs_split_on_every_assert} Value(v: Grammar.Value, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Value(v)
          decreases v, 4
        {
          match v
          case Null(n) =>
            var wr: Writer := writer.Append(n);
            wr
          case Bool(b) =>
            var wr: Writer := writer.Append(b);
            wr
          case String(str) =>
            var wr: Writer := String(str, writer);
            calc {
              wr.Bytes();
              {
                assert wr == String(v.str, writer);
              }
              writer.Bytes() + Spec.String(v.str);
              {
                assert v.String?;
                assert v.String? ==> Spec.Value(v) == Spec.String(v.str);
              }
              writer.Bytes() + Spec.Value(v);
            } wr
          case Number(num) =>
            var wr: Writer := Number(num, writer);
            calc {
              wr.Bytes();
              {
                assert wr == Number(v.num, writer);
              }
              writer.Bytes() + Spec.Number(v.num);
              {
                assert v.Number?;
                assert v.Number? ==> Spec.Value(v) == Spec.Number(v.num);
              }
              writer.Bytes() + Spec.Value(v);
            } wr
          case Object(obj) =>
            var wr: Writer := Object(obj, writer);
            calc {
              wr.Bytes();
              {
                assert wr == Object(v.obj, writer);
              }
              writer.Bytes() + Spec.Object(v.obj);
              {
                assert v.Object?;
                assert v.Object? ==> Spec.Value(v) == Spec.Object(v.obj);
              }
              writer.Bytes() + Spec.Value(v);
            } wr
          case Array(arr) =>
            var wr: Writer := Array(arr, writer);
            calc {
              wr.Bytes();
              {
                assert wr == Array(v.arr, writer);
              }
              writer.Bytes() + Spec.Array(v.arr);
              {
                assert v.Array?;
                assert v.Array? ==> Spec.Value(v) == Spec.Array(v.arr);
              }
              writer.Bytes() + Spec.Value(v);
            }
            wr
        }

        opaque function String(str: jstring, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.String(str)
          decreases str, 0
        {
          writer.Append(str.lq).Append(str.contents).Append(str.rq)
        }

        lemma {:vcs_split_on_every_assert} NumberHelper1(num: jnumber, writer: Writer)
          ensures if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else writer.Append(num.minus).Append(num.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() else writer.Append(num.minus).Append(num.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes()
          decreases num, writer
        {
          if num.exp.NonEmpty? {
            if num.frac.NonEmpty? {
              assert writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
            } else {
              assert writer.Append(num.minus).Append(num.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
            }
          } else {
            if num.frac.NonEmpty? {
              assert writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
            } else {
              assert writer.Append(num.minus).Append(num.num).Bytes() == writer.Bytes() + num.minus.Bytes() + num.num.Bytes();
            }
          }
        }

        lemma {:vcs_split_on_every_assert} NumberHelper2a(num: jnumber, writer: Writer)
          ensures Spec.Number(num) == num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp)
          decreases num, writer
        {
        }

        lemma {:vcs_split_on_every_assert} {:rlimit 10000} NumberHelper2(num: jnumber, writer: Writer)
          ensures if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() else writer.Bytes() + Spec.Number(num) == writer.Bytes() + num.minus.Bytes() + num.num.Bytes()
          decreases num, writer
        {
          if num.exp.NonEmpty? {
            if num.frac.NonEmpty? {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.frac, Spec.Frac) == Spec.Frac(num.frac.t);
                  assert Spec.Maybe(num.exp, Spec.Exp) == Spec.Exp(num.exp.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Frac(num.frac.t) + Spec.Exp(num.exp.t));
                {
                  assert Spec.Frac(num.frac.t) == num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
                  assert Spec.Exp(num.exp.t) == num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + (num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes()));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
              }
            } else {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.frac, Spec.Frac) == [];
                  assert Spec.Maybe(num.exp, Spec.Exp) == Spec.Exp(num.exp.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + ([] + Spec.Exp(num.exp.t));
                {
                  assert [] + Spec.Exp(num.exp.t) == Spec.Exp(num.exp.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + Spec.Exp(num.exp.t);
                {
                  assert Spec.Exp(num.exp.t) == num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes());
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes();
              }
            }
          } else {
            if num.frac.NonEmpty? {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.exp, Spec.Exp) == [];
                  assert Spec.Maybe(num.frac, Spec.Frac) == Spec.Frac(num.frac.t);
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + (Spec.Frac(num.frac.t) + []);
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + Spec.Frac(num.frac.t);
                {
                  assert Spec.Frac(num.frac.t) == num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes();
              }
            } else {
              calc {
                writer.Bytes() + Spec.Number(num);
                {
                  NumberHelper2a(num, writer);
                }
                writer.Bytes() + (num.minus.Bytes() + num.num.Bytes() + Spec.Maybe(num.frac, Spec.Frac) + Spec.Maybe(num.exp, Spec.Exp));
                {
                  assert Spec.Maybe(num.frac, Spec.Frac) == [];
                  assert Spec.Maybe(num.exp, Spec.Exp) == [];
                }
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + [] + [];
                writer.Bytes() + num.minus.Bytes() + num.num.Bytes();
              }
            }
          }
        }

        opaque function {:vcs_split_on_every_assert} Number(num: jnumber, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Number(num)
          decreases num, 0
        {
          var wr1: Writer := writer.Append(num.minus).Append(num.num);
          var wr2: Writer_ := if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num) else wr1;
          var wr3: Writer_ := if num.exp.NonEmpty? then wr2.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num) else wr2;
          var wr: Writer_ := wr3;
          calc {
            wr.Bytes();
            {
              assert wr == wr3;
            }
            wr3.Bytes();
            {
              assert wr3 == if num.exp.NonEmpty? then wr2.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num) else wr2;
            }
            if num.exp.NonEmpty? then wr2.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else wr2.Bytes();
            {
              assert wr2 == if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num) else wr1;
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else wr1.Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else if num.frac.NonEmpty? then wr1.Append(num.frac.t.period).Append(num.frac.t.num).Bytes() else wr1.Bytes();
            {
              assert wr1 == writer.Append(num.minus).Append(num.num);
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else writer.Append(num.minus).Append(num.num).Append(num.exp.t.e).Append(num.exp.t.sign).Append(num.exp.t.num).Bytes() else if num.frac.NonEmpty? then writer.Append(num.minus).Append(num.num).Append(num.frac.t.period).Append(num.frac.t.num).Bytes() else writer.Append(num.minus).Append(num.num).Bytes();
            {
              NumberHelper1(num, writer);
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.exp.t.e.Bytes() + num.exp.t.sign.Bytes() + num.exp.t.num.Bytes() else if num.frac.NonEmpty? then writer.Bytes() + num.minus.Bytes() + num.num.Bytes() + num.frac.t.period.Bytes() + num.frac.t.num.Bytes() else writer.Bytes() + num.minus.Bytes() + num.num.Bytes();
            {
              NumberHelper2(num, writer);
            }
            if num.exp.NonEmpty? then if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) else writer.Bytes() + Spec.Number(num) else if num.frac.NonEmpty? then writer.Bytes() + Spec.Number(num) else writer.Bytes() + Spec.Number(num);
            writer.Bytes() + Spec.Number(num);
          }
          wr
        }

        function {:vcs_split_on_every_assert} StructuralView(st: Structural<View>, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Structural(st, Spec.View)
          decreases st, writer
        {
          writer.Append(st.before).Append(st.t).Append(st.after)
        }

        lemma StructuralViewEns(st: Structural<View>, writer: Writer)
          ensures StructuralView(st, writer).Bytes() == writer.Bytes() + Spec.Structural(st, Spec.View)
          decreases st, writer
        {
        }

        lemma /*{:_induction obj}*/ BracketedToObject(obj: jobject)
          ensures Spec.Bracketed(obj, Spec.Member) == Spec.Object(obj)
          decreases obj
        {
          ghost var rMember := (d: jmember) requires d < obj => Spec.Member(d);
          assert Spec.Bracketed(obj, Spec.Member) == Spec.Bracketed(obj, rMember) by {
            assert SpecProperties.Bracketed_Morphism_Requires(obj, Spec.Member, rMember);
            SpecProperties.Bracketed_Morphism(obj, Spec.Member, rMember);
          }
          calc {
            Spec.Bracketed(obj, Spec.Member);
            Spec.Bracketed(obj, rMember);
            Spec.Object(obj);
          }
        }

        opaque function Object(obj: jobject, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Object(obj)
          decreases obj, 3
        {
          var wr: Writer := StructuralView(obj.l, writer);
          StructuralViewEns(obj.l, writer);
          var wr: Writer := Members(obj, wr);
          var wr: Writer := StructuralView(obj.r, wr);
          Seq.LemmaConcatIsAssociative2(writer.Bytes(), Spec.Structural<View>(obj.l, Spec.View), Spec.ConcatBytes(obj.data, Spec.Member), Spec.Structural<View>(obj.r, Spec.View));
          assert wr.Bytes() == writer.Bytes() + Spec.Bracketed(obj, Spec.Member);
          assert Spec.Bracketed(obj, Spec.Member) == Spec.Object(obj) by {
            BracketedToObject(obj);
          }
          wr
        }

        lemma /*{:_induction arr}*/ BracketedToArray(arr: jarray)
          ensures Spec.Bracketed(arr, Spec.Item) == Spec.Array(arr)
          decreases arr
        {
          ghost var rItem := (d: jitem) requires d < arr => Spec.Item(d);
          assert Spec.Bracketed(arr, Spec.Item) == Spec.Bracketed(arr, rItem) by {
            assert SpecProperties.Bracketed_Morphism_Requires(arr, Spec.Item, rItem);
            SpecProperties.Bracketed_Morphism(arr, Spec.Item, rItem);
          }
          calc {
            Spec.Bracketed(arr, Spec.Item);
            Spec.Bracketed(arr, rItem);
            Spec.Array(arr);
          }
        }

        opaque function Array(arr: jarray, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.Array(arr)
          decreases arr, 3
        {
          var wr: Writer := StructuralView(arr.l, writer);
          StructuralViewEns(arr.l, writer);
          var wr: Writer := Items(arr, wr);
          var wr: Writer := StructuralView(arr.r, wr);
          Seq.LemmaConcatIsAssociative2(writer.Bytes(), Spec.Structural<View>(arr.l, Spec.View), Spec.ConcatBytes(arr.data, Spec.Item), Spec.Structural<View>(arr.r, Spec.View));
          assert wr.Bytes() == writer.Bytes() + Spec.Bracketed(arr, Spec.Item);
          assert Spec.Bracketed(arr, Spec.Item) == Spec.Array(arr) by {
            BracketedToArray(arr);
          }
          wr
        }

        opaque function Members(obj: jobject, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(obj.data, Spec.Member)
          decreases obj, 2
        {
          MembersSpec(obj, obj.data, writer)
        } by method {
          assume {:axiom} false;
          wr := MembersImpl(obj, writer);
        }

        opaque function Items(arr: jarray, writer: Writer): (wr: Writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(arr.data, Spec.Item)
          decreases arr, 2
        {
          ItemsSpec(arr, arr.data, writer)
        } by method {
          assume {:axiom} false;
          wr := ItemsImpl(arr, writer);
        }

        ghost function MembersSpec(obj: jobject, members: seq<jmember>, writer: Writer): (wr: Writer)
          requires forall j: int {:trigger members[j]} | 0 <= j < |members| :: members[j] < obj
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(members, Spec.Member)
          decreases obj, 1, members
        {
          if members == [] then
            writer
          else
            ghost var butLast: seq<Suffixed<jKeyValue, jcomma>>, last: Suffixed<jKeyValue, jcomma> := members[..|members| - 1], members[|members| - 1]; assert members == butLast + [last]; ghost var wr: Writer := MembersSpec(obj, butLast, writer); ghost var wr: Writer := Member(obj, last, wr); assert wr.Bytes() == writer.Bytes() + (Spec.ConcatBytes(butLast, Spec.Member) + Spec.ConcatBytes([last], Spec.Member)) by {
    Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.ConcatBytes(butLast, Spec.Member), Spec.ConcatBytes([last], Spec.Member));
  } SpecProperties.ConcatBytes_Linear(butLast, [last], Spec.Member); wr
        }

        ghost predicate SequenceSpecRequiresHelper<T>(v: Value, items: seq<T>, spec: T -> bytes, impl: (Value, T, Writer) --> Writer, writer: Writer, item: T, wr: Writer)
          requires item in items
          decreases v, items, writer, wr
        {
          impl.requires(v, item, wr) &&
          impl(v, item, wr).Bytes() == wr.Bytes() + spec(item)
        }

        ghost predicate SequenceSpecRequires<T>(v: Value, items: seq<T>, spec: T -> bytes, impl: (Value, T, Writer) --> Writer, writer: Writer)
          decreases v, items, writer
        {
          forall item: T, wr: Writer {:trigger SequenceSpecRequiresHelper<T>(v, items, spec, impl, writer, item, wr)} | item in items :: 
            SequenceSpecRequiresHelper(v, items, spec, impl, writer, item, wr)
        }

        ghost function {:vcs_split_on_every_assert} SequenceSpec<T>(v: Value, items: seq<T>, spec: T -> bytes, impl: (Value, T, Writer) --> Writer, writer: Writer): (wr: Writer)
          requires SequenceSpecRequires(v, items, spec, impl, writer)
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(items, spec)
          decreases v, 1, items
        {
          if items == [] then
            writer
          else
            assert SequenceSpecRequires(v, items[..|items| - 1], spec, impl, writer) by {
    assert forall item: T, wr: Writer {:trigger SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr)} | item in items[..|items| - 1] :: SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr) by {
      forall item: T, wr: Writer {:trigger SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr)} | item in items[..|items| - 1]
        ensures SequenceSpecRequiresHelper(v, items[..|items| - 1], spec, impl, writer, item, wr)
      {
        assert item in items;
        assert SequenceSpecRequiresHelper(v, items, spec, impl, writer, item, wr);
      }
    }
  } ghost var writer': Writer := SequenceSpec(v, items[..|items| - 1], spec, impl, writer); assert impl.requires(v, items[|items| - 1], writer') by {
    assert SequenceSpecRequiresHelper(v, items, spec, impl, writer, items[|items| - 1], writer') by {
      assert SequenceSpecRequires(v, items, spec, impl, writer);
      assert items[|items| - 1] in items;
    }
  } ghost var wr: Writer := impl(v, items[|items| - 1], writer'); assert wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(items, spec) by {
    calc {
      wr.Bytes();
      {
        assert wr == impl(v, items[|items| - 1], writer');
      }
      impl(v, items[|items| - 1], writer').Bytes();
      {
        assert SequenceSpecRequires(v, items, spec, impl, writer);
        assert items[|items| - 1] in items;
        assert SequenceSpecRequiresHelper(v, items, spec, impl, writer, items[|items| - 1], writer');
      }
      writer'.Bytes() + spec(items[|items| - 1]);
      {
        assert writer' == SequenceSpec(v, items[..|items| - 1], spec, impl, writer);
      }
      writer.Bytes() + Spec.ConcatBytes(items[..|items| - 1], spec) + spec(items[|items| - 1]);
      {
        assert spec(items[|items| - 1]) == Spec.ConcatBytes([items[|items| - 1]], spec);
      }
      writer.Bytes() + Spec.ConcatBytes(items[..|items| - 1], spec) + Spec.ConcatBytes([items[|items| - 1]], spec);
      {
        SpecProperties.ConcatBytes_Linear(items[..|items| - 1], [items[|items| - 1]], spec);
      }
      writer.Bytes() + Spec.ConcatBytes(items[..|items| - 1] + [items[|items| - 1]], spec);
      {
        assert items == items[..|items| - 1] + [items[|items| - 1]];
      }
      writer.Bytes() + Spec.ConcatBytes(items, spec);
    }
  } wr
        }

        ghost function ItemsSpec(arr: jarray, items: seq<jitem>, writer: Writer): (wr: Writer)
          requires forall j: int {:trigger items[j]} | 0 <= j < |items| :: items[j] < arr
          ensures wr.Bytes() == writer.Bytes() + Spec.ConcatBytes(items, Spec.Item)
          decreases arr, 1, items
        {
          if items == [] then
            writer
          else
            ghost var butLast: seq<Suffixed<Value, jcomma>>, last: Suffixed<Value, jcomma> := items[..|items| - 1], items[|items| - 1]; assert items == butLast + [last]; ghost var wr: Writer := ItemsSpec(arr, butLast, writer); ghost var wr: Writer := Item(arr, last, wr); assert wr.Bytes() == writer.Bytes() + (Spec.ConcatBytes(butLast, Spec.Item) + Spec.ConcatBytes([last], Spec.Item)) by {
    Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.ConcatBytes(butLast, Spec.Item), Spec.ConcatBytes([last], Spec.Item));
  } SpecProperties.ConcatBytes_Linear(butLast, [last], Spec.Item); wr
        }

        method {:rlimit 10000} MembersImpl(obj: jobject, writer: Writer) returns (wr: Writer)
          ensures wr == MembersSpec(obj, obj.data, writer)
          decreases obj, 1
        {
          wr := writer;
          var members := obj.data;
          assert wr == MembersSpec(obj, members[..0], writer);
          for i: int := 0 to |members|
            invariant wr == MembersSpec(obj, members[..i], writer)
          {
            assert members[..i + 1][..i] == members[..i];
            wr := Member(obj, members[i], wr);
          }
          assert members[..|members|] == members;
          assert wr == MembersSpec(obj, members, writer);
        }

        method {:vcs_split_on_every_assert} ItemsImpl(arr: jarray, writer: Writer) returns (wr: Writer)
          ensures wr == ItemsSpec(arr, arr.data, writer)
          decreases arr, 1
        {
          wr := writer;
          var items := arr.data;
          assert wr == ItemsSpec(arr, items[..0], writer);
          for i: int := 0 to |items|
            invariant wr == ItemsSpec(arr, items[..i], writer)
          {
            assert items[..i + 1][..i] == items[..i] by {
              AboutList(items, i, i + 1);
            }
            wr := Item(arr, items[i], wr);
          }
          assert items[..|items|] == items;
        }

        lemma AboutList<T>(xs: seq<T>, i: nat, j: nat)
          requires i < j <= |xs|
          ensures xs[..j][..i] == xs[..i]
          decreases xs, i, j
        {
        }

        opaque function Member(ghost obj: jobject, m: jmember, writer: Writer): (wr: Writer)
          requires m < obj
          ensures wr.Bytes() == writer.Bytes() + Spec.Member(m)
          decreases obj, 0
        {
          var wr: Writer := String(m.t.k, writer);
          var wr: Writer := StructuralView(m.t.colon, wr);
          var wr: Writer := Value(m.t.v, wr);
          assert wr.Bytes() == writer.Bytes() + (Spec.String(m.t.k) + Spec.Structural<View>(m.t.colon, Spec.View) + Spec.Value(m.t.v)) by {
            Seq.LemmaConcatIsAssociative2(writer.Bytes(), Spec.String(m.t.k), Spec.Structural<View>(m.t.colon, Spec.View), Spec.Value(m.t.v));
          }
          var wr: Writer_ := if m.suffix.Empty? then wr else StructuralView(m.suffix.t, wr);
          assert wr.Bytes() == writer.Bytes() + Spec.KeyValue(m.t) + Spec.CommaSuffix(m.suffix) by {
            if m.suffix.Empty? {
              EmptySequenceIsRightIdentity(Spec.KeyValue(m.t));
              Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.KeyValue(m.t), []);
            } else {
              assert Spec.StructuralView(m.suffix.t) == Spec.CommaSuffix(m.suffix);
            }
          }
          assert wr.Bytes() == writer.Bytes() + (Spec.KeyValue(m.t) + Spec.CommaSuffix(m.suffix)) by {
            Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.KeyValue(m.t), Spec.CommaSuffix(m.suffix));
          }
          wr
        }

        opaque function Item(ghost arr: jarray, m: jitem, writer: Writer): (wr: Writer)
          requires m < arr
          ensures wr.Bytes() == writer.Bytes() + Spec.Item(m)
          decreases arr, 0
        {
          var wr: Writer := Value(m.t, writer);
          var wr: Writer_ := if m.suffix.Empty? then wr else StructuralView(m.suffix.t, wr);
          assert wr.Bytes() == writer.Bytes() + (Spec.Value(m.t) + Spec.CommaSuffix(m.suffix)) by {
            Seq.LemmaConcatIsAssociative(writer.Bytes(), Spec.Value(m.t), Spec.CommaSuffix(m.suffix));
          }
          wr
        }

        import Spec = ConcreteSyntax.Spec

        import SpecProperties = ConcreteSyntax.SpecProperties

        import opened BoundedInts

        import opened Wrappers

        import opened Seq = Collections.Seq

        import opened Errors

        import opened Grammar

        import opened Writers = Utils.Views.Writers

        import opened Vs = Utils.Views.Core
      }
    }
  }
}
")]

namespace Dafny {
  internal class ArrayHelpers {
    public static T[] InitNewArray1<T>(T z, BigInteger size0) {
      int s0 = (int)size0;
      T[] a = new T[s0];
      for (int i0 = 0; i0 < s0; i0++) {
        a[i0] = z;
      }
      return a;
    }
  }
} // end of namespace Dafny
internal static class FuncExtensions {
  public static Func<U, UResult> DowncastClone<T, TResult, U, UResult>(this Func<T, TResult> F, Func<U, T> ArgConv, Func<TResult, UResult> ResConv) {
    return arg => ResConv(F(ArgConv(arg)));
  }
  public static Func<UResult> DowncastClone<TResult, UResult>(this Func<TResult> F, Func<TResult, UResult> ResConv) {
    return () => ResConv(F());
  }
  public static Func<U1, U2, U3, UResult> DowncastClone<T1, T2, T3, TResult, U1, U2, U3, UResult>(this Func<T1, T2, T3, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3)));
  }
  public static Func<U1, U2, UResult> DowncastClone<T1, T2, TResult, U1, U2, UResult>(this Func<T1, T2, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<TResult, UResult> ResConv) {
    return (arg1, arg2) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2)));
  }
  public static Func<U1, U2, U3, U4, UResult> DowncastClone<T1, T2, T3, T4, TResult, U1, U2, U3, U4, UResult>(this Func<T1, T2, T3, T4, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4)));
  }
  public static Func<U1, U2, U3, U4, U5, UResult> DowncastClone<T1, T2, T3, T4, T5, TResult, U1, U2, U3, U4, U5, UResult>(this Func<T1, T2, T3, T4, T5, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5)));
  }
  public static Func<U1, U2, U3, U4, U5, U6, U7, UResult> DowncastClone<T1, T2, T3, T4, T5, T6, T7, TResult, U1, U2, U3, U4, U5, U6, U7, UResult>(this Func<T1, T2, T3, T4, T5, T6, T7, TResult> F, Func<U1, T1> ArgConv1, Func<U2, T2> ArgConv2, Func<U3, T3> ArgConv3, Func<U4, T4> ArgConv4, Func<U5, T5> ArgConv5, Func<U6, T6> ArgConv6, Func<U7, T7> ArgConv7, Func<TResult, UResult> ResConv) {
    return (arg1, arg2, arg3, arg4, arg5, arg6, arg7) => ResConv(F(ArgConv1(arg1), ArgConv2(arg2), ArgConv3(arg3), ArgConv4(arg4), ArgConv5(arg5), ArgConv6(arg6), ArgConv7(arg7)));
  }
}
namespace Std.Wrappers {

  public partial class __default {
    public static Std.Wrappers._IOutcomeResult<__E> Need<__E>(bool condition, __E error)
    {
      if (condition) {
        return Std.Wrappers.OutcomeResult<__E>.create_Pass_k();
      } else {
        return Std.Wrappers.OutcomeResult<__E>.create_Fail_k(error);
      }
    }
  }

  public interface _IOption<out T> {
    bool is_None { get; }
    bool is_Some { get; }
    T dtor_value { get; }
    _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0);
    bool IsFailure();
    Std.Wrappers._IOption<__U> PropagateFailure<__U>();
    T Extract();
    Std.Wrappers._IResult<T, __E> ToResult<__E>(__E error);
    Std.Wrappers._IOutcome<__E> ToOutcome<__E>(__E error);
  }
  public abstract class Option<T> : _IOption<T> {
    public Option() {
    }
    public static Std.Wrappers._IOption<T> Default() {
      return create_None();
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IOption<T>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.Wrappers._IOption<T>>(Std.Wrappers.Option<T>.Default());
    }
    public static _IOption<T> create_None() {
      return new Option_None<T>();
    }
    public static _IOption<T> create_Some(T @value) {
      return new Option_Some<T>(@value);
    }
    public bool is_None { get { return this is Option_None<T>; } }
    public bool is_Some { get { return this is Option_Some<T>; } }
    public T dtor_value {
      get {
        var d = this;
        return ((Option_Some<T>)d)._value;
      }
    }
    public abstract _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0);
    public bool IsFailure() {
      return (this).is_None;
    }
    public Std.Wrappers._IOption<__U> PropagateFailure<__U>() {
      return Std.Wrappers.Option<__U>.create_None();
    }
    public T Extract() {
      return (this).dtor_value;
    }
    public static T GetOr(Std.Wrappers._IOption<T> _this, T @default) {
      Std.Wrappers._IOption<T> _source0 = _this;
      if (_source0.is_None) {
        return @default;
      } else {
        T _0___mcc_h0 = _source0.dtor_value;
        T _1_v = _0___mcc_h0;
        return _1_v;
      }
    }
    public Std.Wrappers._IResult<T, __E> ToResult<__E>(__E error) {
      Std.Wrappers._IOption<T> _source1 = this;
      if (_source1.is_None) {
        return Std.Wrappers.Result<T, __E>.create_Failure(error);
      } else {
        T _2___mcc_h0 = _source1.dtor_value;
        T _3_v = _2___mcc_h0;
        return Std.Wrappers.Result<T, __E>.create_Success(_3_v);
      }
    }
    public Std.Wrappers._IOutcome<__E> ToOutcome<__E>(__E error) {
      Std.Wrappers._IOption<T> _source2 = this;
      if (_source2.is_None) {
        return Std.Wrappers.Outcome<__E>.create_Fail(error);
      } else {
        T _4___mcc_h0 = _source2.dtor_value;
        T _5_v = _4___mcc_h0;
        return Std.Wrappers.Outcome<__E>.create_Pass();
      }
    }
    public static __FC Map<__FC>(Std.Wrappers._IOption<T> _this, Func<Std.Wrappers._IOption<T>, __FC> rewrap) {
      return Dafny.Helpers.Id<Func<Std.Wrappers._IOption<T>, __FC>>(rewrap)(_this);
    }
  }
  public class Option_None<T> : Option<T> {
    public Option_None() : base() {
    }
    public override _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IOption<__T> dt) { return dt; }
      return new Option_None<__T>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Option_None<T>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Option.None";
      return s;
    }
  }
  public class Option_Some<T> : Option<T> {
    public readonly T _value;
    public Option_Some(T @value) : base() {
      this._value = @value;
    }
    public override _IOption<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IOption<__T> dt) { return dt; }
      return new Option_Some<__T>(converter0(_value));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Option_Some<T>;
      return oth != null && object.Equals(this._value, oth._value);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._value));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Option.Some";
      s += "(";
      s += Dafny.Helpers.ToString(this._value);
      s += ")";
      return s;
    }
  }

  public interface _IResult<out R, out E> {
    bool is_Success { get; }
    bool is_Failure { get; }
    R dtor_value { get; }
    E dtor_error { get; }
    _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1);
    bool IsFailure();
    Std.Wrappers._IResult<__U, E> PropagateFailure<__U>();
    R Extract();
    Std.Wrappers._IOption<R> ToOption();
    Std.Wrappers._IOutcome<E> ToOutcome();
  }
  public abstract class Result<R, E> : _IResult<R, E> {
    public Result() {
    }
    public static Std.Wrappers._IResult<R, E> Default(R _default_R) {
      return create_Success(_default_R);
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IResult<R, E>> _TypeDescriptor(Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Std.Wrappers._IResult<R, E>>(Std.Wrappers.Result<R, E>.Default(_td_R.Default()));
    }
    public static _IResult<R, E> create_Success(R @value) {
      return new Result_Success<R, E>(@value);
    }
    public static _IResult<R, E> create_Failure(E error) {
      return new Result_Failure<R, E>(error);
    }
    public bool is_Success { get { return this is Result_Success<R, E>; } }
    public bool is_Failure { get { return this is Result_Failure<R, E>; } }
    public R dtor_value {
      get {
        var d = this;
        return ((Result_Success<R, E>)d)._value;
      }
    }
    public E dtor_error {
      get {
        var d = this;
        return ((Result_Failure<R, E>)d)._error;
      }
    }
    public abstract _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1);
    public bool IsFailure() {
      return (this).is_Failure;
    }
    public Std.Wrappers._IResult<__U, E> PropagateFailure<__U>() {
      return Std.Wrappers.Result<__U, E>.create_Failure((this).dtor_error);
    }
    public R Extract() {
      return (this).dtor_value;
    }
    public static R GetOr(Std.Wrappers._IResult<R, E> _this, R @default) {
      Std.Wrappers._IResult<R, E> _source3 = _this;
      if (_source3.is_Success) {
        R _6___mcc_h0 = _source3.dtor_value;
        R _7_s = _6___mcc_h0;
        return _7_s;
      } else {
        E _8___mcc_h1 = _source3.dtor_error;
        E _9_e = _8___mcc_h1;
        return @default;
      }
    }
    public Std.Wrappers._IOption<R> ToOption() {
      Std.Wrappers._IResult<R, E> _source4 = this;
      if (_source4.is_Success) {
        R _10___mcc_h0 = _source4.dtor_value;
        R _11_s = _10___mcc_h0;
        return Std.Wrappers.Option<R>.create_Some(_11_s);
      } else {
        E _12___mcc_h1 = _source4.dtor_error;
        E _13_e = _12___mcc_h1;
        return Std.Wrappers.Option<R>.create_None();
      }
    }
    public Std.Wrappers._IOutcome<E> ToOutcome() {
      Std.Wrappers._IResult<R, E> _source5 = this;
      if (_source5.is_Success) {
        R _14___mcc_h0 = _source5.dtor_value;
        R _15_s = _14___mcc_h0;
        return Std.Wrappers.Outcome<E>.create_Pass();
      } else {
        E _16___mcc_h1 = _source5.dtor_error;
        E _17_e = _16___mcc_h1;
        return Std.Wrappers.Outcome<E>.create_Fail(_17_e);
      }
    }
    public static __FC Map<__FC>(Std.Wrappers._IResult<R, E> _this, Func<Std.Wrappers._IResult<R, E>, __FC> rewrap) {
      return Dafny.Helpers.Id<Func<Std.Wrappers._IResult<R, E>, __FC>>(rewrap)(_this);
    }
    public static Std.Wrappers._IResult<R, __NewE> MapFailure<__NewE>(Std.Wrappers._IResult<R, E> _this, Func<E, __NewE> reWrap) {
      Std.Wrappers._IResult<R, E> _source6 = _this;
      if (_source6.is_Success) {
        R _18___mcc_h0 = _source6.dtor_value;
        R _19_s = _18___mcc_h0;
        return Std.Wrappers.Result<R, __NewE>.create_Success(_19_s);
      } else {
        E _20___mcc_h1 = _source6.dtor_error;
        E _21_e = _20___mcc_h1;
        return Std.Wrappers.Result<R, __NewE>.create_Failure(Dafny.Helpers.Id<Func<E, __NewE>>(reWrap)(_21_e));
      }
    }
  }
  public class Result_Success<R, E> : Result<R, E> {
    public readonly R _value;
    public Result_Success(R @value) : base() {
      this._value = @value;
    }
    public override _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1) {
      if (this is _IResult<__R, __E> dt) { return dt; }
      return new Result_Success<__R, __E>(converter0(_value));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Result_Success<R, E>;
      return oth != null && object.Equals(this._value, oth._value);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._value));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Result.Success";
      s += "(";
      s += Dafny.Helpers.ToString(this._value);
      s += ")";
      return s;
    }
  }
  public class Result_Failure<R, E> : Result<R, E> {
    public readonly E _error;
    public Result_Failure(E error) : base() {
      this._error = error;
    }
    public override _IResult<__R, __E> DowncastClone<__R, __E>(Func<R, __R> converter0, Func<E, __E> converter1) {
      if (this is _IResult<__R, __E> dt) { return dt; }
      return new Result_Failure<__R, __E>(converter1(_error));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Result_Failure<R, E>;
      return oth != null && object.Equals(this._error, oth._error);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._error));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Result.Failure";
      s += "(";
      s += Dafny.Helpers.ToString(this._error);
      s += ")";
      return s;
    }
  }

  public interface _IOutcome<out E> {
    bool is_Pass { get; }
    bool is_Fail { get; }
    E dtor_error { get; }
    _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0);
    bool IsFailure();
    Std.Wrappers._IOutcome<E> PropagateFailure();
    Std.Wrappers._IOption<__R> ToOption<__R>(__R r);
    Std.Wrappers._IResult<__R, E> ToResult<__R>(__R r);
  }
  public abstract class Outcome<E> : _IOutcome<E> {
    public Outcome() {
    }
    public static Std.Wrappers._IOutcome<E> Default() {
      return create_Pass();
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IOutcome<E>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.Wrappers._IOutcome<E>>(Std.Wrappers.Outcome<E>.Default());
    }
    public static _IOutcome<E> create_Pass() {
      return new Outcome_Pass<E>();
    }
    public static _IOutcome<E> create_Fail(E error) {
      return new Outcome_Fail<E>(error);
    }
    public bool is_Pass { get { return this is Outcome_Pass<E>; } }
    public bool is_Fail { get { return this is Outcome_Fail<E>; } }
    public E dtor_error {
      get {
        var d = this;
        return ((Outcome_Fail<E>)d)._error;
      }
    }
    public abstract _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0);
    public bool IsFailure() {
      return (this).is_Fail;
    }
    public Std.Wrappers._IOutcome<E> PropagateFailure() {
      return this;
    }
    public Std.Wrappers._IOption<__R> ToOption<__R>(__R r) {
      Std.Wrappers._IOutcome<E> _source7 = this;
      if (_source7.is_Pass) {
        return Std.Wrappers.Option<__R>.create_Some(r);
      } else {
        E _22___mcc_h0 = _source7.dtor_error;
        E _23_e = _22___mcc_h0;
        return Std.Wrappers.Option<__R>.create_None();
      }
    }
    public Std.Wrappers._IResult<__R, E> ToResult<__R>(__R r) {
      Std.Wrappers._IOutcome<E> _source8 = this;
      if (_source8.is_Pass) {
        return Std.Wrappers.Result<__R, E>.create_Success(r);
      } else {
        E _24___mcc_h0 = _source8.dtor_error;
        E _25_e = _24___mcc_h0;
        return Std.Wrappers.Result<__R, E>.create_Failure(_25_e);
      }
    }
    public static __FC Map<__FC>(Std.Wrappers._IOutcome<E> _this, Func<Std.Wrappers._IOutcome<E>, __FC> rewrap) {
      return Dafny.Helpers.Id<Func<Std.Wrappers._IOutcome<E>, __FC>>(rewrap)(_this);
    }
    public static Std.Wrappers._IResult<__T, __NewE> MapFailure<__T, __NewE>(Std.Wrappers._IOutcome<E> _this, Func<E, __NewE> rewrap, __T @default)
    {
      Std.Wrappers._IOutcome<E> _source9 = _this;
      if (_source9.is_Pass) {
        return Std.Wrappers.Result<__T, __NewE>.create_Success(@default);
      } else {
        E _26___mcc_h0 = _source9.dtor_error;
        E _27_e = _26___mcc_h0;
        return Std.Wrappers.Result<__T, __NewE>.create_Failure(Dafny.Helpers.Id<Func<E, __NewE>>(rewrap)(_27_e));
      }
    }
    public static Std.Wrappers._IOutcome<E> Need(bool condition, E error)
    {
      if (condition) {
        return Std.Wrappers.Outcome<E>.create_Pass();
      } else {
        return Std.Wrappers.Outcome<E>.create_Fail(error);
      }
    }
  }
  public class Outcome_Pass<E> : Outcome<E> {
    public Outcome_Pass() : base() {
    }
    public override _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcome<__E> dt) { return dt; }
      return new Outcome_Pass<__E>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Outcome_Pass<E>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Outcome.Pass";
      return s;
    }
  }
  public class Outcome_Fail<E> : Outcome<E> {
    public readonly E _error;
    public Outcome_Fail(E error) : base() {
      this._error = error;
    }
    public override _IOutcome<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcome<__E> dt) { return dt; }
      return new Outcome_Fail<__E>(converter0(_error));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.Outcome_Fail<E>;
      return oth != null && object.Equals(this._error, oth._error);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._error));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.Outcome.Fail";
      s += "(";
      s += Dafny.Helpers.ToString(this._error);
      s += ")";
      return s;
    }
  }

  public interface _IOutcomeResult<out E> {
    bool is_Pass_k { get; }
    bool is_Fail_k { get; }
    E dtor_error { get; }
    _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0);
    bool IsFailure();
    Std.Wrappers._IResult<__U, E> PropagateFailure<__U>();
  }
  public abstract class OutcomeResult<E> : _IOutcomeResult<E> {
    public OutcomeResult() {
    }
    public static Std.Wrappers._IOutcomeResult<E> Default() {
      return create_Pass_k();
    }
    public static Dafny.TypeDescriptor<Std.Wrappers._IOutcomeResult<E>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.Wrappers._IOutcomeResult<E>>(Std.Wrappers.OutcomeResult<E>.Default());
    }
    public static _IOutcomeResult<E> create_Pass_k() {
      return new OutcomeResult_Pass_k<E>();
    }
    public static _IOutcomeResult<E> create_Fail_k(E error) {
      return new OutcomeResult_Fail_k<E>(error);
    }
    public bool is_Pass_k { get { return this is OutcomeResult_Pass_k<E>; } }
    public bool is_Fail_k { get { return this is OutcomeResult_Fail_k<E>; } }
    public E dtor_error {
      get {
        var d = this;
        return ((OutcomeResult_Fail_k<E>)d)._error;
      }
    }
    public abstract _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0);
    public bool IsFailure() {
      return (this).is_Fail_k;
    }
    public Std.Wrappers._IResult<__U, E> PropagateFailure<__U>() {
      return Std.Wrappers.Result<__U, E>.create_Failure((this).dtor_error);
    }
  }
  public class OutcomeResult_Pass_k<E> : OutcomeResult<E> {
    public OutcomeResult_Pass_k() : base() {
    }
    public override _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcomeResult<__E> dt) { return dt; }
      return new OutcomeResult_Pass_k<__E>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.OutcomeResult_Pass_k<E>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.OutcomeResult.Pass'";
      return s;
    }
  }
  public class OutcomeResult_Fail_k<E> : OutcomeResult<E> {
    public readonly E _error;
    public OutcomeResult_Fail_k(E error) : base() {
      this._error = error;
    }
    public override _IOutcomeResult<__E> DowncastClone<__E>(Func<E, __E> converter0) {
      if (this is _IOutcomeResult<__E> dt) { return dt; }
      return new OutcomeResult_Fail_k<__E>(converter0(_error));
    }
    public override bool Equals(object other) {
      var oth = other as Std.Wrappers.OutcomeResult_Fail_k<E>;
      return oth != null && object.Equals(this._error, oth._error);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._error));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Wrappers.OutcomeResult.Fail'";
      s += "(";
      s += Dafny.Helpers.ToString(this._error);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.Wrappers
namespace Std.BoundedInts {

  public partial class __default {
    public static BigInteger TWO__TO__THE__8 { get {
      return new BigInteger(256);
    } }
    public static byte UINT8__MAX { get {
      return (byte)(255);
    } }
    public static BigInteger TWO__TO__THE__16 { get {
      return new BigInteger(65536);
    } }
    public static ushort UINT16__MAX { get {
      return (ushort)(65535);
    } }
    public static BigInteger TWO__TO__THE__32 { get {
      return new BigInteger(4294967296L);
    } }
    public static uint UINT32__MAX { get {
      return 4294967295U;
    } }
    public static BigInteger TWO__TO__THE__64 { get {
      return BigInteger.Parse("18446744073709551616");
    } }
    public static ulong UINT64__MAX { get {
      return 18446744073709551615UL;
    } }
    public static BigInteger TWO__TO__THE__7 { get {
      return new BigInteger(128);
    } }
    public static sbyte INT8__MIN { get {
      return (sbyte)(-128);
    } }
    public static sbyte INT8__MAX { get {
      return (sbyte)(127);
    } }
    public static BigInteger TWO__TO__THE__15 { get {
      return new BigInteger(32768);
    } }
    public static short INT16__MIN { get {
      return (short)(-32768);
    } }
    public static short INT16__MAX { get {
      return (short)(32767);
    } }
    public static BigInteger TWO__TO__THE__31 { get {
      return new BigInteger(2147483648L);
    } }
    public static int INT32__MIN { get {
      return -2147483648;
    } }
    public static int INT32__MAX { get {
      return 2147483647;
    } }
    public static BigInteger TWO__TO__THE__63 { get {
      return new BigInteger(9223372036854775808UL);
    } }
    public static long INT64__MIN { get {
      return -9223372036854775808L;
    } }
    public static long INT64__MAX { get {
      return 9223372036854775807L;
    } }
    public static byte NAT8__MAX { get {
      return (byte)(127);
    } }
    public static ushort NAT16__MAX { get {
      return (ushort)(32767);
    } }
    public static uint NAT32__MAX { get {
      return 2147483647U;
    } }
    public static ulong NAT64__MAX { get {
      return 9223372036854775807UL;
    } }
    public static BigInteger TWO__TO__THE__128 { get {
      return BigInteger.Parse("340282366920938463463374607431768211456");
    } }
    public static BigInteger TWO__TO__THE__127 { get {
      return BigInteger.Parse("170141183460469231731687303715884105728");
    } }
    public static BigInteger TWO__TO__THE__0 { get {
      return BigInteger.One;
    } }
    public static BigInteger TWO__TO__THE__1 { get {
      return new BigInteger(2);
    } }
    public static BigInteger TWO__TO__THE__2 { get {
      return new BigInteger(4);
    } }
    public static BigInteger TWO__TO__THE__4 { get {
      return new BigInteger(16);
    } }
    public static BigInteger TWO__TO__THE__5 { get {
      return new BigInteger(32);
    } }
    public static BigInteger TWO__TO__THE__24 { get {
      return new BigInteger(16777216);
    } }
    public static BigInteger TWO__TO__THE__40 { get {
      return new BigInteger(1099511627776L);
    } }
    public static BigInteger TWO__TO__THE__48 { get {
      return new BigInteger(281474976710656L);
    } }
    public static BigInteger TWO__TO__THE__56 { get {
      return new BigInteger(72057594037927936L);
    } }
    public static BigInteger TWO__TO__THE__256 { get {
      return BigInteger.Parse("115792089237316195423570985008687907853269984665640564039457584007913129639936");
    } }
    public static BigInteger TWO__TO__THE__512 { get {
      return BigInteger.Parse("13407807929942597099574024998205846127479365820592393377723561443721764030073546976801874298166903427690031858186486050853753882811946569946433649006084096");
    } }
  }

  public partial class uint8 {
    public static System.Collections.Generic.IEnumerable<byte> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (byte)j; }
    }
    private static readonly Dafny.TypeDescriptor<byte> _TYPE = new Dafny.TypeDescriptor<byte>(0);
    public static Dafny.TypeDescriptor<byte> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class uint16 {
    public static System.Collections.Generic.IEnumerable<ushort> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ushort)j; }
    }
    private static readonly Dafny.TypeDescriptor<ushort> _TYPE = new Dafny.TypeDescriptor<ushort>(0);
    public static Dafny.TypeDescriptor<ushort> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class uint32 {
    public static System.Collections.Generic.IEnumerable<uint> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (uint)j; }
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class uint64 {
    public static System.Collections.Generic.IEnumerable<ulong> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ulong)j; }
    }
    private static readonly Dafny.TypeDescriptor<ulong> _TYPE = new Dafny.TypeDescriptor<ulong>(0);
    public static Dafny.TypeDescriptor<ulong> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class uint128 {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class int8 {
    public static System.Collections.Generic.IEnumerable<sbyte> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (sbyte)j; }
    }
    private static readonly Dafny.TypeDescriptor<sbyte> _TYPE = new Dafny.TypeDescriptor<sbyte>(0);
    public static Dafny.TypeDescriptor<sbyte> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class int16 {
    public static System.Collections.Generic.IEnumerable<short> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (short)j; }
    }
    private static readonly Dafny.TypeDescriptor<short> _TYPE = new Dafny.TypeDescriptor<short>(0);
    public static Dafny.TypeDescriptor<short> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class int32 {
    public static System.Collections.Generic.IEnumerable<int> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (int)j; }
    }
    private static readonly Dafny.TypeDescriptor<int> _TYPE = new Dafny.TypeDescriptor<int>(0);
    public static Dafny.TypeDescriptor<int> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class int64 {
    public static System.Collections.Generic.IEnumerable<long> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (long)j; }
    }
    private static readonly Dafny.TypeDescriptor<long> _TYPE = new Dafny.TypeDescriptor<long>(0);
    public static Dafny.TypeDescriptor<long> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class int128 {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class nat8 {
    public static System.Collections.Generic.IEnumerable<byte> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (byte)j; }
    }
    private static readonly Dafny.TypeDescriptor<byte> _TYPE = new Dafny.TypeDescriptor<byte>(0);
    public static Dafny.TypeDescriptor<byte> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class nat16 {
    public static System.Collections.Generic.IEnumerable<ushort> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ushort)j; }
    }
    private static readonly Dafny.TypeDescriptor<ushort> _TYPE = new Dafny.TypeDescriptor<ushort>(0);
    public static Dafny.TypeDescriptor<ushort> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class nat32 {
    public static System.Collections.Generic.IEnumerable<uint> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (uint)j; }
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class nat64 {
    public static System.Collections.Generic.IEnumerable<ulong> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (ulong)j; }
    }
    private static readonly Dafny.TypeDescriptor<ulong> _TYPE = new Dafny.TypeDescriptor<ulong>(0);
    public static Dafny.TypeDescriptor<ulong> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class nat128 {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class opt__byte {
    public static System.Collections.Generic.IEnumerable<short> IntegerRange(BigInteger lo, BigInteger hi) {
      for (var j = lo; j < hi; j++) { yield return (short)j; }
    }
    private static readonly Dafny.TypeDescriptor<short> _TYPE = new Dafny.TypeDescriptor<short>(0);
    public static Dafny.TypeDescriptor<short> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.BoundedInts
namespace Std.Base64 {

  public partial class __default {
    public static bool IsBase64Char(Dafny.Rune c) {
      return (((((c) == (new Dafny.Rune('+'))) || ((c) == (new Dafny.Rune('/')))) || (((new Dafny.Rune('0')) <= (c)) && ((c) <= (new Dafny.Rune('9'))))) || (((new Dafny.Rune('A')) <= (c)) && ((c) <= (new Dafny.Rune('Z'))))) || (((new Dafny.Rune('a')) <= (c)) && ((c) <= (new Dafny.Rune('z'))));
    }
    public static bool IsUnpaddedBase64String(Dafny.ISequence<Dafny.Rune> s) {
      return ((Dafny.Helpers.EuclideanModulus(new BigInteger((s).Count), new BigInteger(4))).Sign == 0) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_28_s) => Dafny.Helpers.Quantifier<Dafny.Rune>((_28_s).UniqueElements, true, (((_forall_var_0) => {
        Dafny.Rune _29_k = (Dafny.Rune)_forall_var_0;
        return !((_28_s).Contains(_29_k)) || (Std.Base64.__default.IsBase64Char(_29_k));
      }))))(s));
    }
    public static Dafny.Rune IndexToChar(byte i) {
      if ((i) == ((byte)(63))) {
        return new Dafny.Rune('/');
      } else if ((i) == ((byte)(62))) {
        return new Dafny.Rune('+');
      } else if ((((byte)(52)) <= (i)) && ((i) <= ((byte)(61)))) {
        return new Dafny.Rune((int)(unchecked((byte)(((byte)((i) - ((byte)(4)))) & (byte)0x3F))));
      } else if ((((byte)(26)) <= (i)) && ((i) <= ((byte)(51)))) {
        return Dafny.Helpers.AddRunes(new Dafny.Rune((int)(i)), new Dafny.Rune((int)(new BigInteger(71))));
      } else {
        return Dafny.Helpers.AddRunes(new Dafny.Rune((int)(i)), new Dafny.Rune((int)(new BigInteger(65))));
      }
    }
    public static byte CharToIndex(Dafny.Rune c) {
      if ((c) == (new Dafny.Rune('/'))) {
        return (byte)(63);
      } else if ((c) == (new Dafny.Rune('+'))) {
        return (byte)(62);
      } else if (((new Dafny.Rune('0')) <= (c)) && ((c) <= (new Dafny.Rune('9')))) {
        return (byte)((Dafny.Helpers.AddRunes(c, new Dafny.Rune((int)(new BigInteger(4))))).Value);
      } else if (((new Dafny.Rune('a')) <= (c)) && ((c) <= (new Dafny.Rune('z')))) {
        return (byte)((Dafny.Helpers.SubtractRunes(c, new Dafny.Rune((int)(new BigInteger(71))))).Value);
      } else {
        return (byte)((Dafny.Helpers.SubtractRunes(c, new Dafny.Rune((int)(new BigInteger(65))))).Value);
      }
    }
    public static Dafny.ISequence<byte> BV24ToSeq(uint x) {
      byte _30_b0 = (byte)(((x) >> ((int)((byte)(16)))) & (255U));
      byte _31_b1 = (byte)(((x) >> ((int)((byte)(8)))) & (255U));
      byte _32_b2 = (byte)((x) & (255U));
      return Dafny.Sequence<byte>.FromElements(_30_b0, _31_b1, _32_b2);
    }
    public static uint SeqToBV24(Dafny.ISequence<byte> x) {
      return ((unchecked((uint)((((uint)((x).Select(BigInteger.Zero))) << ((int)((byte)(16)))) & (uint)0xFFFFFFU))) | (unchecked((uint)((((uint)((x).Select(BigInteger.One))) << ((int)((byte)(8)))) & (uint)0xFFFFFFU)))) | ((uint)((x).Select(new BigInteger(2))));
    }
    public static Dafny.ISequence<byte> BV24ToIndexSeq(uint x) {
      byte _33_b0 = (byte)(((x) >> ((int)((byte)(18)))) & (63U));
      byte _34_b1 = (byte)(((x) >> ((int)((byte)(12)))) & (63U));
      byte _35_b2 = (byte)(((x) >> ((int)((byte)(6)))) & (63U));
      byte _36_b3 = (byte)((x) & (63U));
      return Dafny.Sequence<byte>.FromElements(_33_b0, _34_b1, _35_b2, _36_b3);
    }
    public static uint IndexSeqToBV24(Dafny.ISequence<byte> x) {
      return (((unchecked((uint)((((uint)((x).Select(BigInteger.Zero))) << ((int)((byte)(18)))) & (uint)0xFFFFFFU))) | (unchecked((uint)((((uint)((x).Select(BigInteger.One))) << ((int)((byte)(12)))) & (uint)0xFFFFFFU)))) | (unchecked((uint)((((uint)((x).Select(new BigInteger(2)))) << ((int)((byte)(6)))) & (uint)0xFFFFFFU)))) | ((uint)((x).Select(new BigInteger(3))));
    }
    public static Dafny.ISequence<byte> DecodeBlock(Dafny.ISequence<byte> s) {
      return Std.Base64.__default.BV24ToSeq(Std.Base64.__default.IndexSeqToBV24(s));
    }
    public static Dafny.ISequence<byte> EncodeBlock(Dafny.ISequence<byte> s) {
      return Std.Base64.__default.BV24ToIndexSeq(Std.Base64.__default.SeqToBV24(s));
    }
    public static Dafny.ISequence<byte> DecodeRecursively(Dafny.ISequence<byte> s)
    {
      Dafny.ISequence<byte> b = Dafny.Sequence<byte>.Empty;
      BigInteger _37_resultLength;
      _37_resultLength = (Dafny.Helpers.EuclideanDivision(new BigInteger((s).Count), new BigInteger(4))) * (new BigInteger(3));
      byte[] _38_result;
      Func<BigInteger, byte> _init0 = ((System.Func<BigInteger, byte>)((_39_i) => {
        return (byte)(0);
      }));
      byte[] _nw0 = new byte[Dafny.Helpers.ToIntChecked(_37_resultLength, "array size exceeds memory limit")];
      for (var _i0_0 = 0; _i0_0 < new BigInteger(_nw0.Length); _i0_0++) {
        _nw0[(int)(_i0_0)] = _init0(_i0_0);
      }
      _38_result = _nw0;
      BigInteger _40_i;
      _40_i = new BigInteger((s).Count);
      BigInteger _41_j;
      _41_j = _37_resultLength;
      while ((_40_i).Sign == 1) {
        _40_i = (_40_i) - (new BigInteger(4));
        _41_j = (_41_j) - (new BigInteger(3));
        Dafny.ISequence<byte> _42_block;
        _42_block = Std.Base64.__default.DecodeBlock((s).Subsequence(_40_i, (_40_i) + (new BigInteger(4))));
        (_38_result)[(int)((_41_j))] = (_42_block).Select(BigInteger.Zero);
        BigInteger _index0 = (_41_j) + (BigInteger.One);
        (_38_result)[(int)(_index0)] = (_42_block).Select(BigInteger.One);
        BigInteger _index1 = (_41_j) + (new BigInteger(2));
        (_38_result)[(int)(_index1)] = (_42_block).Select(new BigInteger(2));
      }
      b = Dafny.Helpers.SeqFromArray(_38_result);
      return b;
    }
    public static Dafny.ISequence<byte> EncodeRecursively(Dafny.ISequence<byte> b)
    {
      Dafny.ISequence<byte> s = Dafny.Sequence<byte>.Empty;
      BigInteger _43_resultLength;
      _43_resultLength = (Dafny.Helpers.EuclideanDivision(new BigInteger((b).Count), new BigInteger(3))) * (new BigInteger(4));
      byte[] _44_result;
      Func<BigInteger, byte> _init1 = ((System.Func<BigInteger, byte>)((_45_i) => {
        return (byte)(0);
      }));
      byte[] _nw1 = new byte[Dafny.Helpers.ToIntChecked(_43_resultLength, "array size exceeds memory limit")];
      for (var _i0_1 = 0; _i0_1 < new BigInteger(_nw1.Length); _i0_1++) {
        _nw1[(int)(_i0_1)] = _init1(_i0_1);
      }
      _44_result = _nw1;
      BigInteger _46_i;
      _46_i = new BigInteger((b).Count);
      BigInteger _47_j;
      _47_j = _43_resultLength;
      while ((_46_i).Sign == 1) {
        _46_i = (_46_i) - (new BigInteger(3));
        _47_j = (_47_j) - (new BigInteger(4));
        Dafny.ISequence<byte> _48_block;
        _48_block = Std.Base64.__default.EncodeBlock((b).Subsequence(_46_i, (_46_i) + (new BigInteger(3))));
        (_44_result)[(int)((_47_j))] = (_48_block).Select(BigInteger.Zero);
        BigInteger _index2 = (_47_j) + (BigInteger.One);
        (_44_result)[(int)(_index2)] = (_48_block).Select(BigInteger.One);
        BigInteger _index3 = (_47_j) + (new BigInteger(2));
        (_44_result)[(int)(_index3)] = (_48_block).Select(new BigInteger(2));
        BigInteger _index4 = (_47_j) + (new BigInteger(3));
        (_44_result)[(int)(_index4)] = (_48_block).Select(new BigInteger(3));
      }
      s = Dafny.Helpers.SeqFromArray(_44_result);
      return s;
    }
    public static Dafny.ISequence<byte> FromCharsToIndices(Dafny.ISequence<Dafny.Rune> s) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim0 = new BigInteger((s).Count);
        var arr0 = new byte[Dafny.Helpers.ToIntChecked(dim0, "array size exceeds memory limit")];
        for (int i0 = 0; i0 < dim0; i0++) {
          var _49_i = (BigInteger) i0;
          arr0[(int)(_49_i)] = Std.Base64.__default.CharToIndex((s).Select(_49_i));
        }
        return Dafny.Sequence<byte>.FromArray(arr0);
      }))();
    }
    public static Dafny.ISequence<Dafny.Rune> FromIndicesToChars(Dafny.ISequence<byte> b) {
      return ((System.Func<Dafny.ISequence<Dafny.Rune>>) (() => {
        BigInteger dim1 = new BigInteger((b).Count);
        var arr1 = new Dafny.Rune[Dafny.Helpers.ToIntChecked(dim1, "array size exceeds memory limit")];
        for (int i1 = 0; i1 < dim1; i1++) {
          var _50_i = (BigInteger) i1;
          arr1[(int)(_50_i)] = Std.Base64.__default.IndexToChar((b).Select(_50_i));
        }
        return Dafny.Sequence<Dafny.Rune>.FromArray(arr1);
      }))();
    }
    public static Dafny.ISequence<byte> DecodeUnpadded(Dafny.ISequence<Dafny.Rune> s) {
      return Std.Base64.__default.DecodeRecursively(Std.Base64.__default.FromCharsToIndices(s));
    }
    public static Dafny.ISequence<Dafny.Rune> EncodeUnpadded(Dafny.ISequence<byte> b) {
      return Std.Base64.__default.FromIndicesToChars(Std.Base64.__default.EncodeRecursively(b));
    }
    public static bool Is1Padding(Dafny.ISequence<Dafny.Rune> s) {
      return ((((((new BigInteger((s).Count)) == (new BigInteger(4))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.Zero)))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.One)))) && (Std.Base64.__default.IsBase64Char((s).Select(new BigInteger(2))))) && (((byte)((Std.Base64.__default.CharToIndex((s).Select(new BigInteger(2)))) & ((byte)(3)))) == ((byte)(0)))) && (((s).Select(new BigInteger(3))) == (new Dafny.Rune('=')));
    }
    public static Dafny.ISequence<byte> Decode1Padding(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<byte> _51_d = Std.Base64.__default.DecodeBlock(Dafny.Sequence<byte>.FromElements(Std.Base64.__default.CharToIndex((s).Select(BigInteger.Zero)), Std.Base64.__default.CharToIndex((s).Select(BigInteger.One)), Std.Base64.__default.CharToIndex((s).Select(new BigInteger(2))), (byte)(0)));
      return Dafny.Sequence<byte>.FromElements((_51_d).Select(BigInteger.Zero), (_51_d).Select(BigInteger.One));
    }
    public static Dafny.ISequence<Dafny.Rune> Encode1Padding(Dafny.ISequence<byte> b) {
      Dafny.ISequence<byte> _52_e = Std.Base64.__default.EncodeBlock(Dafny.Sequence<byte>.FromElements((b).Select(BigInteger.Zero), (b).Select(BigInteger.One), (byte)(0)));
      return Dafny.Sequence<Dafny.Rune>.FromElements(Std.Base64.__default.IndexToChar((_52_e).Select(BigInteger.Zero)), Std.Base64.__default.IndexToChar((_52_e).Select(BigInteger.One)), Std.Base64.__default.IndexToChar((_52_e).Select(new BigInteger(2))), new Dafny.Rune('='));
    }
    public static bool Is2Padding(Dafny.ISequence<Dafny.Rune> s) {
      return ((((((new BigInteger((s).Count)) == (new BigInteger(4))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.Zero)))) && (Std.Base64.__default.IsBase64Char((s).Select(BigInteger.One)))) && (((byte)((Std.Base64.__default.CharToIndex((s).Select(BigInteger.One))) % ((byte)(16)))) == ((byte)(0)))) && (((s).Select(new BigInteger(2))) == (new Dafny.Rune('=')))) && (((s).Select(new BigInteger(3))) == (new Dafny.Rune('=')));
    }
    public static Dafny.ISequence<byte> Decode2Padding(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<byte> _53_d = Std.Base64.__default.DecodeBlock(Dafny.Sequence<byte>.FromElements(Std.Base64.__default.CharToIndex((s).Select(BigInteger.Zero)), Std.Base64.__default.CharToIndex((s).Select(BigInteger.One)), (byte)(0), (byte)(0)));
      return Dafny.Sequence<byte>.FromElements((_53_d).Select(BigInteger.Zero));
    }
    public static Dafny.ISequence<Dafny.Rune> Encode2Padding(Dafny.ISequence<byte> b) {
      Dafny.ISequence<byte> _54_e = Std.Base64.__default.EncodeBlock(Dafny.Sequence<byte>.FromElements((b).Select(BigInteger.Zero), (byte)(0), (byte)(0)));
      return Dafny.Sequence<Dafny.Rune>.FromElements(Std.Base64.__default.IndexToChar((_54_e).Select(BigInteger.Zero)), Std.Base64.__default.IndexToChar((_54_e).Select(BigInteger.One)), new Dafny.Rune('='), new Dafny.Rune('='));
    }
    public static bool IsBase64String(Dafny.ISequence<Dafny.Rune> s) {
      BigInteger _55_finalBlockStart = (new BigInteger((s).Count)) - (new BigInteger(4));
      return ((Dafny.Helpers.EuclideanModulus(new BigInteger((s).Count), new BigInteger(4))).Sign == 0) && ((Std.Base64.__default.IsUnpaddedBase64String(s)) || ((Std.Base64.__default.IsUnpaddedBase64String((s).Take(_55_finalBlockStart))) && ((Std.Base64.__default.Is1Padding((s).Drop(_55_finalBlockStart))) || (Std.Base64.__default.Is2Padding((s).Drop(_55_finalBlockStart))))));
    }
    public static Dafny.ISequence<byte> DecodeValid(Dafny.ISequence<Dafny.Rune> s) {
      if ((s).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return Dafny.Sequence<byte>.FromElements();
      } else {
        BigInteger _56_finalBlockStart = (new BigInteger((s).Count)) - (new BigInteger(4));
        Dafny.ISequence<Dafny.Rune> _57_prefix = (s).Take(_56_finalBlockStart);
        Dafny.ISequence<Dafny.Rune> _58_suffix = (s).Drop(_56_finalBlockStart);
        if (Std.Base64.__default.Is1Padding(_58_suffix)) {
          return Dafny.Sequence<byte>.Concat(Std.Base64.__default.DecodeUnpadded(_57_prefix), Std.Base64.__default.Decode1Padding(_58_suffix));
        } else if (Std.Base64.__default.Is2Padding(_58_suffix)) {
          return Dafny.Sequence<byte>.Concat(Std.Base64.__default.DecodeUnpadded(_57_prefix), Std.Base64.__default.Decode2Padding(_58_suffix));
        } else {
          return Std.Base64.__default.DecodeUnpadded(s);
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> DecodeBV(Dafny.ISequence<Dafny.Rune> s) {
      if (Std.Base64.__default.IsBase64String(s)) {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Success(Std.Base64.__default.DecodeValid(s));
      } else {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Failure(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("The encoding is malformed"));
      }
    }
    public static Dafny.ISequence<Dafny.Rune> EncodeBV(Dafny.ISequence<byte> b) {
      if ((Dafny.Helpers.EuclideanModulus(new BigInteger((b).Count), new BigInteger(3))).Sign == 0) {
        return Std.Base64.__default.EncodeUnpadded(b);
      } else if ((Dafny.Helpers.EuclideanModulus(new BigInteger((b).Count), new BigInteger(3))) == (BigInteger.One)) {
        Dafny.ISequence<Dafny.Rune> _59_s1 = Std.Base64.__default.EncodeUnpadded((b).Take((new BigInteger((b).Count)) - (BigInteger.One)));
        Dafny.ISequence<Dafny.Rune> _60_s2 = Std.Base64.__default.Encode2Padding((b).Drop((new BigInteger((b).Count)) - (BigInteger.One)));
        return Dafny.Sequence<Dafny.Rune>.Concat(_59_s1, _60_s2);
      } else {
        Dafny.ISequence<Dafny.Rune> _61_s1 = Std.Base64.__default.EncodeUnpadded((b).Take((new BigInteger((b).Count)) - (new BigInteger(2))));
        Dafny.ISequence<Dafny.Rune> _62_s2 = Std.Base64.__default.Encode1Padding((b).Drop((new BigInteger((b).Count)) - (new BigInteger(2))));
        return Dafny.Sequence<Dafny.Rune>.Concat(_61_s1, _62_s2);
      }
    }
    public static Dafny.ISequence<byte> UInt8sToBVs(Dafny.ISequence<byte> u) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim2 = new BigInteger((u).Count);
        var arr2 = new byte[Dafny.Helpers.ToIntChecked(dim2, "array size exceeds memory limit")];
        for (int i2 = 0; i2 < dim2; i2++) {
          var _63_i = (BigInteger) i2;
          arr2[(int)(_63_i)] = (byte)((u).Select(_63_i));
        }
        return Dafny.Sequence<byte>.FromArray(arr2);
      }))();
    }
    public static Dafny.ISequence<byte> BVsToUInt8s(Dafny.ISequence<byte> b) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim3 = new BigInteger((b).Count);
        var arr3 = new byte[Dafny.Helpers.ToIntChecked(dim3, "array size exceeds memory limit")];
        for (int i3 = 0; i3 < dim3; i3++) {
          var _64_i = (BigInteger) i3;
          arr3[(int)(_64_i)] = (byte)((b).Select(_64_i));
        }
        return Dafny.Sequence<byte>.FromArray(arr3);
      }))();
    }
    public static Dafny.ISequence<Dafny.Rune> Encode(Dafny.ISequence<byte> u) {
      return Std.Base64.__default.EncodeBV(Std.Base64.__default.UInt8sToBVs(u));
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> Decode(Dafny.ISequence<Dafny.Rune> s) {
      if (Std.Base64.__default.IsBase64String(s)) {
        Dafny.ISequence<byte> _65_b = Std.Base64.__default.DecodeValid(s);
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Success(Std.Base64.__default.BVsToUInt8s(_65_b));
      } else {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Failure(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("The encoding is malformed"));
      }
    }
  }
} // end of namespace Std.Base64
namespace Std.Relations {

} // end of namespace Std.Relations
namespace Std.Math {

  public partial class __default {
    public static BigInteger Min(BigInteger a, BigInteger b)
    {
      if ((a) < (b)) {
        return a;
      } else {
        return b;
      }
    }
    public static BigInteger Min3(BigInteger a, BigInteger b, BigInteger c)
    {
      return Std.Math.__default.Min(a, Std.Math.__default.Min(b, c));
    }
    public static BigInteger Max(BigInteger a, BigInteger b)
    {
      if ((a) < (b)) {
        return b;
      } else {
        return a;
      }
    }
    public static BigInteger Max3(BigInteger a, BigInteger b, BigInteger c)
    {
      return Std.Math.__default.Max(a, Std.Math.__default.Max(b, c));
    }
    public static BigInteger Abs(BigInteger a) {
      if ((a).Sign == -1) {
        return (BigInteger.Zero) - (a);
      } else {
        return a;
      }
    }
  }
} // end of namespace Std.Math
namespace Std.Collections.Seq {

  public partial class __default {
    public static __T First<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Select(BigInteger.Zero);
    }
    public static Dafny.ISequence<__T> DropFirst<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Drop(BigInteger.One);
    }
    public static __T Last<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Select((new BigInteger((xs).Count)) - (BigInteger.One));
    }
    public static Dafny.ISequence<__T> DropLast<__T>(Dafny.ISequence<__T> xs) {
      return (xs).Take((new BigInteger((xs).Count)) - (BigInteger.One));
    }
    public static __T[] ToArray<__T>(Dafny.ISequence<__T> xs)
    {
      __T[] a = new __T[0];
      Func<BigInteger, __T> _init2 = Dafny.Helpers.Id<Func<Dafny.ISequence<__T>, Func<BigInteger, __T>>>((_66_xs) => ((System.Func<BigInteger, __T>)((_67_i) => {
        return (_66_xs).Select(_67_i);
      })))(xs);
      __T[] _nw2 = new __T[Dafny.Helpers.ToIntChecked(new BigInteger((xs).Count), "array size exceeds memory limit")];
      for (var _i0_2 = 0; _i0_2 < new BigInteger(_nw2.Length); _i0_2++) {
        _nw2[(int)(_i0_2)] = _init2(_i0_2);
      }
      a = _nw2;
      return a;
    }
    public static Dafny.ISet<__T> ToSet<__T>(Dafny.ISequence<__T> xs) {
      return Dafny.Helpers.Id<Func<Dafny.ISequence<__T>, Dafny.ISet<__T>>>((_68_xs) => ((System.Func<Dafny.ISet<__T>>)(() => {
        var _coll0 = new System.Collections.Generic.List<__T>();
        foreach (__T _compr_0 in (_68_xs).Elements) {
          __T _69_x = (__T)_compr_0;
          if ((_68_xs).Contains(_69_x)) {
            _coll0.Add(_69_x);
          }
        }
        return Dafny.Set<__T>.FromCollection(_coll0);
      }))())(xs);
    }
    public static BigInteger IndexOf<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      BigInteger _70___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if (object.Equals((xs).Select(BigInteger.Zero), v)) {
        return (BigInteger.Zero) + (_70___accumulator);
      } else {
        _70___accumulator = (_70___accumulator) + (BigInteger.One);
        Dafny.ISequence<__T> _in0 = (xs).Drop(BigInteger.One);
        __T _in1 = v;
        xs = _in0;
        v = _in1;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IOption<BigInteger> IndexOfOption<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Std.Wrappers.Option<BigInteger>.create_None();
      } else if (object.Equals((xs).Select(BigInteger.Zero), v)) {
        return Std.Wrappers.Option<BigInteger>.create_Some(BigInteger.Zero);
      } else {
        Std.Wrappers._IOption<BigInteger> _71_o_k = Std.Collections.Seq.__default.IndexOfOption<__T>((xs).Drop(BigInteger.One), v);
        if ((_71_o_k).is_Some) {
          return Std.Wrappers.Option<BigInteger>.create_Some(((_71_o_k).dtor_value) + (BigInteger.One));
        } else {
          return Std.Wrappers.Option<BigInteger>.create_None();
        }
      }
    }
    public static BigInteger LastIndexOf<__T>(Dafny.ISequence<__T> xs, __T v)
    {
    TAIL_CALL_START: ;
      if (object.Equals((xs).Select((new BigInteger((xs).Count)) - (BigInteger.One)), v)) {
        return (new BigInteger((xs).Count)) - (BigInteger.One);
      } else {
        Dafny.ISequence<__T> _in2 = (xs).Take((new BigInteger((xs).Count)) - (BigInteger.One));
        __T _in3 = v;
        xs = _in2;
        v = _in3;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IOption<BigInteger> LastIndexOfOption<__T>(Dafny.ISequence<__T> xs, __T v)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Std.Wrappers.Option<BigInteger>.create_None();
      } else if (object.Equals((xs).Select((new BigInteger((xs).Count)) - (BigInteger.One)), v)) {
        return Std.Wrappers.Option<BigInteger>.create_Some((new BigInteger((xs).Count)) - (BigInteger.One));
      } else {
        Dafny.ISequence<__T> _in4 = (xs).Take((new BigInteger((xs).Count)) - (BigInteger.One));
        __T _in5 = v;
        xs = _in4;
        v = _in5;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> Remove<__T>(Dafny.ISequence<__T> xs, BigInteger pos)
    {
      return Dafny.Sequence<__T>.Concat((xs).Take(pos), (xs).Drop((pos) + (BigInteger.One)));
    }
    public static Dafny.ISequence<__T> RemoveValue<__T>(Dafny.ISequence<__T> xs, __T v)
    {
      if (!(xs).Contains(v)) {
        return xs;
      } else {
        BigInteger _72_i = Std.Collections.Seq.__default.IndexOf<__T>(xs, v);
        return Dafny.Sequence<__T>.Concat((xs).Take(_72_i), (xs).Drop((_72_i) + (BigInteger.One)));
      }
    }
    public static Dafny.ISequence<__T> Insert<__T>(Dafny.ISequence<__T> xs, __T a, BigInteger pos)
    {
      return Dafny.Sequence<__T>.Concat(Dafny.Sequence<__T>.Concat((xs).Take(pos), Dafny.Sequence<__T>.FromElements(a)), (xs).Drop(pos));
    }
    public static Dafny.ISequence<__T> Reverse<__T>(Dafny.ISequence<__T> xs) {
      Dafny.ISequence<__T> _73___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((xs).Equals(Dafny.Sequence<__T>.FromElements())) {
        return Dafny.Sequence<__T>.Concat(_73___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _73___accumulator = Dafny.Sequence<__T>.Concat(_73___accumulator, Dafny.Sequence<__T>.FromElements((xs).Select((new BigInteger((xs).Count)) - (BigInteger.One))));
        Dafny.ISequence<__T> _in6 = (xs).Subsequence(BigInteger.Zero, (new BigInteger((xs).Count)) - (BigInteger.One));
        xs = _in6;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> Repeat<__T>(__T v, BigInteger length)
    {
      Dafny.ISequence<__T> _74___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((length).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_74___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _74___accumulator = Dafny.Sequence<__T>.Concat(_74___accumulator, Dafny.Sequence<__T>.FromElements(v));
        __T _in7 = v;
        BigInteger _in8 = (length) - (BigInteger.One);
        v = _in7;
        length = _in8;
        goto TAIL_CALL_START;
      }
    }
    public static _System._ITuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>> Unzip<__A, __B>(Dafny.ISequence<_System._ITuple2<__A, __B>> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>>.create(Dafny.Sequence<__A>.FromElements(), Dafny.Sequence<__B>.FromElements());
      } else {
        _System._ITuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>> _let_tmp_rhs0 = Std.Collections.Seq.__default.Unzip<__A, __B>(Std.Collections.Seq.__default.DropLast<_System._ITuple2<__A, __B>>(xs));
        Dafny.ISequence<__A> _75_a = _let_tmp_rhs0.dtor__0;
        Dafny.ISequence<__B> _76_b = _let_tmp_rhs0.dtor__1;
        return _System.Tuple2<Dafny.ISequence<__A>, Dafny.ISequence<__B>>.create(Dafny.Sequence<__A>.Concat(_75_a, Dafny.Sequence<__A>.FromElements((Std.Collections.Seq.__default.Last<_System._ITuple2<__A, __B>>(xs)).dtor__0)), Dafny.Sequence<__B>.Concat(_76_b, Dafny.Sequence<__B>.FromElements((Std.Collections.Seq.__default.Last<_System._ITuple2<__A, __B>>(xs)).dtor__1)));
      }
    }
    public static Dafny.ISequence<_System._ITuple2<__A, __B>> Zip<__A, __B>(Dafny.ISequence<__A> xs, Dafny.ISequence<__B> ys)
    {
      Dafny.ISequence<_System._ITuple2<__A, __B>> _77___accumulator = Dafny.Sequence<_System._ITuple2<__A, __B>>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<_System._ITuple2<__A, __B>>.Concat(Dafny.Sequence<_System._ITuple2<__A, __B>>.FromElements(), _77___accumulator);
      } else {
        _77___accumulator = Dafny.Sequence<_System._ITuple2<__A, __B>>.Concat(Dafny.Sequence<_System._ITuple2<__A, __B>>.FromElements(_System.Tuple2<__A, __B>.create(Std.Collections.Seq.__default.Last<__A>(xs), Std.Collections.Seq.__default.Last<__B>(ys))), _77___accumulator);
        Dafny.ISequence<__A> _in9 = Std.Collections.Seq.__default.DropLast<__A>(xs);
        Dafny.ISequence<__B> _in10 = Std.Collections.Seq.__default.DropLast<__B>(ys);
        xs = _in9;
        ys = _in10;
        goto TAIL_CALL_START;
      }
    }
    public static BigInteger Max(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)) == (BigInteger.One)) {
        return (xs).Select(BigInteger.Zero);
      } else {
        return Std.Math.__default.Max((xs).Select(BigInteger.Zero), Std.Collections.Seq.__default.Max((xs).Drop(BigInteger.One)));
      }
    }
    public static BigInteger Min(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)) == (BigInteger.One)) {
        return (xs).Select(BigInteger.Zero);
      } else {
        return Std.Math.__default.Min((xs).Select(BigInteger.Zero), Std.Collections.Seq.__default.Min((xs).Drop(BigInteger.One)));
      }
    }
    public static Dafny.ISequence<__T> Flatten<__T>(Dafny.ISequence<Dafny.ISequence<__T>> xs) {
      Dafny.ISequence<__T> _78___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_78___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _78___accumulator = Dafny.Sequence<__T>.Concat(_78___accumulator, (xs).Select(BigInteger.Zero));
        Dafny.ISequence<Dafny.ISequence<__T>> _in11 = (xs).Drop(BigInteger.One);
        xs = _in11;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__T> FlattenReverse<__T>(Dafny.ISequence<Dafny.ISequence<__T>> xs) {
      Dafny.ISequence<__T> _79___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(Dafny.Sequence<__T>.FromElements(), _79___accumulator);
      } else {
        _79___accumulator = Dafny.Sequence<__T>.Concat(Std.Collections.Seq.__default.Last<Dafny.ISequence<__T>>(xs), _79___accumulator);
        Dafny.ISequence<Dafny.ISequence<__T>> _in12 = Std.Collections.Seq.__default.DropLast<Dafny.ISequence<__T>>(xs);
        xs = _in12;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<__R> Map<__T, __R>(Func<__T, __R> f, Dafny.ISequence<__T> xs)
    {
      Dafny.ISequence<__R> _80___accumulator = Dafny.Sequence<__R>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__R>.Concat(_80___accumulator, Dafny.Sequence<__R>.FromElements());
      } else {
        _80___accumulator = Dafny.Sequence<__R>.Concat(_80___accumulator, Dafny.Sequence<__R>.FromElements(Dafny.Helpers.Id<Func<__T, __R>>(f)((xs).Select(BigInteger.Zero))));
        Func<__T, __R> _in13 = f;
        Dafny.ISequence<__T> _in14 = (xs).Drop(BigInteger.One);
        f = _in13;
        xs = _in14;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<__R>, __E> MapWithResult<__T, __R, __E>(Func<__T, Std.Wrappers._IResult<__R, __E>> f, Dafny.ISequence<__T> xs)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Std.Wrappers.Result<Dafny.ISequence<__R>, __E>.create_Success(Dafny.Sequence<__R>.FromElements());
      } else {
        Std.Wrappers._IResult<__R, __E> _81_valueOrError0 = Dafny.Helpers.Id<Func<__T, Std.Wrappers._IResult<__R, __E>>>(f)((xs).Select(BigInteger.Zero));
        if ((_81_valueOrError0).IsFailure()) {
          return (_81_valueOrError0).PropagateFailure<Dafny.ISequence<__R>>();
        } else {
          __R _82_head = (_81_valueOrError0).Extract();
          Std.Wrappers._IResult<Dafny.ISequence<__R>, __E> _83_valueOrError1 = Std.Collections.Seq.__default.MapWithResult<__T, __R, __E>(f, (xs).Drop(BigInteger.One));
          if ((_83_valueOrError1).IsFailure()) {
            return (_83_valueOrError1).PropagateFailure<Dafny.ISequence<__R>>();
          } else {
            Dafny.ISequence<__R> _84_tail = (_83_valueOrError1).Extract();
            return Std.Wrappers.Result<Dafny.ISequence<__R>, __E>.create_Success(Dafny.Sequence<__R>.Concat(Dafny.Sequence<__R>.FromElements(_82_head), _84_tail));
          }
        }
      }
    }
    public static Dafny.ISequence<__T> Filter<__T>(Func<__T, bool> f, Dafny.ISequence<__T> xs)
    {
      Dafny.ISequence<__T> _85___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_85___accumulator, Dafny.Sequence<__T>.FromElements());
      } else {
        _85___accumulator = Dafny.Sequence<__T>.Concat(_85___accumulator, ((Dafny.Helpers.Id<Func<__T, bool>>(f)((xs).Select(BigInteger.Zero))) ? (Dafny.Sequence<__T>.FromElements((xs).Select(BigInteger.Zero))) : (Dafny.Sequence<__T>.FromElements())));
        Func<__T, bool> _in15 = f;
        Dafny.ISequence<__T> _in16 = (xs).Drop(BigInteger.One);
        f = _in15;
        xs = _in16;
        goto TAIL_CALL_START;
      }
    }
    public static __A FoldLeft<__A, __T>(Func<__A, __T, __A> f, __A init, Dafny.ISequence<__T> xs)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return init;
      } else {
        Func<__A, __T, __A> _in17 = f;
        __A _in18 = Dafny.Helpers.Id<Func<__A, __T, __A>>(f)(init, (xs).Select(BigInteger.Zero));
        Dafny.ISequence<__T> _in19 = (xs).Drop(BigInteger.One);
        f = _in17;
        init = _in18;
        xs = _in19;
        goto TAIL_CALL_START;
      }
    }
    public static __A FoldRight<__A, __T>(Func<__T, __A, __A> f, Dafny.ISequence<__T> xs, __A init)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return init;
      } else {
        return Dafny.Helpers.Id<Func<__T, __A, __A>>(f)((xs).Select(BigInteger.Zero), Std.Collections.Seq.__default.FoldRight<__A, __T>(f, (xs).Drop(BigInteger.One), init));
      }
    }
    public static Dafny.ISequence<__T> SetToSeq<__T>(Dafny.ISet<__T> s)
    {
      Dafny.ISequence<__T> xs = Dafny.Sequence<__T>.Empty;
      xs = Dafny.Sequence<__T>.FromElements();
      Dafny.ISet<__T> _86_left;
      _86_left = s;
      while (!(_86_left).Equals(Dafny.Set<__T>.FromElements())) {
        __T _87_x;
        foreach (__T _assign_such_that_0 in (_86_left).Elements) {
          _87_x = (__T)_assign_such_that_0;
          if ((_86_left).Contains(_87_x)) {
            goto after__ASSIGN_SUCH_THAT_0;
          }
        }
        throw new System.Exception("assign-such-that search produced no value (line 7192)");
      after__ASSIGN_SUCH_THAT_0: ;
        _86_left = Dafny.Set<__T>.Difference(_86_left, Dafny.Set<__T>.FromElements(_87_x));
        xs = Dafny.Sequence<__T>.Concat(xs, Dafny.Sequence<__T>.FromElements(_87_x));
      }
      return xs;
    }
    public static Dafny.ISequence<__T> SetToSortedSeq<__T>(Dafny.ISet<__T> s, Func<__T, __T, bool> R)
    {
      Dafny.ISequence<__T> xs = Dafny.Sequence<__T>.Empty;
      Dafny.ISequence<__T> _out0;
      _out0 = Std.Collections.Seq.__default.SetToSeq<__T>(s);
      xs = _out0;
      xs = Std.Collections.Seq.__default.MergeSortBy<__T>(R, xs);
      return xs;
    }
    public static Dafny.ISequence<__T> MergeSortBy<__T>(Func<__T, __T, bool> lessThanOrEq, Dafny.ISequence<__T> a)
    {
      if ((new BigInteger((a).Count)) <= (BigInteger.One)) {
        return a;
      } else {
        BigInteger _88_splitIndex = Dafny.Helpers.EuclideanDivision(new BigInteger((a).Count), new BigInteger(2));
        Dafny.ISequence<__T> _89_left = (a).Take(_88_splitIndex);
        Dafny.ISequence<__T> _90_right = (a).Drop(_88_splitIndex);
        Dafny.ISequence<__T> _91_leftSorted = Std.Collections.Seq.__default.MergeSortBy<__T>(lessThanOrEq, _89_left);
        Dafny.ISequence<__T> _92_rightSorted = Std.Collections.Seq.__default.MergeSortBy<__T>(lessThanOrEq, _90_right);
        return Std.Collections.Seq.__default.MergeSortedWith<__T>(_91_leftSorted, _92_rightSorted, lessThanOrEq);
      }
    }
    public static Dafny.ISequence<__T> MergeSortedWith<__T>(Dafny.ISequence<__T> left, Dafny.ISequence<__T> right, Func<__T, __T, bool> lessThanOrEq)
    {
      Dafny.ISequence<__T> _93___accumulator = Dafny.Sequence<__T>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((left).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_93___accumulator, right);
      } else if ((new BigInteger((right).Count)).Sign == 0) {
        return Dafny.Sequence<__T>.Concat(_93___accumulator, left);
      } else if (Dafny.Helpers.Id<Func<__T, __T, bool>>(lessThanOrEq)((left).Select(BigInteger.Zero), (right).Select(BigInteger.Zero))) {
        _93___accumulator = Dafny.Sequence<__T>.Concat(_93___accumulator, Dafny.Sequence<__T>.FromElements((left).Select(BigInteger.Zero)));
        Dafny.ISequence<__T> _in20 = (left).Drop(BigInteger.One);
        Dafny.ISequence<__T> _in21 = right;
        Func<__T, __T, bool> _in22 = lessThanOrEq;
        left = _in20;
        right = _in21;
        lessThanOrEq = _in22;
        goto TAIL_CALL_START;
      } else {
        _93___accumulator = Dafny.Sequence<__T>.Concat(_93___accumulator, Dafny.Sequence<__T>.FromElements((right).Select(BigInteger.Zero)));
        Dafny.ISequence<__T> _in23 = left;
        Dafny.ISequence<__T> _in24 = (right).Drop(BigInteger.One);
        Func<__T, __T, bool> _in25 = lessThanOrEq;
        left = _in23;
        right = _in24;
        lessThanOrEq = _in25;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Collections.Seq
namespace Std.Collections.Array {

  public partial class __default {
    public static Std.Wrappers._IOption<BigInteger> BinarySearch<__T>(__T[] a, __T key, Func<__T, __T, bool> less)
    {
      Std.Wrappers._IOption<BigInteger> r = Std.Wrappers.Option<BigInteger>.Default();
      BigInteger _94_lo;
      BigInteger _95_hi;
      BigInteger _rhs0 = BigInteger.Zero;
      BigInteger _rhs1 = new BigInteger((a).Length);
      _94_lo = _rhs0;
      _95_hi = _rhs1;
      while ((_94_lo) < (_95_hi)) {
        BigInteger _96_mid;
        _96_mid = Dafny.Helpers.EuclideanDivision((_94_lo) + (_95_hi), new BigInteger(2));
        if (Dafny.Helpers.Id<Func<__T, __T, bool>>(less)(key, (a)[(int)(_96_mid)])) {
          _95_hi = _96_mid;
        } else if (Dafny.Helpers.Id<Func<__T, __T, bool>>(less)((a)[(int)(_96_mid)], key)) {
          _94_lo = (_96_mid) + (BigInteger.One);
        } else {
          r = Std.Wrappers.Option<BigInteger>.create_Some(_96_mid);
          return r;
        }
      }
      r = Std.Wrappers.Option<BigInteger>.create_None();
      return r;
      return r;
    }
  }
} // end of namespace Std.Collections.Array
namespace Std.Collections.Imap {

  public partial class __default {
    public static Std.Wrappers._IOption<__Y> Get<__X, __Y>(Dafny.IMap<__X,__Y> m, __X x)
    {
      if ((m).Contains(x)) {
        return Std.Wrappers.Option<__Y>.create_Some(Dafny.Map<__X, __Y>.Select(m,x));
      } else {
        return Std.Wrappers.Option<__Y>.create_None();
      }
    }
  }
} // end of namespace Std.Collections.Imap
namespace Std.Functions {

} // end of namespace Std.Functions
namespace Std.Collections.Iset {

} // end of namespace Std.Collections.Iset
namespace Std.Collections.Map {

  public partial class __default {
    public static Std.Wrappers._IOption<__Y> Get<__X, __Y>(Dafny.IMap<__X,__Y> m, __X x)
    {
      if ((m).Contains(x)) {
        return Std.Wrappers.Option<__Y>.create_Some(Dafny.Map<__X, __Y>.Select(m,x));
      } else {
        return Std.Wrappers.Option<__Y>.create_None();
      }
    }
    public static Dafny.IMap<__X,__Y> ToImap<__X, __Y>(Dafny.IMap<__X,__Y> m) {
      return Dafny.Helpers.Id<Func<Dafny.IMap<__X,__Y>, Dafny.IMap<__X,__Y>>>((_97_m) => ((System.Func<Dafny.IMap<__X,__Y>>)(() => {
        var _coll1 = new System.Collections.Generic.List<Dafny.Pair<__X,__Y>>();
        foreach (__X _compr_1 in (_97_m).Keys.Elements) {
          __X _98_x = (__X)_compr_1;
          if ((_97_m).Contains(_98_x)) {
            _coll1.Add(new Dafny.Pair<__X,__Y>(_98_x, Dafny.Map<__X, __Y>.Select(_97_m,_98_x)));
          }
        }
        return Dafny.Map<__X,__Y>.FromCollection(_coll1);
      }))())(m);
    }
    public static Dafny.IMap<__X,__Y> RemoveKeys<__X, __Y>(Dafny.IMap<__X,__Y> m, Dafny.ISet<__X> xs)
    {
      return Dafny.Map<__X, __Y>.Subtract(m, xs);
    }
    public static Dafny.IMap<__X,__Y> Remove<__X, __Y>(Dafny.IMap<__X,__Y> m, __X x)
    {
      Dafny.IMap<__X,__Y> _99_m_k = Dafny.Helpers.Id<Func<Dafny.IMap<__X,__Y>, __X, Dafny.IMap<__X,__Y>>>((_100_m, _101_x) => ((System.Func<Dafny.IMap<__X,__Y>>)(() => {
        var _coll2 = new System.Collections.Generic.List<Dafny.Pair<__X,__Y>>();
        foreach (__X _compr_2 in (_100_m).Keys.Elements) {
          __X _102_x_k = (__X)_compr_2;
          if (((_100_m).Contains(_102_x_k)) && (!object.Equals(_102_x_k, _101_x))) {
            _coll2.Add(new Dafny.Pair<__X,__Y>(_102_x_k, Dafny.Map<__X, __Y>.Select(_100_m,_102_x_k)));
          }
        }
        return Dafny.Map<__X,__Y>.FromCollection(_coll2);
      }))())(m, x);
      return _99_m_k;
    }
    public static Dafny.IMap<__X,__Y> Restrict<__X, __Y>(Dafny.IMap<__X,__Y> m, Dafny.ISet<__X> xs)
    {
      return Dafny.Helpers.Id<Func<Dafny.ISet<__X>, Dafny.IMap<__X,__Y>, Dafny.IMap<__X,__Y>>>((_103_xs, _104_m) => ((System.Func<Dafny.IMap<__X,__Y>>)(() => {
        var _coll3 = new System.Collections.Generic.List<Dafny.Pair<__X,__Y>>();
        foreach (__X _compr_3 in (_103_xs).Elements) {
          __X _105_x = (__X)_compr_3;
          if (((_103_xs).Contains(_105_x)) && ((_104_m).Contains(_105_x))) {
            _coll3.Add(new Dafny.Pair<__X,__Y>(_105_x, Dafny.Map<__X, __Y>.Select(_104_m,_105_x)));
          }
        }
        return Dafny.Map<__X,__Y>.FromCollection(_coll3);
      }))())(xs, m);
    }
    public static Dafny.IMap<__X,__Y> Union<__X, __Y>(Dafny.IMap<__X,__Y> m, Dafny.IMap<__X,__Y> m_k)
    {
      return Dafny.Map<__X, __Y>.Merge(m, m_k);
    }
  }
} // end of namespace Std.Collections.Map
namespace Std.Collections.Set {

  public partial class __default {
    public static __T ExtractFromSingleton<__T>(Dafny.ISet<__T> s) {
      return Dafny.Helpers.Let<int, __T>(0, _let_dummy_0 =>  {
        __T _106_x = default(__T);
        foreach (__T _assign_such_that_1 in (s).Elements) {
          _106_x = (__T)_assign_such_that_1;
          if ((s).Contains(_106_x)) {
            goto after__ASSIGN_SUCH_THAT_1;
          }
        }
        throw new System.Exception("assign-such-that search produced no value (line 7369)");
      after__ASSIGN_SUCH_THAT_1: ;
        return _106_x;
      }
      );
    }
    public static Dafny.ISet<__Y> Map<__X, __Y>(Func<__X, __Y> f, Dafny.ISet<__X> xs)
    {
      Dafny.ISet<__Y> _107_ys = Dafny.Helpers.Id<Func<Dafny.ISet<__X>, Func<__X, __Y>, Dafny.ISet<__Y>>>((_108_xs, _109_f) => ((System.Func<Dafny.ISet<__Y>>)(() => {
        var _coll4 = new System.Collections.Generic.List<__Y>();
        foreach (__X _compr_4 in (_108_xs).Elements) {
          __X _110_x = (__X)_compr_4;
          if ((_108_xs).Contains(_110_x)) {
            _coll4.Add(Dafny.Helpers.Id<Func<__X, __Y>>(_109_f)(_110_x));
          }
        }
        return Dafny.Set<__Y>.FromCollection(_coll4);
      }))())(xs, f);
      return _107_ys;
    }
    public static Dafny.ISet<__X> Filter<__X>(Func<__X, bool> f, Dafny.ISet<__X> xs)
    {
      Dafny.ISet<__X> _111_ys = Dafny.Helpers.Id<Func<Dafny.ISet<__X>, Func<__X, bool>, Dafny.ISet<__X>>>((_112_xs, _113_f) => ((System.Func<Dafny.ISet<__X>>)(() => {
        var _coll5 = new System.Collections.Generic.List<__X>();
        foreach (__X _compr_5 in (_112_xs).Elements) {
          __X _114_x = (__X)_compr_5;
          if (((_112_xs).Contains(_114_x)) && (Dafny.Helpers.Id<Func<__X, bool>>(_113_f)(_114_x))) {
            _coll5.Add(_114_x);
          }
        }
        return Dafny.Set<__X>.FromCollection(_coll5);
      }))())(xs, f);
      return _111_ys;
    }
    public static Dafny.ISet<BigInteger> SetRange(BigInteger a, BigInteger b)
    {
      Dafny.ISet<BigInteger> _115___accumulator = Dafny.Set<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((a) == (b)) {
        return Dafny.Set<BigInteger>.Union(Dafny.Set<BigInteger>.FromElements(), _115___accumulator);
      } else {
        _115___accumulator = Dafny.Set<BigInteger>.Union(_115___accumulator, Dafny.Set<BigInteger>.FromElements(a));
        BigInteger _in26 = (a) + (BigInteger.One);
        BigInteger _in27 = b;
        a = _in26;
        b = _in27;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISet<BigInteger> SetRangeZeroBound(BigInteger n) {
      return Std.Collections.Set.__default.SetRange(BigInteger.Zero, n);
    }
  }
} // end of namespace Std.Collections.Set
namespace Std.Collections {

} // end of namespace Std.Collections
namespace Std.DynamicArray {


  public partial class DynamicArray<A> {
    public DynamicArray() {
      this.size = BigInteger.Zero;
      this.capacity = BigInteger.Zero;
      this.data = new A[0];
    }
    public BigInteger size {get; set;}
    public BigInteger capacity {get; set;}
    public A[] data {get; set;}
    public void __ctor()
    {
      (this).size = BigInteger.Zero;
      (this).capacity = BigInteger.Zero;
      A[] _nw3 = new A[Dafny.Helpers.ToIntChecked(BigInteger.Zero, "array size exceeds memory limit")];
      (this).data = _nw3;
    }
    public A At(BigInteger index) {
      return (this.data)[(int)(index)];
    }
    public void Put(BigInteger index, A element)
    {
      A[] _arr0 = this.data;
      _arr0[(int)((index))] = element;
    }
    public void Ensure(BigInteger reserved, A defaultValue)
    {
      BigInteger _116_newCapacity;
      _116_newCapacity = this.capacity;
      while ((reserved) > ((_116_newCapacity) - (this.size))) {
        _116_newCapacity = (this).DefaultNewCapacity(_116_newCapacity);
      }
      if ((_116_newCapacity) > (this.capacity)) {
        (this).Realloc(defaultValue, _116_newCapacity);
      }
    }
    public void PopFast()
    {
      (this).size = (this.size) - (BigInteger.One);
    }
    public void PushFast(A element)
    {
      A[] _arr1 = this.data;
      BigInteger _index5 = this.size;
      _arr1[(int)(_index5)] = element;
      (this).size = (this.size) + (BigInteger.One);
    }
    public void Push(A element)
    {
      if ((this.size) == (this.capacity)) {
        (this).ReallocDefault(element);
      }
      (this).PushFast(element);
    }
    public void Realloc(A defaultValue, BigInteger newCapacity)
    {
      A[] _117_oldData;
      BigInteger _118_oldCapacity;
      A[] _rhs2 = this.data;
      BigInteger _rhs3 = this.capacity;
      _117_oldData = _rhs2;
      _118_oldCapacity = _rhs3;
      Func<BigInteger, A> _init3 = Dafny.Helpers.Id<Func<A, Func<BigInteger, A>>>((_119_defaultValue) => ((System.Func<BigInteger, A>)((_120___v0) => {
        return _119_defaultValue;
      })))(defaultValue);
      A[] _nw4 = new A[Dafny.Helpers.ToIntChecked(newCapacity, "array size exceeds memory limit")];
      for (var _i0_3 = 0; _i0_3 < new BigInteger(_nw4.Length); _i0_3++) {
        _nw4[(int)(_i0_3)] = _init3(_i0_3);
      }
      A[] _rhs4 = _nw4;
      BigInteger _rhs5 = newCapacity;
      Std.DynamicArray.DynamicArray<A> _lhs0 = this;
      Std.DynamicArray.DynamicArray<A> _lhs1 = this;
      _lhs0.data = _rhs4;
      _lhs1.capacity = _rhs5;
      (this).CopyFrom(_117_oldData, _118_oldCapacity);
    }
    public BigInteger DefaultNewCapacity(BigInteger capacity) {
      if ((capacity).Sign == 0) {
        return new BigInteger(8);
      } else {
        return (new BigInteger(2)) * (capacity);
      }
    }
    public void ReallocDefault(A defaultValue)
    {
      (this).Realloc(defaultValue, (this).DefaultNewCapacity(this.capacity));
    }
    public void CopyFrom(A[] newData, BigInteger count)
    {
      foreach (BigInteger _guard_loop_0 in Dafny.Helpers.IntegerRange(BigInteger.Zero, count)) {
        BigInteger _121_index = (BigInteger)_guard_loop_0;
        if ((true) && (((_121_index).Sign != -1) && ((_121_index) < (count)))) {
          A[] _arr2 = this.data;
          _arr2[(int)((_121_index))] = (newData)[(int)(_121_index)];
        }
      }
    }
  }
} // end of namespace Std.DynamicArray
namespace Std.FileIO {

  public partial class __default {
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> ReadBytesFromFile(Dafny.ISequence<Dafny.Rune> path)
    {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>> res = Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.Default(Dafny.Sequence<byte>.Empty);
      bool _122_isError;
      Dafny.ISequence<byte> _123_bytesRead;
      Dafny.ISequence<Dafny.Rune> _124_errorMsg;
      bool _out1;
      Dafny.ISequence<byte> _out2;
      Dafny.ISequence<Dafny.Rune> _out3;
      Std.CSharpFileIOInternalExterns.__default.INTERNAL__ReadBytesFromFile(path, out _out1, out _out2, out _out3);
      _122_isError = _out1;
      _123_bytesRead = _out2;
      _124_errorMsg = _out3;
      res = ((_122_isError) ? (Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Failure(_124_errorMsg)) : (Std.Wrappers.Result<Dafny.ISequence<byte>, Dafny.ISequence<Dafny.Rune>>.create_Success(_123_bytesRead)));
      return res;
      return res;
    }
    public static Std.Wrappers._IResult<_System._ITuple0, Dafny.ISequence<Dafny.Rune>> WriteBytesToFile(Dafny.ISequence<Dafny.Rune> path, Dafny.ISequence<byte> bytes)
    {
      Std.Wrappers._IResult<_System._ITuple0, Dafny.ISequence<Dafny.Rune>> res = Std.Wrappers.Result<_System._ITuple0, Dafny.ISequence<Dafny.Rune>>.Default(_System.Tuple0.Default());
      bool _125_isError;
      Dafny.ISequence<Dafny.Rune> _126_errorMsg;
      bool _out4;
      Dafny.ISequence<Dafny.Rune> _out5;
      Std.CSharpFileIOInternalExterns.__default.INTERNAL__WriteBytesToFile(path, bytes, out _out4, out _out5);
      _125_isError = _out4;
      _126_errorMsg = _out5;
      res = ((_125_isError) ? (Std.Wrappers.Result<_System._ITuple0, Dafny.ISequence<Dafny.Rune>>.create_Failure(_126_errorMsg)) : (Std.Wrappers.Result<_System._ITuple0, Dafny.ISequence<Dafny.Rune>>.create_Success(_System.Tuple0.create())));
      return res;
      return res;
    }
  }
} // end of namespace Std.FileIO
namespace Std.Arithmetic.GeneralInternals {

} // end of namespace Std.Arithmetic.GeneralInternals
namespace Std.Arithmetic.MulInternalsNonlinear {

} // end of namespace Std.Arithmetic.MulInternalsNonlinear
namespace Std.Arithmetic.MulInternals {

  public partial class __default {
    public static BigInteger MulPos(BigInteger x, BigInteger y)
    {
      BigInteger _127___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((x).Sign == 0) {
        return (BigInteger.Zero) + (_127___accumulator);
      } else {
        _127___accumulator = (_127___accumulator) + (y);
        BigInteger _in28 = (x) - (BigInteger.One);
        BigInteger _in29 = y;
        x = _in28;
        y = _in29;
        goto TAIL_CALL_START;
      }
    }
    public static BigInteger MulRecursive(BigInteger x, BigInteger y)
    {
      if ((x).Sign != -1) {
        return Std.Arithmetic.MulInternals.__default.MulPos(x, y);
      } else {
        return (new BigInteger(-1)) * (Std.Arithmetic.MulInternals.__default.MulPos((new BigInteger(-1)) * (x), y));
      }
    }
  }
} // end of namespace Std.Arithmetic.MulInternals
namespace Std.Arithmetic.Mul {

} // end of namespace Std.Arithmetic.Mul
namespace Std.Arithmetic.ModInternalsNonlinear {

} // end of namespace Std.Arithmetic.ModInternalsNonlinear
namespace Std.Arithmetic.DivInternalsNonlinear {

} // end of namespace Std.Arithmetic.DivInternalsNonlinear
namespace Std.Arithmetic.ModInternals {

  public partial class __default {
    public static BigInteger ModRecursive(BigInteger x, BigInteger d)
    {
    TAIL_CALL_START: ;
      if ((x).Sign == -1) {
        BigInteger _in30 = (d) + (x);
        BigInteger _in31 = d;
        x = _in30;
        d = _in31;
        goto TAIL_CALL_START;
      } else if ((x) < (d)) {
        return x;
      } else {
        BigInteger _in32 = (x) - (d);
        BigInteger _in33 = d;
        x = _in32;
        d = _in33;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Arithmetic.ModInternals
namespace Std.Arithmetic.DivInternals {

  public partial class __default {
    public static BigInteger DivPos(BigInteger x, BigInteger d)
    {
      BigInteger _128___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((x).Sign == -1) {
        _128___accumulator = (_128___accumulator) + (new BigInteger(-1));
        BigInteger _in34 = (x) + (d);
        BigInteger _in35 = d;
        x = _in34;
        d = _in35;
        goto TAIL_CALL_START;
      } else if ((x) < (d)) {
        return (BigInteger.Zero) + (_128___accumulator);
      } else {
        _128___accumulator = (_128___accumulator) + (BigInteger.One);
        BigInteger _in36 = (x) - (d);
        BigInteger _in37 = d;
        x = _in36;
        d = _in37;
        goto TAIL_CALL_START;
      }
    }
    public static BigInteger DivRecursive(BigInteger x, BigInteger d)
    {
      if ((d).Sign == 1) {
        return Std.Arithmetic.DivInternals.__default.DivPos(x, d);
      } else {
        return (new BigInteger(-1)) * (Std.Arithmetic.DivInternals.__default.DivPos(x, (new BigInteger(-1)) * (d)));
      }
    }
  }
} // end of namespace Std.Arithmetic.DivInternals
namespace Std.Arithmetic.DivMod {

  public partial class __default {
    public static bool MultiplesVanish(BigInteger a, BigInteger b, BigInteger m)
    {
      return (Dafny.Helpers.EuclideanModulus(((m) * (a)) + (b), m)) == (Dafny.Helpers.EuclideanModulus(b, m));
    }
  }
} // end of namespace Std.Arithmetic.DivMod
namespace Std.Arithmetic.Power {

  public partial class __default {
    public static BigInteger Pow(BigInteger b, BigInteger e)
    {
      BigInteger _129___accumulator = BigInteger.One;
    TAIL_CALL_START: ;
      if ((e).Sign == 0) {
        return (BigInteger.One) * (_129___accumulator);
      } else {
        _129___accumulator = (_129___accumulator) * (b);
        BigInteger _in38 = b;
        BigInteger _in39 = (e) - (BigInteger.One);
        b = _in38;
        e = _in39;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Arithmetic.Power
namespace Std.Arithmetic.Logarithm {

  public partial class __default {
    public static BigInteger Log(BigInteger @base, BigInteger pow)
    {
      BigInteger _130___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((pow) < (@base)) {
        return (BigInteger.Zero) + (_130___accumulator);
      } else {
        _130___accumulator = (_130___accumulator) + (BigInteger.One);
        BigInteger _in40 = @base;
        BigInteger _in41 = Dafny.Helpers.EuclideanDivision(pow, @base);
        @base = _in40;
        pow = _in41;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Arithmetic.Logarithm
namespace Std.Arithmetic.Power2 {

  public partial class __default {
    public static BigInteger Pow2(BigInteger e) {
      return Std.Arithmetic.Power.__default.Pow(new BigInteger(2), e);
    }
  }
} // end of namespace Std.Arithmetic.Power2
namespace Std.Arithmetic {

} // end of namespace Std.Arithmetic
namespace Std.Strings.HexConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.Strings.HexConversion.__default.@base;
    }
    public static Dafny.ISequence<Dafny.Rune> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<Dafny.Rune> _131___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(), _131___accumulator);
      } else {
        _131___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.HexConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _131___accumulator);
        Dafny.ISequence<BigInteger> _in42 = (digits).Drop(BigInteger.One);
        digits = _in42;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<Dafny.Rune> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.HexConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.Strings.HexConversion.__default.OfDigits(Std.Strings.HexConversion.__default.FromNat(n));
      }
    }
    public static bool OfNumberStr(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      return !(!(str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.Strings.HexConversion.__default.chars).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_132_str) => Dafny.Helpers.Quantifier<Dafny.Rune>(((_132_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_1) => {
        Dafny.Rune _133_c = (Dafny.Rune)_forall_var_1;
        return !(((_132_str).Drop(BigInteger.One)).Contains(_133_c)) || ((Std.Strings.HexConversion.__default.chars).Contains(_133_c));
      }))))(str)));
    }
    public static bool ToNumberStr(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      return !(!(str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.Strings.HexConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_134_str) => Dafny.Helpers.Quantifier<Dafny.Rune>(((_134_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_2) => {
        Dafny.Rune _135_c = (Dafny.Rune)_forall_var_2;
        return !(((_134_str).Drop(BigInteger.One)).Contains(_135_c)) || ((Std.Strings.HexConversion.__default.charToDigit).Contains(_135_c));
      }))))(str)));
    }
    public static Dafny.ISequence<Dafny.Rune> OfInt(BigInteger n, Dafny.Rune minus)
    {
      if ((n).Sign != -1) {
        return Std.Strings.HexConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(minus), Std.Strings.HexConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<Dafny.Rune> str) {
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return BigInteger.Zero;
      } else {
        return ((Std.Strings.HexConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.Strings.HexConversion.__default.@base)) + (Dafny.Map<Dafny.Rune, BigInteger>.Select(Std.Strings.HexConversion.__default.charToDigit,(str).Select((new BigInteger((str).Count)) - (BigInteger.One))));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      if (Dafny.Sequence<Dafny.Rune>.IsPrefixOf(Dafny.Sequence<Dafny.Rune>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.Strings.HexConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.Strings.HexConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.Strings.HexConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.Strings.HexConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _136___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_136___accumulator);
      } else {
        _136___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.Strings.HexConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_136___accumulator);
        Dafny.ISequence<BigInteger> _in43 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in43;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _137___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_137___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _137___accumulator = Dafny.Sequence<BigInteger>.Concat(_137___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.Strings.HexConversion.__default.BASE())));
        BigInteger _in44 = Dafny.Helpers.EuclideanDivision(n, Std.Strings.HexConversion.__default.BASE());
        n = _in44;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in45 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in46 = n;
        xs = _in45;
        n = _in46;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _138_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.Strings.HexConversion.__default.SeqExtend(xs, _138_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.Strings.HexConversion.__default.SeqExtend(Std.Strings.HexConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _139_xs = Std.Strings.HexConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _139_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs1 = Std.Strings.HexConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _140_zs_k = _let_tmp_rhs1.dtor__0;
        BigInteger _141_cin = _let_tmp_rhs1.dtor__1;
        BigInteger _142_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_141_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs2 = (((_142_sum) < (Std.Strings.HexConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_142_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_142_sum) - (Std.Strings.HexConversion.__default.BASE()), BigInteger.One)));
        BigInteger _143_sum__out = _let_tmp_rhs2.dtor__0;
        BigInteger _144_cout = _let_tmp_rhs2.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_140_zs_k, Dafny.Sequence<BigInteger>.FromElements(_143_sum__out)), _144_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs3 = Std.Strings.HexConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _145_zs = _let_tmp_rhs3.dtor__0;
        BigInteger _146_cin = _let_tmp_rhs3.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs4 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_146_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_146_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.Strings.HexConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_146_cin), BigInteger.One)));
        BigInteger _147_diff__out = _let_tmp_rhs4.dtor__0;
        BigInteger _148_cout = _let_tmp_rhs4.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_145_zs, Dafny.Sequence<BigInteger>.FromElements(_147_diff__out)), _148_cout);
      }
    }
    public static Dafny.ISequence<Dafny.Rune> HEX__DIGITS { get {
      return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("0123456789ABCDEF");
    } }
    public static Dafny.ISequence<Dafny.Rune> chars { get {
      return Std.Strings.HexConversion.__default.HEX__DIGITS;
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.Strings.HexConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<Dafny.Rune,BigInteger> charToDigit { get {
      return Dafny.Map<Dafny.Rune, BigInteger>.FromElements(new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('0'), BigInteger.Zero), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('1'), BigInteger.One), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('2'), new BigInteger(2)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('3'), new BigInteger(3)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('4'), new BigInteger(4)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('5'), new BigInteger(5)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('6'), new BigInteger(6)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('7'), new BigInteger(7)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('8'), new BigInteger(8)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('9'), new BigInteger(9)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('a'), new BigInteger(10)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('b'), new BigInteger(11)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('c'), new BigInteger(12)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('d'), new BigInteger(13)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('e'), new BigInteger(14)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('f'), new BigInteger(15)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('A'), new BigInteger(10)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('B'), new BigInteger(11)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('C'), new BigInteger(12)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('D'), new BigInteger(13)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('E'), new BigInteger(14)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('F'), new BigInteger(15)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>>(Dafny.Sequence<Dafny.Rune>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.Strings.HexConversion
namespace Std.Strings.DecimalConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.Strings.DecimalConversion.__default.@base;
    }
    public static Dafny.ISequence<Dafny.Rune> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<Dafny.Rune> _149___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(), _149___accumulator);
      } else {
        _149___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.DecimalConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _149___accumulator);
        Dafny.ISequence<BigInteger> _in47 = (digits).Drop(BigInteger.One);
        digits = _in47;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<Dafny.Rune> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<Dafny.Rune>.FromElements((Std.Strings.DecimalConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.Strings.DecimalConversion.__default.OfDigits(Std.Strings.DecimalConversion.__default.FromNat(n));
      }
    }
    public static bool OfNumberStr(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      return !(!(str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.Strings.DecimalConversion.__default.chars).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_150_str) => Dafny.Helpers.Quantifier<Dafny.Rune>(((_150_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_3) => {
        Dafny.Rune _151_c = (Dafny.Rune)_forall_var_3;
        return !(((_150_str).Drop(BigInteger.One)).Contains(_151_c)) || ((Std.Strings.DecimalConversion.__default.chars).Contains(_151_c));
      }))))(str)));
    }
    public static bool ToNumberStr(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      return !(!(str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.Strings.DecimalConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<Dafny.Rune>, bool>>((_152_str) => Dafny.Helpers.Quantifier<Dafny.Rune>(((_152_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_4) => {
        Dafny.Rune _153_c = (Dafny.Rune)_forall_var_4;
        return !(((_152_str).Drop(BigInteger.One)).Contains(_153_c)) || ((Std.Strings.DecimalConversion.__default.charToDigit).Contains(_153_c));
      }))))(str)));
    }
    public static Dafny.ISequence<Dafny.Rune> OfInt(BigInteger n, Dafny.Rune minus)
    {
      if ((n).Sign != -1) {
        return Std.Strings.DecimalConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements(minus), Std.Strings.DecimalConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<Dafny.Rune> str) {
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return BigInteger.Zero;
      } else {
        return ((Std.Strings.DecimalConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.Strings.DecimalConversion.__default.@base)) + (Dafny.Map<Dafny.Rune, BigInteger>.Select(Std.Strings.DecimalConversion.__default.charToDigit,(str).Select((new BigInteger((str).Count)) - (BigInteger.One))));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune minus)
    {
      if (Dafny.Sequence<Dafny.Rune>.IsPrefixOf(Dafny.Sequence<Dafny.Rune>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.Strings.DecimalConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.Strings.DecimalConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.Strings.DecimalConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.Strings.DecimalConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _154___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_154___accumulator);
      } else {
        _154___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.Strings.DecimalConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_154___accumulator);
        Dafny.ISequence<BigInteger> _in48 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in48;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _155___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_155___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _155___accumulator = Dafny.Sequence<BigInteger>.Concat(_155___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.Strings.DecimalConversion.__default.BASE())));
        BigInteger _in49 = Dafny.Helpers.EuclideanDivision(n, Std.Strings.DecimalConversion.__default.BASE());
        n = _in49;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in50 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in51 = n;
        xs = _in50;
        n = _in51;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _156_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.Strings.DecimalConversion.__default.SeqExtend(xs, _156_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.Strings.DecimalConversion.__default.SeqExtend(Std.Strings.DecimalConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _157_xs = Std.Strings.DecimalConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _157_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs5 = Std.Strings.DecimalConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _158_zs_k = _let_tmp_rhs5.dtor__0;
        BigInteger _159_cin = _let_tmp_rhs5.dtor__1;
        BigInteger _160_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_159_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs6 = (((_160_sum) < (Std.Strings.DecimalConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_160_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_160_sum) - (Std.Strings.DecimalConversion.__default.BASE()), BigInteger.One)));
        BigInteger _161_sum__out = _let_tmp_rhs6.dtor__0;
        BigInteger _162_cout = _let_tmp_rhs6.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_158_zs_k, Dafny.Sequence<BigInteger>.FromElements(_161_sum__out)), _162_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs7 = Std.Strings.DecimalConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _163_zs = _let_tmp_rhs7.dtor__0;
        BigInteger _164_cin = _let_tmp_rhs7.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs8 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_164_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_164_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.Strings.DecimalConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_164_cin), BigInteger.One)));
        BigInteger _165_diff__out = _let_tmp_rhs8.dtor__0;
        BigInteger _166_cout = _let_tmp_rhs8.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_163_zs, Dafny.Sequence<BigInteger>.FromElements(_165_diff__out)), _166_cout);
      }
    }
    public static Dafny.ISequence<Dafny.Rune> DIGITS { get {
      return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("0123456789");
    } }
    public static Dafny.ISequence<Dafny.Rune> chars { get {
      return Std.Strings.DecimalConversion.__default.DIGITS;
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.Strings.DecimalConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<Dafny.Rune,BigInteger> charToDigit { get {
      return Dafny.Map<Dafny.Rune, BigInteger>.FromElements(new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('0'), BigInteger.Zero), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('1'), BigInteger.One), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('2'), new BigInteger(2)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('3'), new BigInteger(3)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('4'), new BigInteger(4)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('5'), new BigInteger(5)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('6'), new BigInteger(6)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('7'), new BigInteger(7)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('8'), new BigInteger(8)), new Dafny.Pair<Dafny.Rune, BigInteger>(new Dafny.Rune('9'), new BigInteger(9)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>>(Dafny.Sequence<Dafny.Rune>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.Strings.DecimalConversion
namespace Std.Strings.CharStrEscaping {

  public partial class __default {
    public static Dafny.ISequence<Dafny.Rune> Escape(Dafny.ISequence<Dafny.Rune> str, Dafny.ISet<Dafny.Rune> mustEscape, Dafny.Rune escape)
    {
      Dafny.ISequence<Dafny.Rune> _167___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return Dafny.Sequence<Dafny.Rune>.Concat(_167___accumulator, str);
      } else if ((mustEscape).Contains((str).Select(BigInteger.Zero))) {
        _167___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(_167___accumulator, Dafny.Sequence<Dafny.Rune>.FromElements(escape, (str).Select(BigInteger.Zero)));
        Dafny.ISequence<Dafny.Rune> _in52 = (str).Drop(BigInteger.One);
        Dafny.ISet<Dafny.Rune> _in53 = mustEscape;
        Dafny.Rune _in54 = escape;
        str = _in52;
        mustEscape = _in53;
        escape = _in54;
        goto TAIL_CALL_START;
      } else {
        _167___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(_167___accumulator, Dafny.Sequence<Dafny.Rune>.FromElements((str).Select(BigInteger.Zero)));
        Dafny.ISequence<Dafny.Rune> _in55 = (str).Drop(BigInteger.One);
        Dafny.ISet<Dafny.Rune> _in56 = mustEscape;
        Dafny.Rune _in57 = escape;
        str = _in55;
        mustEscape = _in56;
        escape = _in57;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> Unescape(Dafny.ISequence<Dafny.Rune> str, Dafny.Rune escape)
    {
      if ((str).Equals(Dafny.Sequence<Dafny.Rune>.FromElements())) {
        return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(str);
      } else if (((str).Select(BigInteger.Zero)) == (escape)) {
        if ((new BigInteger((str).Count)) > (BigInteger.One)) {
          Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> _168_valueOrError0 = Std.Strings.CharStrEscaping.__default.Unescape((str).Drop(new BigInteger(2)), escape);
          if ((_168_valueOrError0).IsFailure()) {
            return (_168_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
          } else {
            Dafny.ISequence<Dafny.Rune> _169_tl = (_168_valueOrError0).Extract();
            return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((str).Select(BigInteger.One)), _169_tl));
          }
        } else {
          return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_None();
        }
      } else {
        Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> _170_valueOrError1 = Std.Strings.CharStrEscaping.__default.Unescape((str).Drop(BigInteger.One), escape);
        if ((_170_valueOrError1).IsFailure()) {
          return (_170_valueOrError1).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
        } else {
          Dafny.ISequence<Dafny.Rune> _171_tl = (_170_valueOrError1).Extract();
          return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.FromElements((str).Select(BigInteger.Zero)), _171_tl));
        }
      }
    }
  }
} // end of namespace Std.Strings.CharStrEscaping
namespace Std.Strings {

  public partial class __default {
    public static Dafny.ISequence<Dafny.Rune> OfNat(BigInteger n) {
      return Std.Strings.DecimalConversion.__default.OfNat(n);
    }
    public static Dafny.ISequence<Dafny.Rune> OfInt(BigInteger n) {
      return Std.Strings.DecimalConversion.__default.OfInt(n, new Dafny.Rune('-'));
    }
    public static BigInteger ToNat(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.DecimalConversion.__default.ToNat(str);
    }
    public static BigInteger ToInt(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.DecimalConversion.__default.ToInt(str, new Dafny.Rune('-'));
    }
    public static Dafny.ISequence<Dafny.Rune> EscapeQuotes(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.CharStrEscaping.__default.Escape(str, Dafny.Set<Dafny.Rune>.FromElements(new Dafny.Rune('\"'), new Dafny.Rune('\'')), new Dafny.Rune('\\'));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> UnescapeQuotes(Dafny.ISequence<Dafny.Rune> str) {
      return Std.Strings.CharStrEscaping.__default.Unescape(str, new Dafny.Rune('\\'));
    }
    public static Dafny.ISequence<Dafny.Rune> OfBool(bool b) {
      if (b) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("true");
      } else {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("false");
      }
    }
    public static Dafny.ISequence<Dafny.Rune> OfChar(Dafny.Rune c) {
      return Dafny.Sequence<Dafny.Rune>.FromElements(c);
    }
    public static Dafny.ISequence<Dafny.Rune> Join(Dafny.ISequence<Dafny.Rune> sep, Dafny.ISequence<Dafny.ISequence<Dafny.Rune>> strs)
    {
      Dafny.ISequence<Dafny.Rune> _172___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((strs).Count)).Sign == 0) {
        return Dafny.Sequence<Dafny.Rune>.Concat(_172___accumulator, Dafny.Sequence<Dafny.Rune>.UnicodeFromString(""));
      } else if ((new BigInteger((strs).Count)) == (BigInteger.One)) {
        return Dafny.Sequence<Dafny.Rune>.Concat(_172___accumulator, (strs).Select(BigInteger.Zero));
      } else {
        _172___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(_172___accumulator, Dafny.Sequence<Dafny.Rune>.Concat((strs).Select(BigInteger.Zero), sep));
        Dafny.ISequence<Dafny.Rune> _in58 = sep;
        Dafny.ISequence<Dafny.ISequence<Dafny.Rune>> _in59 = (strs).Drop(BigInteger.One);
        sep = _in58;
        strs = _in59;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<Dafny.Rune> Concat(Dafny.ISequence<Dafny.ISequence<Dafny.Rune>> strs) {
      Dafny.ISequence<Dafny.Rune> _173___accumulator = Dafny.Sequence<Dafny.Rune>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((strs).Count)).Sign == 0) {
        return Dafny.Sequence<Dafny.Rune>.Concat(_173___accumulator, Dafny.Sequence<Dafny.Rune>.UnicodeFromString(""));
      } else {
        _173___accumulator = Dafny.Sequence<Dafny.Rune>.Concat(_173___accumulator, (strs).Select(BigInteger.Zero));
        Dafny.ISequence<Dafny.ISequence<Dafny.Rune>> _in60 = (strs).Drop(BigInteger.One);
        strs = _in60;
        goto TAIL_CALL_START;
      }
    }
  }
} // end of namespace Std.Strings
namespace Std.Unicode.Base {

  public partial class __default {
    public static bool IsInAssignedPlane(uint i) {
      byte _174_plane = (byte)((i) >> ((int)((byte)(16))));
      return (Std.Unicode.Base.__default.ASSIGNED__PLANES).Contains(_174_plane);
    }
    public static uint HIGH__SURROGATE__MIN { get {
      return 55296U;
    } }
    public static uint HIGH__SURROGATE__MAX { get {
      return 56319U;
    } }
    public static uint LOW__SURROGATE__MIN { get {
      return 56320U;
    } }
    public static uint LOW__SURROGATE__MAX { get {
      return 57343U;
    } }
    public static Dafny.ISet<byte> ASSIGNED__PLANES { get {
      return Dafny.Set<byte>.FromElements((byte)(0), (byte)(1), (byte)(2), (byte)(3), (byte)(14), (byte)(15), (byte)(16));
    } }
  }

  public partial class CodePoint {
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class HighSurrogateCodePoint {
    private static readonly uint Witness = Std.Unicode.Base.__default.HIGH__SURROGATE__MIN;
    public static uint Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(Std.Unicode.Base.HighSurrogateCodePoint.Default());
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class LowSurrogateCodePoint {
    private static readonly uint Witness = Std.Unicode.Base.__default.LOW__SURROGATE__MIN;
    public static uint Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(Std.Unicode.Base.LowSurrogateCodePoint.Default());
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class ScalarValue {
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class AssignedCodePoint {
    private static readonly Dafny.TypeDescriptor<uint> _TYPE = new Dafny.TypeDescriptor<uint>(0);
    public static Dafny.TypeDescriptor<uint> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.Unicode.Base
namespace Std.Unicode.Utf8EncodingForm {

  public partial class __default {
    public static bool IsMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<byte> s) {
      if ((new BigInteger((s).Count)) == (BigInteger.One)) {
        bool _175_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedSingleCodeUnitSequence(s);
        return _175_b;
      } else if ((new BigInteger((s).Count)) == (new BigInteger(2))) {
        bool _176_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence(s);
        return _176_b;
      } else if ((new BigInteger((s).Count)) == (new BigInteger(3))) {
        bool _177_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedTripleCodeUnitSequence(s);
        return _177_b;
      } else if ((new BigInteger((s).Count)) == (new BigInteger(4))) {
        bool _178_b = Std.Unicode.Utf8EncodingForm.__default.IsWellFormedQuadrupleCodeUnitSequence(s);
        return _178_b;
      } else {
        return false;
      }
    }
    public static bool IsWellFormedSingleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _179_firstByte = (s).Select(BigInteger.Zero);
      return (true) && ((((byte)(0)) <= (_179_firstByte)) && ((_179_firstByte) <= ((byte)(127))));
    }
    public static bool IsWellFormedDoubleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _180_firstByte = (s).Select(BigInteger.Zero);
      byte _181_secondByte = (s).Select(BigInteger.One);
      return ((((byte)(194)) <= (_180_firstByte)) && ((_180_firstByte) <= ((byte)(223)))) && ((((byte)(128)) <= (_181_secondByte)) && ((_181_secondByte) <= ((byte)(191))));
    }
    public static bool IsWellFormedTripleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _182_firstByte = (s).Select(BigInteger.Zero);
      byte _183_secondByte = (s).Select(BigInteger.One);
      byte _184_thirdByte = (s).Select(new BigInteger(2));
      return ((((((_182_firstByte) == ((byte)(224))) && ((((byte)(160)) <= (_183_secondByte)) && ((_183_secondByte) <= ((byte)(191))))) || (((((byte)(225)) <= (_182_firstByte)) && ((_182_firstByte) <= ((byte)(236)))) && ((((byte)(128)) <= (_183_secondByte)) && ((_183_secondByte) <= ((byte)(191)))))) || (((_182_firstByte) == ((byte)(237))) && ((((byte)(128)) <= (_183_secondByte)) && ((_183_secondByte) <= ((byte)(159)))))) || (((((byte)(238)) <= (_182_firstByte)) && ((_182_firstByte) <= ((byte)(239)))) && ((((byte)(128)) <= (_183_secondByte)) && ((_183_secondByte) <= ((byte)(191)))))) && ((((byte)(128)) <= (_184_thirdByte)) && ((_184_thirdByte) <= ((byte)(191))));
    }
    public static bool IsWellFormedQuadrupleCodeUnitSequence(Dafny.ISequence<byte> s) {
      byte _185_firstByte = (s).Select(BigInteger.Zero);
      byte _186_secondByte = (s).Select(BigInteger.One);
      byte _187_thirdByte = (s).Select(new BigInteger(2));
      byte _188_fourthByte = (s).Select(new BigInteger(3));
      return ((((((_185_firstByte) == ((byte)(240))) && ((((byte)(144)) <= (_186_secondByte)) && ((_186_secondByte) <= ((byte)(191))))) || (((((byte)(241)) <= (_185_firstByte)) && ((_185_firstByte) <= ((byte)(243)))) && ((((byte)(128)) <= (_186_secondByte)) && ((_186_secondByte) <= ((byte)(191)))))) || (((_185_firstByte) == ((byte)(244))) && ((((byte)(128)) <= (_186_secondByte)) && ((_186_secondByte) <= ((byte)(143)))))) && ((((byte)(128)) <= (_187_thirdByte)) && ((_187_thirdByte) <= ((byte)(191))))) && ((((byte)(128)) <= (_188_fourthByte)) && ((_188_fourthByte) <= ((byte)(191))));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<byte>> SplitPrefixMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<byte> s) {
      if (((new BigInteger((s).Count)) >= (BigInteger.One)) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedSingleCodeUnitSequence((s).Take(BigInteger.One)))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(BigInteger.One));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(2))) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence((s).Take(new BigInteger(2))))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(new BigInteger(2)));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(3))) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedTripleCodeUnitSequence((s).Take(new BigInteger(3))))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(new BigInteger(3)));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(4))) && (Std.Unicode.Utf8EncodingForm.__default.IsWellFormedQuadrupleCodeUnitSequence((s).Take(new BigInteger(4))))) {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some((s).Take(new BigInteger(4)));
      } else {
        return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_None();
      }
    }
    public static Dafny.ISequence<byte> EncodeScalarValue(uint v) {
      if ((v) <= (127U)) {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueSingleByte(v);
      } else if ((v) <= (2047U)) {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueDoubleByte(v);
      } else if ((v) <= (65535U)) {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueTripleByte(v);
      } else {
        return Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValueQuadrupleByte(v);
      }
    }
    public static Dafny.ISequence<byte> EncodeScalarValueSingleByte(uint v) {
      byte _189_x = (byte)((v) & (127U));
      byte _190_firstByte = (byte)(_189_x);
      return Dafny.Sequence<byte>.FromElements(_190_firstByte);
    }
    public static Dafny.ISequence<byte> EncodeScalarValueDoubleByte(uint v) {
      byte _191_x = (byte)((v) & (63U));
      byte _192_y = (byte)(((v) & (1984U)) >> ((int)((byte)(6))));
      byte _193_firstByte = (byte)(((byte)(192)) | ((byte)(_192_y)));
      byte _194_secondByte = (byte)(((byte)(128)) | ((byte)(_191_x)));
      return Dafny.Sequence<byte>.FromElements(_193_firstByte, _194_secondByte);
    }
    public static Dafny.ISequence<byte> EncodeScalarValueTripleByte(uint v) {
      byte _195_x = (byte)((v) & (63U));
      byte _196_y = (byte)(((v) & (4032U)) >> ((int)((byte)(6))));
      byte _197_z = (byte)(((v) & (61440U)) >> ((int)((byte)(12))));
      byte _198_firstByte = (byte)(((byte)(224)) | ((byte)(_197_z)));
      byte _199_secondByte = (byte)(((byte)(128)) | ((byte)(_196_y)));
      byte _200_thirdByte = (byte)(((byte)(128)) | ((byte)(_195_x)));
      return Dafny.Sequence<byte>.FromElements(_198_firstByte, _199_secondByte, _200_thirdByte);
    }
    public static Dafny.ISequence<byte> EncodeScalarValueQuadrupleByte(uint v) {
      byte _201_x = (byte)((v) & (63U));
      byte _202_y = (byte)(((v) & (4032U)) >> ((int)((byte)(6))));
      byte _203_z = (byte)(((v) & (61440U)) >> ((int)((byte)(12))));
      byte _204_u2 = (byte)(((v) & (196608U)) >> ((int)((byte)(16))));
      byte _205_u1 = (byte)(((v) & (1835008U)) >> ((int)((byte)(18))));
      byte _206_firstByte = (byte)(((byte)(240)) | ((byte)(_205_u1)));
      byte _207_secondByte = (byte)(((byte)(((byte)(128)) | (unchecked((byte)(((byte)(((byte)(_204_u2)) << ((int)((byte)(4)))))))))) | ((byte)(_203_z)));
      byte _208_thirdByte = (byte)(((byte)(128)) | ((byte)(_202_y)));
      byte _209_fourthByte = (byte)(((byte)(128)) | ((byte)(_201_x)));
      return Dafny.Sequence<byte>.FromElements(_206_firstByte, _207_secondByte, _208_thirdByte, _209_fourthByte);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<byte> m) {
      if ((new BigInteger((m).Count)) == (BigInteger.One)) {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(m);
      } else if ((new BigInteger((m).Count)) == (new BigInteger(2))) {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(m);
      } else if ((new BigInteger((m).Count)) == (new BigInteger(3))) {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(m);
      } else {
        return Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(m);
      }
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceSingleByte(Dafny.ISequence<byte> m) {
      byte _210_firstByte = (m).Select(BigInteger.Zero);
      byte _211_x = (byte)(_210_firstByte);
      return (uint)(_211_x);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceDoubleByte(Dafny.ISequence<byte> m) {
      byte _212_firstByte = (m).Select(BigInteger.Zero);
      byte _213_secondByte = (m).Select(BigInteger.One);
      uint _214_y = (uint)((byte)((_212_firstByte) & ((byte)(31))));
      uint _215_x = (uint)((byte)((_213_secondByte) & ((byte)(63))));
      return (unchecked((uint)(((_214_y) << ((int)((byte)(6)))) & (uint)0xFFFFFFU))) | ((uint)(_215_x));
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceTripleByte(Dafny.ISequence<byte> m) {
      byte _216_firstByte = (m).Select(BigInteger.Zero);
      byte _217_secondByte = (m).Select(BigInteger.One);
      byte _218_thirdByte = (m).Select(new BigInteger(2));
      uint _219_z = (uint)((byte)((_216_firstByte) & ((byte)(15))));
      uint _220_y = (uint)((byte)((_217_secondByte) & ((byte)(63))));
      uint _221_x = (uint)((byte)((_218_thirdByte) & ((byte)(63))));
      return ((unchecked((uint)(((_219_z) << ((int)((byte)(12)))) & (uint)0xFFFFFFU))) | (unchecked((uint)(((_220_y) << ((int)((byte)(6)))) & (uint)0xFFFFFFU)))) | ((uint)(_221_x));
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceQuadrupleByte(Dafny.ISequence<byte> m) {
      byte _222_firstByte = (m).Select(BigInteger.Zero);
      byte _223_secondByte = (m).Select(BigInteger.One);
      byte _224_thirdByte = (m).Select(new BigInteger(2));
      byte _225_fourthByte = (m).Select(new BigInteger(3));
      uint _226_u1 = (uint)((byte)((_222_firstByte) & ((byte)(7))));
      uint _227_u2 = (uint)((byte)(((byte)((_223_secondByte) & ((byte)(48)))) >> ((int)((byte)(4)))));
      uint _228_z = (uint)((byte)((_223_secondByte) & ((byte)(15))));
      uint _229_y = (uint)((byte)((_224_thirdByte) & ((byte)(63))));
      uint _230_x = (uint)((byte)((_225_fourthByte) & ((byte)(63))));
      return ((((unchecked((uint)(((_226_u1) << ((int)((byte)(18)))) & (uint)0xFFFFFFU))) | (unchecked((uint)(((_227_u2) << ((int)((byte)(16)))) & (uint)0xFFFFFFU)))) | (unchecked((uint)(((_228_z) << ((int)((byte)(12)))) & (uint)0xFFFFFFU)))) | (unchecked((uint)(((_229_y) << ((int)((byte)(6)))) & (uint)0xFFFFFFU)))) | ((uint)(_230_x));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<byte>>> PartitionCodeUnitSequenceChecked(Dafny.ISequence<byte> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<byte>>> maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<byte>>>.Default();
      if ((s).Equals(Dafny.Sequence<byte>.FromElements())) {
        maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<byte>>>.create_Some(Dafny.Sequence<Dafny.ISequence<byte>>.FromElements());
        return maybeParts;
      }
      Dafny.ISequence<Dafny.ISequence<byte>> _231_result;
      _231_result = Dafny.Sequence<Dafny.ISequence<byte>>.FromElements();
      Dafny.ISequence<byte> _232_rest;
      _232_rest = s;
      while ((new BigInteger((_232_rest).Count)).Sign == 1) {
        Dafny.ISequence<byte> _233_prefix;
        Std.Wrappers._IOption<Dafny.ISequence<byte>> _234_valueOrError0 = Std.Wrappers.Option<Dafny.ISequence<byte>>.Default();
        _234_valueOrError0 = Std.Unicode.Utf8EncodingForm.__default.SplitPrefixMinimalWellFormedCodeUnitSubsequence(_232_rest);
        if ((_234_valueOrError0).IsFailure()) {
          maybeParts = (_234_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.ISequence<byte>>>();
          return maybeParts;
        }
        _233_prefix = (_234_valueOrError0).Extract();
        _231_result = Dafny.Sequence<Dafny.ISequence<byte>>.Concat(_231_result, Dafny.Sequence<Dafny.ISequence<byte>>.FromElements(_233_prefix));
        _232_rest = (_232_rest).Drop(new BigInteger((_233_prefix).Count));
      }
      maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<byte>>>.create_Some(_231_result);
      return maybeParts;
      return maybeParts;
    }
    public static Dafny.ISequence<Dafny.ISequence<byte>> PartitionCodeUnitSequence(Dafny.ISequence<byte> s) {
      return (Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).Extract();
    }
    public static bool IsWellFormedCodeUnitSequence(Dafny.ISequence<byte> s) {
      return (Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).is_Some;
    }
    public static Dafny.ISequence<byte> EncodeScalarSequence(Dafny.ISequence<uint> vs)
    {
      Dafny.ISequence<byte> s = Std.Unicode.Utf8EncodingForm.WellFormedCodeUnitSeq.Default();
      s = Dafny.Sequence<byte>.FromElements();
      BigInteger _lo0 = BigInteger.Zero;
      for (BigInteger _235_i = new BigInteger((vs).Count); _lo0 < _235_i; ) {
        _235_i--;
        Dafny.ISequence<byte> _236_next;
        _236_next = Std.Unicode.Utf8EncodingForm.__default.EncodeScalarValue((vs).Select(_235_i));
        s = Dafny.Sequence<byte>.Concat(_236_next, s);
      }
      return s;
    }
    public static Dafny.ISequence<uint> DecodeCodeUnitSequence(Dafny.ISequence<byte> s) {
      Dafny.ISequence<Dafny.ISequence<byte>> _237_parts = Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequence(s);
      Dafny.ISequence<uint> _238_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<byte>, uint>(Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _237_parts);
      return _238_vs;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<uint>> DecodeCodeUnitSequenceChecked(Dafny.ISequence<byte> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<uint>> maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.Default();
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<byte>>> _239_maybeParts;
      _239_maybeParts = Std.Unicode.Utf8EncodingForm.__default.PartitionCodeUnitSequenceChecked(s);
      if ((_239_maybeParts).is_None) {
        maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_None();
        return maybeVs;
      }
      Dafny.ISequence<Dafny.ISequence<byte>> _240_parts;
      _240_parts = (_239_maybeParts).dtor_value;
      Dafny.ISequence<uint> _241_vs;
      _241_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<byte>, uint>(Std.Unicode.Utf8EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _240_parts);
      maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_Some(_241_vs);
      return maybeVs;
      return maybeVs;
    }
  }

  public partial class WellFormedCodeUnitSeq {
    private static readonly Dafny.ISequence<byte> Witness = Dafny.Sequence<byte>.FromElements();
    public static Dafny.ISequence<byte> Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Std.Unicode.Utf8EncodingForm.WellFormedCodeUnitSeq.Default());
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class MinimalWellFormedCodeUnitSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Dafny.Sequence<byte>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.Unicode.Utf8EncodingForm
namespace Std.Unicode.Utf16EncodingForm {

  public partial class __default {
    public static bool IsMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<ushort> s) {
      if ((new BigInteger((s).Count)) == (BigInteger.One)) {
        return Std.Unicode.Utf16EncodingForm.__default.IsWellFormedSingleCodeUnitSequence(s);
      } else if ((new BigInteger((s).Count)) == (new BigInteger(2))) {
        bool _242_b = Std.Unicode.Utf16EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence(s);
        return _242_b;
      } else {
        return false;
      }
    }
    public static bool IsWellFormedSingleCodeUnitSequence(Dafny.ISequence<ushort> s) {
      ushort _243_firstWord = (s).Select(BigInteger.Zero);
      return ((((ushort)(0)) <= (_243_firstWord)) && ((_243_firstWord) <= ((ushort)(55295)))) || ((((ushort)(57344)) <= (_243_firstWord)) && ((_243_firstWord) <= ((ushort)(65535))));
    }
    public static bool IsWellFormedDoubleCodeUnitSequence(Dafny.ISequence<ushort> s) {
      ushort _244_firstWord = (s).Select(BigInteger.Zero);
      ushort _245_secondWord = (s).Select(BigInteger.One);
      return ((((ushort)(55296)) <= (_244_firstWord)) && ((_244_firstWord) <= ((ushort)(56319)))) && ((((ushort)(56320)) <= (_245_secondWord)) && ((_245_secondWord) <= ((ushort)(57343))));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<ushort>> SplitPrefixMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<ushort> s) {
      if (((new BigInteger((s).Count)) >= (BigInteger.One)) && (Std.Unicode.Utf16EncodingForm.__default.IsWellFormedSingleCodeUnitSequence((s).Take(BigInteger.One)))) {
        return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_Some((s).Take(BigInteger.One));
      } else if (((new BigInteger((s).Count)) >= (new BigInteger(2))) && (Std.Unicode.Utf16EncodingForm.__default.IsWellFormedDoubleCodeUnitSequence((s).Take(new BigInteger(2))))) {
        return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_Some((s).Take(new BigInteger(2)));
      } else {
        return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_None();
      }
    }
    public static Dafny.ISequence<ushort> EncodeScalarValue(uint v) {
      if ((((0U) <= (v)) && ((v) <= (55295U))) || (((57344U) <= (v)) && ((v) <= (65535U)))) {
        return Std.Unicode.Utf16EncodingForm.__default.EncodeScalarValueSingleWord(v);
      } else {
        return Std.Unicode.Utf16EncodingForm.__default.EncodeScalarValueDoubleWord(v);
      }
    }
    public static Dafny.ISequence<ushort> EncodeScalarValueSingleWord(uint v) {
      ushort _246_firstWord = (ushort)(v);
      return Dafny.Sequence<ushort>.FromElements(_246_firstWord);
    }
    public static Dafny.ISequence<ushort> EncodeScalarValueDoubleWord(uint v) {
      ushort _247_x2 = (ushort)((v) & (1023U));
      byte _248_x1 = (byte)(((v) & (64512U)) >> ((int)((byte)(10))));
      byte _249_u = (byte)(((v) & (2031616U)) >> ((int)((byte)(16))));
      byte _250_w = (byte)(unchecked((byte)(((byte)((_249_u) - ((byte)(1)))) & (byte)0x1F)));
      ushort _251_firstWord = (ushort)(((ushort)(((ushort)(55296)) | (unchecked((ushort)(((ushort)(((ushort)(_250_w)) << ((int)((byte)(6)))))))))) | ((ushort)(_248_x1)));
      ushort _252_secondWord = (ushort)(((ushort)(56320)) | ((ushort)(_247_x2)));
      return Dafny.Sequence<ushort>.FromElements(_251_firstWord, _252_secondWord);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequence(Dafny.ISequence<ushort> m) {
      if ((new BigInteger((m).Count)) == (BigInteger.One)) {
        return Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(m);
      } else {
        return Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(m);
      }
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceSingleWord(Dafny.ISequence<ushort> m) {
      ushort _253_firstWord = (m).Select(BigInteger.Zero);
      ushort _254_x = (ushort)(_253_firstWord);
      return (uint)(_254_x);
    }
    public static uint DecodeMinimalWellFormedCodeUnitSubsequenceDoubleWord(Dafny.ISequence<ushort> m) {
      ushort _255_firstWord = (m).Select(BigInteger.Zero);
      ushort _256_secondWord = (m).Select(BigInteger.One);
      uint _257_x2 = (uint)((ushort)((_256_secondWord) & ((ushort)(1023))));
      uint _258_x1 = (uint)((ushort)((_255_firstWord) & ((ushort)(63))));
      uint _259_w = (uint)((ushort)(((ushort)((_255_firstWord) & ((ushort)(960)))) >> ((int)((byte)(6)))));
      uint _260_u = (uint)(unchecked((uint)(((_259_w) + (1U)) & (uint)0xFFFFFFU)));
      uint _261_v = ((unchecked((uint)(((_260_u) << ((int)((byte)(16)))) & (uint)0xFFFFFFU))) | (unchecked((uint)(((_258_x1) << ((int)((byte)(10)))) & (uint)0xFFFFFFU)))) | ((uint)(_257_x2));
      return _261_v;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<ushort>>> PartitionCodeUnitSequenceChecked(Dafny.ISequence<ushort> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<ushort>>> maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<ushort>>>.Default();
      if ((s).Equals(Dafny.Sequence<ushort>.FromElements())) {
        maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<ushort>>>.create_Some(Dafny.Sequence<Dafny.ISequence<ushort>>.FromElements());
        return maybeParts;
      }
      Dafny.ISequence<Dafny.ISequence<ushort>> _262_result;
      _262_result = Dafny.Sequence<Dafny.ISequence<ushort>>.FromElements();
      Dafny.ISequence<ushort> _263_rest;
      _263_rest = s;
      while ((new BigInteger((_263_rest).Count)).Sign == 1) {
        Dafny.ISequence<ushort> _264_prefix;
        Std.Wrappers._IOption<Dafny.ISequence<ushort>> _265_valueOrError0 = Std.Wrappers.Option<Dafny.ISequence<ushort>>.Default();
        _265_valueOrError0 = Std.Unicode.Utf16EncodingForm.__default.SplitPrefixMinimalWellFormedCodeUnitSubsequence(_263_rest);
        if ((_265_valueOrError0).IsFailure()) {
          maybeParts = (_265_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.ISequence<ushort>>>();
          return maybeParts;
        }
        _264_prefix = (_265_valueOrError0).Extract();
        _262_result = Dafny.Sequence<Dafny.ISequence<ushort>>.Concat(_262_result, Dafny.Sequence<Dafny.ISequence<ushort>>.FromElements(_264_prefix));
        _263_rest = (_263_rest).Drop(new BigInteger((_264_prefix).Count));
      }
      maybeParts = Std.Wrappers.Option<Dafny.ISequence<Dafny.ISequence<ushort>>>.create_Some(_262_result);
      return maybeParts;
      return maybeParts;
    }
    public static Dafny.ISequence<Dafny.ISequence<ushort>> PartitionCodeUnitSequence(Dafny.ISequence<ushort> s) {
      return (Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).Extract();
    }
    public static bool IsWellFormedCodeUnitSequence(Dafny.ISequence<ushort> s) {
      return (Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequenceChecked(s)).is_Some;
    }
    public static Dafny.ISequence<ushort> EncodeScalarSequence(Dafny.ISequence<uint> vs)
    {
      Dafny.ISequence<ushort> s = Std.Unicode.Utf16EncodingForm.WellFormedCodeUnitSeq.Default();
      s = Dafny.Sequence<ushort>.FromElements();
      BigInteger _lo1 = BigInteger.Zero;
      for (BigInteger _266_i = new BigInteger((vs).Count); _lo1 < _266_i; ) {
        _266_i--;
        Dafny.ISequence<ushort> _267_next;
        _267_next = Std.Unicode.Utf16EncodingForm.__default.EncodeScalarValue((vs).Select(_266_i));
        s = Dafny.Sequence<ushort>.Concat(_267_next, s);
      }
      return s;
    }
    public static Dafny.ISequence<uint> DecodeCodeUnitSequence(Dafny.ISequence<ushort> s) {
      Dafny.ISequence<Dafny.ISequence<ushort>> _268_parts = Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequence(s);
      Dafny.ISequence<uint> _269_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<ushort>, uint>(Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _268_parts);
      return _269_vs;
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<uint>> DecodeCodeUnitSequenceChecked(Dafny.ISequence<ushort> s)
    {
      Std.Wrappers._IOption<Dafny.ISequence<uint>> maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.Default();
      Std.Wrappers._IOption<Dafny.ISequence<Dafny.ISequence<ushort>>> _270_maybeParts;
      _270_maybeParts = Std.Unicode.Utf16EncodingForm.__default.PartitionCodeUnitSequenceChecked(s);
      if ((_270_maybeParts).is_None) {
        maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_None();
        return maybeVs;
      }
      Dafny.ISequence<Dafny.ISequence<ushort>> _271_parts;
      _271_parts = (_270_maybeParts).dtor_value;
      Dafny.ISequence<uint> _272_vs;
      _272_vs = Std.Collections.Seq.__default.Map<Dafny.ISequence<ushort>, uint>(Std.Unicode.Utf16EncodingForm.__default.DecodeMinimalWellFormedCodeUnitSubsequence, _271_parts);
      maybeVs = Std.Wrappers.Option<Dafny.ISequence<uint>>.create_Some(_272_vs);
      return maybeVs;
      return maybeVs;
    }
  }

  public partial class WellFormedCodeUnitSeq {
    private static readonly Dafny.ISequence<ushort> Witness = Dafny.Sequence<ushort>.FromElements();
    public static Dafny.ISequence<ushort> Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<ushort>>(Std.Unicode.Utf16EncodingForm.WellFormedCodeUnitSeq.Default());
    public static Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class MinimalWellFormedCodeUnitSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<ushort>>(Dafny.Sequence<ushort>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.Unicode.Utf16EncodingForm
namespace Std.Unicode.UnicodeStringsWithUnicodeChar {

  public partial class __default {
    public static uint CharAsUnicodeScalarValue(Dafny.Rune c) {
      return (uint)((c).Value);
    }
    public static Dafny.Rune CharFromUnicodeScalarValue(uint sv) {
      return new Dafny.Rune((int)(new BigInteger(sv)));
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<byte>> ToUTF8Checked(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<uint> _273_asCodeUnits = Std.Collections.Seq.__default.Map<Dafny.Rune, uint>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharAsUnicodeScalarValue, s);
      Dafny.ISequence<byte> _274_asUtf8CodeUnits = Std.Unicode.Utf8EncodingForm.__default.EncodeScalarSequence(_273_asCodeUnits);
      Dafny.ISequence<byte> _275_asBytes = Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_276_cu) => {
        return (byte)(_276_cu);
      })), _274_asUtf8CodeUnits);
      return Std.Wrappers.Option<Dafny.ISequence<byte>>.create_Some(_275_asBytes);
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> FromUTF8Checked(Dafny.ISequence<byte> bs) {
      Dafny.ISequence<byte> _277_asCodeUnits = Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_278_c) => {
        return (byte)(_278_c);
      })), bs);
      Std.Wrappers._IOption<Dafny.ISequence<uint>> _279_valueOrError0 = Std.Unicode.Utf8EncodingForm.__default.DecodeCodeUnitSequenceChecked(_277_asCodeUnits);
      if ((_279_valueOrError0).IsFailure()) {
        return (_279_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
      } else {
        Dafny.ISequence<uint> _280_utf32 = (_279_valueOrError0).Extract();
        Dafny.ISequence<Dafny.Rune> _281_asChars = Std.Collections.Seq.__default.Map<uint, Dafny.Rune>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharFromUnicodeScalarValue, _280_utf32);
        return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(_281_asChars);
      }
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<ushort>> ToUTF16Checked(Dafny.ISequence<Dafny.Rune> s) {
      Dafny.ISequence<uint> _282_asCodeUnits = Std.Collections.Seq.__default.Map<Dafny.Rune, uint>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharAsUnicodeScalarValue, s);
      Dafny.ISequence<ushort> _283_asUtf16CodeUnits = Std.Unicode.Utf16EncodingForm.__default.EncodeScalarSequence(_282_asCodeUnits);
      Dafny.ISequence<ushort> _284_asBytes = Std.Collections.Seq.__default.Map<ushort, ushort>(((System.Func<ushort, ushort>)((_285_cu) => {
        return (ushort)(_285_cu);
      })), _283_asUtf16CodeUnits);
      return Std.Wrappers.Option<Dafny.ISequence<ushort>>.create_Some(_284_asBytes);
    }
    public static Std.Wrappers._IOption<Dafny.ISequence<Dafny.Rune>> FromUTF16Checked(Dafny.ISequence<ushort> bs) {
      Dafny.ISequence<ushort> _286_asCodeUnits = Std.Collections.Seq.__default.Map<ushort, ushort>(((System.Func<ushort, ushort>)((_287_c) => {
        return (ushort)(_287_c);
      })), bs);
      Std.Wrappers._IOption<Dafny.ISequence<uint>> _288_valueOrError0 = Std.Unicode.Utf16EncodingForm.__default.DecodeCodeUnitSequenceChecked(_286_asCodeUnits);
      if ((_288_valueOrError0).IsFailure()) {
        return (_288_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
      } else {
        Dafny.ISequence<uint> _289_utf32 = (_288_valueOrError0).Extract();
        Dafny.ISequence<Dafny.Rune> _290_asChars = Std.Collections.Seq.__default.Map<uint, Dafny.Rune>(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.CharFromUnicodeScalarValue, _289_utf32);
        return Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.create_Some(_290_asChars);
      }
    }
    public static Dafny.ISequence<byte> ASCIIToUTF8(Dafny.ISequence<Dafny.Rune> s) {
      return Std.Collections.Seq.__default.Map<Dafny.Rune, byte>(((System.Func<Dafny.Rune, byte>)((_291_c) => {
        return (byte)((_291_c).Value);
      })), s);
    }
    public static Dafny.ISequence<ushort> ASCIIToUTF16(Dafny.ISequence<Dafny.Rune> s) {
      return Std.Collections.Seq.__default.Map<Dafny.Rune, ushort>(((System.Func<Dafny.Rune, ushort>)((_292_c) => {
        return (ushort)((_292_c).Value);
      })), s);
    }
  }
} // end of namespace Std.Unicode.UnicodeStringsWithUnicodeChar
namespace Std.Unicode.Utf8EncodingScheme {

  public partial class __default {
    public static Dafny.ISequence<byte> Serialize(Dafny.ISequence<byte> s) {
      return Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_293_c) => {
        return (byte)(_293_c);
      })), s);
    }
    public static Dafny.ISequence<byte> Deserialize(Dafny.ISequence<byte> b) {
      return Std.Collections.Seq.__default.Map<byte, byte>(((System.Func<byte, byte>)((_294_b) => {
        return (byte)(_294_b);
      })), b);
    }
  }
} // end of namespace Std.Unicode.Utf8EncodingScheme
namespace Std.Unicode {

} // end of namespace Std.Unicode
namespace Std.CSharpFileIOInternalExterns {

} // end of namespace Std.CSharpFileIOInternalExterns
namespace Std.JSON.Values {

  public partial class __default {
    public static Std.JSON.Values._IDecimal Int(BigInteger n) {
      return Std.JSON.Values.Decimal.create(n, BigInteger.Zero);
    }
  }

  public interface _IDecimal {
    bool is_Decimal { get; }
    BigInteger dtor_n { get; }
    BigInteger dtor_e10 { get; }
    _IDecimal DowncastClone();
  }
  public class Decimal : _IDecimal {
    public readonly BigInteger _n;
    public readonly BigInteger _e10;
    public Decimal(BigInteger n, BigInteger e10) {
      this._n = n;
      this._e10 = e10;
    }
    public _IDecimal DowncastClone() {
      if (this is _IDecimal dt) { return dt; }
      return new Decimal(_n, _e10);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.Decimal;
      return oth != null && this._n == oth._n && this._e10 == oth._e10;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._n));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._e10));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.Decimal.Decimal";
      s += "(";
      s += Dafny.Helpers.ToString(this._n);
      s += ", ";
      s += Dafny.Helpers.ToString(this._e10);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Values._IDecimal theDefault = create(BigInteger.Zero, BigInteger.Zero);
    public static Std.JSON.Values._IDecimal Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Values._IDecimal> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Values._IDecimal>(Std.JSON.Values.Decimal.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Values._IDecimal> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IDecimal create(BigInteger n, BigInteger e10) {
      return new Decimal(n, e10);
    }
    public static _IDecimal create_Decimal(BigInteger n, BigInteger e10) {
      return create(n, e10);
    }
    public bool is_Decimal { get { return true; } }
    public BigInteger dtor_n {
      get {
        return this._n;
      }
    }
    public BigInteger dtor_e10 {
      get {
        return this._e10;
      }
    }
  }

  public interface _IJSON {
    bool is_Null { get; }
    bool is_Bool { get; }
    bool is_String { get; }
    bool is_Number { get; }
    bool is_Object { get; }
    bool is_Array { get; }
    bool dtor_b { get; }
    Dafny.ISequence<Dafny.Rune> dtor_str { get; }
    Std.JSON.Values._IDecimal dtor_num { get; }
    Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> dtor_obj { get; }
    Dafny.ISequence<Std.JSON.Values._IJSON> dtor_arr { get; }
    _IJSON DowncastClone();
  }
  public abstract class JSON : _IJSON {
    public JSON() {
    }
    private static readonly Std.JSON.Values._IJSON theDefault = create_Null();
    public static Std.JSON.Values._IJSON Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Values._IJSON> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Values._IJSON>(Std.JSON.Values.JSON.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Values._IJSON> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IJSON create_Null() {
      return new JSON_Null();
    }
    public static _IJSON create_Bool(bool b) {
      return new JSON_Bool(b);
    }
    public static _IJSON create_String(Dafny.ISequence<Dafny.Rune> str) {
      return new JSON_String(str);
    }
    public static _IJSON create_Number(Std.JSON.Values._IDecimal num) {
      return new JSON_Number(num);
    }
    public static _IJSON create_Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) {
      return new JSON_Object(obj);
    }
    public static _IJSON create_Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) {
      return new JSON_Array(arr);
    }
    public bool is_Null { get { return this is JSON_Null; } }
    public bool is_Bool { get { return this is JSON_Bool; } }
    public bool is_String { get { return this is JSON_String; } }
    public bool is_Number { get { return this is JSON_Number; } }
    public bool is_Object { get { return this is JSON_Object; } }
    public bool is_Array { get { return this is JSON_Array; } }
    public bool dtor_b {
      get {
        var d = this;
        return ((JSON_Bool)d)._b;
      }
    }
    public Dafny.ISequence<Dafny.Rune> dtor_str {
      get {
        var d = this;
        return ((JSON_String)d)._str;
      }
    }
    public Std.JSON.Values._IDecimal dtor_num {
      get {
        var d = this;
        return ((JSON_Number)d)._num;
      }
    }
    public Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> dtor_obj {
      get {
        var d = this;
        return ((JSON_Object)d)._obj;
      }
    }
    public Dafny.ISequence<Std.JSON.Values._IJSON> dtor_arr {
      get {
        var d = this;
        return ((JSON_Array)d)._arr;
      }
    }
    public abstract _IJSON DowncastClone();
  }
  public class JSON_Null : JSON {
    public JSON_Null() : base() {
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Null();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Null;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Null";
      return s;
    }
  }
  public class JSON_Bool : JSON {
    public readonly bool _b;
    public JSON_Bool(bool b) : base() {
      this._b = b;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Bool(_b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Bool;
      return oth != null && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Bool";
      s += "(";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class JSON_String : JSON {
    public readonly Dafny.ISequence<Dafny.Rune> _str;
    public JSON_String(Dafny.ISequence<Dafny.Rune> str) : base() {
      this._str = str;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_String(_str);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_String;
      return oth != null && object.Equals(this._str, oth._str);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._str));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.String";
      s += "(";
      s += this._str.ToVerbatimString(true);
      s += ")";
      return s;
    }
  }
  public class JSON_Number : JSON {
    public readonly Std.JSON.Values._IDecimal _num;
    public JSON_Number(Std.JSON.Values._IDecimal num) : base() {
      this._num = num;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Number(_num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Number;
      return oth != null && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Number";
      s += "(";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
  }
  public class JSON_Object : JSON {
    public readonly Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _obj;
    public JSON_Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) : base() {
      this._obj = obj;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Object(_obj);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Object;
      return oth != null && object.Equals(this._obj, oth._obj);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 4;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._obj));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Object";
      s += "(";
      s += Dafny.Helpers.ToString(this._obj);
      s += ")";
      return s;
    }
  }
  public class JSON_Array : JSON {
    public readonly Dafny.ISequence<Std.JSON.Values._IJSON> _arr;
    public JSON_Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) : base() {
      this._arr = arr;
    }
    public override _IJSON DowncastClone() {
      if (this is _IJSON dt) { return dt; }
      return new JSON_Array(_arr);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Values.JSON_Array;
      return oth != null && object.Equals(this._arr, oth._arr);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 5;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._arr));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Values.JSON.Array";
      s += "(";
      s += Dafny.Helpers.ToString(this._arr);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.JSON.Values
namespace Std.JSON.Errors {


  public interface _IDeserializationError {
    bool is_UnterminatedSequence { get; }
    bool is_UnsupportedEscape { get; }
    bool is_EscapeAtEOS { get; }
    bool is_EmptyNumber { get; }
    bool is_ExpectingEOF { get; }
    bool is_IntOverflow { get; }
    bool is_ReachedEOF { get; }
    bool is_ExpectingByte { get; }
    bool is_ExpectingAnyByte { get; }
    bool is_InvalidUnicode { get; }
    Dafny.ISequence<Dafny.Rune> dtor_str { get; }
    byte dtor_expected { get; }
    short dtor_b { get; }
    Dafny.ISequence<byte> dtor_expected__sq { get; }
    _IDeserializationError DowncastClone();
    Dafny.ISequence<Dafny.Rune> _ToString();
  }
  public abstract class DeserializationError : _IDeserializationError {
    public DeserializationError() {
    }
    private static readonly Std.JSON.Errors._IDeserializationError theDefault = create_UnterminatedSequence();
    public static Std.JSON.Errors._IDeserializationError Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Errors._IDeserializationError> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Errors._IDeserializationError> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IDeserializationError create_UnterminatedSequence() {
      return new DeserializationError_UnterminatedSequence();
    }
    public static _IDeserializationError create_UnsupportedEscape(Dafny.ISequence<Dafny.Rune> str) {
      return new DeserializationError_UnsupportedEscape(str);
    }
    public static _IDeserializationError create_EscapeAtEOS() {
      return new DeserializationError_EscapeAtEOS();
    }
    public static _IDeserializationError create_EmptyNumber() {
      return new DeserializationError_EmptyNumber();
    }
    public static _IDeserializationError create_ExpectingEOF() {
      return new DeserializationError_ExpectingEOF();
    }
    public static _IDeserializationError create_IntOverflow() {
      return new DeserializationError_IntOverflow();
    }
    public static _IDeserializationError create_ReachedEOF() {
      return new DeserializationError_ReachedEOF();
    }
    public static _IDeserializationError create_ExpectingByte(byte expected, short b) {
      return new DeserializationError_ExpectingByte(expected, b);
    }
    public static _IDeserializationError create_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) {
      return new DeserializationError_ExpectingAnyByte(expected__sq, b);
    }
    public static _IDeserializationError create_InvalidUnicode() {
      return new DeserializationError_InvalidUnicode();
    }
    public bool is_UnterminatedSequence { get { return this is DeserializationError_UnterminatedSequence; } }
    public bool is_UnsupportedEscape { get { return this is DeserializationError_UnsupportedEscape; } }
    public bool is_EscapeAtEOS { get { return this is DeserializationError_EscapeAtEOS; } }
    public bool is_EmptyNumber { get { return this is DeserializationError_EmptyNumber; } }
    public bool is_ExpectingEOF { get { return this is DeserializationError_ExpectingEOF; } }
    public bool is_IntOverflow { get { return this is DeserializationError_IntOverflow; } }
    public bool is_ReachedEOF { get { return this is DeserializationError_ReachedEOF; } }
    public bool is_ExpectingByte { get { return this is DeserializationError_ExpectingByte; } }
    public bool is_ExpectingAnyByte { get { return this is DeserializationError_ExpectingAnyByte; } }
    public bool is_InvalidUnicode { get { return this is DeserializationError_InvalidUnicode; } }
    public Dafny.ISequence<Dafny.Rune> dtor_str {
      get {
        var d = this;
        return ((DeserializationError_UnsupportedEscape)d)._str;
      }
    }
    public byte dtor_expected {
      get {
        var d = this;
        return ((DeserializationError_ExpectingByte)d)._expected;
      }
    }
    public short dtor_b {
      get {
        var d = this;
        if (d is DeserializationError_ExpectingByte) { return ((DeserializationError_ExpectingByte)d)._b; }
        return ((DeserializationError_ExpectingAnyByte)d)._b;
      }
    }
    public Dafny.ISequence<byte> dtor_expected__sq {
      get {
        var d = this;
        return ((DeserializationError_ExpectingAnyByte)d)._expected__sq;
      }
    }
    public abstract _IDeserializationError DowncastClone();
    public Dafny.ISequence<Dafny.Rune> _ToString() {
      Std.JSON.Errors._IDeserializationError _source10 = this;
      if (_source10.is_UnterminatedSequence) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Unterminated sequence");
      } else if (_source10.is_UnsupportedEscape) {
        Dafny.ISequence<Dafny.Rune> _295___mcc_h0 = _source10.dtor_str;
        Dafny.ISequence<Dafny.Rune> _296_str = _295___mcc_h0;
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Unsupported escape sequence: "), _296_str);
      } else if (_source10.is_EscapeAtEOS) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Escape character at end of string");
      } else if (_source10.is_EmptyNumber) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Number must contain at least one digit");
      } else if (_source10.is_ExpectingEOF) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting EOF");
      } else if (_source10.is_IntOverflow) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Input length does not fit in a 32-bit counter");
      } else if (_source10.is_ReachedEOF) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Reached EOF");
      } else if (_source10.is_ExpectingByte) {
        byte _297___mcc_h1 = _source10.dtor_expected;
        short _298___mcc_h2 = _source10.dtor_b;
        short _299_b = _298___mcc_h2;
        byte _300_b0 = _297___mcc_h1;
        Dafny.ISequence<Dafny.Rune> _301_c = (((_299_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_299_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting '"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_300_b0)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _301_c);
      } else if (_source10.is_ExpectingAnyByte) {
        Dafny.ISequence<byte> _302___mcc_h3 = _source10.dtor_expected__sq;
        short _303___mcc_h4 = _source10.dtor_b;
        short _304_b = _303___mcc_h4;
        Dafny.ISequence<byte> _305_bs0 = _302___mcc_h3;
        Dafny.ISequence<Dafny.Rune> _306_c = (((_304_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_304_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
        Dafny.ISequence<Dafny.Rune> _307_c0s = ((System.Func<Dafny.ISequence<Dafny.Rune>>) (() => {
          BigInteger dim4 = new BigInteger((_305_bs0).Count);
          var arr4 = new Dafny.Rune[Dafny.Helpers.ToIntChecked(dim4, "array size exceeds memory limit")];
          for (int i4 = 0; i4 < dim4; i4++) {
            var _308_idx = (BigInteger) i4;
            arr4[(int)(_308_idx)] = new Dafny.Rune((int)((_305_bs0).Select(_308_idx)));
          }
          return Dafny.Sequence<Dafny.Rune>.FromArray(arr4);
        }))();
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting one of '"), _307_c0s), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _306_c);
      } else {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Invalid Unicode sequence");
      }
    }
  }
  public class DeserializationError_UnterminatedSequence : DeserializationError {
    public DeserializationError_UnterminatedSequence() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_UnterminatedSequence();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_UnterminatedSequence;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.UnterminatedSequence";
      return s;
    }
  }
  public class DeserializationError_UnsupportedEscape : DeserializationError {
    public readonly Dafny.ISequence<Dafny.Rune> _str;
    public DeserializationError_UnsupportedEscape(Dafny.ISequence<Dafny.Rune> str) : base() {
      this._str = str;
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_UnsupportedEscape(_str);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_UnsupportedEscape;
      return oth != null && object.Equals(this._str, oth._str);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._str));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.UnsupportedEscape";
      s += "(";
      s += this._str.ToVerbatimString(true);
      s += ")";
      return s;
    }
  }
  public class DeserializationError_EscapeAtEOS : DeserializationError {
    public DeserializationError_EscapeAtEOS() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_EscapeAtEOS();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_EscapeAtEOS;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.EscapeAtEOS";
      return s;
    }
  }
  public class DeserializationError_EmptyNumber : DeserializationError {
    public DeserializationError_EmptyNumber() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_EmptyNumber();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_EmptyNumber;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.EmptyNumber";
      return s;
    }
  }
  public class DeserializationError_ExpectingEOF : DeserializationError {
    public DeserializationError_ExpectingEOF() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ExpectingEOF();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ExpectingEOF;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 4;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ExpectingEOF";
      return s;
    }
  }
  public class DeserializationError_IntOverflow : DeserializationError {
    public DeserializationError_IntOverflow() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_IntOverflow();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_IntOverflow;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 5;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.IntOverflow";
      return s;
    }
  }
  public class DeserializationError_ReachedEOF : DeserializationError {
    public DeserializationError_ReachedEOF() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ReachedEOF();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ReachedEOF;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 6;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ReachedEOF";
      return s;
    }
  }
  public class DeserializationError_ExpectingByte : DeserializationError {
    public readonly byte _expected;
    public readonly short _b;
    public DeserializationError_ExpectingByte(byte expected, short b) : base() {
      this._expected = expected;
      this._b = b;
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ExpectingByte(_expected, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ExpectingByte;
      return oth != null && this._expected == oth._expected && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 7;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ExpectingByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class DeserializationError_ExpectingAnyByte : DeserializationError {
    public readonly Dafny.ISequence<byte> _expected__sq;
    public readonly short _b;
    public DeserializationError_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) : base() {
      this._expected__sq = expected__sq;
      this._b = b;
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_ExpectingAnyByte(_expected__sq, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_ExpectingAnyByte;
      return oth != null && object.Equals(this._expected__sq, oth._expected__sq) && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 8;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected__sq));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.ExpectingAnyByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected__sq);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class DeserializationError_InvalidUnicode : DeserializationError {
    public DeserializationError_InvalidUnicode() : base() {
    }
    public override _IDeserializationError DowncastClone() {
      if (this is _IDeserializationError dt) { return dt; }
      return new DeserializationError_InvalidUnicode();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.DeserializationError_InvalidUnicode;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 9;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.DeserializationError.InvalidUnicode";
      return s;
    }
  }

  public interface _ISerializationError {
    bool is_OutOfMemory { get; }
    bool is_IntTooLarge { get; }
    bool is_StringTooLong { get; }
    bool is_InvalidUnicode { get; }
    BigInteger dtor_i { get; }
    Dafny.ISequence<Dafny.Rune> dtor_s { get; }
    _ISerializationError DowncastClone();
    Dafny.ISequence<Dafny.Rune> _ToString();
  }
  public abstract class SerializationError : _ISerializationError {
    public SerializationError() {
    }
    private static readonly Std.JSON.Errors._ISerializationError theDefault = create_OutOfMemory();
    public static Std.JSON.Errors._ISerializationError Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Errors._ISerializationError> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Errors._ISerializationError> _TypeDescriptor() {
      return _TYPE;
    }
    public static _ISerializationError create_OutOfMemory() {
      return new SerializationError_OutOfMemory();
    }
    public static _ISerializationError create_IntTooLarge(BigInteger i) {
      return new SerializationError_IntTooLarge(i);
    }
    public static _ISerializationError create_StringTooLong(Dafny.ISequence<Dafny.Rune> s) {
      return new SerializationError_StringTooLong(s);
    }
    public static _ISerializationError create_InvalidUnicode() {
      return new SerializationError_InvalidUnicode();
    }
    public bool is_OutOfMemory { get { return this is SerializationError_OutOfMemory; } }
    public bool is_IntTooLarge { get { return this is SerializationError_IntTooLarge; } }
    public bool is_StringTooLong { get { return this is SerializationError_StringTooLong; } }
    public bool is_InvalidUnicode { get { return this is SerializationError_InvalidUnicode; } }
    public BigInteger dtor_i {
      get {
        var d = this;
        return ((SerializationError_IntTooLarge)d)._i;
      }
    }
    public Dafny.ISequence<Dafny.Rune> dtor_s {
      get {
        var d = this;
        return ((SerializationError_StringTooLong)d)._s;
      }
    }
    public abstract _ISerializationError DowncastClone();
    public Dafny.ISequence<Dafny.Rune> _ToString() {
      Std.JSON.Errors._ISerializationError _source11 = this;
      if (_source11.is_OutOfMemory) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Out of memory");
      } else if (_source11.is_IntTooLarge) {
        BigInteger _309___mcc_h0 = _source11.dtor_i;
        BigInteger _310_i = _309___mcc_h0;
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Integer too large: "), Std.Strings.__default.OfInt(_310_i));
      } else if (_source11.is_StringTooLong) {
        Dafny.ISequence<Dafny.Rune> _311___mcc_h1 = _source11.dtor_s;
        Dafny.ISequence<Dafny.Rune> _312_s = _311___mcc_h1;
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("String too long: "), _312_s);
      } else {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Invalid Unicode sequence");
      }
    }
  }
  public class SerializationError_OutOfMemory : SerializationError {
    public SerializationError_OutOfMemory() : base() {
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_OutOfMemory();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_OutOfMemory;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.SerializationError.OutOfMemory";
      return s;
    }
  }
  public class SerializationError_IntTooLarge : SerializationError {
    public readonly BigInteger _i;
    public SerializationError_IntTooLarge(BigInteger i) : base() {
      this._i = i;
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_IntTooLarge(_i);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_IntTooLarge;
      return oth != null && this._i == oth._i;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._i));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.SerializationError.IntTooLarge";
      s += "(";
      s += Dafny.Helpers.ToString(this._i);
      s += ")";
      return s;
    }
  }
  public class SerializationError_StringTooLong : SerializationError {
    public readonly Dafny.ISequence<Dafny.Rune> _s;
    public SerializationError_StringTooLong(Dafny.ISequence<Dafny.Rune> s) : base() {
      this._s = s;
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_StringTooLong(_s);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_StringTooLong;
      return oth != null && object.Equals(this._s, oth._s);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._s));
      return (int) hash;
    }
    public override string ToString() {
      string ss = "Errors.SerializationError.StringTooLong";
      ss += "(";
      ss += this._s.ToVerbatimString(true);
      ss += ")";
      return ss;
    }
  }
  public class SerializationError_InvalidUnicode : SerializationError {
    public SerializationError_InvalidUnicode() : base() {
    }
    public override _ISerializationError DowncastClone() {
      if (this is _ISerializationError dt) { return dt; }
      return new SerializationError_InvalidUnicode();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Errors.SerializationError_InvalidUnicode;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Errors.SerializationError.InvalidUnicode";
      return s;
    }
  }
} // end of namespace Std.JSON.Errors
namespace Std.JSON.Spec {

  public partial class __default {
    public static Dafny.ISequence<ushort> EscapeUnicode(ushort c) {
      Dafny.ISequence<Dafny.Rune> _313_sStr = Std.Strings.HexConversion.__default.OfNat(new BigInteger(c));
      Dafny.ISequence<ushort> _314_s = Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(_313_sStr);
      return Dafny.Sequence<ushort>.Concat(_314_s, ((System.Func<Dafny.ISequence<ushort>>) (() => {
        BigInteger dim5 = (new BigInteger(4)) - (new BigInteger((_314_s).Count));
        var arr5 = new ushort[Dafny.Helpers.ToIntChecked(dim5, "array size exceeds memory limit")];
        for (int i5 = 0; i5 < dim5; i5++) {
          var _315___v8 = (BigInteger) i5;
          arr5[(int)(_315___v8)] = (ushort)((new Dafny.Rune(' ')).Value);
        }
        return Dafny.Sequence<ushort>.FromArray(arr5);
      }))());
    }
    public static Dafny.ISequence<ushort> Escape(Dafny.ISequence<ushort> str, BigInteger start)
    {
      Dafny.ISequence<ushort> _316___accumulator = Dafny.Sequence<ushort>.FromElements();
    TAIL_CALL_START: ;
      var _pat_let_tv0 = str;
      var _pat_let_tv1 = start;
      if ((start) >= (new BigInteger((str).Count))) {
        return Dafny.Sequence<ushort>.Concat(_316___accumulator, Dafny.Sequence<ushort>.FromElements());
      } else {
        _316___accumulator = Dafny.Sequence<ushort>.Concat(_316___accumulator, ((((str).Select(start)) == ((ushort)(34))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\\""))) : (((((str).Select(start)) == ((ushort)(92))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\\\"))) : (((((str).Select(start)) == ((ushort)(8))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\b"))) : (((((str).Select(start)) == ((ushort)(12))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\f"))) : (((((str).Select(start)) == ((ushort)(10))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\n"))) : (((((str).Select(start)) == ((ushort)(13))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\r"))) : (((((str).Select(start)) == ((ushort)(9))) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\t"))) : (Dafny.Helpers.Let<ushort, Dafny.ISequence<ushort>>((str).Select(start), _pat_let1_0 => Dafny.Helpers.Let<ushort, Dafny.ISequence<ushort>>(_pat_let1_0, _317_c => (((_317_c) < ((ushort)(31))) ? (Dafny.Sequence<ushort>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF16(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\\u")), Std.JSON.Spec.__default.EscapeUnicode(_317_c))) : (Dafny.Sequence<ushort>.FromElements((_pat_let_tv0).Select(_pat_let_tv1)))))))))))))))))))));
        Dafny.ISequence<ushort> _in61 = str;
        BigInteger _in62 = (start) + (BigInteger.One);
        str = _in61;
        start = _in62;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> EscapeToUTF8(Dafny.ISequence<Dafny.Rune> str, BigInteger start)
    {
      Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._ISerializationError> _318_valueOrError0 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ToUTF16Checked(str)).ToResult<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.create_InvalidUnicode());
      if ((_318_valueOrError0).IsFailure()) {
        return (_318_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<ushort> _319_utf16 = (_318_valueOrError0).Extract();
        Dafny.ISequence<ushort> _320_escaped = Std.JSON.Spec.__default.Escape(_319_utf16, BigInteger.Zero);
        Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._ISerializationError> _321_valueOrError1 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF16Checked(_320_escaped)).ToResult<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.create_InvalidUnicode());
        if ((_321_valueOrError1).IsFailure()) {
          return (_321_valueOrError1).PropagateFailure<Dafny.ISequence<byte>>();
        } else {
          Dafny.ISequence<Dafny.Rune> _322_utf32 = (_321_valueOrError1).Extract();
          return (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ToUTF8Checked(_322_utf32)).ToResult<Std.JSON.Errors._ISerializationError>(Std.JSON.Errors.SerializationError.create_InvalidUnicode());
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> String(Dafny.ISequence<Dafny.Rune> str) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _323_valueOrError0 = Std.JSON.Spec.__default.EscapeToUTF8(str, BigInteger.Zero);
      if ((_323_valueOrError0).IsFailure()) {
        return (_323_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _324_inBytes = (_323_valueOrError0).Extract();
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\"")), _324_inBytes), Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("\""))));
      }
    }
    public static Dafny.ISequence<byte> IntToBytes(BigInteger n) {
      Dafny.ISequence<Dafny.Rune> _325_s = Std.Strings.__default.OfInt(n);
      return Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(_325_s);
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Number(Std.JSON.Values._IDecimal dec) {
      return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Std.JSON.Spec.__default.IntToBytes((dec).dtor_n), ((((dec).dtor_e10).Sign == 0) ? (Dafny.Sequence<byte>.FromElements()) : (Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("e")), Std.JSON.Spec.__default.IntToBytes((dec).dtor_e10))))));
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> KeyValue(_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON> kv) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _326_valueOrError0 = Std.JSON.Spec.__default.String((kv).dtor__0);
      if ((_326_valueOrError0).IsFailure()) {
        return (_326_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _327_key = (_326_valueOrError0).Extract();
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _328_valueOrError1 = Std.JSON.Spec.__default.JSON((kv).dtor__1);
        if ((_328_valueOrError1).IsFailure()) {
          return (_328_valueOrError1).PropagateFailure<Dafny.ISequence<byte>>();
        } else {
          Dafny.ISequence<byte> _329_value = (_328_valueOrError1).Extract();
          return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(_327_key, Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(":"))), _329_value));
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Join(Dafny.ISequence<byte> sep, Dafny.ISequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>> items)
    {
      if ((new BigInteger((items).Count)).Sign == 0) {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.FromElements());
      } else {
        Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _330_valueOrError0 = (items).Select(BigInteger.Zero);
        if ((_330_valueOrError0).IsFailure()) {
          return (_330_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
        } else {
          Dafny.ISequence<byte> _331_first = (_330_valueOrError0).Extract();
          if ((new BigInteger((items).Count)) == (BigInteger.One)) {
            return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(_331_first);
          } else {
            Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _332_valueOrError1 = Std.JSON.Spec.__default.Join(sep, (items).Drop(BigInteger.One));
            if ((_332_valueOrError1).IsFailure()) {
              return (_332_valueOrError1).PropagateFailure<Dafny.ISequence<byte>>();
            } else {
              Dafny.ISequence<byte> _333_rest = (_332_valueOrError1).Extract();
              return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(_331_first, sep), _333_rest));
            }
          }
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _334_valueOrError0 = Std.JSON.Spec.__default.Join(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(",")), ((System.Func<Dafny.ISequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>>) (() => {
        BigInteger dim6 = new BigInteger((obj).Count);
        var arr6 = new Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>[Dafny.Helpers.ToIntChecked(dim6, "array size exceeds memory limit")];
        for (int i6 = 0; i6 < dim6; i6++) {
          var _335_i = (BigInteger) i6;
          arr6[(int)(_335_i)] = Std.JSON.Spec.__default.KeyValue((obj).Select(_335_i));
        }
        return Dafny.Sequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>.FromArray(arr6);
      }))());
      if ((_334_valueOrError0).IsFailure()) {
        return (_334_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _336_middle = (_334_valueOrError0).Extract();
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("{")), _336_middle), Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("}"))));
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _337_valueOrError0 = Std.JSON.Spec.__default.Join(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString(",")), ((System.Func<Dafny.ISequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>>) (() => {
        BigInteger dim7 = new BigInteger((arr).Count);
        var arr7 = new Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>[Dafny.Helpers.ToIntChecked(dim7, "array size exceeds memory limit")];
        for (int i7 = 0; i7 < dim7; i7++) {
          var _338_i = (BigInteger) i7;
          arr7[(int)(_338_i)] = Std.JSON.Spec.__default.JSON((arr).Select(_338_i));
        }
        return Dafny.Sequence<Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>>.FromArray(arr7);
      }))());
      if ((_337_valueOrError0).IsFailure()) {
        return (_337_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Dafny.ISequence<byte> _339_middle = (_337_valueOrError0).Extract();
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("[")), _339_middle), Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("]"))));
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> JSON(Std.JSON.Values._IJSON js) {
      Std.JSON.Values._IJSON _source12 = js;
      if (_source12.is_Null) {
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("null")));
      } else if (_source12.is_Bool) {
        bool _340___mcc_h0 = _source12.dtor_b;
        bool _341_b = _340___mcc_h0;
        return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success(((_341_b) ? (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("true"))) : (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ASCIIToUTF8(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("false")))));
      } else if (_source12.is_String) {
        Dafny.ISequence<Dafny.Rune> _342___mcc_h1 = _source12.dtor_str;
        Dafny.ISequence<Dafny.Rune> _343_str = _342___mcc_h1;
        return Std.JSON.Spec.__default.String(_343_str);
      } else if (_source12.is_Number) {
        Std.JSON.Values._IDecimal _344___mcc_h2 = _source12.dtor_num;
        Std.JSON.Values._IDecimal _345_dec = _344___mcc_h2;
        return Std.JSON.Spec.__default.Number(_345_dec);
      } else if (_source12.is_Object) {
        Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _346___mcc_h3 = _source12.dtor_obj;
        Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _347_obj = _346___mcc_h3;
        return Std.JSON.Spec.__default.Object(_347_obj);
      } else {
        Dafny.ISequence<Std.JSON.Values._IJSON> _348___mcc_h4 = _source12.dtor_arr;
        Dafny.ISequence<Std.JSON.Values._IJSON> _349_arr = _348___mcc_h4;
        return Std.JSON.Spec.__default.Array(_349_arr);
      }
    }
  }
} // end of namespace Std.JSON.Spec
namespace Std.JSON.Utils.Views.Core {

  public partial class __default {
    public static bool Adjacent(Std.JSON.Utils.Views.Core._IView__ lv, Std.JSON.Utils.Views.Core._IView__ rv)
    {
      return (((lv).dtor_end) == ((rv).dtor_beg)) && (((lv).dtor_s).Equals((rv).dtor_s));
    }
    public static Std.JSON.Utils.Views.Core._IView__ Merge(Std.JSON.Utils.Views.Core._IView__ lv, Std.JSON.Utils.Views.Core._IView__ rv)
    {
      Std.JSON.Utils.Views.Core._IView__ _350_dt__update__tmp_h0 = lv;
      uint _351_dt__update_hend_h0 = (rv).dtor_end;
      return Std.JSON.Utils.Views.Core.View__.create((_350_dt__update__tmp_h0).dtor_s, (_350_dt__update__tmp_h0).dtor_beg, _351_dt__update_hend_h0);
    }
  }

  public partial class View {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Utils.Views.Core.View.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _IView__ {
    bool is_View { get; }
    Dafny.ISequence<byte> dtor_s { get; }
    uint dtor_beg { get; }
    uint dtor_end { get; }
    _IView__ DowncastClone();
    bool Empty_q { get; }
    uint Length();
    Dafny.ISequence<byte> Bytes();
    bool Byte_q(byte c);
    bool Char_q(Dafny.Rune c);
    byte At(uint idx);
    short Peek();
    void CopyTo(byte[] dest, uint start);
  }
  public class View__ : _IView__ {
    public readonly Dafny.ISequence<byte> _s;
    public readonly uint _beg;
    public readonly uint _end;
    public View__(Dafny.ISequence<byte> s, uint beg, uint end) {
      this._s = s;
      this._beg = beg;
      this._end = end;
    }
    public _IView__ DowncastClone() {
      if (this is _IView__ dt) { return dt; }
      return new View__(_s, _beg, _end);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Core.View__;
      return oth != null && object.Equals(this._s, oth._s) && this._beg == oth._beg && this._end == oth._end;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._s));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._beg));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._end));
      return (int) hash;
    }
    public override string ToString() {
      string ss = "Core.View_.View";
      ss += "(";
      ss += Dafny.Helpers.ToString(this._s);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._beg);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._end);
      ss += ")";
      return ss;
    }
    private static readonly Std.JSON.Utils.Views.Core._IView__ theDefault = create(Dafny.Sequence<byte>.Empty, 0, 0);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Utils.Views.Core.View__.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IView__ create(Dafny.ISequence<byte> s, uint beg, uint end) {
      return new View__(s, beg, end);
    }
    public static _IView__ create_View(Dafny.ISequence<byte> s, uint beg, uint end) {
      return create(s, beg, end);
    }
    public bool is_View { get { return true; } }
    public Dafny.ISequence<byte> dtor_s {
      get {
        return this._s;
      }
    }
    public uint dtor_beg {
      get {
        return this._beg;
      }
    }
    public uint dtor_end {
      get {
        return this._end;
      }
    }
    public uint Length() {
      return ((this).dtor_end) - ((this).dtor_beg);
    }
    public Dafny.ISequence<byte> Bytes() {
      return ((this).dtor_s).Subsequence((this).dtor_beg, (this).dtor_end);
    }
    public static Std.JSON.Utils.Views.Core._IView__ OfBytes(Dafny.ISequence<byte> bs) {
      return Std.JSON.Utils.Views.Core.View__.create(bs, (uint)(0U), (uint)(bs).LongCount);
    }
    public static Dafny.ISequence<byte> OfString(Dafny.ISequence<Dafny.Rune> s) {
      return ((System.Func<Dafny.ISequence<byte>>) (() => {
        BigInteger dim8 = new BigInteger((s).Count);
        var arr8 = new byte[Dafny.Helpers.ToIntChecked(dim8, "array size exceeds memory limit")];
        for (int i8 = 0; i8 < dim8; i8++) {
          var _352_i = (BigInteger) i8;
          arr8[(int)(_352_i)] = (byte)(((s).Select(_352_i)).Value);
        }
        return Dafny.Sequence<byte>.FromArray(arr8);
      }))();
    }
    public bool Byte_q(byte c)
    {
      bool _hresult = false;
      _hresult = (((this).Length()) == (1U)) && (((this).At(0U)) == (c));
      return _hresult;
      return _hresult;
    }
    public bool Char_q(Dafny.Rune c) {
      return (this).Byte_q((byte)((c).Value));
    }
    public byte At(uint idx) {
      return ((this).dtor_s).Select(((this).dtor_beg) + (idx));
    }
    public short Peek() {
      if ((this).Empty_q) {
        return (short)(-1);
      } else {
        return (short)((this).At(0U));
      }
    }
    public void CopyTo(byte[] dest, uint start)
    {
      uint _hi0 = (this).Length();
      for (uint _353_idx = 0U; _353_idx < _hi0; _353_idx++) {
        uint _index6 = (start) + (_353_idx);
        (dest)[(int)(_index6)] = ((this).dtor_s).Select(((this).dtor_beg) + (_353_idx));
      }
    }
    public static Std.JSON.Utils.Views.Core._IView__ Empty { get {
      return Std.JSON.Utils.Views.Core.View__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U);
    } }
    public bool Empty_q { get {
      return ((this).dtor_beg) == ((this).dtor_end);
    } }
  }
} // end of namespace Std.JSON.Utils.Views.Core
namespace Std.JSON.Utils.Views.Writers {


  public interface _IChain {
    bool is_Empty { get; }
    bool is_Chain { get; }
    Std.JSON.Utils.Views.Writers._IChain dtor_previous { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_v { get; }
    _IChain DowncastClone();
    BigInteger Length();
    BigInteger Count();
    Dafny.ISequence<byte> Bytes();
    Std.JSON.Utils.Views.Writers._IChain Append(Std.JSON.Utils.Views.Core._IView__ v_k);
    void CopyTo(byte[] dest, uint end);
  }
  public abstract class Chain : _IChain {
    public Chain() {
    }
    private static readonly Std.JSON.Utils.Views.Writers._IChain theDefault = create_Empty();
    public static Std.JSON.Utils.Views.Writers._IChain Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IChain> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IChain>(Std.JSON.Utils.Views.Writers.Chain.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IChain> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IChain create_Empty() {
      return new Chain_Empty();
    }
    public static _IChain create_Chain(Std.JSON.Utils.Views.Writers._IChain previous, Std.JSON.Utils.Views.Core._IView__ v) {
      return new Chain_Chain(previous, v);
    }
    public bool is_Empty { get { return this is Chain_Empty; } }
    public bool is_Chain { get { return this is Chain_Chain; } }
    public Std.JSON.Utils.Views.Writers._IChain dtor_previous {
      get {
        var d = this;
        return ((Chain_Chain)d)._previous;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_v {
      get {
        var d = this;
        return ((Chain_Chain)d)._v;
      }
    }
    public abstract _IChain DowncastClone();
    public BigInteger Length() {
      BigInteger _354___accumulator = BigInteger.Zero;
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Empty) {
        return (BigInteger.Zero) + (_354___accumulator);
      } else {
        _354___accumulator = (new BigInteger(((_this).dtor_v).Length())) + (_354___accumulator);
        Std.JSON.Utils.Views.Writers._IChain _in63 = (_this).dtor_previous;
        _this = _in63;
        ;
        goto TAIL_CALL_START;
      }
    }
    public BigInteger Count() {
      BigInteger _355___accumulator = BigInteger.Zero;
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Empty) {
        return (BigInteger.Zero) + (_355___accumulator);
      } else {
        _355___accumulator = (BigInteger.One) + (_355___accumulator);
        Std.JSON.Utils.Views.Writers._IChain _in64 = (_this).dtor_previous;
        _this = _in64;
        ;
        goto TAIL_CALL_START;
      }
    }
    public Dafny.ISequence<byte> Bytes() {
      Dafny.ISequence<byte> _356___accumulator = Dafny.Sequence<byte>.FromElements();
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Empty) {
        return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements(), _356___accumulator);
      } else {
        _356___accumulator = Dafny.Sequence<byte>.Concat(((_this).dtor_v).Bytes(), _356___accumulator);
        Std.JSON.Utils.Views.Writers._IChain _in65 = (_this).dtor_previous;
        _this = _in65;
        ;
        goto TAIL_CALL_START;
      }
    }
    public Std.JSON.Utils.Views.Writers._IChain Append(Std.JSON.Utils.Views.Core._IView__ v_k) {
      if (((this).is_Chain) && (Std.JSON.Utils.Views.Core.__default.Adjacent((this).dtor_v, v_k))) {
        return Std.JSON.Utils.Views.Writers.Chain.create_Chain((this).dtor_previous, Std.JSON.Utils.Views.Core.__default.Merge((this).dtor_v, v_k));
      } else {
        return Std.JSON.Utils.Views.Writers.Chain.create_Chain(this, v_k);
      }
    }
    public void CopyTo(byte[] dest, uint end)
    {
      _IChain _this = this;
    TAIL_CALL_START: ;
      if ((_this).is_Chain) {
        uint _357_end;
        _357_end = (end) - (((_this).dtor_v).Length());
        ((_this).dtor_v).CopyTo(dest, _357_end);
        Std.JSON.Utils.Views.Writers._IChain _in66 = (_this).dtor_previous;
        byte[] _in67 = dest;
        uint _in68 = _357_end;
        _this = _in66;
        ;
        dest = _in67;
        end = _in68;
        goto TAIL_CALL_START;
      }
    }
  }
  public class Chain_Empty : Chain {
    public Chain_Empty() : base() {
    }
    public override _IChain DowncastClone() {
      if (this is _IChain dt) { return dt; }
      return new Chain_Empty();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Writers.Chain_Empty;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Writers.Chain.Empty";
      return s;
    }
  }
  public class Chain_Chain : Chain {
    public readonly Std.JSON.Utils.Views.Writers._IChain _previous;
    public readonly Std.JSON.Utils.Views.Core._IView__ _v;
    public Chain_Chain(Std.JSON.Utils.Views.Writers._IChain previous, Std.JSON.Utils.Views.Core._IView__ v) : base() {
      this._previous = previous;
      this._v = v;
    }
    public override _IChain DowncastClone() {
      if (this is _IChain dt) { return dt; }
      return new Chain_Chain(_previous, _v);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Writers.Chain_Chain;
      return oth != null && object.Equals(this._previous, oth._previous) && object.Equals(this._v, oth._v);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._previous));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._v));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Writers.Chain.Chain";
      s += "(";
      s += Dafny.Helpers.ToString(this._previous);
      s += ", ";
      s += Dafny.Helpers.ToString(this._v);
      s += ")";
      return s;
    }
  }

  public partial class Writer {
    private static readonly Std.JSON.Utils.Views.Writers._IWriter__ Witness = Std.JSON.Utils.Views.Writers.Writer__.create(0U, Std.JSON.Utils.Views.Writers.Chain.create_Empty());
    public static Std.JSON.Utils.Views.Writers._IWriter__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__>(Std.JSON.Utils.Views.Writers.Writer.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _IWriter__ {
    bool is_Writer { get; }
    uint dtor_length { get; }
    Std.JSON.Utils.Views.Writers._IChain dtor_chain { get; }
    _IWriter__ DowncastClone();
    bool Empty_q { get; }
    bool Unsaturated_q { get; }
    Dafny.ISequence<byte> Bytes();
    Std.JSON.Utils.Views.Writers._IWriter__ Append(Std.JSON.Utils.Views.Core._IView__ v_k);
    Std.JSON.Utils.Views.Writers._IWriter__ Then(Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__> fn);
    void CopyTo(byte[] dest);
    byte[] ToArray();
  }
  public class Writer__ : _IWriter__ {
    public readonly uint _length;
    public readonly Std.JSON.Utils.Views.Writers._IChain _chain;
    public Writer__(uint length, Std.JSON.Utils.Views.Writers._IChain chain) {
      this._length = length;
      this._chain = chain;
    }
    public _IWriter__ DowncastClone() {
      if (this is _IWriter__ dt) { return dt; }
      return new Writer__(_length, _chain);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Views.Writers.Writer__;
      return oth != null && this._length == oth._length && object.Equals(this._chain, oth._chain);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._length));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._chain));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Writers.Writer_.Writer";
      s += "(";
      s += Dafny.Helpers.ToString(this._length);
      s += ", ";
      s += Dafny.Helpers.ToString(this._chain);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Utils.Views.Writers._IWriter__ theDefault = create(0, Std.JSON.Utils.Views.Writers.Chain.Default());
    public static Std.JSON.Utils.Views.Writers._IWriter__ Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__>(Std.JSON.Utils.Views.Writers.Writer__.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Writers._IWriter__> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IWriter__ create(uint length, Std.JSON.Utils.Views.Writers._IChain chain) {
      return new Writer__(length, chain);
    }
    public static _IWriter__ create_Writer(uint length, Std.JSON.Utils.Views.Writers._IChain chain) {
      return create(length, chain);
    }
    public bool is_Writer { get { return true; } }
    public uint dtor_length {
      get {
        return this._length;
      }
    }
    public Std.JSON.Utils.Views.Writers._IChain dtor_chain {
      get {
        return this._chain;
      }
    }
    public Dafny.ISequence<byte> Bytes() {
      return ((this).dtor_chain).Bytes();
    }
    public static uint SaturatedAddU32(uint a, uint b)
    {
      if ((a) <= ((Std.BoundedInts.__default.UINT32__MAX) - (b))) {
        return (a) + (b);
      } else {
        return Std.BoundedInts.__default.UINT32__MAX;
      }
    }
    public Std.JSON.Utils.Views.Writers._IWriter__ Append(Std.JSON.Utils.Views.Core._IView__ v_k) {
      return Std.JSON.Utils.Views.Writers.Writer__.create(Std.JSON.Utils.Views.Writers.Writer__.SaturatedAddU32((this).dtor_length, (v_k).Length()), ((this).dtor_chain).Append(v_k));
    }
    public Std.JSON.Utils.Views.Writers._IWriter__ Then(Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__> fn) {
      return Dafny.Helpers.Id<Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__>>(fn)(this);
    }
    public void CopyTo(byte[] dest)
    {
      ((this).dtor_chain).CopyTo(dest, (this).dtor_length);
    }
    public byte[] ToArray()
    {
      byte[] bs = new byte[0];
      Func<BigInteger, byte> _init4 = ((System.Func<BigInteger, byte>)((_358_i) => {
        return (byte)(0);
      }));
      byte[] _nw5 = new byte[Dafny.Helpers.ToIntChecked((this).dtor_length, "array size exceeds memory limit")];
      for (var _i0_4 = 0; _i0_4 < new BigInteger(_nw5.Length); _i0_4++) {
        _nw5[(int)(_i0_4)] = _init4(_i0_4);
      }
      bs = _nw5;
      (this).CopyTo(bs);
      return bs;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Empty { get {
      return Std.JSON.Utils.Views.Writers.Writer__.create(0U, Std.JSON.Utils.Views.Writers.Chain.create_Empty());
    } }
    public bool Unsaturated_q { get {
      return ((this).dtor_length) != (Std.BoundedInts.__default.UINT32__MAX);
    } }
    public bool Empty_q { get {
      return ((this).dtor_chain).is_Empty;
    } }
  }
} // end of namespace Std.JSON.Utils.Views.Writers
namespace Std.JSON.Utils.Views {

} // end of namespace Std.JSON.Utils.Views
namespace Std.JSON.Utils.Lexers.Core {


  public interface _ILexerResult<out T, out R> {
    bool is_Accept { get; }
    bool is_Reject { get; }
    bool is_Partial { get; }
    R dtor_err { get; }
    T dtor_st { get; }
    _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1);
  }
  public abstract class LexerResult<T, R> : _ILexerResult<T, R> {
    public LexerResult() {
    }
    public static Std.JSON.Utils.Lexers.Core._ILexerResult<T, R> Default() {
      return create_Accept();
    }
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Core._ILexerResult<T, R>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Core._ILexerResult<T, R>>(Std.JSON.Utils.Lexers.Core.LexerResult<T, R>.Default());
    }
    public static _ILexerResult<T, R> create_Accept() {
      return new LexerResult_Accept<T, R>();
    }
    public static _ILexerResult<T, R> create_Reject(R err) {
      return new LexerResult_Reject<T, R>(err);
    }
    public static _ILexerResult<T, R> create_Partial(T st) {
      return new LexerResult_Partial<T, R>(st);
    }
    public bool is_Accept { get { return this is LexerResult_Accept<T, R>; } }
    public bool is_Reject { get { return this is LexerResult_Reject<T, R>; } }
    public bool is_Partial { get { return this is LexerResult_Partial<T, R>; } }
    public R dtor_err {
      get {
        var d = this;
        return ((LexerResult_Reject<T, R>)d)._err;
      }
    }
    public T dtor_st {
      get {
        var d = this;
        return ((LexerResult_Partial<T, R>)d)._st;
      }
    }
    public abstract _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1);
  }
  public class LexerResult_Accept<T, R> : LexerResult<T, R> {
    public LexerResult_Accept() : base() {
    }
    public override _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1) {
      if (this is _ILexerResult<__T, __R> dt) { return dt; }
      return new LexerResult_Accept<__T, __R>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Core.LexerResult_Accept<T, R>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Core.LexerResult.Accept";
      return s;
    }
  }
  public class LexerResult_Reject<T, R> : LexerResult<T, R> {
    public readonly R _err;
    public LexerResult_Reject(R err) : base() {
      this._err = err;
    }
    public override _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1) {
      if (this is _ILexerResult<__T, __R> dt) { return dt; }
      return new LexerResult_Reject<__T, __R>(converter1(_err));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Core.LexerResult_Reject<T, R>;
      return oth != null && object.Equals(this._err, oth._err);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._err));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Core.LexerResult.Reject";
      s += "(";
      s += Dafny.Helpers.ToString(this._err);
      s += ")";
      return s;
    }
  }
  public class LexerResult_Partial<T, R> : LexerResult<T, R> {
    public readonly T _st;
    public LexerResult_Partial(T st) : base() {
      this._st = st;
    }
    public override _ILexerResult<__T, __R> DowncastClone<__T, __R>(Func<T, __T> converter0, Func<R, __R> converter1) {
      if (this is _ILexerResult<__T, __R> dt) { return dt; }
      return new LexerResult_Partial<__T, __R>(converter0(_st));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Core.LexerResult_Partial<T, R>;
      return oth != null && object.Equals(this._st, oth._st);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._st));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Core.LexerResult.Partial";
      s += "(";
      s += Dafny.Helpers.ToString(this._st);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.JSON.Utils.Lexers.Core
namespace Std.JSON.Utils.Lexers.Strings {

  public partial class __default {
    public static Std.JSON.Utils.Lexers.Core._ILexerResult<bool, __R> StringBody<__R>(bool escaped, short @byte)
    {
      if ((@byte) == ((short)((new Dafny.Rune('\\')).Value))) {
        return Std.JSON.Utils.Lexers.Core.LexerResult<bool, __R>.create_Partial(!(escaped));
      } else if (((@byte) == ((short)((new Dafny.Rune('\"')).Value))) && (!(escaped))) {
        return Std.JSON.Utils.Lexers.Core.LexerResult<bool, __R>.create_Accept();
      } else {
        return Std.JSON.Utils.Lexers.Core.LexerResult<bool, __R>.create_Partial(false);
      }
    }
    public static Std.JSON.Utils.Lexers.Core._ILexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>> String(Std.JSON.Utils.Lexers.Strings._IStringLexerState st, short @byte)
    {
      Std.JSON.Utils.Lexers.Strings._IStringLexerState _source13 = st;
      if (_source13.is_Start) {
        if ((@byte) == ((short)((new Dafny.Rune('\"')).Value))) {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Body(false));
        } else {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Reject(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("String must start with double quote"));
        }
      } else if (_source13.is_Body) {
        bool _359___mcc_h0 = _source13.dtor_escaped;
        bool _360_escaped = _359___mcc_h0;
        if ((@byte) == ((short)((new Dafny.Rune('\\')).Value))) {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Body(!(_360_escaped)));
        } else if (((@byte) == ((short)((new Dafny.Rune('\"')).Value))) && (!(_360_escaped))) {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_End());
        } else {
          return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Partial(Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Body(false));
        }
      } else {
        return Std.JSON.Utils.Lexers.Core.LexerResult<Std.JSON.Utils.Lexers.Strings._IStringLexerState, Dafny.ISequence<Dafny.Rune>>.create_Accept();
      }
    }
    public static bool StringBodyLexerStart { get {
      return false;
    } }
    public static Std.JSON.Utils.Lexers.Strings._IStringLexerState StringLexerStart { get {
      return Std.JSON.Utils.Lexers.Strings.StringLexerState.create_Start();
    } }
  }

  public interface _IStringLexerState {
    bool is_Start { get; }
    bool is_Body { get; }
    bool is_End { get; }
    bool dtor_escaped { get; }
    _IStringLexerState DowncastClone();
  }
  public abstract class StringLexerState : _IStringLexerState {
    public StringLexerState() {
    }
    private static readonly Std.JSON.Utils.Lexers.Strings._IStringLexerState theDefault = create_Start();
    public static Std.JSON.Utils.Lexers.Strings._IStringLexerState Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Strings._IStringLexerState> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Strings._IStringLexerState>(Std.JSON.Utils.Lexers.Strings.StringLexerState.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Lexers.Strings._IStringLexerState> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IStringLexerState create_Start() {
      return new StringLexerState_Start();
    }
    public static _IStringLexerState create_Body(bool escaped) {
      return new StringLexerState_Body(escaped);
    }
    public static _IStringLexerState create_End() {
      return new StringLexerState_End();
    }
    public bool is_Start { get { return this is StringLexerState_Start; } }
    public bool is_Body { get { return this is StringLexerState_Body; } }
    public bool is_End { get { return this is StringLexerState_End; } }
    public bool dtor_escaped {
      get {
        var d = this;
        return ((StringLexerState_Body)d)._escaped;
      }
    }
    public abstract _IStringLexerState DowncastClone();
  }
  public class StringLexerState_Start : StringLexerState {
    public StringLexerState_Start() : base() {
    }
    public override _IStringLexerState DowncastClone() {
      if (this is _IStringLexerState dt) { return dt; }
      return new StringLexerState_Start();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Strings.StringLexerState_Start;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Strings.StringLexerState.Start";
      return s;
    }
  }
  public class StringLexerState_Body : StringLexerState {
    public readonly bool _escaped;
    public StringLexerState_Body(bool escaped) : base() {
      this._escaped = escaped;
    }
    public override _IStringLexerState DowncastClone() {
      if (this is _IStringLexerState dt) { return dt; }
      return new StringLexerState_Body(_escaped);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Strings.StringLexerState_Body;
      return oth != null && this._escaped == oth._escaped;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._escaped));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Strings.StringLexerState.Body";
      s += "(";
      s += Dafny.Helpers.ToString(this._escaped);
      s += ")";
      return s;
    }
  }
  public class StringLexerState_End : StringLexerState {
    public StringLexerState_End() : base() {
    }
    public override _IStringLexerState DowncastClone() {
      if (this is _IStringLexerState dt) { return dt; }
      return new StringLexerState_End();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Lexers.Strings.StringLexerState_End;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Strings.StringLexerState.End";
      return s;
    }
  }
} // end of namespace Std.JSON.Utils.Lexers.Strings
namespace Std.JSON.Utils.Lexers {

} // end of namespace Std.JSON.Utils.Lexers
namespace Std.JSON.Utils.Cursors {


  public interface _ISplit<out T> {
    bool is_SP { get; }
    T dtor_t { get; }
    Std.JSON.Utils.Cursors._ICursor__ dtor_cs { get; }
    _ISplit<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public class Split<T> : _ISplit<T> {
    public readonly T _t;
    public readonly Std.JSON.Utils.Cursors._ICursor__ _cs;
    public Split(T t, Std.JSON.Utils.Cursors._ICursor__ cs) {
      this._t = t;
      this._cs = cs;
    }
    public _ISplit<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _ISplit<__T> dt) { return dt; }
      return new Split<__T>(converter0(_t), _cs);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.Split<T>;
      return oth != null && object.Equals(this._t, oth._t) && object.Equals(this._cs, oth._cs);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._cs));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.Split.SP";
      s += "(";
      s += Dafny.Helpers.ToString(this._t);
      s += ", ";
      s += Dafny.Helpers.ToString(this._cs);
      s += ")";
      return s;
    }
    public static Std.JSON.Utils.Cursors._ISplit<T> Default(T _default_T) {
      return create(_default_T, Std.JSON.Utils.Cursors.FreshCursor.Default());
    }
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ISplit<T>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ISplit<T>>(Std.JSON.Utils.Cursors.Split<T>.Default(_td_T.Default()));
    }
    public static _ISplit<T> create(T t, Std.JSON.Utils.Cursors._ICursor__ cs) {
      return new Split<T>(t, cs);
    }
    public static _ISplit<T> create_SP(T t, Std.JSON.Utils.Cursors._ICursor__ cs) {
      return create(t, cs);
    }
    public bool is_SP { get { return true; } }
    public T dtor_t {
      get {
        return this._t;
      }
    }
    public Std.JSON.Utils.Cursors._ICursor__ dtor_cs {
      get {
        return this._cs;
      }
    }
  }

  public partial class Cursor {
    private static readonly Std.JSON.Utils.Cursors._ICursor__ Witness = Std.JSON.Utils.Cursors.Cursor__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U, 0U);
    public static Std.JSON.Utils.Cursors._ICursor__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__>(Std.JSON.Utils.Cursors.Cursor.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class FreshCursor {
    private static readonly Std.JSON.Utils.Cursors._ICursor__ Witness = Std.JSON.Utils.Cursors.Cursor__.create(Dafny.Sequence<byte>.FromElements(), 0U, 0U, 0U);
    public static Std.JSON.Utils.Cursors._ICursor__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__>(Std.JSON.Utils.Cursors.FreshCursor.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _ICursorError<out R> {
    bool is_EOF { get; }
    bool is_ExpectingByte { get; }
    bool is_ExpectingAnyByte { get; }
    bool is_OtherError { get; }
    byte dtor_expected { get; }
    short dtor_b { get; }
    Dafny.ISequence<byte> dtor_expected__sq { get; }
    R dtor_err { get; }
    _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0);
  }
  public abstract class CursorError<R> : _ICursorError<R> {
    public CursorError() {
    }
    public static Std.JSON.Utils.Cursors._ICursorError<R> Default() {
      return create_EOF();
    }
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursorError<R>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursorError<R>>(Std.JSON.Utils.Cursors.CursorError<R>.Default());
    }
    public static _ICursorError<R> create_EOF() {
      return new CursorError_EOF<R>();
    }
    public static _ICursorError<R> create_ExpectingByte(byte expected, short b) {
      return new CursorError_ExpectingByte<R>(expected, b);
    }
    public static _ICursorError<R> create_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) {
      return new CursorError_ExpectingAnyByte<R>(expected__sq, b);
    }
    public static _ICursorError<R> create_OtherError(R err) {
      return new CursorError_OtherError<R>(err);
    }
    public bool is_EOF { get { return this is CursorError_EOF<R>; } }
    public bool is_ExpectingByte { get { return this is CursorError_ExpectingByte<R>; } }
    public bool is_ExpectingAnyByte { get { return this is CursorError_ExpectingAnyByte<R>; } }
    public bool is_OtherError { get { return this is CursorError_OtherError<R>; } }
    public byte dtor_expected {
      get {
        var d = this;
        return ((CursorError_ExpectingByte<R>)d)._expected;
      }
    }
    public short dtor_b {
      get {
        var d = this;
        if (d is CursorError_ExpectingByte<R>) { return ((CursorError_ExpectingByte<R>)d)._b; }
        return ((CursorError_ExpectingAnyByte<R>)d)._b;
      }
    }
    public Dafny.ISequence<byte> dtor_expected__sq {
      get {
        var d = this;
        return ((CursorError_ExpectingAnyByte<R>)d)._expected__sq;
      }
    }
    public R dtor_err {
      get {
        var d = this;
        return ((CursorError_OtherError<R>)d)._err;
      }
    }
    public abstract _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0);
    public static Dafny.ISequence<Dafny.Rune> _ToString(Std.JSON.Utils.Cursors._ICursorError<R> _this, Func<R, Dafny.ISequence<Dafny.Rune>> pr) {
      Std.JSON.Utils.Cursors._ICursorError<R> _source14 = _this;
      if (_source14.is_EOF) {
        return Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Reached EOF");
      } else if (_source14.is_ExpectingByte) {
        byte _361___mcc_h0 = _source14.dtor_expected;
        short _362___mcc_h1 = _source14.dtor_b;
        short _363_b = _362___mcc_h1;
        byte _364_b0 = _361___mcc_h0;
        Dafny.ISequence<Dafny.Rune> _365_c = (((_363_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_363_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting '"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_364_b0)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _365_c);
      } else if (_source14.is_ExpectingAnyByte) {
        Dafny.ISequence<byte> _366___mcc_h2 = _source14.dtor_expected__sq;
        short _367___mcc_h3 = _source14.dtor_b;
        short _368_b = _367___mcc_h3;
        Dafny.ISequence<byte> _369_bs0 = _366___mcc_h2;
        Dafny.ISequence<Dafny.Rune> _370_c = (((_368_b) > ((short)(0))) ? (Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"), Dafny.Sequence<Dafny.Rune>.FromElements(new Dafny.Rune((int)(_368_b)))), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("'"))) : (Dafny.Sequence<Dafny.Rune>.UnicodeFromString("EOF")));
        Dafny.ISequence<Dafny.Rune> _371_c0s = ((System.Func<Dafny.ISequence<Dafny.Rune>>) (() => {
          BigInteger dim9 = new BigInteger((_369_bs0).Count);
          var arr9 = new Dafny.Rune[Dafny.Helpers.ToIntChecked(dim9, "array size exceeds memory limit")];
          for (int i9 = 0; i9 < dim9; i9++) {
            var _372_idx = (BigInteger) i9;
            arr9[(int)(_372_idx)] = new Dafny.Rune((int)((_369_bs0).Select(_372_idx)));
          }
          return Dafny.Sequence<Dafny.Rune>.FromArray(arr9);
        }))();
        return Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.Concat(Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Expecting one of '"), _371_c0s), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("', read ")), _370_c);
      } else {
        R _373___mcc_h4 = _source14.dtor_err;
        R _374_err = _373___mcc_h4;
        return Dafny.Helpers.Id<Func<R, Dafny.ISequence<Dafny.Rune>>>(pr)(_374_err);
      }
    }
  }
  public class CursorError_EOF<R> : CursorError<R> {
    public CursorError_EOF() : base() {
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_EOF<__R>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_EOF<R>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.EOF";
      return s;
    }
  }
  public class CursorError_ExpectingByte<R> : CursorError<R> {
    public readonly byte _expected;
    public readonly short _b;
    public CursorError_ExpectingByte(byte expected, short b) : base() {
      this._expected = expected;
      this._b = b;
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_ExpectingByte<__R>(_expected, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_ExpectingByte<R>;
      return oth != null && this._expected == oth._expected && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.ExpectingByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class CursorError_ExpectingAnyByte<R> : CursorError<R> {
    public readonly Dafny.ISequence<byte> _expected__sq;
    public readonly short _b;
    public CursorError_ExpectingAnyByte(Dafny.ISequence<byte> expected__sq, short b) : base() {
      this._expected__sq = expected__sq;
      this._b = b;
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_ExpectingAnyByte<__R>(_expected__sq, _b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_ExpectingAnyByte<R>;
      return oth != null && object.Equals(this._expected__sq, oth._expected__sq) && this._b == oth._b;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._expected__sq));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.ExpectingAnyByte";
      s += "(";
      s += Dafny.Helpers.ToString(this._expected__sq);
      s += ", ";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class CursorError_OtherError<R> : CursorError<R> {
    public readonly R _err;
    public CursorError_OtherError(R err) : base() {
      this._err = err;
    }
    public override _ICursorError<__R> DowncastClone<__R>(Func<R, __R> converter0) {
      if (this is _ICursorError<__R> dt) { return dt; }
      return new CursorError_OtherError<__R>(converter0(_err));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.CursorError_OtherError<R>;
      return oth != null && object.Equals(this._err, oth._err);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._err));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Cursors.CursorError.OtherError";
      s += "(";
      s += Dafny.Helpers.ToString(this._err);
      s += ")";
      return s;
    }
  }

  public interface _ICursor__ {
    bool is_Cursor { get; }
    Dafny.ISequence<byte> dtor_s { get; }
    uint dtor_beg { get; }
    uint dtor_point { get; }
    uint dtor_end { get; }
    _ICursor__ DowncastClone();
    bool BOF_q { get; }
    bool EOF_q { get; }
    Dafny.ISequence<byte> Bytes();
    Std.JSON.Utils.Views.Core._IView__ Prefix();
    Std.JSON.Utils.Cursors._ICursor__ Suffix();
    Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> Split();
    uint PrefixLength();
    uint SuffixLength();
    uint Length();
    byte At(uint idx);
    byte SuffixAt(uint idx);
    short Peek();
    bool LookingAt(Dafny.Rune c);
    Std.JSON.Utils.Cursors._ICursor__ Skip(uint n);
    Std.JSON.Utils.Cursors._ICursor__ Unskip(uint n);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> Get<__R>(__R err);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertByte<__R>(byte b);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertBytes<__R>(Dafny.ISequence<byte> bs, uint offset);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertChar<__R>(Dafny.Rune c0);
    Std.JSON.Utils.Cursors._ICursor__ SkipByte();
    Std.JSON.Utils.Cursors._ICursor__ SkipIf(Func<byte, bool> p);
    Std.JSON.Utils.Cursors._ICursor__ SkipWhile(Func<byte, bool> p);
    Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> SkipWhileLexer<__A, __R>(Func<__A, short, Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R>> step, __A st);
  }
  public class Cursor__ : _ICursor__ {
    public readonly Dafny.ISequence<byte> _s;
    public readonly uint _beg;
    public readonly uint _point;
    public readonly uint _end;
    public Cursor__(Dafny.ISequence<byte> s, uint beg, uint point, uint end) {
      this._s = s;
      this._beg = beg;
      this._point = point;
      this._end = end;
    }
    public _ICursor__ DowncastClone() {
      if (this is _ICursor__ dt) { return dt; }
      return new Cursor__(_s, _beg, _point, _end);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Cursors.Cursor__;
      return oth != null && object.Equals(this._s, oth._s) && this._beg == oth._beg && this._point == oth._point && this._end == oth._end;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._s));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._beg));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._point));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._end));
      return (int) hash;
    }
    public override string ToString() {
      string ss = "Cursors.Cursor_.Cursor";
      ss += "(";
      ss += Dafny.Helpers.ToString(this._s);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._beg);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._point);
      ss += ", ";
      ss += Dafny.Helpers.ToString(this._end);
      ss += ")";
      return ss;
    }
    private static readonly Std.JSON.Utils.Cursors._ICursor__ theDefault = create(Dafny.Sequence<byte>.Empty, 0, 0, 0);
    public static Std.JSON.Utils.Cursors._ICursor__ Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__>(Std.JSON.Utils.Cursors.Cursor__.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Cursors._ICursor__> _TypeDescriptor() {
      return _TYPE;
    }
    public static _ICursor__ create(Dafny.ISequence<byte> s, uint beg, uint point, uint end) {
      return new Cursor__(s, beg, point, end);
    }
    public static _ICursor__ create_Cursor(Dafny.ISequence<byte> s, uint beg, uint point, uint end) {
      return create(s, beg, point, end);
    }
    public bool is_Cursor { get { return true; } }
    public Dafny.ISequence<byte> dtor_s {
      get {
        return this._s;
      }
    }
    public uint dtor_beg {
      get {
        return this._beg;
      }
    }
    public uint dtor_point {
      get {
        return this._point;
      }
    }
    public uint dtor_end {
      get {
        return this._end;
      }
    }
    public static Std.JSON.Utils.Cursors._ICursor__ OfView(Std.JSON.Utils.Views.Core._IView__ v) {
      return Std.JSON.Utils.Cursors.Cursor__.create((v).dtor_s, (v).dtor_beg, (v).dtor_beg, (v).dtor_end);
    }
    public static Std.JSON.Utils.Cursors._ICursor__ OfBytes(Dafny.ISequence<byte> bs) {
      return Std.JSON.Utils.Cursors.Cursor__.create(bs, 0U, 0U, (uint)(bs).LongCount);
    }
    public Dafny.ISequence<byte> Bytes() {
      return ((this).dtor_s).Subsequence((this).dtor_beg, (this).dtor_end);
    }
    public Std.JSON.Utils.Views.Core._IView__ Prefix() {
      return Std.JSON.Utils.Views.Core.View__.create((this).dtor_s, (this).dtor_beg, (this).dtor_point);
    }
    public Std.JSON.Utils.Cursors._ICursor__ Suffix() {
      Std.JSON.Utils.Cursors._ICursor__ _375_dt__update__tmp_h0 = this;
      uint _376_dt__update_hbeg_h0 = (this).dtor_point;
      return Std.JSON.Utils.Cursors.Cursor__.create((_375_dt__update__tmp_h0).dtor_s, _376_dt__update_hbeg_h0, (_375_dt__update__tmp_h0).dtor_point, (_375_dt__update__tmp_h0).dtor_end);
    }
    public Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> Split() {
      return Std.JSON.Utils.Cursors.Split<Std.JSON.Utils.Views.Core._IView__>.create((this).Prefix(), (this).Suffix());
    }
    public uint PrefixLength() {
      return ((this).dtor_point) - ((this).dtor_beg);
    }
    public uint SuffixLength() {
      return ((this).dtor_end) - ((this).dtor_point);
    }
    public uint Length() {
      return ((this).dtor_end) - ((this).dtor_beg);
    }
    public byte At(uint idx) {
      return ((this).dtor_s).Select(((this).dtor_beg) + (idx));
    }
    public byte SuffixAt(uint idx) {
      return ((this).dtor_s).Select(((this).dtor_point) + (idx));
    }
    public short Peek() {
      if ((this).EOF_q) {
        return (short)(-1);
      } else {
        return (short)((this).SuffixAt(0U));
      }
    }
    public bool LookingAt(Dafny.Rune c) {
      return ((this).Peek()) == ((short)((c).Value));
    }
    public Std.JSON.Utils.Cursors._ICursor__ Skip(uint n) {
      Std.JSON.Utils.Cursors._ICursor__ _377_dt__update__tmp_h0 = this;
      uint _378_dt__update_hpoint_h0 = ((this).dtor_point) + (n);
      return Std.JSON.Utils.Cursors.Cursor__.create((_377_dt__update__tmp_h0).dtor_s, (_377_dt__update__tmp_h0).dtor_beg, _378_dt__update_hpoint_h0, (_377_dt__update__tmp_h0).dtor_end);
    }
    public Std.JSON.Utils.Cursors._ICursor__ Unskip(uint n) {
      Std.JSON.Utils.Cursors._ICursor__ _379_dt__update__tmp_h0 = this;
      uint _380_dt__update_hpoint_h0 = ((this).dtor_point) - (n);
      return Std.JSON.Utils.Cursors.Cursor__.create((_379_dt__update__tmp_h0).dtor_s, (_379_dt__update__tmp_h0).dtor_beg, _380_dt__update_hpoint_h0, (_379_dt__update__tmp_h0).dtor_end);
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> Get<__R>(__R err) {
      if ((this).EOF_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_OtherError(err));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success((this).Skip(1U));
      }
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertByte<__R>(byte b) {
      short _381_nxt = (this).Peek();
      if ((_381_nxt) == ((short)(b))) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success((this).Skip(1U));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_ExpectingByte(b, _381_nxt));
      }
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertBytes<__R>(Dafny.ISequence<byte> bs, uint offset)
    {
      _ICursor__ _this = this;
    TAIL_CALL_START: ;
      if ((offset) == ((uint)(bs).LongCount)) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success(_this);
      } else {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> _382_valueOrError0 = (_this).AssertByte<__R>((byte)((bs).Select(offset)));
        if ((_382_valueOrError0).IsFailure()) {
          return (_382_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ICursor__>();
        } else {
          Std.JSON.Utils.Cursors._ICursor__ _383_ps = (_382_valueOrError0).Extract();
          Std.JSON.Utils.Cursors._ICursor__ _in69 = _383_ps;
          Dafny.ISequence<byte> _in70 = bs;
          uint _in71 = (offset) + (1U);
          _this = _in69;
          ;
          bs = _in70;
          offset = _in71;
          goto TAIL_CALL_START;
        }
      }
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> AssertChar<__R>(Dafny.Rune c0) {
      return (this).AssertByte<__R>((byte)((c0).Value));
    }
    public Std.JSON.Utils.Cursors._ICursor__ SkipByte() {
      if ((this).EOF_q) {
        return this;
      } else {
        return (this).Skip(1U);
      }
    }
    public Std.JSON.Utils.Cursors._ICursor__ SkipIf(Func<byte, bool> p) {
      if (((this).EOF_q) || (!(Dafny.Helpers.Id<Func<byte, bool>>(p)((this).SuffixAt(0U))))) {
        return this;
      } else {
        return (this).Skip(1U);
      }
    }
    public Std.JSON.Utils.Cursors._ICursor__ SkipWhile(Func<byte, bool> p)
    {
      Std.JSON.Utils.Cursors._ICursor__ ps = Std.JSON.Utils.Cursors.Cursor.Default();
      uint _384_point_k;
      _384_point_k = (this).dtor_point;
      uint _385_end;
      _385_end = (this).dtor_end;
      while (((_384_point_k) < (_385_end)) && (Dafny.Helpers.Id<Func<byte, bool>>(p)(((this).dtor_s).Select(_384_point_k)))) {
        _384_point_k = (_384_point_k) + (1U);
      }
      ps = Std.JSON.Utils.Cursors.Cursor__.create((this).dtor_s, (this).dtor_beg, _384_point_k, (this).dtor_end);
      return ps;
      return ps;
    }
    public Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> SkipWhileLexer<__A, __R>(Func<__A, short, Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R>> step, __A st)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>> pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.Default(Std.JSON.Utils.Cursors.Cursor.Default());
      uint _386_point_k;
      _386_point_k = (this).dtor_point;
      uint _387_end;
      _387_end = (this).dtor_end;
      __A _388_st_k;
      _388_st_k = st;
      while (true) {
        bool _389_eof;
        _389_eof = (_386_point_k) == (_387_end);
        short _390_minusone;
        _390_minusone = (short)(-1);
        short _391_c;
        _391_c = ((_389_eof) ? (_390_minusone) : ((short)(((this).dtor_s).Select(_386_point_k))));
        Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R> _source15 = Dafny.Helpers.Id<Func<__A, short, Std.JSON.Utils.Lexers.Core._ILexerResult<__A, __R>>>(step)(_388_st_k, _391_c);
        if (_source15.is_Accept) {
          pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Success(Std.JSON.Utils.Cursors.Cursor__.create((this).dtor_s, (this).dtor_beg, _386_point_k, (this).dtor_end));
          return pr;
        } else if (_source15.is_Reject) {
          __R _392___mcc_h0 = _source15.dtor_err;
          __R _393_err = _392___mcc_h0;
          pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_OtherError(_393_err));
          return pr;
        } else {
          __A _394___mcc_h1 = _source15.dtor_st;
          __A _395_st_k_k = _394___mcc_h1;
          if (_389_eof) {
            pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_EOF());
            return pr;
          } else {
            _388_st_k = _395_st_k_k;
            _386_point_k = (_386_point_k) + (1U);
          }
        }
      }
      return pr;
    }
    public bool BOF_q { get {
      return ((this).dtor_point) == ((this).dtor_beg);
    } }
    public bool EOF_q { get {
      return ((this).dtor_point) == ((this).dtor_end);
    } }
  }
} // end of namespace Std.JSON.Utils.Cursors
namespace Std.JSON.Utils.Parsers {

  public partial class __default {
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> ParserWitness<__T, __R>() {
      return ((System.Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>)((_396___v9) => {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_EOF());
      }));
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> SubParserWitness<__T, __R>() {
      return ((System.Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>)((_397_cs) => {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<__R>.create_EOF());
      }));
    }
  }

  public partial class Parser<T, R> {
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default() {
      return Std.JSON.Utils.Parsers.__default.ParserWitness<T, R>();
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T, Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(Std.JSON.Utils.Parsers.Parser<T, R>.Default());
    }
  }

  public interface _IParser__<T, out R> {
    bool is_Parser { get; }
    Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn { get; }
  }
  public class Parser__<T, R> : _IParser__<T, R> {
    public readonly Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _fn;
    public Parser__(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      this._fn = fn;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> DowncastClone<__T, __R>(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _this, Func<T, __T> converter0, Func<R, __R> converter1) {
      return (_this).DowncastClone<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>(Dafny.Helpers.Id<Std.JSON.Utils.Cursors._ICursor__>, Dafny.Helpers.CastConverter<Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Parsers.Parser__<T, R>;
      return oth != null && object.Equals(this._fn, oth._fn);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._fn));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Parsers.Parser_.Parser";
      s += "(";
      s += Dafny.Helpers.ToString(this._fn);
      s += ")";
      return s;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default(T _default_T) {
      return ((Std.JSON.Utils.Cursors._ICursor__ x0) => Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>.Default(Std.JSON.Utils.Cursors.Split<T>.Default(_default_T)));
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(((Std.JSON.Utils.Cursors._ICursor__ x0) => Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>.Default(Std.JSON.Utils.Cursors.Split<T>.Default(_td_T.Default()))));
    }
    public static _IParser__<T, R> create(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return new Parser__<T, R>(fn);
    }
    public static _IParser__<T, R> create_Parser(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return create(fn);
    }
    public bool is_Parser { get { return true; } }
    public Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn {
      get {
        return this._fn;
      }
    }
  }

  public interface _ISubParser__<T, out R> {
    bool is_SubParser { get; }
    Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn { get; }
  }
  public class SubParser__<T, R> : _ISubParser__<T, R> {
    public readonly Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _fn;
    public SubParser__(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      this._fn = fn;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>> DowncastClone<__T, __R>(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> _this, Func<T, __T> converter0, Func<R, __R> converter1) {
      return (_this).DowncastClone<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>(Dafny.Helpers.Id<Std.JSON.Utils.Cursors._ICursor__>, Dafny.Helpers.CastConverter<Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<__R>>>);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Utils.Parsers.SubParser__<T, R>;
      return oth != null && object.Equals(this._fn, oth._fn);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._fn));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Parsers.SubParser_.SubParser";
      s += "(";
      s += Dafny.Helpers.ToString(this._fn);
      s += ")";
      return s;
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default() {
      return ((Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>)null);
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(((Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>)null));
    }
    public static _ISubParser__<T, R> create(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return new SubParser__<T, R>(fn);
    }
    public static _ISubParser__<T, R> create_SubParser(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> fn) {
      return create(fn);
    }
    public bool is_SubParser { get { return true; } }
    public Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> dtor_fn {
      get {
        return this._fn;
      }
    }
  }

  public partial class SubParser<T, R> {
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>> Default() {
      return Std.JSON.Utils.Parsers.__default.SubParserWitness<T, R>();
    }
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T, Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<T>, Std.JSON.Utils.Cursors._ICursorError<R>>>>(Std.JSON.Utils.Parsers.SubParser<T, R>.Default());
    }
  }
} // end of namespace Std.JSON.Utils.Parsers
namespace Std.JSON.Utils {

} // end of namespace Std.JSON.Utils
namespace Std.JSON.Grammar {

  public partial class __default {
    public static bool Blank_q(byte b) {
      return ((((b) == ((byte)(32))) || ((b) == ((byte)(9)))) || ((b) == ((byte)(10)))) || ((b) == ((byte)(13)));
    }
    public static bool Digit_q(byte b) {
      return (((byte)((new Dafny.Rune('0')).Value)) <= (b)) && ((b) <= ((byte)((new Dafny.Rune('9')).Value)));
    }
    public static Dafny.ISequence<byte> NULL { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('n')).Value), (byte)((new Dafny.Rune('u')).Value), (byte)((new Dafny.Rune('l')).Value), (byte)((new Dafny.Rune('l')).Value));
    } }
    public static Dafny.ISequence<byte> TRUE { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('t')).Value), (byte)((new Dafny.Rune('r')).Value), (byte)((new Dafny.Rune('u')).Value), (byte)((new Dafny.Rune('e')).Value));
    } }
    public static Dafny.ISequence<byte> FALSE { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('f')).Value), (byte)((new Dafny.Rune('a')).Value), (byte)((new Dafny.Rune('l')).Value), (byte)((new Dafny.Rune('s')).Value), (byte)((new Dafny.Rune('e')).Value));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ DOUBLEQUOTE { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('\"')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ PERIOD { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('.')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ E { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('e')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ COLON { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune(':')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ COMMA { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune(',')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ LBRACE { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('{')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ RBRACE { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('}')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ LBRACKET { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('[')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ RBRACKET { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune(']')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ MINUS { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('-')).Value)));
    } }
    public static Std.JSON.Utils.Views.Core._IView__ EMPTY { get {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    } }
  }

  public partial class jchar {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('b')).Value)));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jchar.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jquote {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.DOUBLEQUOTE;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jquote.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jperiod {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.PERIOD;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jperiod.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class je {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.E;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.je.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jcolon {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.COLON;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jcolon.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jcomma {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.COMMA;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jcomma.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jlbrace {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.LBRACE;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jlbrace.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jrbrace {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.RBRACE;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jrbrace.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jlbracket {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.LBRACKET;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jlbracket.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jrbracket {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.RBRACKET;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jrbracket.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jminus {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.MINUS;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jminus.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jsign {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Grammar.__default.EMPTY;
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jsign.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jblanks {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jblanks.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _IStructural<out T> {
    bool is_Structural { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_before { get; }
    T dtor_t { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_after { get; }
    _IStructural<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public class Structural<T> : _IStructural<T> {
    public readonly Std.JSON.Utils.Views.Core._IView__ _before;
    public readonly T _t;
    public readonly Std.JSON.Utils.Views.Core._IView__ _after;
    public Structural(Std.JSON.Utils.Views.Core._IView__ before, T t, Std.JSON.Utils.Views.Core._IView__ after) {
      this._before = before;
      this._t = t;
      this._after = after;
    }
    public _IStructural<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IStructural<__T> dt) { return dt; }
      return new Structural<__T>(_before, converter0(_t), _after);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Structural<T>;
      return oth != null && object.Equals(this._before, oth._before) && object.Equals(this._t, oth._t) && object.Equals(this._after, oth._after);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._before));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._after));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Structural.Structural";
      s += "(";
      s += Dafny.Helpers.ToString(this._before);
      s += ", ";
      s += Dafny.Helpers.ToString(this._t);
      s += ", ";
      s += Dafny.Helpers.ToString(this._after);
      s += ")";
      return s;
    }
    public static Std.JSON.Grammar._IStructural<T> Default(T _default_T) {
      return create(Std.JSON.Grammar.jblanks.Default(), _default_T, Std.JSON.Grammar.jblanks.Default());
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IStructural<T>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._IStructural<T>>(Std.JSON.Grammar.Structural<T>.Default(_td_T.Default()));
    }
    public static _IStructural<T> create(Std.JSON.Utils.Views.Core._IView__ before, T t, Std.JSON.Utils.Views.Core._IView__ after) {
      return new Structural<T>(before, t, after);
    }
    public static _IStructural<T> create_Structural(Std.JSON.Utils.Views.Core._IView__ before, T t, Std.JSON.Utils.Views.Core._IView__ after) {
      return create(before, t, after);
    }
    public bool is_Structural { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_before {
      get {
        return this._before;
      }
    }
    public T dtor_t {
      get {
        return this._t;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_after {
      get {
        return this._after;
      }
    }
  }

  public interface _IMaybe<out T> {
    bool is_Empty { get; }
    bool is_NonEmpty { get; }
    T dtor_t { get; }
    _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public abstract class Maybe<T> : _IMaybe<T> {
    public Maybe() {
    }
    public static Std.JSON.Grammar._IMaybe<T> Default() {
      return create_Empty();
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IMaybe<T>> _TypeDescriptor() {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._IMaybe<T>>(Std.JSON.Grammar.Maybe<T>.Default());
    }
    public static _IMaybe<T> create_Empty() {
      return new Maybe_Empty<T>();
    }
    public static _IMaybe<T> create_NonEmpty(T t) {
      return new Maybe_NonEmpty<T>(t);
    }
    public bool is_Empty { get { return this is Maybe_Empty<T>; } }
    public bool is_NonEmpty { get { return this is Maybe_NonEmpty<T>; } }
    public T dtor_t {
      get {
        var d = this;
        return ((Maybe_NonEmpty<T>)d)._t;
      }
    }
    public abstract _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0);
  }
  public class Maybe_Empty<T> : Maybe<T> {
    public Maybe_Empty() : base() {
    }
    public override _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IMaybe<__T> dt) { return dt; }
      return new Maybe_Empty<__T>();
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Maybe_Empty<T>;
      return oth != null;
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Maybe.Empty";
      return s;
    }
  }
  public class Maybe_NonEmpty<T> : Maybe<T> {
    public readonly T _t;
    public Maybe_NonEmpty(T t) : base() {
      this._t = t;
    }
    public override _IMaybe<__T> DowncastClone<__T>(Func<T, __T> converter0) {
      if (this is _IMaybe<__T> dt) { return dt; }
      return new Maybe_NonEmpty<__T>(converter0(_t));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Maybe_NonEmpty<T>;
      return oth != null && object.Equals(this._t, oth._t);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Maybe.NonEmpty";
      s += "(";
      s += Dafny.Helpers.ToString(this._t);
      s += ")";
      return s;
    }
  }

  public interface _ISuffixed<out T, out S> {
    bool is_Suffixed { get; }
    T dtor_t { get; }
    Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> dtor_suffix { get; }
    _ISuffixed<__T, __S> DowncastClone<__T, __S>(Func<T, __T> converter0, Func<S, __S> converter1);
  }
  public class Suffixed<T, S> : _ISuffixed<T, S> {
    public readonly T _t;
    public readonly Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> _suffix;
    public Suffixed(T t, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> suffix) {
      this._t = t;
      this._suffix = suffix;
    }
    public _ISuffixed<__T, __S> DowncastClone<__T, __S>(Func<T, __T> converter0, Func<S, __S> converter1) {
      if (this is _ISuffixed<__T, __S> dt) { return dt; }
      return new Suffixed<__T, __S>(converter0(_t), (_suffix).DowncastClone<Std.JSON.Grammar._IStructural<__S>>(Dafny.Helpers.CastConverter<Std.JSON.Grammar._IStructural<S>, Std.JSON.Grammar._IStructural<__S>>));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Suffixed<T, S>;
      return oth != null && object.Equals(this._t, oth._t) && object.Equals(this._suffix, oth._suffix);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._t));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._suffix));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Suffixed.Suffixed";
      s += "(";
      s += Dafny.Helpers.ToString(this._t);
      s += ", ";
      s += Dafny.Helpers.ToString(this._suffix);
      s += ")";
      return s;
    }
    public static Std.JSON.Grammar._ISuffixed<T, S> Default(T _default_T) {
      return create(_default_T, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<S>>.Default());
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._ISuffixed<T, S>> _TypeDescriptor(Dafny.TypeDescriptor<T> _td_T) {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._ISuffixed<T, S>>(Std.JSON.Grammar.Suffixed<T, S>.Default(_td_T.Default()));
    }
    public static _ISuffixed<T, S> create(T t, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> suffix) {
      return new Suffixed<T, S>(t, suffix);
    }
    public static _ISuffixed<T, S> create_Suffixed(T t, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> suffix) {
      return create(t, suffix);
    }
    public bool is_Suffixed { get { return true; } }
    public T dtor_t {
      get {
        return this._t;
      }
    }
    public Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<S>> dtor_suffix {
      get {
        return this._suffix;
      }
    }
  }

  public partial class SuffixedSequence<D, S> {
    public static Dafny.TypeDescriptor<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>>> _TypeDescriptor(Dafny.TypeDescriptor<D> _td_D, Dafny.TypeDescriptor<S> _td_S) {
      return new Dafny.TypeDescriptor<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>>>(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<D, S>>.Empty);
    }
  }

  public interface _IBracketed<out L, out D, out S, out R> {
    bool is_Bracketed { get; }
    Std.JSON.Grammar._IStructural<L> dtor_l { get; }
    Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> dtor_data { get; }
    Std.JSON.Grammar._IStructural<R> dtor_r { get; }
    _IBracketed<__L, __D, __S, __R> DowncastClone<__L, __D, __S, __R>(Func<L, __L> converter0, Func<D, __D> converter1, Func<S, __S> converter2, Func<R, __R> converter3);
  }
  public class Bracketed<L, D, S, R> : _IBracketed<L, D, S, R> {
    public readonly Std.JSON.Grammar._IStructural<L> _l;
    public readonly Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> _data;
    public readonly Std.JSON.Grammar._IStructural<R> _r;
    public Bracketed(Std.JSON.Grammar._IStructural<L> l, Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> data, Std.JSON.Grammar._IStructural<R> r) {
      this._l = l;
      this._data = data;
      this._r = r;
    }
    public _IBracketed<__L, __D, __S, __R> DowncastClone<__L, __D, __S, __R>(Func<L, __L> converter0, Func<D, __D> converter1, Func<S, __S> converter2, Func<R, __R> converter3) {
      if (this is _IBracketed<__L, __D, __S, __R> dt) { return dt; }
      return new Bracketed<__L, __D, __S, __R>((_l).DowncastClone<__L>(Dafny.Helpers.CastConverter<L, __L>), (_data).DowncastClone<Std.JSON.Grammar._ISuffixed<__D, __S>>(Dafny.Helpers.CastConverter<Std.JSON.Grammar._ISuffixed<D, S>, Std.JSON.Grammar._ISuffixed<__D, __S>>), (_r).DowncastClone<__R>(Dafny.Helpers.CastConverter<R, __R>));
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Bracketed<L, D, S, R>;
      return oth != null && object.Equals(this._l, oth._l) && object.Equals(this._data, oth._data) && object.Equals(this._r, oth._r);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._l));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._data));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._r));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Bracketed.Bracketed";
      s += "(";
      s += Dafny.Helpers.ToString(this._l);
      s += ", ";
      s += Dafny.Helpers.ToString(this._data);
      s += ", ";
      s += Dafny.Helpers.ToString(this._r);
      s += ")";
      return s;
    }
    public static Std.JSON.Grammar._IBracketed<L, D, S, R> Default(L _default_L, R _default_R) {
      return create(Std.JSON.Grammar.Structural<L>.Default(_default_L), Dafny.Sequence<Std.JSON.Grammar._ISuffixed<D, S>>.Empty, Std.JSON.Grammar.Structural<R>.Default(_default_R));
    }
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IBracketed<L, D, S, R>> _TypeDescriptor(Dafny.TypeDescriptor<L> _td_L, Dafny.TypeDescriptor<R> _td_R) {
      return new Dafny.TypeDescriptor<Std.JSON.Grammar._IBracketed<L, D, S, R>>(Std.JSON.Grammar.Bracketed<L, D, S, R>.Default(_td_L.Default(), _td_R.Default()));
    }
    public static _IBracketed<L, D, S, R> create(Std.JSON.Grammar._IStructural<L> l, Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> data, Std.JSON.Grammar._IStructural<R> r) {
      return new Bracketed<L, D, S, R>(l, data, r);
    }
    public static _IBracketed<L, D, S, R> create_Bracketed(Std.JSON.Grammar._IStructural<L> l, Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> data, Std.JSON.Grammar._IStructural<R> r) {
      return create(l, data, r);
    }
    public bool is_Bracketed { get { return true; } }
    public Std.JSON.Grammar._IStructural<L> dtor_l {
      get {
        return this._l;
      }
    }
    public Dafny.ISequence<Std.JSON.Grammar._ISuffixed<D, S>> dtor_data {
      get {
        return this._data;
      }
    }
    public Std.JSON.Grammar._IStructural<R> dtor_r {
      get {
        return this._r;
      }
    }
  }

  public partial class jnull {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Std.JSON.Grammar.__default.NULL);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jnull.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jbool {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Std.JSON.Grammar.__default.TRUE);
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jbool.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jdigits {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jdigits.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jnum {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('0')).Value)));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jnum.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jint {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('0')).Value)));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jint.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jstr {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.jstr.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public interface _Ijstring {
    bool is_JString { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_lq { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_contents { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_rq { get; }
    _Ijstring DowncastClone();
  }
  public class jstring : _Ijstring {
    public readonly Std.JSON.Utils.Views.Core._IView__ _lq;
    public readonly Std.JSON.Utils.Views.Core._IView__ _contents;
    public readonly Std.JSON.Utils.Views.Core._IView__ _rq;
    public jstring(Std.JSON.Utils.Views.Core._IView__ lq, Std.JSON.Utils.Views.Core._IView__ contents, Std.JSON.Utils.Views.Core._IView__ rq) {
      this._lq = lq;
      this._contents = contents;
      this._rq = rq;
    }
    public _Ijstring DowncastClone() {
      if (this is _Ijstring dt) { return dt; }
      return new jstring(_lq, _contents, _rq);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jstring;
      return oth != null && object.Equals(this._lq, oth._lq) && object.Equals(this._contents, oth._contents) && object.Equals(this._rq, oth._rq);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._lq));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._contents));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._rq));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jstring.JString";
      s += "(";
      s += Dafny.Helpers.ToString(this._lq);
      s += ", ";
      s += Dafny.Helpers.ToString(this._contents);
      s += ", ";
      s += Dafny.Helpers.ToString(this._rq);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijstring theDefault = create(Std.JSON.Grammar.jquote.Default(), Std.JSON.Grammar.jstr.Default(), Std.JSON.Grammar.jquote.Default());
    public static Std.JSON.Grammar._Ijstring Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijstring> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijstring>(Std.JSON.Grammar.jstring.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijstring> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijstring create(Std.JSON.Utils.Views.Core._IView__ lq, Std.JSON.Utils.Views.Core._IView__ contents, Std.JSON.Utils.Views.Core._IView__ rq) {
      return new jstring(lq, contents, rq);
    }
    public static _Ijstring create_JString(Std.JSON.Utils.Views.Core._IView__ lq, Std.JSON.Utils.Views.Core._IView__ contents, Std.JSON.Utils.Views.Core._IView__ rq) {
      return create(lq, contents, rq);
    }
    public bool is_JString { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_lq {
      get {
        return this._lq;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_contents {
      get {
        return this._contents;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_rq {
      get {
        return this._rq;
      }
    }
  }

  public interface _IjKeyValue {
    bool is_KeyValue { get; }
    Std.JSON.Grammar._Ijstring dtor_k { get; }
    Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> dtor_colon { get; }
    Std.JSON.Grammar._IValue dtor_v { get; }
    _IjKeyValue DowncastClone();
  }
  public class jKeyValue : _IjKeyValue {
    public readonly Std.JSON.Grammar._Ijstring _k;
    public readonly Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> _colon;
    public readonly Std.JSON.Grammar._IValue _v;
    public jKeyValue(Std.JSON.Grammar._Ijstring k, Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> colon, Std.JSON.Grammar._IValue v) {
      this._k = k;
      this._colon = colon;
      this._v = v;
    }
    public _IjKeyValue DowncastClone() {
      if (this is _IjKeyValue dt) { return dt; }
      return new jKeyValue(_k, _colon, _v);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jKeyValue;
      return oth != null && object.Equals(this._k, oth._k) && object.Equals(this._colon, oth._colon) && object.Equals(this._v, oth._v);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._k));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._colon));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._v));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jKeyValue.KeyValue";
      s += "(";
      s += Dafny.Helpers.ToString(this._k);
      s += ", ";
      s += Dafny.Helpers.ToString(this._colon);
      s += ", ";
      s += Dafny.Helpers.ToString(this._v);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._IjKeyValue theDefault = create(Std.JSON.Grammar.jstring.Default(), Std.JSON.Grammar.Structural<Std.JSON.Utils.Views.Core._IView__>.Default(Std.JSON.Grammar.jcolon.Default()), Std.JSON.Grammar.Value.Default());
    public static Std.JSON.Grammar._IjKeyValue Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._IjKeyValue> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._IjKeyValue>(Std.JSON.Grammar.jKeyValue.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IjKeyValue> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IjKeyValue create(Std.JSON.Grammar._Ijstring k, Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> colon, Std.JSON.Grammar._IValue v) {
      return new jKeyValue(k, colon, v);
    }
    public static _IjKeyValue create_KeyValue(Std.JSON.Grammar._Ijstring k, Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> colon, Std.JSON.Grammar._IValue v) {
      return create(k, colon, v);
    }
    public bool is_KeyValue { get { return true; } }
    public Std.JSON.Grammar._Ijstring dtor_k {
      get {
        return this._k;
      }
    }
    public Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> dtor_colon {
      get {
        return this._colon;
      }
    }
    public Std.JSON.Grammar._IValue dtor_v {
      get {
        return this._v;
      }
    }
  }

  public interface _Ijfrac {
    bool is_JFrac { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_period { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_num { get; }
    _Ijfrac DowncastClone();
  }
  public class jfrac : _Ijfrac {
    public readonly Std.JSON.Utils.Views.Core._IView__ _period;
    public readonly Std.JSON.Utils.Views.Core._IView__ _num;
    public jfrac(Std.JSON.Utils.Views.Core._IView__ period, Std.JSON.Utils.Views.Core._IView__ num) {
      this._period = period;
      this._num = num;
    }
    public _Ijfrac DowncastClone() {
      if (this is _Ijfrac dt) { return dt; }
      return new jfrac(_period, _num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jfrac;
      return oth != null && object.Equals(this._period, oth._period) && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._period));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jfrac.JFrac";
      s += "(";
      s += Dafny.Helpers.ToString(this._period);
      s += ", ";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijfrac theDefault = create(Std.JSON.Grammar.jperiod.Default(), Std.JSON.Grammar.jnum.Default());
    public static Std.JSON.Grammar._Ijfrac Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijfrac> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijfrac>(Std.JSON.Grammar.jfrac.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijfrac> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijfrac create(Std.JSON.Utils.Views.Core._IView__ period, Std.JSON.Utils.Views.Core._IView__ num) {
      return new jfrac(period, num);
    }
    public static _Ijfrac create_JFrac(Std.JSON.Utils.Views.Core._IView__ period, Std.JSON.Utils.Views.Core._IView__ num) {
      return create(period, num);
    }
    public bool is_JFrac { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_period {
      get {
        return this._period;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_num {
      get {
        return this._num;
      }
    }
  }

  public interface _Ijexp {
    bool is_JExp { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_e { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_sign { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_num { get; }
    _Ijexp DowncastClone();
  }
  public class jexp : _Ijexp {
    public readonly Std.JSON.Utils.Views.Core._IView__ _e;
    public readonly Std.JSON.Utils.Views.Core._IView__ _sign;
    public readonly Std.JSON.Utils.Views.Core._IView__ _num;
    public jexp(Std.JSON.Utils.Views.Core._IView__ e, Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ num) {
      this._e = e;
      this._sign = sign;
      this._num = num;
    }
    public _Ijexp DowncastClone() {
      if (this is _Ijexp dt) { return dt; }
      return new jexp(_e, _sign, _num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jexp;
      return oth != null && object.Equals(this._e, oth._e) && object.Equals(this._sign, oth._sign) && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._e));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._sign));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jexp.JExp";
      s += "(";
      s += Dafny.Helpers.ToString(this._e);
      s += ", ";
      s += Dafny.Helpers.ToString(this._sign);
      s += ", ";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijexp theDefault = create(Std.JSON.Grammar.je.Default(), Std.JSON.Grammar.jsign.Default(), Std.JSON.Grammar.jnum.Default());
    public static Std.JSON.Grammar._Ijexp Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijexp> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijexp>(Std.JSON.Grammar.jexp.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijexp> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijexp create(Std.JSON.Utils.Views.Core._IView__ e, Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ num) {
      return new jexp(e, sign, num);
    }
    public static _Ijexp create_JExp(Std.JSON.Utils.Views.Core._IView__ e, Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ num) {
      return create(e, sign, num);
    }
    public bool is_JExp { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_e {
      get {
        return this._e;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_sign {
      get {
        return this._sign;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_num {
      get {
        return this._num;
      }
    }
  }

  public interface _Ijnumber {
    bool is_JNumber { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_minus { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_num { get; }
    Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> dtor_frac { get; }
    Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> dtor_exp { get; }
    _Ijnumber DowncastClone();
  }
  public class jnumber : _Ijnumber {
    public readonly Std.JSON.Utils.Views.Core._IView__ _minus;
    public readonly Std.JSON.Utils.Views.Core._IView__ _num;
    public readonly Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _frac;
    public readonly Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _exp;
    public jnumber(Std.JSON.Utils.Views.Core._IView__ minus, Std.JSON.Utils.Views.Core._IView__ num, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> frac, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> exp) {
      this._minus = minus;
      this._num = num;
      this._frac = frac;
      this._exp = exp;
    }
    public _Ijnumber DowncastClone() {
      if (this is _Ijnumber dt) { return dt; }
      return new jnumber(_minus, _num, _frac, _exp);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.jnumber;
      return oth != null && object.Equals(this._minus, oth._minus) && object.Equals(this._num, oth._num) && object.Equals(this._frac, oth._frac) && object.Equals(this._exp, oth._exp);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._minus));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._frac));
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._exp));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.jnumber.JNumber";
      s += "(";
      s += Dafny.Helpers.ToString(this._minus);
      s += ", ";
      s += Dafny.Helpers.ToString(this._num);
      s += ", ";
      s += Dafny.Helpers.ToString(this._frac);
      s += ", ";
      s += Dafny.Helpers.ToString(this._exp);
      s += ")";
      return s;
    }
    private static readonly Std.JSON.Grammar._Ijnumber theDefault = create(Std.JSON.Grammar.jminus.Default(), Std.JSON.Grammar.jnum.Default(), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.Default(), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.Default());
    public static Std.JSON.Grammar._Ijnumber Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._Ijnumber> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._Ijnumber>(Std.JSON.Grammar.jnumber.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._Ijnumber> _TypeDescriptor() {
      return _TYPE;
    }
    public static _Ijnumber create(Std.JSON.Utils.Views.Core._IView__ minus, Std.JSON.Utils.Views.Core._IView__ num, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> frac, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> exp) {
      return new jnumber(minus, num, frac, exp);
    }
    public static _Ijnumber create_JNumber(Std.JSON.Utils.Views.Core._IView__ minus, Std.JSON.Utils.Views.Core._IView__ num, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> frac, Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> exp) {
      return create(minus, num, frac, exp);
    }
    public bool is_JNumber { get { return true; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_minus {
      get {
        return this._minus;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_num {
      get {
        return this._num;
      }
    }
    public Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> dtor_frac {
      get {
        return this._frac;
      }
    }
    public Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> dtor_exp {
      get {
        return this._exp;
      }
    }
  }

  public interface _IValue {
    bool is_Null { get; }
    bool is_Bool { get; }
    bool is_String { get; }
    bool is_Number { get; }
    bool is_Object { get; }
    bool is_Array { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_n { get; }
    Std.JSON.Utils.Views.Core._IView__ dtor_b { get; }
    Std.JSON.Grammar._Ijstring dtor_str { get; }
    Std.JSON.Grammar._Ijnumber dtor_num { get; }
    Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_obj { get; }
    Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_arr { get; }
    _IValue DowncastClone();
  }
  public abstract class Value : _IValue {
    public Value() {
    }
    private static readonly Std.JSON.Grammar._IValue theDefault = create_Null(Std.JSON.Grammar.jnull.Default());
    public static Std.JSON.Grammar._IValue Default() {
      return theDefault;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Grammar._IValue> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Grammar._IValue>(Std.JSON.Grammar.Value.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Grammar._IValue> _TypeDescriptor() {
      return _TYPE;
    }
    public static _IValue create_Null(Std.JSON.Utils.Views.Core._IView__ n) {
      return new Value_Null(n);
    }
    public static _IValue create_Bool(Std.JSON.Utils.Views.Core._IView__ b) {
      return new Value_Bool(b);
    }
    public static _IValue create_String(Std.JSON.Grammar._Ijstring str) {
      return new Value_String(str);
    }
    public static _IValue create_Number(Std.JSON.Grammar._Ijnumber num) {
      return new Value_Number(num);
    }
    public static _IValue create_Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj) {
      return new Value_Object(obj);
    }
    public static _IValue create_Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr) {
      return new Value_Array(arr);
    }
    public bool is_Null { get { return this is Value_Null; } }
    public bool is_Bool { get { return this is Value_Bool; } }
    public bool is_String { get { return this is Value_String; } }
    public bool is_Number { get { return this is Value_Number; } }
    public bool is_Object { get { return this is Value_Object; } }
    public bool is_Array { get { return this is Value_Array; } }
    public Std.JSON.Utils.Views.Core._IView__ dtor_n {
      get {
        var d = this;
        return ((Value_Null)d)._n;
      }
    }
    public Std.JSON.Utils.Views.Core._IView__ dtor_b {
      get {
        var d = this;
        return ((Value_Bool)d)._b;
      }
    }
    public Std.JSON.Grammar._Ijstring dtor_str {
      get {
        var d = this;
        return ((Value_String)d)._str;
      }
    }
    public Std.JSON.Grammar._Ijnumber dtor_num {
      get {
        var d = this;
        return ((Value_Number)d)._num;
      }
    }
    public Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_obj {
      get {
        var d = this;
        return ((Value_Object)d)._obj;
      }
    }
    public Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> dtor_arr {
      get {
        var d = this;
        return ((Value_Array)d)._arr;
      }
    }
    public abstract _IValue DowncastClone();
  }
  public class Value_Null : Value {
    public readonly Std.JSON.Utils.Views.Core._IView__ _n;
    public Value_Null(Std.JSON.Utils.Views.Core._IView__ n) : base() {
      this._n = n;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Null(_n);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Null;
      return oth != null && object.Equals(this._n, oth._n);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 0;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._n));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Null";
      s += "(";
      s += Dafny.Helpers.ToString(this._n);
      s += ")";
      return s;
    }
  }
  public class Value_Bool : Value {
    public readonly Std.JSON.Utils.Views.Core._IView__ _b;
    public Value_Bool(Std.JSON.Utils.Views.Core._IView__ b) : base() {
      this._b = b;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Bool(_b);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Bool;
      return oth != null && object.Equals(this._b, oth._b);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 1;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._b));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Bool";
      s += "(";
      s += Dafny.Helpers.ToString(this._b);
      s += ")";
      return s;
    }
  }
  public class Value_String : Value {
    public readonly Std.JSON.Grammar._Ijstring _str;
    public Value_String(Std.JSON.Grammar._Ijstring str) : base() {
      this._str = str;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_String(_str);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_String;
      return oth != null && object.Equals(this._str, oth._str);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 2;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._str));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.String";
      s += "(";
      s += Dafny.Helpers.ToString(this._str);
      s += ")";
      return s;
    }
  }
  public class Value_Number : Value {
    public readonly Std.JSON.Grammar._Ijnumber _num;
    public Value_Number(Std.JSON.Grammar._Ijnumber num) : base() {
      this._num = num;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Number(_num);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Number;
      return oth != null && object.Equals(this._num, oth._num);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 3;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._num));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Number";
      s += "(";
      s += Dafny.Helpers.ToString(this._num);
      s += ")";
      return s;
    }
  }
  public class Value_Object : Value {
    public readonly Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _obj;
    public Value_Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj) : base() {
      this._obj = obj;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Object(_obj);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Object;
      return oth != null && object.Equals(this._obj, oth._obj);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 4;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._obj));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Object";
      s += "(";
      s += Dafny.Helpers.ToString(this._obj);
      s += ")";
      return s;
    }
  }
  public class Value_Array : Value {
    public readonly Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _arr;
    public Value_Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr) : base() {
      this._arr = arr;
    }
    public override _IValue DowncastClone() {
      if (this is _IValue dt) { return dt; }
      return new Value_Array(_arr);
    }
    public override bool Equals(object other) {
      var oth = other as Std.JSON.Grammar.Value_Array;
      return oth != null && object.Equals(this._arr, oth._arr);
    }
    public override int GetHashCode() {
      ulong hash = 5381;
      hash = ((hash << 5) + hash) + 5;
      hash = ((hash << 5) + hash) + ((ulong)Dafny.Helpers.GetHashCode(this._arr));
      return (int) hash;
    }
    public override string ToString() {
      string s = "Grammar.Value.Array";
      s += "(";
      s += Dafny.Helpers.ToString(this._arr);
      s += ")";
      return s;
    }
  }
} // end of namespace Std.JSON.Grammar
namespace Std.JSON.ByteStrConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.JSON.ByteStrConversion.__default.@base;
    }
    public static Dafny.ISequence<byte> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<byte> _398___accumulator = Dafny.Sequence<byte>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements(), _398___accumulator);
      } else {
        _398___accumulator = Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements((Std.JSON.ByteStrConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _398___accumulator);
        Dafny.ISequence<BigInteger> _in72 = (digits).Drop(BigInteger.One);
        digits = _in72;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<byte> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<byte>.FromElements((Std.JSON.ByteStrConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.JSON.ByteStrConversion.__default.OfDigits(Std.JSON.ByteStrConversion.__default.FromNat(n));
      }
    }
    public static bool OfNumberStr(Dafny.ISequence<byte> str, byte minus)
    {
      return !(!(str).Equals(Dafny.Sequence<byte>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.JSON.ByteStrConversion.__default.chars).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<byte>, bool>>((_399_str) => Dafny.Helpers.Quantifier<byte>(((_399_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_5) => {
        byte _400_c = (byte)_forall_var_5;
        return !(((_399_str).Drop(BigInteger.One)).Contains(_400_c)) || ((Std.JSON.ByteStrConversion.__default.chars).Contains(_400_c));
      }))))(str)));
    }
    public static bool ToNumberStr(Dafny.ISequence<byte> str, byte minus)
    {
      return !(!(str).Equals(Dafny.Sequence<byte>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.JSON.ByteStrConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<byte>, bool>>((_401_str) => Dafny.Helpers.Quantifier<byte>(((_401_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_6) => {
        byte _402_c = (byte)_forall_var_6;
        return !(((_401_str).Drop(BigInteger.One)).Contains(_402_c)) || ((Std.JSON.ByteStrConversion.__default.charToDigit).Contains(_402_c));
      }))))(str)));
    }
    public static Dafny.ISequence<byte> OfInt(BigInteger n, byte minus)
    {
      if ((n).Sign != -1) {
        return Std.JSON.ByteStrConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.FromElements(minus), Std.JSON.ByteStrConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<byte> str) {
      if ((str).Equals(Dafny.Sequence<byte>.FromElements())) {
        return BigInteger.Zero;
      } else {
        return ((Std.JSON.ByteStrConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.JSON.ByteStrConversion.__default.@base)) + (Dafny.Map<byte, BigInteger>.Select(Std.JSON.ByteStrConversion.__default.charToDigit,(str).Select((new BigInteger((str).Count)) - (BigInteger.One))));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<byte> str, byte minus)
    {
      if (Dafny.Sequence<byte>.IsPrefixOf(Dafny.Sequence<byte>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.JSON.ByteStrConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.JSON.ByteStrConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.JSON.ByteStrConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.JSON.ByteStrConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _403___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_403___accumulator);
      } else {
        _403___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.JSON.ByteStrConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_403___accumulator);
        Dafny.ISequence<BigInteger> _in73 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in73;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _404___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_404___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _404___accumulator = Dafny.Sequence<BigInteger>.Concat(_404___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.JSON.ByteStrConversion.__default.BASE())));
        BigInteger _in74 = Dafny.Helpers.EuclideanDivision(n, Std.JSON.ByteStrConversion.__default.BASE());
        n = _in74;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in75 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in76 = n;
        xs = _in75;
        n = _in76;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _405_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.JSON.ByteStrConversion.__default.SeqExtend(xs, _405_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.JSON.ByteStrConversion.__default.SeqExtend(Std.JSON.ByteStrConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _406_xs = Std.JSON.ByteStrConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _406_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs9 = Std.JSON.ByteStrConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _407_zs_k = _let_tmp_rhs9.dtor__0;
        BigInteger _408_cin = _let_tmp_rhs9.dtor__1;
        BigInteger _409_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_408_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs10 = (((_409_sum) < (Std.JSON.ByteStrConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_409_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_409_sum) - (Std.JSON.ByteStrConversion.__default.BASE()), BigInteger.One)));
        BigInteger _410_sum__out = _let_tmp_rhs10.dtor__0;
        BigInteger _411_cout = _let_tmp_rhs10.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_407_zs_k, Dafny.Sequence<BigInteger>.FromElements(_410_sum__out)), _411_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs11 = Std.JSON.ByteStrConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _412_zs = _let_tmp_rhs11.dtor__0;
        BigInteger _413_cin = _let_tmp_rhs11.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs12 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_413_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_413_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.JSON.ByteStrConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_413_cin), BigInteger.One)));
        BigInteger _414_diff__out = _let_tmp_rhs12.dtor__0;
        BigInteger _415_cout = _let_tmp_rhs12.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_412_zs, Dafny.Sequence<BigInteger>.FromElements(_414_diff__out)), _415_cout);
      }
    }
    public static Dafny.ISequence<byte> chars { get {
      return Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('0')).Value), (byte)((new Dafny.Rune('1')).Value), (byte)((new Dafny.Rune('2')).Value), (byte)((new Dafny.Rune('3')).Value), (byte)((new Dafny.Rune('4')).Value), (byte)((new Dafny.Rune('5')).Value), (byte)((new Dafny.Rune('6')).Value), (byte)((new Dafny.Rune('7')).Value), (byte)((new Dafny.Rune('8')).Value), (byte)((new Dafny.Rune('9')).Value));
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.JSON.ByteStrConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<byte,BigInteger> charToDigit { get {
      return Dafny.Map<byte, BigInteger>.FromElements(new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('0')).Value), BigInteger.Zero), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('1')).Value), BigInteger.One), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('2')).Value), new BigInteger(2)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('3')).Value), new BigInteger(3)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('4')).Value), new BigInteger(4)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('5')).Value), new BigInteger(5)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('6')).Value), new BigInteger(6)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('7')).Value), new BigInteger(7)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('8')).Value), new BigInteger(8)), new Dafny.Pair<byte, BigInteger>((byte)((new Dafny.Rune('9')).Value), new BigInteger(9)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Dafny.Sequence<byte>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ByteStrConversion
namespace Std.JSON.Serializer {

  public partial class __default {
    public static Std.JSON.Utils.Views.Core._IView__ Bool(bool b) {
      return Std.JSON.Utils.Views.Core.View__.OfBytes(((b) ? (Std.JSON.Grammar.__default.TRUE) : (Std.JSON.Grammar.__default.FALSE)));
    }
    public static Std.Wrappers._IOutcome<Std.JSON.Errors._ISerializationError> CheckLength<__T>(Dafny.ISequence<__T> s, Std.JSON.Errors._ISerializationError err)
    {
      return Std.Wrappers.Outcome<Std.JSON.Errors._ISerializationError>.Need((new BigInteger((s).Count)) < (Std.BoundedInts.__default.TWO__TO__THE__32), err);
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError> String(Dafny.ISequence<Dafny.Rune> str) {
      Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> _416_valueOrError0 = Std.JSON.Spec.__default.EscapeToUTF8(str, BigInteger.Zero);
      if ((_416_valueOrError0).IsFailure()) {
        return (_416_valueOrError0).PropagateFailure<Std.JSON.Grammar._Ijstring>();
      } else {
        Dafny.ISequence<byte> _417_bs = (_416_valueOrError0).Extract();
        Std.Wrappers._IOutcome<Std.JSON.Errors._ISerializationError> _418_o = Std.JSON.Serializer.__default.CheckLength<byte>(_417_bs, Std.JSON.Errors.SerializationError.create_StringTooLong(str));
        if ((_418_o).is_Pass) {
          return Std.Wrappers.Result<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.jstring.create(Std.JSON.Grammar.__default.DOUBLEQUOTE, Std.JSON.Utils.Views.Core.View__.OfBytes(_417_bs), Std.JSON.Grammar.__default.DOUBLEQUOTE));
        } else {
          return Std.Wrappers.Result<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError>.create_Failure((_418_o).dtor_error);
        }
      }
    }
    public static Std.JSON.Utils.Views.Core._IView__ Sign(BigInteger n) {
      return Std.JSON.Utils.Views.Core.View__.OfBytes((((n).Sign == -1) ? (Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('-')).Value))) : (Dafny.Sequence<byte>.FromElements())));
    }
    public static Dafny.ISequence<byte> Int_k(BigInteger n) {
      return Std.JSON.ByteStrConversion.__default.OfInt(n, Std.JSON.Serializer.__default.MINUS);
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError> Int(BigInteger n) {
      Dafny.ISequence<byte> _419_bs = Std.JSON.Serializer.__default.Int_k(n);
      Std.Wrappers._IOutcome<Std.JSON.Errors._ISerializationError> _420_o = Std.JSON.Serializer.__default.CheckLength<byte>(_419_bs, Std.JSON.Errors.SerializationError.create_IntTooLarge(n));
      if ((_420_o).is_Pass) {
        return Std.Wrappers.Result<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Utils.Views.Core.View__.OfBytes(_419_bs));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>.create_Failure((_420_o).dtor_error);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._Ijnumber, Std.JSON.Errors._ISerializationError> Number(Std.JSON.Values._IDecimal dec) {
      var _pat_let_tv2 = dec;
      var _pat_let_tv3 = dec;
      Std.JSON.Utils.Views.Core._IView__ _421_minus = Std.JSON.Serializer.__default.Sign((dec).dtor_n);
      Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError> _422_valueOrError0 = Std.JSON.Serializer.__default.Int(Std.Math.__default.Abs((dec).dtor_n));
      if ((_422_valueOrError0).IsFailure()) {
        return (_422_valueOrError0).PropagateFailure<Std.JSON.Grammar._Ijnumber>();
      } else {
        Std.JSON.Utils.Views.Core._IView__ _423_num = (_422_valueOrError0).Extract();
        Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _424_frac = Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_Empty();
        Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError> _425_valueOrError1 = ((((dec).dtor_e10).Sign == 0) ? (Std.Wrappers.Result<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_Empty())) : (Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements((byte)((new Dafny.Rune('e')).Value))), _pat_let2_0 => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let2_0, _426_e => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(Std.JSON.Serializer.__default.Sign((_pat_let_tv2).dtor_e10), _pat_let3_0 => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let3_0, _427_sign => Dafny.Helpers.Let<Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(Std.JSON.Serializer.__default.Int(Std.Math.__default.Abs((_pat_let_tv3).dtor_e10)), _pat_let4_0 => Dafny.Helpers.Let<Std.Wrappers._IResult<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Errors._ISerializationError>, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let4_0, _428_valueOrError2 => (((_428_valueOrError2).IsFailure()) ? ((_428_valueOrError2).PropagateFailure<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>()) : (Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>((_428_valueOrError2).Extract(), _pat_let5_0 => Dafny.Helpers.Let<Std.JSON.Utils.Views.Core._IView__, Std.Wrappers._IResult<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>>(_pat_let5_0, _429_num => Std.Wrappers.Result<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_NonEmpty(Std.JSON.Grammar.jexp.create(_426_e, _427_sign, _429_num)))))))))))))));
        if ((_425_valueOrError1).IsFailure()) {
          return (_425_valueOrError1).PropagateFailure<Std.JSON.Grammar._Ijnumber>();
        } else {
          Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _430_exp = (_425_valueOrError1).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._Ijnumber, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.jnumber.create(_421_minus, _423_num, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_Empty(), _430_exp));
        }
      }
    }
    public static Std.JSON.Grammar._IStructural<__T> MkStructural<__T>(__T v) {
      return Std.JSON.Grammar.Structural<__T>.create(Std.JSON.Grammar.__default.EMPTY, v, Std.JSON.Grammar.__default.EMPTY);
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError> KeyValue(_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON> kv) {
      Std.Wrappers._IResult<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError> _431_valueOrError0 = Std.JSON.Serializer.__default.String((kv).dtor__0);
      if ((_431_valueOrError0).IsFailure()) {
        return (_431_valueOrError0).PropagateFailure<Std.JSON.Grammar._IjKeyValue>();
      } else {
        Std.JSON.Grammar._Ijstring _432_k = (_431_valueOrError0).Extract();
        Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError> _433_valueOrError1 = Std.JSON.Serializer.__default.Value((kv).dtor__1);
        if ((_433_valueOrError1).IsFailure()) {
          return (_433_valueOrError1).PropagateFailure<Std.JSON.Grammar._IjKeyValue>();
        } else {
          Std.JSON.Grammar._IValue _434_v = (_433_valueOrError1).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.jKeyValue.create(_432_k, Std.JSON.Serializer.__default.COLON, _434_v));
        }
      }
    }
    public static Dafny.ISequence<Std.JSON.Grammar._ISuffixed<__D, __S>> MkSuffixedSequence<__D, __S>(Dafny.ISequence<__D> ds, Std.JSON.Grammar._IStructural<__S> suffix, BigInteger start)
    {
      Dafny.ISequence<Std.JSON.Grammar._ISuffixed<__D, __S>> _435___accumulator = Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements();
    TAIL_CALL_START: ;
      if ((start) >= (new BigInteger((ds).Count))) {
        return Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.Concat(_435___accumulator, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements());
      } else if ((start) == ((new BigInteger((ds).Count)) - (BigInteger.One))) {
        return Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.Concat(_435___accumulator, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements(Std.JSON.Grammar.Suffixed<__D, __S>.create((ds).Select(start), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<__S>>.create_Empty())));
      } else {
        _435___accumulator = Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.Concat(_435___accumulator, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<__D, __S>>.FromElements(Std.JSON.Grammar.Suffixed<__D, __S>.create((ds).Select(start), Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<__S>>.create_NonEmpty(suffix))));
        Dafny.ISequence<__D> _in77 = ds;
        Std.JSON.Grammar._IStructural<__S> _in78 = suffix;
        BigInteger _in79 = (start) + (BigInteger.One);
        ds = _in77;
        suffix = _in78;
        start = _in79;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> Object(Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> obj) {
      Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Errors._ISerializationError> _436_valueOrError0 = Std.Collections.Seq.__default.MapWithResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>(Dafny.Helpers.Id<Func<Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>, Func<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.Wrappers._IResult<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>>>>((_437_obj) => ((System.Func<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.Wrappers._IResult<Std.JSON.Grammar._IjKeyValue, Std.JSON.Errors._ISerializationError>>)((_438_v) => {
        return Std.JSON.Serializer.__default.KeyValue(_438_v);
      })))(obj), obj);
      if ((_436_valueOrError0).IsFailure()) {
        return (_436_valueOrError0).PropagateFailure<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Dafny.ISequence<Std.JSON.Grammar._IjKeyValue> _439_items = (_436_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create(Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.LBRACE), Std.JSON.Serializer.__default.MkSuffixedSequence<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>(_439_items, Std.JSON.Serializer.__default.COMMA, BigInteger.Zero), Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.RBRACE)));
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> Array(Dafny.ISequence<Std.JSON.Values._IJSON> arr) {
      Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _440_valueOrError0 = Std.Collections.Seq.__default.MapWithResult<Std.JSON.Values._IJSON, Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>(Dafny.Helpers.Id<Func<Dafny.ISequence<Std.JSON.Values._IJSON>, Func<Std.JSON.Values._IJSON, Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>>>>((_441_arr) => ((System.Func<Std.JSON.Values._IJSON, Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>>)((_442_v) => {
        return Std.JSON.Serializer.__default.Value(_442_v);
      })))(arr), arr);
      if ((_440_valueOrError0).IsFailure()) {
        return (_440_valueOrError0).PropagateFailure<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Dafny.ISequence<Std.JSON.Grammar._IValue> _443_items = (_440_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create(Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.LBRACKET), Std.JSON.Serializer.__default.MkSuffixedSequence<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>(_443_items, Std.JSON.Serializer.__default.COMMA, BigInteger.Zero), Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.RBRACKET)));
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError> Value(Std.JSON.Values._IJSON js) {
      Std.JSON.Values._IJSON _source16 = js;
      if (_source16.is_Null) {
        return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Null(Std.JSON.Utils.Views.Core.View__.OfBytes(Std.JSON.Grammar.__default.NULL)));
      } else if (_source16.is_Bool) {
        bool _444___mcc_h0 = _source16.dtor_b;
        bool _445_b = _444___mcc_h0;
        return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Bool(Std.JSON.Serializer.__default.Bool(_445_b)));
      } else if (_source16.is_String) {
        Dafny.ISequence<Dafny.Rune> _446___mcc_h1 = _source16.dtor_str;
        Dafny.ISequence<Dafny.Rune> _447_str = _446___mcc_h1;
        Std.Wrappers._IResult<Std.JSON.Grammar._Ijstring, Std.JSON.Errors._ISerializationError> _448_valueOrError0 = Std.JSON.Serializer.__default.String(_447_str);
        if ((_448_valueOrError0).IsFailure()) {
          return (_448_valueOrError0).PropagateFailure<Std.JSON.Grammar._IValue>();
        } else {
          Std.JSON.Grammar._Ijstring _449_s = (_448_valueOrError0).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_String(_449_s));
        }
      } else if (_source16.is_Number) {
        Std.JSON.Values._IDecimal _450___mcc_h2 = _source16.dtor_num;
        Std.JSON.Values._IDecimal _451_dec = _450___mcc_h2;
        Std.Wrappers._IResult<Std.JSON.Grammar._Ijnumber, Std.JSON.Errors._ISerializationError> _452_valueOrError1 = Std.JSON.Serializer.__default.Number(_451_dec);
        if ((_452_valueOrError1).IsFailure()) {
          return (_452_valueOrError1).PropagateFailure<Std.JSON.Grammar._IValue>();
        } else {
          Std.JSON.Grammar._Ijnumber _453_n = (_452_valueOrError1).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Number(_453_n));
        }
      } else if (_source16.is_Object) {
        Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _454___mcc_h3 = _source16.dtor_obj;
        Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _455_obj = _454___mcc_h3;
        Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> _456_valueOrError2 = Std.JSON.Serializer.__default.Object(_455_obj);
        if ((_456_valueOrError2).IsFailure()) {
          return (_456_valueOrError2).PropagateFailure<Std.JSON.Grammar._IValue>();
        } else {
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _457_o = (_456_valueOrError2).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Object(_457_o));
        }
      } else {
        Dafny.ISequence<Std.JSON.Values._IJSON> _458___mcc_h4 = _source16.dtor_arr;
        Dafny.ISequence<Std.JSON.Values._IJSON> _459_arr = _458___mcc_h4;
        Std.Wrappers._IResult<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Errors._ISerializationError> _460_valueOrError3 = Std.JSON.Serializer.__default.Array(_459_arr);
        if ((_460_valueOrError3).IsFailure()) {
          return (_460_valueOrError3).PropagateFailure<Std.JSON.Grammar._IValue>();
        } else {
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _461_a = (_460_valueOrError3).Extract();
          return Std.Wrappers.Result<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Grammar.Value.create_Array(_461_a));
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> JSON(Std.JSON.Values._IJSON js) {
      Std.Wrappers._IResult<Std.JSON.Grammar._IValue, Std.JSON.Errors._ISerializationError> _462_valueOrError0 = Std.JSON.Serializer.__default.Value(js);
      if ((_462_valueOrError0).IsFailure()) {
        return (_462_valueOrError0).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
      } else {
        Std.JSON.Grammar._IValue _463_val = (_462_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError>.create_Success(Std.JSON.Serializer.__default.MkStructural<Std.JSON.Grammar._IValue>(_463_val));
      }
    }
    public static Dafny.ISequence<byte> DIGITS { get {
      return Std.JSON.ByteStrConversion.__default.chars;
    } }
    public static byte MINUS { get {
      return (byte)((new Dafny.Rune('-')).Value);
    } }
    public static Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> COLON { get {
      return Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.COLON);
    } }
    public static Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> COMMA { get {
      return Std.JSON.Serializer.__default.MkStructural<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.Grammar.__default.COMMA);
    } }
  }

  public partial class bytes32 {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<byte>>(Dafny.Sequence<byte>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<byte>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class string32 {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>>(Dafny.Sequence<Dafny.Rune>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<Dafny.Rune>> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.Serializer
namespace Std.JSON.Deserializer.Uint16StrConversion {

  public partial class __default {
    public static BigInteger BASE() {
      return Std.JSON.Deserializer.Uint16StrConversion.__default.@base;
    }
    public static Dafny.ISequence<ushort> OfDigits(Dafny.ISequence<BigInteger> digits) {
      Dafny.ISequence<ushort> _464___accumulator = Dafny.Sequence<ushort>.FromElements();
    TAIL_CALL_START: ;
      if ((digits).Equals(Dafny.Sequence<BigInteger>.FromElements())) {
        return Dafny.Sequence<ushort>.Concat(Dafny.Sequence<ushort>.FromElements(), _464___accumulator);
      } else {
        _464___accumulator = Dafny.Sequence<ushort>.Concat(Dafny.Sequence<ushort>.FromElements((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Select((digits).Select(BigInteger.Zero))), _464___accumulator);
        Dafny.ISequence<BigInteger> _in80 = (digits).Drop(BigInteger.One);
        digits = _in80;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<ushort> OfNat(BigInteger n) {
      if ((n).Sign == 0) {
        return Dafny.Sequence<ushort>.FromElements((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Select(BigInteger.Zero));
      } else {
        return Std.JSON.Deserializer.Uint16StrConversion.__default.OfDigits(Std.JSON.Deserializer.Uint16StrConversion.__default.FromNat(n));
      }
    }
    public static bool OfNumberStr(Dafny.ISequence<ushort> str, ushort minus)
    {
      return !(!(str).Equals(Dafny.Sequence<ushort>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<ushort>, bool>>((_465_str) => Dafny.Helpers.Quantifier<ushort>(((_465_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_7) => {
        ushort _466_c = (ushort)_forall_var_7;
        return !(((_465_str).Drop(BigInteger.One)).Contains(_466_c)) || ((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Contains(_466_c));
      }))))(str)));
    }
    public static bool ToNumberStr(Dafny.ISequence<ushort> str, ushort minus)
    {
      return !(!(str).Equals(Dafny.Sequence<ushort>.FromElements())) || (((((str).Select(BigInteger.Zero)) == (minus)) || ((Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit).Contains((str).Select(BigInteger.Zero)))) && (Dafny.Helpers.Id<Func<Dafny.ISequence<ushort>, bool>>((_467_str) => Dafny.Helpers.Quantifier<ushort>(((_467_str).Drop(BigInteger.One)).UniqueElements, true, (((_forall_var_8) => {
        ushort _468_c = (ushort)_forall_var_8;
        return !(((_467_str).Drop(BigInteger.One)).Contains(_468_c)) || ((Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit).Contains(_468_c));
      }))))(str)));
    }
    public static Dafny.ISequence<ushort> OfInt(BigInteger n, ushort minus)
    {
      if ((n).Sign != -1) {
        return Std.JSON.Deserializer.Uint16StrConversion.__default.OfNat(n);
      } else {
        return Dafny.Sequence<ushort>.Concat(Dafny.Sequence<ushort>.FromElements(minus), Std.JSON.Deserializer.Uint16StrConversion.__default.OfNat((BigInteger.Zero) - (n)));
      }
    }
    public static BigInteger ToNat(Dafny.ISequence<ushort> str) {
      if ((str).Equals(Dafny.Sequence<ushort>.FromElements())) {
        return BigInteger.Zero;
      } else {
        return ((Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat((str).Take((new BigInteger((str).Count)) - (BigInteger.One)))) * (Std.JSON.Deserializer.Uint16StrConversion.__default.@base)) + (Dafny.Map<ushort, BigInteger>.Select(Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit,(str).Select((new BigInteger((str).Count)) - (BigInteger.One))));
      }
    }
    public static BigInteger ToInt(Dafny.ISequence<ushort> str, ushort minus)
    {
      if (Dafny.Sequence<ushort>.IsPrefixOf(Dafny.Sequence<ushort>.FromElements(minus), str)) {
        return (BigInteger.Zero) - (Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat((str).Drop(BigInteger.One)));
      } else {
        return Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat(str);
      }
    }
    public static BigInteger ToNatRight(Dafny.ISequence<BigInteger> xs) {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return BigInteger.Zero;
      } else {
        return ((Std.JSON.Deserializer.Uint16StrConversion.__default.ToNatRight(Std.Collections.Seq.__default.DropFirst<BigInteger>(xs))) * (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE())) + (Std.Collections.Seq.__default.First<BigInteger>(xs));
      }
    }
    public static BigInteger ToNatLeft(Dafny.ISequence<BigInteger> xs) {
      BigInteger _469___accumulator = BigInteger.Zero;
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return (BigInteger.Zero) + (_469___accumulator);
      } else {
        _469___accumulator = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) * (Std.Arithmetic.Power.__default.Pow(Std.JSON.Deserializer.Uint16StrConversion.__default.BASE(), (new BigInteger((xs).Count)) - (BigInteger.One)))) + (_469___accumulator);
        Dafny.ISequence<BigInteger> _in81 = Std.Collections.Seq.__default.DropLast<BigInteger>(xs);
        xs = _in81;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> FromNat(BigInteger n) {
      Dafny.ISequence<BigInteger> _470___accumulator = Dafny.Sequence<BigInteger>.FromElements();
    TAIL_CALL_START: ;
      if ((n).Sign == 0) {
        return Dafny.Sequence<BigInteger>.Concat(_470___accumulator, Dafny.Sequence<BigInteger>.FromElements());
      } else {
        _470___accumulator = Dafny.Sequence<BigInteger>.Concat(_470___accumulator, Dafny.Sequence<BigInteger>.FromElements(Dafny.Helpers.EuclideanModulus(n, Std.JSON.Deserializer.Uint16StrConversion.__default.BASE())));
        BigInteger _in82 = Dafny.Helpers.EuclideanDivision(n, Std.JSON.Deserializer.Uint16StrConversion.__default.BASE());
        n = _in82;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtend(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
    TAIL_CALL_START: ;
      if ((new BigInteger((xs).Count)) >= (n)) {
        return xs;
      } else {
        Dafny.ISequence<BigInteger> _in83 = Dafny.Sequence<BigInteger>.Concat(xs, Dafny.Sequence<BigInteger>.FromElements(BigInteger.Zero));
        BigInteger _in84 = n;
        xs = _in83;
        n = _in84;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<BigInteger> SeqExtendMultiple(Dafny.ISequence<BigInteger> xs, BigInteger n)
    {
      BigInteger _471_newLen = ((new BigInteger((xs).Count)) + (n)) - (Dafny.Helpers.EuclideanModulus(new BigInteger((xs).Count), n));
      return Std.JSON.Deserializer.Uint16StrConversion.__default.SeqExtend(xs, _471_newLen);
    }
    public static Dafny.ISequence<BigInteger> FromNatWithLen(BigInteger n, BigInteger len)
    {
      return Std.JSON.Deserializer.Uint16StrConversion.__default.SeqExtend(Std.JSON.Deserializer.Uint16StrConversion.__default.FromNat(n), len);
    }
    public static Dafny.ISequence<BigInteger> SeqZero(BigInteger len) {
      Dafny.ISequence<BigInteger> _472_xs = Std.JSON.Deserializer.Uint16StrConversion.__default.FromNatWithLen(BigInteger.Zero, len);
      return _472_xs;
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqAdd(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs13 = Std.JSON.Deserializer.Uint16StrConversion.__default.SeqAdd(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _473_zs_k = _let_tmp_rhs13.dtor__0;
        BigInteger _474_cin = _let_tmp_rhs13.dtor__1;
        BigInteger _475_sum = ((Std.Collections.Seq.__default.Last<BigInteger>(xs)) + (Std.Collections.Seq.__default.Last<BigInteger>(ys))) + (_474_cin);
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs14 = (((_475_sum) < (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE())) ? (_System.Tuple2<BigInteger, BigInteger>.create(_475_sum, BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((_475_sum) - (Std.JSON.Deserializer.Uint16StrConversion.__default.BASE()), BigInteger.One)));
        BigInteger _476_sum__out = _let_tmp_rhs14.dtor__0;
        BigInteger _477_cout = _let_tmp_rhs14.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_473_zs_k, Dafny.Sequence<BigInteger>.FromElements(_476_sum__out)), _477_cout);
      }
    }
    public static _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> SeqSub(Dafny.ISequence<BigInteger> xs, Dafny.ISequence<BigInteger> ys)
    {
      if ((new BigInteger((xs).Count)).Sign == 0) {
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.FromElements(), BigInteger.Zero);
      } else {
        _System._ITuple2<Dafny.ISequence<BigInteger>, BigInteger> _let_tmp_rhs15 = Std.JSON.Deserializer.Uint16StrConversion.__default.SeqSub(Std.Collections.Seq.__default.DropLast<BigInteger>(xs), Std.Collections.Seq.__default.DropLast<BigInteger>(ys));
        Dafny.ISequence<BigInteger> _478_zs = _let_tmp_rhs15.dtor__0;
        BigInteger _479_cin = _let_tmp_rhs15.dtor__1;
        _System._ITuple2<BigInteger, BigInteger> _let_tmp_rhs16 = (((Std.Collections.Seq.__default.Last<BigInteger>(xs)) >= ((Std.Collections.Seq.__default.Last<BigInteger>(ys)) + (_479_cin))) ? (_System.Tuple2<BigInteger, BigInteger>.create(((Std.Collections.Seq.__default.Last<BigInteger>(xs)) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_479_cin), BigInteger.Zero)) : (_System.Tuple2<BigInteger, BigInteger>.create((((Std.JSON.Deserializer.Uint16StrConversion.__default.BASE()) + (Std.Collections.Seq.__default.Last<BigInteger>(xs))) - (Std.Collections.Seq.__default.Last<BigInteger>(ys))) - (_479_cin), BigInteger.One)));
        BigInteger _480_diff__out = _let_tmp_rhs16.dtor__0;
        BigInteger _481_cout = _let_tmp_rhs16.dtor__1;
        return _System.Tuple2<Dafny.ISequence<BigInteger>, BigInteger>.create(Dafny.Sequence<BigInteger>.Concat(_478_zs, Dafny.Sequence<BigInteger>.FromElements(_480_diff__out)), _481_cout);
      }
    }
    public static Dafny.ISequence<ushort> chars { get {
      return Dafny.Sequence<ushort>.FromElements((ushort)((new Dafny.Rune('0')).Value), (ushort)((new Dafny.Rune('1')).Value), (ushort)((new Dafny.Rune('2')).Value), (ushort)((new Dafny.Rune('3')).Value), (ushort)((new Dafny.Rune('4')).Value), (ushort)((new Dafny.Rune('5')).Value), (ushort)((new Dafny.Rune('6')).Value), (ushort)((new Dafny.Rune('7')).Value), (ushort)((new Dafny.Rune('8')).Value), (ushort)((new Dafny.Rune('9')).Value), (ushort)((new Dafny.Rune('a')).Value), (ushort)((new Dafny.Rune('b')).Value), (ushort)((new Dafny.Rune('c')).Value), (ushort)((new Dafny.Rune('d')).Value), (ushort)((new Dafny.Rune('e')).Value), (ushort)((new Dafny.Rune('f')).Value), (ushort)((new Dafny.Rune('A')).Value), (ushort)((new Dafny.Rune('B')).Value), (ushort)((new Dafny.Rune('C')).Value), (ushort)((new Dafny.Rune('D')).Value), (ushort)((new Dafny.Rune('E')).Value), (ushort)((new Dafny.Rune('F')).Value));
    } }
    public static BigInteger @base { get {
      return new BigInteger((Std.JSON.Deserializer.Uint16StrConversion.__default.chars).Count);
    } }
    public static Dafny.IMap<ushort,BigInteger> charToDigit { get {
      return Dafny.Map<ushort, BigInteger>.FromElements(new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('0')).Value), BigInteger.Zero), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('1')).Value), BigInteger.One), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('2')).Value), new BigInteger(2)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('3')).Value), new BigInteger(3)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('4')).Value), new BigInteger(4)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('5')).Value), new BigInteger(5)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('6')).Value), new BigInteger(6)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('7')).Value), new BigInteger(7)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('8')).Value), new BigInteger(8)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('9')).Value), new BigInteger(9)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('a')).Value), new BigInteger(10)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('b')).Value), new BigInteger(11)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('c')).Value), new BigInteger(12)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('d')).Value), new BigInteger(13)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('e')).Value), new BigInteger(14)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('f')).Value), new BigInteger(15)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('A')).Value), new BigInteger(10)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('B')).Value), new BigInteger(11)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('C')).Value), new BigInteger(12)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('D')).Value), new BigInteger(13)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('E')).Value), new BigInteger(14)), new Dafny.Pair<ushort, BigInteger>((ushort)((new Dafny.Rune('F')).Value), new BigInteger(15)));
    } }
  }

  public partial class CharSeq {
    private static readonly Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TYPE = new Dafny.TypeDescriptor<Dafny.ISequence<ushort>>(Dafny.Sequence<ushort>.Empty);
    public static Dafny.TypeDescriptor<Dafny.ISequence<ushort>> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class digit {
    private static readonly Dafny.TypeDescriptor<BigInteger> _TYPE = new Dafny.TypeDescriptor<BigInteger>(BigInteger.Zero);
    public static Dafny.TypeDescriptor<BigInteger> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.Deserializer.Uint16StrConversion
namespace Std.JSON.Deserializer {

  public partial class __default {
    public static bool Bool(Std.JSON.Utils.Views.Core._IView__ js) {
      return ((js).At(0U)) == ((byte)((new Dafny.Rune('t')).Value));
    }
    public static Std.JSON.Errors._IDeserializationError UnsupportedEscape16(Dafny.ISequence<ushort> code) {
      return Std.JSON.Errors.DeserializationError.create_UnsupportedEscape(Std.Wrappers.Option<Dafny.ISequence<Dafny.Rune>>.GetOr(Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF16Checked(code), Dafny.Sequence<Dafny.Rune>.UnicodeFromString("Couldn't decode UTF-16")));
    }
    public static ushort ToNat16(Dafny.ISequence<ushort> str) {
      BigInteger _482_hd = Std.JSON.Deserializer.Uint16StrConversion.__default.ToNat(str);
      return (ushort)(_482_hd);
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError> Unescape(Dafny.ISequence<ushort> str, BigInteger start, Dafny.ISequence<ushort> prefix)
    {
    TAIL_CALL_START: ;
      if ((start) >= (new BigInteger((str).Count))) {
        return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Success(prefix);
      } else if (((str).Select(start)) == ((ushort)((new Dafny.Rune('\\')).Value))) {
        if ((new BigInteger((str).Count)) == ((start) + (BigInteger.One))) {
          return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Errors.DeserializationError.create_EscapeAtEOS());
        } else {
          ushort _483_c = (str).Select((start) + (BigInteger.One));
          if ((_483_c) == ((ushort)((new Dafny.Rune('u')).Value))) {
            if ((new BigInteger((str).Count)) <= ((start) + (new BigInteger(6)))) {
              return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Errors.DeserializationError.create_EscapeAtEOS());
            } else {
              Dafny.ISequence<ushort> _484_code = (str).Subsequence((start) + (new BigInteger(2)), (start) + (new BigInteger(6)));
              if (Dafny.Helpers.Id<Func<Dafny.ISequence<ushort>, bool>>((_485_code) => Dafny.Helpers.Quantifier<ushort>((_485_code).UniqueElements, false, (((_exists_var_0) => {
                ushort _486_c = (ushort)_exists_var_0;
                return ((_485_code).Contains(_486_c)) && (!(Std.JSON.Deserializer.__default.HEX__TABLE__16).Contains(_486_c));
              }))))(_484_code)) {
                return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Deserializer.__default.UnsupportedEscape16(_484_code));
              } else {
                ushort _487_hd = Std.JSON.Deserializer.__default.ToNat16(_484_code);
                Dafny.ISequence<ushort> _in85 = str;
                BigInteger _in86 = (start) + (new BigInteger(6));
                Dafny.ISequence<ushort> _in87 = Dafny.Sequence<ushort>.Concat(prefix, Dafny.Sequence<ushort>.FromElements(_487_hd));
                str = _in85;
                start = _in86;
                prefix = _in87;
                goto TAIL_CALL_START;
              }
            }
          } else {
            ushort _488_unescaped = (((_483_c) == ((ushort)(34))) ? ((ushort)(34)) : ((((_483_c) == ((ushort)(92))) ? ((ushort)(92)) : ((((_483_c) == ((ushort)(98))) ? ((ushort)(8)) : ((((_483_c) == ((ushort)(102))) ? ((ushort)(12)) : ((((_483_c) == ((ushort)(110))) ? ((ushort)(10)) : ((((_483_c) == ((ushort)(114))) ? ((ushort)(13)) : ((((_483_c) == ((ushort)(116))) ? ((ushort)(9)) : ((ushort)(0)))))))))))))));
            if ((new BigInteger(_488_unescaped)).Sign == 0) {
              return Std.Wrappers.Result<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError>.create_Failure(Std.JSON.Deserializer.__default.UnsupportedEscape16((str).Subsequence(start, (start) + (new BigInteger(2)))));
            } else {
              Dafny.ISequence<ushort> _in88 = str;
              BigInteger _in89 = (start) + (new BigInteger(2));
              Dafny.ISequence<ushort> _in90 = Dafny.Sequence<ushort>.Concat(prefix, Dafny.Sequence<ushort>.FromElements(_488_unescaped));
              str = _in88;
              start = _in89;
              prefix = _in90;
              goto TAIL_CALL_START;
            }
          }
        }
      } else {
        Dafny.ISequence<ushort> _in91 = str;
        BigInteger _in92 = (start) + (BigInteger.One);
        Dafny.ISequence<ushort> _in93 = Dafny.Sequence<ushort>.Concat(prefix, Dafny.Sequence<ushort>.FromElements((str).Select(start)));
        str = _in91;
        start = _in92;
        prefix = _in93;
        goto TAIL_CALL_START;
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> String(Std.JSON.Grammar._Ijstring js) {
      Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> _489_valueOrError0 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF8Checked(((js).dtor_contents).Bytes())).ToResult<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.create_InvalidUnicode());
      if ((_489_valueOrError0).IsFailure()) {
        return (_489_valueOrError0).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
      } else {
        Dafny.ISequence<Dafny.Rune> _490_asUtf32 = (_489_valueOrError0).Extract();
        Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError> _491_valueOrError1 = (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.ToUTF16Checked(_490_asUtf32)).ToResult<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.create_InvalidUnicode());
        if ((_491_valueOrError1).IsFailure()) {
          return (_491_valueOrError1).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
        } else {
          Dafny.ISequence<ushort> _492_asUint16 = (_491_valueOrError1).Extract();
          Std.Wrappers._IResult<Dafny.ISequence<ushort>, Std.JSON.Errors._IDeserializationError> _493_valueOrError2 = Std.JSON.Deserializer.__default.Unescape(_492_asUint16, BigInteger.Zero, Dafny.Sequence<ushort>.FromElements());
          if ((_493_valueOrError2).IsFailure()) {
            return (_493_valueOrError2).PropagateFailure<Dafny.ISequence<Dafny.Rune>>();
          } else {
            Dafny.ISequence<ushort> _494_unescaped = (_493_valueOrError2).Extract();
            return (Std.Unicode.UnicodeStringsWithUnicodeChar.__default.FromUTF16Checked(_494_unescaped)).ToResult<Std.JSON.Errors._IDeserializationError>(Std.JSON.Errors.DeserializationError.create_InvalidUnicode());
          }
        }
      }
    }
    public static Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> ToInt(Std.JSON.Utils.Views.Core._IView__ sign, Std.JSON.Utils.Views.Core._IView__ n)
    {
      BigInteger _495_n = Std.JSON.ByteStrConversion.__default.ToNat((n).Bytes());
      return Std.Wrappers.Result<BigInteger, Std.JSON.Errors._IDeserializationError>.create_Success((((sign).Char_q(new Dafny.Rune('-'))) ? ((BigInteger.Zero) - (_495_n)) : (_495_n)));
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError> Number(Std.JSON.Grammar._Ijnumber js) {
      Std.JSON.Grammar._Ijnumber _let_tmp_rhs17 = js;
      Std.JSON.Utils.Views.Core._IView__ _496_minus = _let_tmp_rhs17.dtor_minus;
      Std.JSON.Utils.Views.Core._IView__ _497_num = _let_tmp_rhs17.dtor_num;
      Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _498_frac = _let_tmp_rhs17.dtor_frac;
      Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp> _499_exp = _let_tmp_rhs17.dtor_exp;
      Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> _500_valueOrError0 = Std.JSON.Deserializer.__default.ToInt(_496_minus, _497_num);
      if ((_500_valueOrError0).IsFailure()) {
        return (_500_valueOrError0).PropagateFailure<Std.JSON.Values._IDecimal>();
      } else {
        BigInteger _501_n = (_500_valueOrError0).Extract();
        Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> _502_valueOrError1 = ((System.Func<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>, Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError>>)((_source17) => {
          if (_source17.is_Empty) {
            return Std.Wrappers.Result<BigInteger, Std.JSON.Errors._IDeserializationError>.create_Success(BigInteger.Zero);
          } else {
            Std.JSON.Grammar._Ijexp _503___mcc_h0 = _source17.dtor_t;
            Std.JSON.Grammar._Ijexp _source18 = _503___mcc_h0;
            Std.JSON.Utils.Views.Core._IView__ _504___mcc_h1 = _source18.dtor_e;
            Std.JSON.Utils.Views.Core._IView__ _505___mcc_h2 = _source18.dtor_sign;
            Std.JSON.Utils.Views.Core._IView__ _506___mcc_h3 = _source18.dtor_num;
            Std.JSON.Utils.Views.Core._IView__ _507_num = _506___mcc_h3;
            Std.JSON.Utils.Views.Core._IView__ _508_sign = _505___mcc_h2;
            return Std.JSON.Deserializer.__default.ToInt(_508_sign, _507_num);
          }
        }))(_499_exp);
        if ((_502_valueOrError1).IsFailure()) {
          return (_502_valueOrError1).PropagateFailure<Std.JSON.Values._IDecimal>();
        } else {
          BigInteger _509_e10 = (_502_valueOrError1).Extract();
          Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac> _source19 = _498_frac;
          if (_source19.is_Empty) {
            return Std.Wrappers.Result<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.Decimal.create(_501_n, _509_e10));
          } else {
            Std.JSON.Grammar._Ijfrac _510___mcc_h4 = _source19.dtor_t;
            Std.JSON.Grammar._Ijfrac _source20 = _510___mcc_h4;
            Std.JSON.Utils.Views.Core._IView__ _511___mcc_h5 = _source20.dtor_period;
            Std.JSON.Utils.Views.Core._IView__ _512___mcc_h6 = _source20.dtor_num;
            Std.JSON.Utils.Views.Core._IView__ _513_num = _512___mcc_h6;
            BigInteger _514_pow10 = new BigInteger((_513_num).Length());
            Std.Wrappers._IResult<BigInteger, Std.JSON.Errors._IDeserializationError> _515_valueOrError2 = Std.JSON.Deserializer.__default.ToInt(_496_minus, _513_num);
            if ((_515_valueOrError2).IsFailure()) {
              return (_515_valueOrError2).PropagateFailure<Std.JSON.Values._IDecimal>();
            } else {
              BigInteger _516_frac = (_515_valueOrError2).Extract();
              return Std.Wrappers.Result<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.Decimal.create(((_501_n) * (Std.Arithmetic.Power.__default.Pow(new BigInteger(10), _514_pow10))) + (_516_frac), (_509_e10) - (_514_pow10)));
            }
          }
        }
      }
    }
    public static Std.Wrappers._IResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError> KeyValue(Std.JSON.Grammar._IjKeyValue js) {
      Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> _517_valueOrError0 = Std.JSON.Deserializer.__default.String((js).dtor_k);
      if ((_517_valueOrError0).IsFailure()) {
        return (_517_valueOrError0).PropagateFailure<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>();
      } else {
        Dafny.ISequence<Dafny.Rune> _518_k = (_517_valueOrError0).Extract();
        Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> _519_valueOrError1 = Std.JSON.Deserializer.__default.Value((js).dtor_v);
        if ((_519_valueOrError1).IsFailure()) {
          return (_519_valueOrError1).PropagateFailure<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>();
        } else {
          Std.JSON.Values._IJSON _520_v = (_519_valueOrError1).Extract();
          return Std.Wrappers.Result<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>.create_Success(_System.Tuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>.create(_518_k, _520_v));
        }
      }
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>, Std.JSON.Errors._IDeserializationError> Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> js) {
      return Std.Collections.Seq.__default.MapWithResult<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, _System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>(Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>>>>((_521_js) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError>>)((_522_d) => {
        return Std.JSON.Deserializer.__default.KeyValue((_522_d).dtor_t);
      })))(js), (js).dtor_data);
    }
    public static Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError> Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> js) {
      return Std.Collections.Seq.__default.MapWithResult<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>(Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>>>>((_523_js) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>>)((_524_d) => {
        return Std.JSON.Deserializer.__default.Value((_524_d).dtor_t);
      })))(js), (js).dtor_data);
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> Value(Std.JSON.Grammar._IValue js) {
      Std.JSON.Grammar._IValue _source21 = js;
      if (_source21.is_Null) {
        Std.JSON.Utils.Views.Core._IView__ _525___mcc_h0 = _source21.dtor_n;
        return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Null());
      } else if (_source21.is_Bool) {
        Std.JSON.Utils.Views.Core._IView__ _526___mcc_h1 = _source21.dtor_b;
        Std.JSON.Utils.Views.Core._IView__ _527_b = _526___mcc_h1;
        return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Bool(Std.JSON.Deserializer.__default.Bool(_527_b)));
      } else if (_source21.is_String) {
        Std.JSON.Grammar._Ijstring _528___mcc_h2 = _source21.dtor_str;
        Std.JSON.Grammar._Ijstring _529_str = _528___mcc_h2;
        Std.Wrappers._IResult<Dafny.ISequence<Dafny.Rune>, Std.JSON.Errors._IDeserializationError> _530_valueOrError0 = Std.JSON.Deserializer.__default.String(_529_str);
        if ((_530_valueOrError0).IsFailure()) {
          return (_530_valueOrError0).PropagateFailure<Std.JSON.Values._IJSON>();
        } else {
          Dafny.ISequence<Dafny.Rune> _531_s = (_530_valueOrError0).Extract();
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_String(_531_s));
        }
      } else if (_source21.is_Number) {
        Std.JSON.Grammar._Ijnumber _532___mcc_h3 = _source21.dtor_num;
        Std.JSON.Grammar._Ijnumber _533_dec = _532___mcc_h3;
        Std.Wrappers._IResult<Std.JSON.Values._IDecimal, Std.JSON.Errors._IDeserializationError> _534_valueOrError1 = Std.JSON.Deserializer.__default.Number(_533_dec);
        if ((_534_valueOrError1).IsFailure()) {
          return (_534_valueOrError1).PropagateFailure<Std.JSON.Values._IJSON>();
        } else {
          Std.JSON.Values._IDecimal _535_n = (_534_valueOrError1).Extract();
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Number(_535_n));
        }
      } else if (_source21.is_Object) {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _536___mcc_h4 = _source21.dtor_obj;
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _537_obj = _536___mcc_h4;
        Std.Wrappers._IResult<Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>>, Std.JSON.Errors._IDeserializationError> _538_valueOrError2 = Std.JSON.Deserializer.__default.Object(_537_obj);
        if ((_538_valueOrError2).IsFailure()) {
          return (_538_valueOrError2).PropagateFailure<Std.JSON.Values._IJSON>();
        } else {
          Dafny.ISequence<_System._ITuple2<Dafny.ISequence<Dafny.Rune>, Std.JSON.Values._IJSON>> _539_o = (_538_valueOrError2).Extract();
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Object(_539_o));
        }
      } else {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _540___mcc_h5 = _source21.dtor_arr;
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _541_arr = _540___mcc_h5;
        Std.Wrappers._IResult<Dafny.ISequence<Std.JSON.Values._IJSON>, Std.JSON.Errors._IDeserializationError> _542_valueOrError3 = Std.JSON.Deserializer.__default.Array(_541_arr);
        if ((_542_valueOrError3).IsFailure()) {
          return (_542_valueOrError3).PropagateFailure<Std.JSON.Values._IJSON>();
        } else {
          Dafny.ISequence<Std.JSON.Values._IJSON> _543_a = (_542_valueOrError3).Extract();
          return Std.Wrappers.Result<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError>.create_Success(Std.JSON.Values.JSON.create_Array(_543_a));
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> JSON(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.JSON.Deserializer.__default.Value((js).dtor_t);
    }
    public static Dafny.IMap<ushort,BigInteger> HEX__TABLE__16 { get {
      return Std.JSON.Deserializer.Uint16StrConversion.__default.charToDigit;
    } }
    public static Dafny.IMap<byte,BigInteger> DIGITS { get {
      return Std.JSON.ByteStrConversion.__default.charToDigit;
    } }
    public static byte MINUS { get {
      return (byte)((new Dafny.Rune('-')).Value);
    } }
  }
} // end of namespace Std.JSON.Deserializer
namespace Std.JSON.ConcreteSyntax.Spec {

  public partial class __default {
    public static Dafny.ISequence<byte> View(Std.JSON.Utils.Views.Core._IView__ v) {
      return (v).Bytes();
    }
    public static Dafny.ISequence<byte> Structural<__T>(Std.JSON.Grammar._IStructural<__T> self, Func<__T, Dafny.ISequence<byte>> fT)
    {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_before), Dafny.Helpers.Id<Func<__T, Dafny.ISequence<byte>>>(fT)((self).dtor_t)), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_after));
    }
    public static Dafny.ISequence<byte> StructuralView(Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> self) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Structural<Std.JSON.Utils.Views.Core._IView__>(self, Std.JSON.ConcreteSyntax.Spec.__default.View);
    }
    public static Dafny.ISequence<byte> Maybe<__T>(Std.JSON.Grammar._IMaybe<__T> self, Func<__T, Dafny.ISequence<byte>> fT)
    {
      if ((self).is_Empty) {
        return Dafny.Sequence<byte>.FromElements();
      } else {
        return Dafny.Helpers.Id<Func<__T, Dafny.ISequence<byte>>>(fT)((self).dtor_t);
      }
    }
    public static Dafny.ISequence<byte> ConcatBytes<__T>(Dafny.ISequence<__T> ts, Func<__T, Dafny.ISequence<byte>> fT)
    {
      Dafny.ISequence<byte> _544___accumulator = Dafny.Sequence<byte>.FromElements();
    TAIL_CALL_START: ;
      if ((new BigInteger((ts).Count)).Sign == 0) {
        return Dafny.Sequence<byte>.Concat(_544___accumulator, Dafny.Sequence<byte>.FromElements());
      } else {
        _544___accumulator = Dafny.Sequence<byte>.Concat(_544___accumulator, Dafny.Helpers.Id<Func<__T, Dafny.ISequence<byte>>>(fT)((ts).Select(BigInteger.Zero)));
        Dafny.ISequence<__T> _in94 = (ts).Drop(BigInteger.One);
        Func<__T, Dafny.ISequence<byte>> _in95 = fT;
        ts = _in94;
        fT = _in95;
        goto TAIL_CALL_START;
      }
    }
    public static Dafny.ISequence<byte> Bracketed<__D, __S>(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, __D, __S, Std.JSON.Utils.Views.Core._IView__> self, Func<Std.JSON.Grammar._ISuffixed<__D, __S>, Dafny.ISequence<byte>> fDatum)
    {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.StructuralView((self).dtor_l), Std.JSON.ConcreteSyntax.Spec.__default.ConcatBytes<Std.JSON.Grammar._ISuffixed<__D, __S>>((self).dtor_data, fDatum)), Std.JSON.ConcreteSyntax.Spec.__default.StructuralView((self).dtor_r));
    }
    public static Dafny.ISequence<byte> KeyValue(Std.JSON.Grammar._IjKeyValue self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.String((self).dtor_k), Std.JSON.ConcreteSyntax.Spec.__default.StructuralView((self).dtor_colon)), Std.JSON.ConcreteSyntax.Spec.__default.Value((self).dtor_v));
    }
    public static Dafny.ISequence<byte> Frac(Std.JSON.Grammar._Ijfrac self) {
      return Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_period), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_num));
    }
    public static Dafny.ISequence<byte> Exp(Std.JSON.Grammar._Ijexp self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_e), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_sign)), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_num));
    }
    public static Dafny.ISequence<byte> Number(Std.JSON.Grammar._Ijnumber self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_minus), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_num)), Std.JSON.ConcreteSyntax.Spec.__default.Maybe<Std.JSON.Grammar._Ijfrac>((self).dtor_frac, Std.JSON.ConcreteSyntax.Spec.__default.Frac)), Std.JSON.ConcreteSyntax.Spec.__default.Maybe<Std.JSON.Grammar._Ijexp>((self).dtor_exp, Std.JSON.ConcreteSyntax.Spec.__default.Exp));
    }
    public static Dafny.ISequence<byte> String(Std.JSON.Grammar._Ijstring self) {
      return Dafny.Sequence<byte>.Concat(Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_lq), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_contents)), Std.JSON.ConcreteSyntax.Spec.__default.View((self).dtor_rq));
    }
    public static Dafny.ISequence<byte> CommaSuffix(Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> c) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>(c, Std.JSON.ConcreteSyntax.Spec.__default.StructuralView);
    }
    public static Dafny.ISequence<byte> Member(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> self) {
      return Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.KeyValue((self).dtor_t), Std.JSON.ConcreteSyntax.Spec.__default.CommaSuffix((self).dtor_suffix));
    }
    public static Dafny.ISequence<byte> Item(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> self) {
      return Dafny.Sequence<byte>.Concat(Std.JSON.ConcreteSyntax.Spec.__default.Value((self).dtor_t), Std.JSON.ConcreteSyntax.Spec.__default.CommaSuffix((self).dtor_suffix));
    }
    public static Dafny.ISequence<byte> Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Bracketed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>(obj, Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>>>((_545_obj) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>)((_546_d) => {
        return Std.JSON.ConcreteSyntax.Spec.__default.Member(_546_d);
      })))(obj));
    }
    public static Dafny.ISequence<byte> Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Bracketed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>(arr, Dafny.Helpers.Id<Func<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>, Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>>>((_547_arr) => ((System.Func<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>, Dafny.ISequence<byte>>)((_548_d) => {
        return Std.JSON.ConcreteSyntax.Spec.__default.Item(_548_d);
      })))(arr));
    }
    public static Dafny.ISequence<byte> Value(Std.JSON.Grammar._IValue self) {
      Std.JSON.Grammar._IValue _source22 = self;
      if (_source22.is_Null) {
        Std.JSON.Utils.Views.Core._IView__ _549___mcc_h0 = _source22.dtor_n;
        Std.JSON.Utils.Views.Core._IView__ _550_n = _549___mcc_h0;
        return Std.JSON.ConcreteSyntax.Spec.__default.View(_550_n);
      } else if (_source22.is_Bool) {
        Std.JSON.Utils.Views.Core._IView__ _551___mcc_h1 = _source22.dtor_b;
        Std.JSON.Utils.Views.Core._IView__ _552_b = _551___mcc_h1;
        return Std.JSON.ConcreteSyntax.Spec.__default.View(_552_b);
      } else if (_source22.is_String) {
        Std.JSON.Grammar._Ijstring _553___mcc_h2 = _source22.dtor_str;
        Std.JSON.Grammar._Ijstring _554_str = _553___mcc_h2;
        return Std.JSON.ConcreteSyntax.Spec.__default.String(_554_str);
      } else if (_source22.is_Number) {
        Std.JSON.Grammar._Ijnumber _555___mcc_h3 = _source22.dtor_num;
        Std.JSON.Grammar._Ijnumber _556_num = _555___mcc_h3;
        return Std.JSON.ConcreteSyntax.Spec.__default.Number(_556_num);
      } else if (_source22.is_Object) {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _557___mcc_h4 = _source22.dtor_obj;
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _558_obj = _557___mcc_h4;
        return Std.JSON.ConcreteSyntax.Spec.__default.Object(_558_obj);
      } else {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _559___mcc_h5 = _source22.dtor_arr;
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _560_arr = _559___mcc_h5;
        return Std.JSON.ConcreteSyntax.Spec.__default.Array(_560_arr);
      }
    }
    public static Dafny.ISequence<byte> JSON(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Structural<Std.JSON.Grammar._IValue>(js, Std.JSON.ConcreteSyntax.Spec.__default.Value);
    }
  }
} // end of namespace Std.JSON.ConcreteSyntax.Spec
namespace Std.JSON.ConcreteSyntax.SpecProperties {

} // end of namespace Std.JSON.ConcreteSyntax.SpecProperties
namespace Std.JSON.ConcreteSyntax {

} // end of namespace Std.JSON.ConcreteSyntax
namespace Std.JSON.ZeroCopy.Serializer {

  public partial class __default {
    public static Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> Serialize(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js)
    {
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> rbs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.Default(new byte[0]);
      Std.JSON.Utils.Views.Writers._IWriter__ _561_writer;
      _561_writer = Std.JSON.ZeroCopy.Serializer.__default.Text(js);
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._ISerializationError> _562_valueOrError0 = Std.Wrappers.OutcomeResult<Std.JSON.Errors._ISerializationError>.Default();
      _562_valueOrError0 = Std.Wrappers.__default.Need<Std.JSON.Errors._ISerializationError>((_561_writer).Unsaturated_q, Std.JSON.Errors.SerializationError.create_OutOfMemory());
      if ((_562_valueOrError0).IsFailure()) {
        rbs = (_562_valueOrError0).PropagateFailure<byte[]>();
        return rbs;
      }
      byte[] _563_bs;
      byte[] _out6;
      _out6 = (_561_writer).ToArray();
      _563_bs = _out6;
      rbs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.create_Success(_563_bs);
      return rbs;
      return rbs;
    }
    public static Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> SerializeTo(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js, byte[] dest)
    {
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.Default(0);
      Std.JSON.Utils.Views.Writers._IWriter__ _564_writer;
      _564_writer = Std.JSON.ZeroCopy.Serializer.__default.Text(js);
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._ISerializationError> _565_valueOrError0 = Std.Wrappers.OutcomeResult<Std.JSON.Errors._ISerializationError>.Default();
      _565_valueOrError0 = Std.Wrappers.__default.Need<Std.JSON.Errors._ISerializationError>((_564_writer).Unsaturated_q, Std.JSON.Errors.SerializationError.create_OutOfMemory());
      if ((_565_valueOrError0).IsFailure()) {
        len = (_565_valueOrError0).PropagateFailure<uint>();
        return len;
      }
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._ISerializationError> _566_valueOrError1 = Std.Wrappers.OutcomeResult<Std.JSON.Errors._ISerializationError>.Default();
      _566_valueOrError1 = Std.Wrappers.__default.Need<Std.JSON.Errors._ISerializationError>((new BigInteger((_564_writer).dtor_length)) <= (new BigInteger((dest).Length)), Std.JSON.Errors.SerializationError.create_OutOfMemory());
      if ((_566_valueOrError1).IsFailure()) {
        len = (_566_valueOrError1).PropagateFailure<uint>();
        return len;
      }
      (_564_writer).CopyTo(dest);
      len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.create_Success((_564_writer).dtor_length);
      return len;
      return len;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Text(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.JSON.ZeroCopy.Serializer.__default.JSON(js, Std.JSON.Utils.Views.Writers.Writer__.Empty);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ JSON(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      return (((writer).Append((js).dtor_before)).Then(Dafny.Helpers.Id<Func<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__>>>((_567_js) => ((System.Func<Std.JSON.Utils.Views.Writers._IWriter__, Std.JSON.Utils.Views.Writers._IWriter__>)((_568_wr) => {
        return Std.JSON.ZeroCopy.Serializer.__default.Value((_567_js).dtor_t, _568_wr);
      })))(js))).Append((js).dtor_after);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Value(Std.JSON.Grammar._IValue v, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Grammar._IValue _source23 = v;
      if (_source23.is_Null) {
        Std.JSON.Utils.Views.Core._IView__ _569___mcc_h0 = _source23.dtor_n;
        Std.JSON.Utils.Views.Core._IView__ _570_n = _569___mcc_h0;
        Std.JSON.Utils.Views.Writers._IWriter__ _571_wr = (writer).Append(_570_n);
        return _571_wr;
      } else if (_source23.is_Bool) {
        Std.JSON.Utils.Views.Core._IView__ _572___mcc_h1 = _source23.dtor_b;
        Std.JSON.Utils.Views.Core._IView__ _573_b = _572___mcc_h1;
        Std.JSON.Utils.Views.Writers._IWriter__ _574_wr = (writer).Append(_573_b);
        return _574_wr;
      } else if (_source23.is_String) {
        Std.JSON.Grammar._Ijstring _575___mcc_h2 = _source23.dtor_str;
        Std.JSON.Grammar._Ijstring _576_str = _575___mcc_h2;
        Std.JSON.Utils.Views.Writers._IWriter__ _577_wr = Std.JSON.ZeroCopy.Serializer.__default.String(_576_str, writer);
        return _577_wr;
      } else if (_source23.is_Number) {
        Std.JSON.Grammar._Ijnumber _578___mcc_h3 = _source23.dtor_num;
        Std.JSON.Grammar._Ijnumber _579_num = _578___mcc_h3;
        Std.JSON.Utils.Views.Writers._IWriter__ _580_wr = Std.JSON.ZeroCopy.Serializer.__default.Number(_579_num, writer);
        return _580_wr;
      } else if (_source23.is_Object) {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _581___mcc_h4 = _source23.dtor_obj;
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _582_obj = _581___mcc_h4;
        Std.JSON.Utils.Views.Writers._IWriter__ _583_wr = Std.JSON.ZeroCopy.Serializer.__default.Object(_582_obj, writer);
        return _583_wr;
      } else {
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _584___mcc_h5 = _source23.dtor_arr;
        Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _585_arr = _584___mcc_h5;
        Std.JSON.Utils.Views.Writers._IWriter__ _586_wr = Std.JSON.ZeroCopy.Serializer.__default.Array(_585_arr, writer);
        return _586_wr;
      }
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ String(Std.JSON.Grammar._Ijstring str, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      return (((writer).Append((str).dtor_lq)).Append((str).dtor_contents)).Append((str).dtor_rq);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Number(Std.JSON.Grammar._Ijnumber num, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _587_wr1 = ((writer).Append((num).dtor_minus)).Append((num).dtor_num);
      Std.JSON.Utils.Views.Writers._IWriter__ _588_wr2 = ((((num).dtor_frac).is_NonEmpty) ? (((_587_wr1).Append((((num).dtor_frac).dtor_t).dtor_period)).Append((((num).dtor_frac).dtor_t).dtor_num)) : (_587_wr1));
      Std.JSON.Utils.Views.Writers._IWriter__ _589_wr3 = ((((num).dtor_exp).is_NonEmpty) ? ((((_588_wr2).Append((((num).dtor_exp).dtor_t).dtor_e)).Append((((num).dtor_exp).dtor_t).dtor_sign)).Append((((num).dtor_exp).dtor_t).dtor_num)) : (_588_wr2));
      Std.JSON.Utils.Views.Writers._IWriter__ _590_wr = _589_wr3;
      return _590_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ StructuralView(Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__> st, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      return (((writer).Append((st).dtor_before)).Append((st).dtor_t)).Append((st).dtor_after);
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Object(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _591_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((obj).dtor_l, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _592_wr = Std.JSON.ZeroCopy.Serializer.__default.Members(obj, _591_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _593_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((obj).dtor_r, _592_wr);
      return _593_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Array(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _594_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((arr).dtor_l, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _595_wr = Std.JSON.ZeroCopy.Serializer.__default.Items(arr, _594_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _596_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView((arr).dtor_r, _595_wr);
      return _596_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Members(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      Std.JSON.Utils.Views.Writers._IWriter__ _out7;
      _out7 = Std.JSON.ZeroCopy.Serializer.__default.MembersImpl(obj, writer);
      wr = _out7;
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Items(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      Std.JSON.Utils.Views.Writers._IWriter__ _out8;
      _out8 = Std.JSON.ZeroCopy.Serializer.__default.ItemsImpl(arr, writer);
      wr = _out8;
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ MembersImpl(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> obj, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      wr = writer;
      Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>> _597_members;
      _597_members = (obj).dtor_data;
      BigInteger _hi1 = new BigInteger((_597_members).Count);
      for (BigInteger _598_i = BigInteger.Zero; _598_i < _hi1; _598_i++) {
        wr = Std.JSON.ZeroCopy.Serializer.__default.Member((_597_members).Select(_598_i), wr);
      }
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ ItemsImpl(Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> arr, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ wr = Std.JSON.Utils.Views.Writers.Writer.Default();
      wr = writer;
      Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>> _599_items;
      _599_items = (arr).dtor_data;
      BigInteger _hi2 = new BigInteger((_599_items).Count);
      for (BigInteger _600_i = BigInteger.Zero; _600_i < _hi2; _600_i++) {
        wr = Std.JSON.ZeroCopy.Serializer.__default.Item((_599_items).Select(_600_i), wr);
      }
      return wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Member(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> m, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _601_wr = Std.JSON.ZeroCopy.Serializer.__default.String(((m).dtor_t).dtor_k, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _602_wr = Std.JSON.ZeroCopy.Serializer.__default.StructuralView(((m).dtor_t).dtor_colon, _601_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _603_wr = Std.JSON.ZeroCopy.Serializer.__default.Value(((m).dtor_t).dtor_v, _602_wr);
      Std.JSON.Utils.Views.Writers._IWriter__ _604_wr = ((((m).dtor_suffix).is_Empty) ? (_603_wr) : (Std.JSON.ZeroCopy.Serializer.__default.StructuralView(((m).dtor_suffix).dtor_t, _603_wr)));
      return _604_wr;
    }
    public static Std.JSON.Utils.Views.Writers._IWriter__ Item(Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> m, Std.JSON.Utils.Views.Writers._IWriter__ writer)
    {
      Std.JSON.Utils.Views.Writers._IWriter__ _605_wr = Std.JSON.ZeroCopy.Serializer.__default.Value((m).dtor_t, writer);
      Std.JSON.Utils.Views.Writers._IWriter__ _606_wr = ((((m).dtor_suffix).is_Empty) ? (_605_wr) : (Std.JSON.ZeroCopy.Serializer.__default.StructuralView(((m).dtor_suffix).dtor_t, _605_wr)));
      return _606_wr;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Serializer
namespace Std.JSON.ZeroCopy.Deserializer.Core {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Get(Std.JSON.Utils.Cursors._ICursor__ cs, Std.JSON.Errors._IDeserializationError err)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _607_valueOrError0 = (cs).Get<Std.JSON.Errors._IDeserializationError>(err);
      if ((_607_valueOrError0).IsFailure()) {
        return (_607_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _608_cs = (_607_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_608_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> WS(Std.JSON.Utils.Cursors._ICursor__ cs)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Utils.Views.Core._IView__>.Default(Std.JSON.Grammar.jblanks.Default());
      uint _609_point_k;
      _609_point_k = (cs).dtor_point;
      uint _610_end;
      _610_end = (cs).dtor_end;
      while (((_609_point_k) < (_610_end)) && (Std.JSON.Grammar.__default.Blank_q(((cs).dtor_s).Select(_609_point_k)))) {
        _609_point_k = (_609_point_k) + (1U);
      }
      sp = (Std.JSON.Utils.Cursors.Cursor__.create((cs).dtor_s, (cs).dtor_beg, _609_point_k, (cs).dtor_end)).Split();
      return sp;
      return sp;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<__T>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Structural<__T>(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> parser)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs18 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(cs);
      Std.JSON.Utils.Views.Core._IView__ _611_before = _let_tmp_rhs18.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _612_cs = _let_tmp_rhs18.dtor_cs;
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _613_valueOrError0 = Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<__T>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>((parser))(_612_cs);
      if ((_613_valueOrError0).IsFailure()) {
        return (_613_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<__T>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<__T> _let_tmp_rhs19 = (_613_valueOrError0).Extract();
        __T _614_val = _let_tmp_rhs19.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _615_cs = _let_tmp_rhs19.dtor_cs;
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs20 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(_615_cs);
        Std.JSON.Utils.Views.Core._IView__ _616_after = _let_tmp_rhs20.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _617_cs = _let_tmp_rhs20.dtor_cs;
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<__T>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IStructural<__T>>.create(Std.JSON.Grammar.Structural<__T>.create(_611_before, _614_val, _616_after), _617_cs));
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> TryStructural(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs21 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(cs);
      Std.JSON.Utils.Views.Core._IView__ _618_before = _let_tmp_rhs21.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _619_cs = _let_tmp_rhs21.dtor_cs;
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs22 = ((_619_cs).SkipByte()).Split();
      Std.JSON.Utils.Views.Core._IView__ _620_val = _let_tmp_rhs22.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _621_cs = _let_tmp_rhs22.dtor_cs;
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs23 = Std.JSON.ZeroCopy.Deserializer.Core.__default.WS(_621_cs);
      Std.JSON.Utils.Views.Core._IView__ _622_after = _let_tmp_rhs23.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _623_cs = _let_tmp_rhs23.dtor_cs;
      return Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create(Std.JSON.Grammar.Structural<Std.JSON.Utils.Views.Core._IView__>.create(_618_before, _620_val, _622_after), _623_cs);
    }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecView { get {
      return ((System.Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>>)((_624_v) => {
        return Std.JSON.ConcreteSyntax.Spec.__default.View(_624_v);
      }));
    } }
  }

  public partial class jopt {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements());
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Core.jopt.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class ValueParser {
    private static readonly Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>> _TYPE = new Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>(Std.JSON.Utils.Parsers.SubParser<Std.JSON.Grammar._IValue, Std.JSON.Errors._IDeserializationError>.Default());
    public static Dafny.TypeDescriptor<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Core
namespace Std.JSON.ZeroCopy.Deserializer.Strings {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> StringBody(Std.JSON.Utils.Cursors._ICursor__ cs)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.Default(Std.JSON.Utils.Cursors.Cursor.Default());
      bool _625_escaped;
      _625_escaped = false;
      uint _hi3 = (cs).dtor_end;
      for (uint _626_point_k = (cs).dtor_point; _626_point_k < _hi3; _626_point_k++) {
        byte _627_byte;
        _627_byte = ((cs).dtor_s).Select(_626_point_k);
        if (((_627_byte) == ((byte)((new Dafny.Rune('\"')).Value))) && (!(_625_escaped))) {
          pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Cursor__.create((cs).dtor_s, (cs).dtor_beg, _626_point_k, (cs).dtor_end));
          return pr;
        } else if ((_627_byte) == ((byte)((new Dafny.Rune('\\')).Value))) {
          _625_escaped = !(_625_escaped);
        } else {
          _625_escaped = false;
        }
      }
      pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_EOF());
      return pr;
      return pr;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Quote(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _628_valueOrError0 = (cs).AssertChar<Std.JSON.Errors._IDeserializationError>(new Dafny.Rune('\"'));
      if ((_628_valueOrError0).IsFailure()) {
        return (_628_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _629_cs = (_628_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_629_cs).Split());
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> String(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _630_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.Quote(cs);
      if ((_630_valueOrError0).IsFailure()) {
        return (_630_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs24 = (_630_valueOrError0).Extract();
        Std.JSON.Utils.Views.Core._IView__ _631_lq = _let_tmp_rhs24.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _632_cs = _let_tmp_rhs24.dtor_cs;
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _633_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.StringBody(_632_cs);
        if ((_633_valueOrError1).IsFailure()) {
          return (_633_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>>();
        } else {
          Std.JSON.Utils.Cursors._ICursor__ _634_contents = (_633_valueOrError1).Extract();
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs25 = (_634_contents).Split();
          Std.JSON.Utils.Views.Core._IView__ _635_contents = _let_tmp_rhs25.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _636_cs = _let_tmp_rhs25.dtor_cs;
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _637_valueOrError2 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.Quote(_636_cs);
          if ((_637_valueOrError2).IsFailure()) {
            return (_637_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs26 = (_637_valueOrError2).Extract();
            Std.JSON.Utils.Views.Core._IView__ _638_rq = _let_tmp_rhs26.dtor_t;
            Std.JSON.Utils.Cursors._ICursor__ _639_cs = _let_tmp_rhs26.dtor_cs;
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._Ijstring>.create(Std.JSON.Grammar.jstring.create(_631_lq, _635_contents, _638_rq), _639_cs));
          }
        }
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Strings
namespace Std.JSON.ZeroCopy.Deserializer.Numbers {

  public partial class __default {
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> Digits(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return ((cs).SkipWhile(Std.JSON.Grammar.__default.Digit_q)).Split();
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> NonEmptyDigits(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _640_sp = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Digits(cs);
      if (((_640_sp).dtor_t).Empty_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_OtherError(Std.JSON.Errors.DeserializationError.create_EmptyNumber()));
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_640_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> NonZeroInt(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonEmptyDigits(cs);
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> OptionalMinus(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return ((cs).SkipIf(((System.Func<byte, bool>)((_641_c) => {
        return (_641_c) == ((byte)((new Dafny.Rune('-')).Value));
      })))).Split();
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> OptionalSign(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return ((cs).SkipIf(((System.Func<byte, bool>)((_642_c) => {
        return ((_642_c) == ((byte)((new Dafny.Rune('-')).Value))) || ((_642_c) == ((byte)((new Dafny.Rune('+')).Value)));
      })))).Split();
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> TrimmedInt(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _643_sp = ((cs).SkipIf(((System.Func<byte, bool>)((_644_c) => {
        return (_644_c) == ((byte)((new Dafny.Rune('0')).Value));
      })))).Split();
      if (((_643_sp).dtor_t).Empty_q) {
        return Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonZeroInt((_643_sp).dtor_cs);
      } else {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_643_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Exp(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs27 = ((cs).SkipIf(((System.Func<byte, bool>)((_645_c) => {
        return ((_645_c) == ((byte)((new Dafny.Rune('e')).Value))) || ((_645_c) == ((byte)((new Dafny.Rune('E')).Value)));
      })))).Split();
      Std.JSON.Utils.Views.Core._IView__ _646_e = _let_tmp_rhs27.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _647_cs = _let_tmp_rhs27.dtor_cs;
      if ((_646_e).Empty_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_Empty(), _647_cs));
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs28 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.OptionalSign(_647_cs);
        Std.JSON.Utils.Views.Core._IView__ _648_sign = _let_tmp_rhs28.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _649_cs = _let_tmp_rhs28.dtor_cs;
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _650_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonEmptyDigits(_649_cs);
        if ((_650_valueOrError0).IsFailure()) {
          return (_650_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs29 = (_650_valueOrError0).Extract();
          Std.JSON.Utils.Views.Core._IView__ _651_num = _let_tmp_rhs29.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _652_cs = _let_tmp_rhs29.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijexp>.create_NonEmpty(Std.JSON.Grammar.jexp.create(_646_e, _648_sign, _651_num)), _652_cs));
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Frac(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs30 = ((cs).SkipIf(((System.Func<byte, bool>)((_653_c) => {
        return (_653_c) == ((byte)((new Dafny.Rune('.')).Value));
      })))).Split();
      Std.JSON.Utils.Views.Core._IView__ _654_period = _let_tmp_rhs30.dtor_t;
      Std.JSON.Utils.Cursors._ICursor__ _655_cs = _let_tmp_rhs30.dtor_cs;
      if ((_654_period).Empty_q) {
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_Empty(), _655_cs));
      } else {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _656_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NonEmptyDigits(_655_cs);
        if ((_656_valueOrError0).IsFailure()) {
          return (_656_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs31 = (_656_valueOrError0).Extract();
          Std.JSON.Utils.Views.Core._IView__ _657_num = _let_tmp_rhs31.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _658_cs = _let_tmp_rhs31.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>.create(Std.JSON.Grammar.Maybe<Std.JSON.Grammar._Ijfrac>.create_NonEmpty(Std.JSON.Grammar.jfrac.create(_654_period, _657_num)), _658_cs));
        }
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber> NumberFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> minus, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> num, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>> frac, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>> exp)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber> _659_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._Ijnumber>.create(Std.JSON.Grammar.jnumber.create((minus).dtor_t, (num).dtor_t, (frac).dtor_t, (exp).dtor_t), (exp).dtor_cs);
      return _659_sp;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Number(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _660_minus = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.OptionalMinus(cs);
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _661_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.TrimmedInt((_660_minus).dtor_cs);
      if ((_661_valueOrError0).IsFailure()) {
        return (_661_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _662_num = (_661_valueOrError0).Extract();
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _663_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Frac((_662_num).dtor_cs);
        if ((_663_valueOrError1).IsFailure()) {
          return (_663_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijfrac>> _664_frac = (_663_valueOrError1).Extract();
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _665_valueOrError2 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Exp((_664_frac).dtor_cs);
          if ((_665_valueOrError2).IsFailure()) {
            return (_665_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IMaybe<Std.JSON.Grammar._Ijexp>> _666_exp = (_665_valueOrError2).Extract();
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.ZeroCopy.Deserializer.Numbers.__default.NumberFromParts(_660_minus, _662_num, _664_frac, _666_exp));
          }
        }
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Numbers
namespace Std.JSON.ZeroCopy.Deserializer.ObjectParams {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Colon(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _667_valueOrError0 = (cs).AssertChar<Std.JSON.Errors._IDeserializationError>(new Dafny.Rune(':'));
      if ((_667_valueOrError0).IsFailure()) {
        return (_667_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _668_cs = (_667_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_668_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> KeyValueFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring> k, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> colon, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> v)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> _669_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IjKeyValue>.create(Std.JSON.Grammar.jKeyValue.create((k).dtor_t, (colon).dtor_t, (v).dtor_t), (v).dtor_cs);
      return _669_sp;
    }
    public static Dafny.ISequence<byte> ElementSpec(Std.JSON.Grammar._IjKeyValue t) {
      return Std.JSON.ConcreteSyntax.Spec.__default.KeyValue(t);
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Element(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _670_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.String(cs);
      if ((_670_valueOrError0).IsFailure()) {
        return (_670_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring> _671_k = (_670_valueOrError0).Extract();
        Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _672_p = Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.Colon;
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _673_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>((_671_k).dtor_cs, _672_p);
        if ((_673_valueOrError1).IsFailure()) {
          return (_673_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _674_colon = (_673_valueOrError1).Extract();
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _675_valueOrError2 = Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>((json))((_674_colon).dtor_cs);
          if ((_675_valueOrError2).IsFailure()) {
            return (_675_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _676_v = (_675_valueOrError2).Extract();
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> _677_kv = Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.KeyValueFromParts(_671_k, _674_colon, _676_v);
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_677_kv);
          }
        }
      }
    }
    public static byte OPEN { get {
      return (byte)((new Dafny.Rune('{')).Value);
    } }
    public static byte CLOSE { get {
      return (byte)((new Dafny.Rune('}')).Value);
    } }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.ObjectParams
namespace Std.JSON.ZeroCopy.Deserializer.Objects {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Object(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _678_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Objects.__default.Bracketed(cs, json);
      if ((_678_valueOrError0).IsFailure()) {
        return (_678_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _679_sp = (_678_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_679_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Open(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _680_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.OPEN);
      if ((_680_valueOrError0).IsFailure()) {
        return (_680_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _681_cs = (_680_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_681_cs).Split());
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Close(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _682_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE);
      if ((_682_valueOrError0).IsFailure()) {
        return (_682_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _683_cs = (_682_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_683_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> BracketedFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> close)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _684_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>.create(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create((open).dtor_t, (elems).dtor_t, (close).dtor_t), (close).dtor_cs);
      return _684_sp;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> AppendWithSuffix(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> _685_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_NonEmpty((sep).dtor_t));
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _686_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_685_suffixed)), (sep).dtor_cs);
      return _686_elems_k;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> AppendLast(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__> _687_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_Empty());
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _688_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_687_suffixed)), (elem).dtor_cs);
      return _688_elems_k;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Elements(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> elems)
    {
    TAIL_CALL_START: ;
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _689_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.Element((elems).dtor_cs, json);
      if ((_689_valueOrError0).IsFailure()) {
        return (_689_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IjKeyValue> _690_elem = (_689_valueOrError0).Extract();
        if (((_690_elem).dtor_cs).EOF_q) {
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_EOF());
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _691_sep = Std.JSON.ZeroCopy.Deserializer.Core.__default.TryStructural((_690_elem).dtor_cs);
          short _692_s0 = (((_691_sep).dtor_t).dtor_t).Peek();
          if (((_692_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.Objects.__default.SEPARATOR))) && (((((_691_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _693_sep = _691_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _694_elems = Std.JSON.ZeroCopy.Deserializer.Objects.__default.AppendWithSuffix(elems, _690_elem, _693_sep);
            Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _in96 = json;
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _in97 = open;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _in98 = _694_elems;
            json = _in96;
            open = _in97;
            elems = _in98;
            goto TAIL_CALL_START;
          } else if (((_692_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE))) && (((((_691_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _695_sep = _691_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _696_elems_k = Std.JSON.ZeroCopy.Deserializer.Objects.__default.AppendLast(elems, _690_elem, _695_sep);
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _697_bracketed = Std.JSON.ZeroCopy.Deserializer.Objects.__default.BracketedFromParts(open, _696_elems_k, _695_sep);
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_697_bracketed);
          } else {
            byte _698_separator = Std.JSON.ZeroCopy.Deserializer.Objects.__default.SEPARATOR;
            Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _699_pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_ExpectingAnyByte(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE, _698_separator), _692_s0));
            return _699_pr;
          }
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Bracketed(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _700_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>(cs, Std.JSON.ZeroCopy.Deserializer.Objects.__default.Open);
      if ((_700_valueOrError0).IsFailure()) {
        return (_700_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _701_open = (_700_valueOrError0).Extract();
        Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>> _702_elems = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(), (_701_open).dtor_cs);
        if ((((_701_open).dtor_cs).Peek()) == ((short)(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE))) {
          Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _703_p = Std.JSON.ZeroCopy.Deserializer.Objects.__default.Close;
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _704_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>((_701_open).dtor_cs, _703_p);
          if ((_704_valueOrError1).IsFailure()) {
            return (_704_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _705_close = (_704_valueOrError1).Extract();
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.ZeroCopy.Deserializer.Objects.__default.BracketedFromParts(_701_open, _702_elems, _705_close));
          }
        } else {
          return Std.JSON.ZeroCopy.Deserializer.Objects.__default.Elements(json, _701_open, _702_elems);
        }
      }
    }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewOpen { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewClose { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static byte SEPARATOR { get {
      return (byte)((new Dafny.Rune(',')).Value);
    } }
  }

  public partial class jopen {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.OPEN));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Objects.jopen.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jclose {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ObjectParams.__default.CLOSE));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Objects.jclose.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Objects
namespace Std.JSON.ZeroCopy.Deserializer.ArrayParams {

  public partial class __default {
    public static Dafny.ISequence<byte> ElementSpec(Std.JSON.Grammar._IValue t) {
      return Std.JSON.ConcreteSyntax.Spec.__default.Value(t);
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Element(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      return Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>((json))(cs);
    }
    public static byte OPEN { get {
      return (byte)((new Dafny.Rune('[')).Value);
    } }
    public static byte CLOSE { get {
      return (byte)((new Dafny.Rune(']')).Value);
    } }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.ArrayParams
namespace Std.JSON.ZeroCopy.Deserializer.Arrays {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Array(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _706_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Bracketed(cs, json);
      if ((_706_valueOrError0).IsFailure()) {
        return (_706_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _707_sp = (_706_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_707_sp);
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Open(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _708_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.OPEN);
      if ((_708_valueOrError0).IsFailure()) {
        return (_708_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _709_cs = (_708_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_709_cs).Split());
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Close(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _710_valueOrError0 = (cs).AssertByte<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE);
      if ((_710_valueOrError0).IsFailure()) {
        return (_710_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _711_cs = (_710_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_711_cs).Split());
      }
    }
    public static Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> BracketedFromParts(Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> close)
    {
      Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _712_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>.create(Std.JSON.Grammar.Bracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>.create((open).dtor_t, (elems).dtor_t, (close).dtor_t), (close).dtor_cs);
      return _712_sp;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> AppendWithSuffix(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> _713_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_NonEmpty((sep).dtor_t));
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _714_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_713_suffixed)), (sep).dtor_cs);
      return _714_elems_k;
    }
    public static Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> AppendLast(Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> elem, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> sep)
    {
      Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__> _715_suffixed = Std.JSON.Grammar.Suffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>.create((elem).dtor_t, Std.JSON.Grammar.Maybe<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>.create_Empty());
      Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _716_elems_k = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.Concat((elems).dtor_t, Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(_715_suffixed)), (elem).dtor_cs);
      return _716_elems_k;
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Elements(Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json, Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> open, Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> elems)
    {
    TAIL_CALL_START: ;
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _717_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.Element((elems).dtor_cs, json);
      if ((_717_valueOrError0).IsFailure()) {
        return (_717_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _718_elem = (_717_valueOrError0).Extract();
        if (((_718_elem).dtor_cs).EOF_q) {
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_EOF());
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _719_sep = Std.JSON.ZeroCopy.Deserializer.Core.__default.TryStructural((_718_elem).dtor_cs);
          short _720_s0 = (((_719_sep).dtor_t).dtor_t).Peek();
          if (((_720_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.Arrays.__default.SEPARATOR))) && (((((_719_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _721_sep = _719_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _722_elems = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.AppendWithSuffix(elems, _718_elem, _721_sep);
            Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _in99 = json;
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _in100 = open;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _in101 = _722_elems;
            json = _in99;
            open = _in100;
            elems = _in101;
            goto TAIL_CALL_START;
          } else if (((_720_s0) == ((short)(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE))) && (((((_719_sep).dtor_t).dtor_t).Length()) == (1U))) {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _723_sep = _719_sep;
            Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _724_elems_k = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.AppendLast(elems, _718_elem, _723_sep);
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _725_bracketed = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.BracketedFromParts(open, _724_elems_k, _723_sep);
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_725_bracketed);
          } else {
            byte _726_separator = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.SEPARATOR;
            Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _727_pr = Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Failure(Std.JSON.Utils.Cursors.CursorError<Std.JSON.Errors._IDeserializationError>.create_ExpectingAnyByte(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE, _726_separator), _720_s0));
            return _727_pr;
          }
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Bracketed(Std.JSON.Utils.Cursors._ICursor__ cs, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> json)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _728_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>(cs, Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Open);
      if ((_728_valueOrError0).IsFailure()) {
        return (_728_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _729_open = (_728_valueOrError0).Extract();
        Std.JSON.Utils.Cursors._ISplit<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>> _730_elems = Std.JSON.Utils.Cursors.Split<Dafny.ISequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>>.create(Dafny.Sequence<Std.JSON.Grammar._ISuffixed<Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__>>.FromElements(), (_729_open).dtor_cs);
        if ((((_729_open).dtor_cs).Peek()) == ((short)(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE))) {
          Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _731_p = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Close;
          Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _732_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Utils.Views.Core._IView__>((_729_open).dtor_cs, _731_p);
          if ((_732_valueOrError1).IsFailure()) {
            return (_732_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>>();
          } else {
            Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Utils.Views.Core._IView__>> _733_close = (_732_valueOrError1).Extract();
            return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.ZeroCopy.Deserializer.Arrays.__default.BracketedFromParts(_729_open, _730_elems, _733_close));
          }
        } else {
          return Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Elements(json, _729_open, _730_elems);
        }
      }
    }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewOpen { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static Func<Std.JSON.Utils.Views.Core._IView__, Dafny.ISequence<byte>> SpecViewClose { get {
      return Std.JSON.ZeroCopy.Deserializer.Core.__default.SpecView;
    } }
    public static byte SEPARATOR { get {
      return (byte)((new Dafny.Rune(',')).Value);
    } }
  }

  public partial class jopen {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.OPEN));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Arrays.jopen.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }

  public partial class jclose {
    private static readonly Std.JSON.Utils.Views.Core._IView__ Witness = Std.JSON.Utils.Views.Core.View__.OfBytes(Dafny.Sequence<byte>.FromElements(Std.JSON.ZeroCopy.Deserializer.ArrayParams.__default.CLOSE));
    public static Std.JSON.Utils.Views.Core._IView__ Default() {
      return Witness;
    }
    private static readonly Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TYPE = new Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__>(Std.JSON.ZeroCopy.Deserializer.Arrays.jclose.Default());
    public static Dafny.TypeDescriptor<Std.JSON.Utils.Views.Core._IView__> _TypeDescriptor() {
      return _TYPE;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Arrays
namespace Std.JSON.ZeroCopy.Deserializer.Constants {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Constant(Std.JSON.Utils.Cursors._ICursor__ cs, Dafny.ISequence<byte> expected)
    {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ICursor__, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _734_valueOrError0 = (cs).AssertBytes<Std.JSON.Errors._IDeserializationError>(expected, 0U);
      if ((_734_valueOrError0).IsFailure()) {
        return (_734_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>>();
      } else {
        Std.JSON.Utils.Cursors._ICursor__ _735_cs = (_734_valueOrError0).Extract();
        return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success((_735_cs).Split());
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Constants
namespace Std.JSON.ZeroCopy.Deserializer.Values {

  public partial class __default {
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> Value(Std.JSON.Utils.Cursors._ICursor__ cs) {
      short _736_c = (cs).Peek();
      if ((_736_c) == ((short)((new Dafny.Rune('{')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _737_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.Objects.__default.Object(cs, Std.JSON.ZeroCopy.Deserializer.Values.__default.ValueParser(cs));
        if ((_737_valueOrError0).IsFailure()) {
          return (_737_valueOrError0).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _let_tmp_rhs32 = (_737_valueOrError0).Extract();
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IjKeyValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _738_obj = _let_tmp_rhs32.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _739_cs_k = _let_tmp_rhs32.dtor_cs;
          Std.JSON.Grammar._IValue _740_v = Std.JSON.Grammar.Value.create_Object(_738_obj);
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _741_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(_740_v, _739_cs_k);
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_741_sp);
        }
      } else if ((_736_c) == ((short)((new Dafny.Rune('[')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _742_valueOrError1 = Std.JSON.ZeroCopy.Deserializer.Arrays.__default.Array(cs, Std.JSON.ZeroCopy.Deserializer.Values.__default.ValueParser(cs));
        if ((_742_valueOrError1).IsFailure()) {
          return (_742_valueOrError1).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__>> _let_tmp_rhs33 = (_742_valueOrError1).Extract();
          Std.JSON.Grammar._IBracketed<Std.JSON.Utils.Views.Core._IView__, Std.JSON.Grammar._IValue, Std.JSON.Utils.Views.Core._IView__, Std.JSON.Utils.Views.Core._IView__> _743_arr = _let_tmp_rhs33.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _744_cs_k = _let_tmp_rhs33.dtor_cs;
          Std.JSON.Grammar._IValue _745_v = Std.JSON.Grammar.Value.create_Array(_743_arr);
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _746_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(_745_v, _744_cs_k);
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_746_sp);
        }
      } else if ((_736_c) == ((short)((new Dafny.Rune('\"')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _747_valueOrError2 = Std.JSON.ZeroCopy.Deserializer.Strings.__default.String(cs);
        if ((_747_valueOrError2).IsFailure()) {
          return (_747_valueOrError2).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijstring> _let_tmp_rhs34 = (_747_valueOrError2).Extract();
          Std.JSON.Grammar._Ijstring _748_str = _let_tmp_rhs34.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _749_cs_k = _let_tmp_rhs34.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_String(_748_str), _749_cs_k));
        }
      } else if ((_736_c) == ((short)((new Dafny.Rune('t')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _750_valueOrError3 = Std.JSON.ZeroCopy.Deserializer.Constants.__default.Constant(cs, Std.JSON.Grammar.__default.TRUE);
        if ((_750_valueOrError3).IsFailure()) {
          return (_750_valueOrError3).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs35 = (_750_valueOrError3).Extract();
          Std.JSON.Utils.Views.Core._IView__ _751_cst = _let_tmp_rhs35.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _752_cs_k = _let_tmp_rhs35.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_Bool(_751_cst), _752_cs_k));
        }
      } else if ((_736_c) == ((short)((new Dafny.Rune('f')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _753_valueOrError4 = Std.JSON.ZeroCopy.Deserializer.Constants.__default.Constant(cs, Std.JSON.Grammar.__default.FALSE);
        if ((_753_valueOrError4).IsFailure()) {
          return (_753_valueOrError4).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs36 = (_753_valueOrError4).Extract();
          Std.JSON.Utils.Views.Core._IView__ _754_cst = _let_tmp_rhs36.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _755_cs_k = _let_tmp_rhs36.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_Bool(_754_cst), _755_cs_k));
        }
      } else if ((_736_c) == ((short)((new Dafny.Rune('n')).Value))) {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _756_valueOrError5 = Std.JSON.ZeroCopy.Deserializer.Constants.__default.Constant(cs, Std.JSON.Grammar.__default.NULL);
        if ((_756_valueOrError5).IsFailure()) {
          return (_756_valueOrError5).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Utils.Views.Core._IView__> _let_tmp_rhs37 = (_756_valueOrError5).Extract();
          Std.JSON.Utils.Views.Core._IView__ _757_cst = _let_tmp_rhs37.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _758_cs_k = _let_tmp_rhs37.dtor_cs;
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(Std.JSON.Grammar.Value.create_Null(_757_cst), _758_cs_k));
        }
      } else {
        Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>> _759_valueOrError6 = Std.JSON.ZeroCopy.Deserializer.Numbers.__default.Number(cs);
        if ((_759_valueOrError6).IsFailure()) {
          return (_759_valueOrError6).PropagateFailure<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>>();
        } else {
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._Ijnumber> _let_tmp_rhs38 = (_759_valueOrError6).Extract();
          Std.JSON.Grammar._Ijnumber _760_num = _let_tmp_rhs38.dtor_t;
          Std.JSON.Utils.Cursors._ICursor__ _761_cs_k = _let_tmp_rhs38.dtor_cs;
          Std.JSON.Grammar._IValue _762_v = Std.JSON.Grammar.Value.create_Number(_760_num);
          Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue> _763_sp = Std.JSON.Utils.Cursors.Split<Std.JSON.Grammar._IValue>.create(_762_v, _761_cs_k);
          return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.create_Success(_763_sp);
        }
      }
    }
    public static Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> ValueParser(Std.JSON.Utils.Cursors._ICursor__ cs) {
      Func<Std.JSON.Utils.Cursors._ICursor__, bool> _764_pre = Dafny.Helpers.Id<Func<Std.JSON.Utils.Cursors._ICursor__, Func<Std.JSON.Utils.Cursors._ICursor__, bool>>>((_765_cs) => ((System.Func<Std.JSON.Utils.Cursors._ICursor__, bool>)((_766_ps_k) => {
        return ((_766_ps_k).Length()) < ((_765_cs).Length());
      })))(cs);
      Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>> _767_fn = Dafny.Helpers.Id<Func<Func<Std.JSON.Utils.Cursors._ICursor__, bool>, Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>>>((_768_pre) => ((System.Func<Std.JSON.Utils.Cursors._ICursor__, Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IValue>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>>)((_769_ps_k) => {
        return Std.JSON.ZeroCopy.Deserializer.Values.__default.Value(_769_ps_k);
      })))(_764_pre);
      return _767_fn;
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.Values
namespace Std.JSON.ZeroCopy.Deserializer.API {

  public partial class __default {
    public static Std.JSON.Errors._IDeserializationError LiftCursorError(Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError> err) {
      Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError> _source24 = err;
      if (_source24.is_EOF) {
        return Std.JSON.Errors.DeserializationError.create_ReachedEOF();
      } else if (_source24.is_ExpectingByte) {
        byte _770___mcc_h0 = _source24.dtor_expected;
        short _771___mcc_h1 = _source24.dtor_b;
        short _772_b = _771___mcc_h1;
        byte _773_expected = _770___mcc_h0;
        return Std.JSON.Errors.DeserializationError.create_ExpectingByte(_773_expected, _772_b);
      } else if (_source24.is_ExpectingAnyByte) {
        Dafny.ISequence<byte> _774___mcc_h2 = _source24.dtor_expected__sq;
        short _775___mcc_h3 = _source24.dtor_b;
        short _776_b = _775___mcc_h3;
        Dafny.ISequence<byte> _777_expected__sq = _774___mcc_h2;
        return Std.JSON.Errors.DeserializationError.create_ExpectingAnyByte(_777_expected__sq, _776_b);
      } else {
        Std.JSON.Errors._IDeserializationError _778___mcc_h4 = _source24.dtor_err;
        Std.JSON.Errors._IDeserializationError _779_err = _778___mcc_h4;
        return _779_err;
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>, Std.JSON.Errors._IDeserializationError> JSON(Std.JSON.Utils.Cursors._ICursor__ cs) {
      return Std.Wrappers.Result<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>, Std.JSON.Utils.Cursors._ICursorError<Std.JSON.Errors._IDeserializationError>>.MapFailure<Std.JSON.Errors._IDeserializationError>(Std.JSON.ZeroCopy.Deserializer.Core.__default.Structural<Std.JSON.Grammar._IValue>(cs, Std.JSON.ZeroCopy.Deserializer.Values.__default.Value), Std.JSON.ZeroCopy.Deserializer.API.__default.LiftCursorError);
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> Text(Std.JSON.Utils.Views.Core._IView__ v) {
      Std.Wrappers._IResult<Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>, Std.JSON.Errors._IDeserializationError> _780_valueOrError0 = Std.JSON.ZeroCopy.Deserializer.API.__default.JSON(Std.JSON.Utils.Cursors.Cursor__.OfView(v));
      if ((_780_valueOrError0).IsFailure()) {
        return (_780_valueOrError0).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
      } else {
        Std.JSON.Utils.Cursors._ISplit<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>> _let_tmp_rhs39 = (_780_valueOrError0).Extract();
        Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _781_text = _let_tmp_rhs39.dtor_t;
        Std.JSON.Utils.Cursors._ICursor__ _782_cs = _let_tmp_rhs39.dtor_cs;
        Std.Wrappers._IOutcomeResult<Std.JSON.Errors._IDeserializationError> _783_valueOrError1 = Std.Wrappers.__default.Need<Std.JSON.Errors._IDeserializationError>((_782_cs).EOF_q, Std.JSON.Errors.DeserializationError.create_ExpectingEOF());
        if ((_783_valueOrError1).IsFailure()) {
          return (_783_valueOrError1).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
        } else {
          return Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError>.create_Success(_781_text);
        }
      }
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> OfBytes(Dafny.ISequence<byte> bs) {
      Std.Wrappers._IOutcomeResult<Std.JSON.Errors._IDeserializationError> _784_valueOrError0 = Std.Wrappers.__default.Need<Std.JSON.Errors._IDeserializationError>((new BigInteger((bs).Count)) < (Std.BoundedInts.__default.TWO__TO__THE__32), Std.JSON.Errors.DeserializationError.create_IntOverflow());
      if ((_784_valueOrError0).IsFailure()) {
        return (_784_valueOrError0).PropagateFailure<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>>();
      } else {
        return Std.JSON.ZeroCopy.Deserializer.API.__default.Text(Std.JSON.Utils.Views.Core.View__.OfBytes(bs));
      }
    }
  }
} // end of namespace Std.JSON.ZeroCopy.Deserializer.API
namespace Std.JSON.ZeroCopy.Deserializer {

} // end of namespace Std.JSON.ZeroCopy.Deserializer
namespace Std.JSON.ZeroCopy.API {

  public partial class __default {
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Serialize(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js) {
      return Std.Wrappers.Result<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError>.create_Success((Std.JSON.ZeroCopy.Serializer.__default.Text(js)).Bytes());
    }
    public static Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> SerializeAlloc(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js)
    {
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> bs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.Default(new byte[0]);
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> _out9;
      _out9 = Std.JSON.ZeroCopy.Serializer.__default.Serialize(js);
      bs = _out9;
      return bs;
    }
    public static Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> SerializeInto(Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> js, byte[] bs)
    {
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.Default(0);
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> _out10;
      _out10 = Std.JSON.ZeroCopy.Serializer.__default.SerializeTo(js, bs);
      len = _out10;
      return len;
    }
    public static Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> Deserialize(Dafny.ISequence<byte> bs) {
      return Std.JSON.ZeroCopy.Deserializer.API.__default.OfBytes(bs);
    }
  }
} // end of namespace Std.JSON.ZeroCopy.API
namespace Std.JSON.ZeroCopy {

} // end of namespace Std.JSON.ZeroCopy
namespace Std.JSON.API {

  public partial class __default {
    public static Std.Wrappers._IResult<Dafny.ISequence<byte>, Std.JSON.Errors._ISerializationError> Serialize(Std.JSON.Values._IJSON js) {
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _785_valueOrError0 = Std.JSON.Serializer.__default.JSON(js);
      if ((_785_valueOrError0).IsFailure()) {
        return (_785_valueOrError0).PropagateFailure<Dafny.ISequence<byte>>();
      } else {
        Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _786_js = (_785_valueOrError0).Extract();
        return Std.JSON.ZeroCopy.API.__default.Serialize(_786_js);
      }
    }
    public static Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> SerializeAlloc(Std.JSON.Values._IJSON js)
    {
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> bs = Std.Wrappers.Result<byte[], Std.JSON.Errors._ISerializationError>.Default(new byte[0]);
      Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _787_js;
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _788_valueOrError0 = Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError>.Default(Std.JSON.Grammar.Structural<Std.JSON.Grammar._IValue>.Default(Std.JSON.Grammar.Value.Default()));
      _788_valueOrError0 = Std.JSON.Serializer.__default.JSON(js);
      if ((_788_valueOrError0).IsFailure()) {
        bs = (_788_valueOrError0).PropagateFailure<byte[]>();
        return bs;
      }
      _787_js = (_788_valueOrError0).Extract();
      Std.Wrappers._IResult<byte[], Std.JSON.Errors._ISerializationError> _out11;
      _out11 = Std.JSON.ZeroCopy.API.__default.SerializeAlloc(_787_js);
      bs = _out11;
      return bs;
    }
    public static Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> SerializeInto(Std.JSON.Values._IJSON js, byte[] bs)
    {
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> len = Std.Wrappers.Result<uint, Std.JSON.Errors._ISerializationError>.Default(0);
      Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _789_js;
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError> _790_valueOrError0 = Std.Wrappers.Result<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._ISerializationError>.Default(Std.JSON.Grammar.Structural<Std.JSON.Grammar._IValue>.Default(Std.JSON.Grammar.Value.Default()));
      _790_valueOrError0 = Std.JSON.Serializer.__default.JSON(js);
      if ((_790_valueOrError0).IsFailure()) {
        len = (_790_valueOrError0).PropagateFailure<uint>();
        return len;
      }
      _789_js = (_790_valueOrError0).Extract();
      Std.Wrappers._IResult<uint, Std.JSON.Errors._ISerializationError> _out12;
      _out12 = Std.JSON.ZeroCopy.API.__default.SerializeInto(_789_js, bs);
      len = _out12;
      return len;
    }
    public static Std.Wrappers._IResult<Std.JSON.Values._IJSON, Std.JSON.Errors._IDeserializationError> Deserialize(Dafny.ISequence<byte> bs) {
      Std.Wrappers._IResult<Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue>, Std.JSON.Errors._IDeserializationError> _791_valueOrError0 = Std.JSON.ZeroCopy.API.__default.Deserialize(bs);
      if ((_791_valueOrError0).IsFailure()) {
        return (_791_valueOrError0).PropagateFailure<Std.JSON.Values._IJSON>();
      } else {
        Std.JSON.Grammar._IStructural<Std.JSON.Grammar._IValue> _792_js = (_791_valueOrError0).Extract();
        return Std.JSON.Deserializer.__default.JSON(_792_js);
      }
    }
  }
} // end of namespace Std.JSON.API
namespace Std.JSON {

} // end of namespace Std.JSON
namespace Std {

} // end of namespace Std
namespace _module {

} // end of namespace _module
